{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN based on Steinmetz `spks` dataset and code from [nma](https://deeplearning.neuromatch.io/projects/Neuroscience/neuro_seq_to_seq.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# For DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n"
     ]
    }
   ],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataset files in the datasets folder\n",
    "import os, requests\n",
    "\n",
    "fname = []\n",
    "ds = \"../datasets\"\n",
    "\n",
    "for j in range(3):\n",
    "  fname.append('steinmetz_part%d.npz'%j)\n",
    "url = [\"https://osf.io/agvxh/download\"]\n",
    "url.append(\"https://osf.io/uv3mw/download\")\n",
    "url.append(\"https://osf.io/ehmw2/download\")\n",
    "\n",
    "for j in range(len(url)):\n",
    "  if not os.path.isfile(\"/\".join([ds, fname[j]])):\n",
    "    try:\n",
    "      r = requests.get(url[j])\n",
    "    except requests.ConnectionError:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      if r.status_code != requests.codes.ok:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "      else:\n",
    "        with open(\"/\".join([ds, fname[j]]), \"wb\") as fid:\n",
    "          fid.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "alldat = np.array([])\n",
    "for j in range(len(fname)):\n",
    "  alldat = np.hstack((alldat,\n",
    "                      np.load(\"/\".join([ds, 'steinmetz_part%d.npz'%j]),\n",
    "                              allow_pickle=True)['dat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset `spks` from recording 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select dataset spks from recording 11\n",
    "dat = alldat[11]\n",
    "dt = dat['bin_size']  # binning at 10 ms\n",
    "NT = dat['spks'].shape[-1]\n",
    "\n",
    "# data are neurons X trials x time samples, but transpose to time samples X trials X neurons\n",
    "X = dat['spks'].T\n",
    "\n",
    "# response is -1, 0, 1 so expand to hot encoding for logistic regression\n",
    "y_raw = dat['response']\n",
    "y = np.vstack(([(y_raw == -1) * 1], [y_raw == 0], [y_raw == 1])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, ncomp, NN1, NN2, bidi=True):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    # play with some of the options in the RNN!\n",
    "    self.rnn = nn.RNN(NN1, ncomp, num_layers = 1, dropout = 0,\n",
    "                      bidirectional = bidi, nonlinearity = 'tanh')\n",
    "    self.fc = nn.Linear(ncomp, NN2)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    y = self.rnn(x)[0]\n",
    "\n",
    "    if self.rnn.bidirectional:\n",
    "      # if the rnn is bidirectional, it concatenates the activations from the forward and backward pass\n",
    "      # we want to add them instead, so as to enforce the latents to match between the forward and backward pass\n",
    "      q = (y[:, :, :ncomp] + y[:, :, ncomp:])/2\n",
    "    else:\n",
    "      q = y\n",
    "\n",
    "    # the softplus function is just like a relu but it's smoothed out so we can't predict 0\n",
    "    # if we predict 0 and there was a spike, that's an instant Inf in the Poisson log-likelihood which leads to failure\n",
    "    z = F.softplus(self.fc(q), 10)\n",
    "\n",
    "    return z, q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the RNN: setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the trial data into two populations: training and testing\n",
    "trials = X.shape[1]\n",
    "train = test = int(trials / 2)\n",
    "Xtrain = torch.from_numpy(X[:, :train, :]).to(device).float()\n",
    "Xtest = torch.from_numpy(X[:, test:, :]).to(device).float()\n",
    "\n",
    "NN1 = Xtrain.shape[1]\n",
    "NN2 = Xtest.shape[1]\n",
    "\n",
    "# 10 ms bin\n",
    "ncomp = int(dt * 1000)\n",
    "\n",
    "# we initialize the neural network\n",
    "net = Net(ncomp, NN1, NN2, bidi = True).to(device)\n",
    "\n",
    "# special thing:  we initialize the biases of the last layer in the neural network\n",
    "# we set them as the mean firing rates of the neurons.\n",
    "# this should make the initial predictions close to the mean, because the latents don't contribute much\n",
    "net.fc.bias.data[:] = Xtrain.mean((0, 2))\n",
    "\n",
    "# we set up the optimizer. Adjust the learning rate if the training is slow or if it explodes.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 170, 698])\n",
      "torch.Size([250, 170, 698])\n",
      "170\n",
      "170\n",
      "torch.Size([170])\n"
     ]
    }
   ],
   "source": [
    "# define the Poisson log-likelihood loss\n",
    "def Poisson_loss(lam, spk):\n",
    "  return lam - spk * torch.log(lam)\n",
    "\n",
    "niter = ncomp * NN2\n",
    "\n",
    "for k in range(niter):\n",
    "  # the network outputs the single-neuron prediction and the latents\n",
    "  z, y = net(Xtest)\n",
    "\n",
    "  # our log-likelihood cost\n",
    "  cost = Poisson_loss(z, xTrain).mean()\n",
    "\n",
    "  # train the network as usual\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if k % 100 == 0:\n",
    "    print(f'iteration {k}, cost {cost.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
