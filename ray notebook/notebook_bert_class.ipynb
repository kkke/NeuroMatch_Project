{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT classification of mouse wheel movement based on Steinmetz `spks` dataset and code from [nma](https://deeplearning.neuromatch.io/projects/Neuroscience/neuro_seq_to_seq.html)\n",
    "\n",
    "__Note__: You must restart the notebook for training each time you rerun a model. This appears to be an issue of the previous model remaining on the GPU after training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, io, models, ops, transforms, utils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set device (GPU or CPU). Execute `set_device()`\n",
    "\n",
    "# Inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  \"\"\"\n",
    "  Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# For DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n",
      "GPU is enabled in this notebook.\n"
     ]
    }
   ],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataset files in the datasets folder\n",
    "import os, requests\n",
    "\n",
    "fname = []\n",
    "ds = \"../datasets\"\n",
    "\n",
    "for j in range(3):\n",
    "  fname.append('steinmetz_part%d.npz'%j)\n",
    "url = [\"https://osf.io/agvxh/download\"]\n",
    "url.append(\"https://osf.io/uv3mw/download\")\n",
    "url.append(\"https://osf.io/ehmw2/download\")\n",
    "\n",
    "for j in range(len(url)):\n",
    "  if not os.path.isfile(\"/\".join([ds, fname[j]])):\n",
    "    try:\n",
    "      r = requests.get(url[j])\n",
    "    except requests.ConnectionError:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      if r.status_code != requests.codes.ok:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "      else:\n",
    "        with open(\"/\".join([ds, fname[j]]), \"wb\") as fid:\n",
    "          fid.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "alldat = np.array([])\n",
    "for j in range(len(fname)):\n",
    "  alldat = np.hstack((alldat,\n",
    "                      np.load(\"/\".join([ds, 'steinmetz_part%d.npz'%j]),\n",
    "                              allow_pickle=True)['dat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select recording 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select recording 11\n",
    "dat = alldat[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Format dataset\n",
    "The depth of the network in a time or data series is given by `hidden_size`. In the case of the `spks` dataset this is 250 because one trial lasts for this many samples. These are the 250 sequenced datapoints related to the same mouse event trial from the same probe sensor size of 698 neurons over a time period of 2500ms. Further mouse trials are added in sequence in the dataset. This dataset is then 698 neurons wide with 250 datapoints and 340 trials in length, before being split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data are neurons X trials x time samples, but permute to trials X time samples X neurons\n",
    "x = torch.tensor(dat['spks']).permute(1,2,0)\n",
    "\n",
    "# slice off the first 50 and last 100 neurons in the time series data\n",
    "x = x[:,50:150,:]\n",
    "\n",
    "# response is -1, 0, 1, but convert to one hot where 2 takes the place of -1 to satisfy torch one hot\n",
    "dat['response'][dat['response'] == -1] = 2 \n",
    "y = torch.as_tensor(dat['response']).long()\n",
    "y = F.one_hot(y)\n",
    "\n",
    "# split into train (70%), validation(20%) and test(10%) sets using batch size of 34\n",
    "n_trials = int(x.shape[0])\n",
    "ntr = int(n_trials * 7 / 10)\n",
    "nv = int(n_trials * 2 / 10) + ntr\n",
    "\n",
    "X_train = x[:ntr, :, :].to(device).float()\n",
    "X_val = x[ntr:nv, :, :].to(device).float()\n",
    "X_test = x[nv:, :, :].to(device).float()\n",
    "\n",
    "y_train = y[:ntr].to(device).float()\n",
    "y_val = y[ntr:nv].to(device).float()\n",
    "y_test = y[nv:].to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0])\n",
      "torch.Size([340, 100, 698])\n",
      "torch.Size([340, 3])\n",
      "torch.Size([238, 100, 698])\n",
      "torch.Size([238, 3])\n",
      "torch.Size([68, 100, 698])\n",
      "torch.Size([68, 3])\n",
      "torch.Size([34, 100, 698])\n",
      "torch.Size([34, 3])\n"
     ]
    }
   ],
   "source": [
    "print(y[0])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Visualise data from one trial\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.imshow(x[0,:,:].T, cmap='gray_r', vmax = 3, vmin=0, aspect='auto')\n",
    "plt.xticks([0, 20, 40, 60, 80], [500, 700, 900, 1100, 1300]) \n",
    "plt.xlabel('Time (ms) with 10ms bins')\n",
    "plt.ylabel('Cell #')\n",
    "plt.colorbar(orientation='vertical', label='# Spikes in 10ms time bin')\n",
    "plt.title('Example trial')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size of 34 used to match number of trials\n",
    "# this will likely change to the number of trials in a different recording\n",
    "batch_size = 34\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create DataLoader for validation data\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create DataLoader for test data\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden RNN stages, inputs and outputs\n",
    "hidden_size = x.shape[1]\n",
    "input_size = x.shape[2]\n",
    "output_size = y_train.shape[1]\n",
    "num_layers = 1\n",
    "learning_rate = 0.003\n",
    "num_heads = 4\n",
    "dropout = 0.1\n",
    "number_of_epochs = 10000\n",
    "BERT_number_of_epochs = 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "698\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(hidden_size)\n",
    "print(input_size)\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define BERT\n",
    "BERT still requires time sequence data, here represented by `hidden_size`, which is currently 100 in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt 3.5 generated code\n",
    "# Define the Transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(hidden_size, num_heads, dim_feedforward=hidden_size * 4, dropout=dropout),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # Convert (batch_size, seq_len, hidden_size) to (seq_len, batch_size, hidden_size)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # Convert back to (batch_size, seq_len, hidden_size)\n",
    "        x = self.fc(x[:, -1, :])  # Use only the last time step's output for classification\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train BERT: setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt 3.5 generated code (well, it actually forgot to do this)\n",
    "model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads, dropout).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train BERT and plot training and validation losses and accuracies\n",
    "Note that the trained model seems to remain resident on the graphics card unless we restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [3/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [4/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5/10000], Training Loss: 0.58843385, Training Accuracy: 0.9622\n",
      "Epoch [5/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6/10000], Validation Loss: 0.97819844, Validation Accuracy: 0.5735\n",
      "Epoch [7/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [7/10000], Validation Loss: 0.94859505, Validation Accuracy: 0.6029\n",
      "Epoch [8/10000], Training Loss: 0.58505224, Training Accuracy: 0.9664\n",
      "Epoch [8/10000], Validation Loss: 0.94850406, Validation Accuracy: 0.6029\n",
      "Epoch [9/10000], Training Loss: 0.56825167, Training Accuracy: 0.9832\n",
      "Epoch [9/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [10/10000], Training Loss: 0.58913765, Training Accuracy: 0.9622\n",
      "Epoch [10/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [11/10000], Training Loss: 0.59346180, Training Accuracy: 0.9580\n",
      "Epoch [11/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [12/10000], Training Loss: 0.58090891, Training Accuracy: 0.9706\n",
      "Epoch [12/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [13/10000], Training Loss: 0.59684667, Training Accuracy: 0.9538\n",
      "Epoch [13/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [14/10000], Training Loss: 0.57660028, Training Accuracy: 0.9748\n",
      "Epoch [14/10000], Validation Loss: 0.93870571, Validation Accuracy: 0.6176\n",
      "Epoch [15/10000], Training Loss: 0.58085685, Training Accuracy: 0.9706\n",
      "Epoch [15/10000], Validation Loss: 0.94684473, Validation Accuracy: 0.6029\n",
      "Epoch [16/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [16/10000], Validation Loss: 0.94848409, Validation Accuracy: 0.6029\n",
      "Epoch [17/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [17/10000], Validation Loss: 0.94833604, Validation Accuracy: 0.6029\n",
      "Epoch [18/10000], Training Loss: 0.58926026, Training Accuracy: 0.9622\n",
      "Epoch [18/10000], Validation Loss: 0.94803607, Validation Accuracy: 0.6029\n",
      "Epoch [19/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [19/10000], Validation Loss: 0.94774440, Validation Accuracy: 0.6029\n",
      "Epoch [20/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [20/10000], Validation Loss: 0.94754884, Validation Accuracy: 0.6029\n",
      "Epoch [21/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [21/10000], Validation Loss: 0.94743899, Validation Accuracy: 0.6029\n",
      "Epoch [22/10000], Training Loss: 0.58456740, Training Accuracy: 0.9664\n",
      "Epoch [22/10000], Validation Loss: 0.94767466, Validation Accuracy: 0.6029\n",
      "Epoch [23/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [23/10000], Validation Loss: 0.96311790, Validation Accuracy: 0.5882\n",
      "Epoch [24/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [24/10000], Validation Loss: 0.97655636, Validation Accuracy: 0.5735\n",
      "Epoch [25/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [25/10000], Validation Loss: 0.97774825, Validation Accuracy: 0.5735\n",
      "Epoch [26/10000], Training Loss: 0.58084256, Training Accuracy: 0.9706\n",
      "Epoch [26/10000], Validation Loss: 0.97778726, Validation Accuracy: 0.5735\n",
      "Epoch [27/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [27/10000], Validation Loss: 0.97778684, Validation Accuracy: 0.5735\n",
      "Epoch [28/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [28/10000], Validation Loss: 0.97778344, Validation Accuracy: 0.5735\n",
      "Epoch [29/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [29/10000], Validation Loss: 0.97778124, Validation Accuracy: 0.5735\n",
      "Epoch [30/10000], Training Loss: 0.56405000, Training Accuracy: 0.9874\n",
      "Epoch [30/10000], Validation Loss: 0.97778001, Validation Accuracy: 0.5735\n",
      "Epoch [31/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [31/10000], Validation Loss: 0.97777942, Validation Accuracy: 0.5735\n",
      "Epoch [32/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [32/10000], Validation Loss: 0.97777918, Validation Accuracy: 0.5735\n",
      "Epoch [33/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [33/10000], Validation Loss: 0.97777900, Validation Accuracy: 0.5735\n",
      "Epoch [34/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [34/10000], Validation Loss: 0.97777894, Validation Accuracy: 0.5735\n",
      "Epoch [35/10000], Training Loss: 0.58085677, Training Accuracy: 0.9706\n",
      "Epoch [35/10000], Validation Loss: 0.97777891, Validation Accuracy: 0.5735\n",
      "Epoch [36/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [36/10000], Validation Loss: 0.97777885, Validation Accuracy: 0.5735\n",
      "Epoch [37/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [37/10000], Validation Loss: 0.97777885, Validation Accuracy: 0.5735\n",
      "Epoch [38/10000], Training Loss: 0.58503120, Training Accuracy: 0.9664\n",
      "Epoch [38/10000], Validation Loss: 0.97765788, Validation Accuracy: 0.5735\n",
      "Epoch [39/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [39/10000], Validation Loss: 0.97683743, Validation Accuracy: 0.5735\n",
      "Epoch [40/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [40/10000], Validation Loss: 0.97579986, Validation Accuracy: 0.5735\n",
      "Epoch [41/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [41/10000], Validation Loss: 0.97501731, Validation Accuracy: 0.5735\n",
      "Epoch [42/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [42/10000], Validation Loss: 0.97455513, Validation Accuracy: 0.5735\n",
      "Epoch [43/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [43/10000], Validation Loss: 0.97431079, Validation Accuracy: 0.5735\n",
      "Epoch [44/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [44/10000], Validation Loss: 0.97418812, Validation Accuracy: 0.5735\n",
      "Epoch [45/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [45/10000], Validation Loss: 0.97412777, Validation Accuracy: 0.5735\n",
      "Epoch [46/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [46/10000], Validation Loss: 0.97409859, Validation Accuracy: 0.5735\n",
      "Epoch [47/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [47/10000], Validation Loss: 0.97408456, Validation Accuracy: 0.5735\n",
      "Epoch [48/10000], Training Loss: 0.57652031, Training Accuracy: 0.9748\n",
      "Epoch [48/10000], Validation Loss: 0.94870618, Validation Accuracy: 0.6029\n",
      "Epoch [49/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [49/10000], Validation Loss: 0.94850415, Validation Accuracy: 0.6029\n",
      "Epoch [50/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [50/10000], Validation Loss: 0.94371492, Validation Accuracy: 0.6029\n",
      "Epoch [51/10000], Training Loss: 0.59359216, Training Accuracy: 0.9580\n",
      "Epoch [51/10000], Validation Loss: 0.93303129, Validation Accuracy: 0.6176\n",
      "Epoch [52/10000], Training Loss: 0.57665474, Training Accuracy: 0.9748\n",
      "Epoch [52/10000], Validation Loss: 0.91780895, Validation Accuracy: 0.6176\n",
      "Epoch [53/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [53/10000], Validation Loss: 0.90617165, Validation Accuracy: 0.6471\n",
      "Epoch [54/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [54/10000], Validation Loss: 0.90524319, Validation Accuracy: 0.6471\n",
      "Epoch [55/10000], Training Loss: 0.59346183, Training Accuracy: 0.9580\n",
      "Epoch [55/10000], Validation Loss: 0.90498349, Validation Accuracy: 0.6471\n",
      "Epoch [56/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [56/10000], Validation Loss: 0.90488771, Validation Accuracy: 0.6471\n",
      "Epoch [57/10000], Training Loss: 0.57105721, Training Accuracy: 0.9790\n",
      "Epoch [57/10000], Validation Loss: 0.94826829, Validation Accuracy: 0.6029\n",
      "Epoch [58/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [58/10000], Validation Loss: 0.95788610, Validation Accuracy: 0.5882\n",
      "Epoch [59/10000], Training Loss: 0.57244102, Training Accuracy: 0.9790\n",
      "Epoch [59/10000], Validation Loss: 0.94853184, Validation Accuracy: 0.6029\n",
      "Epoch [60/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [60/10000], Validation Loss: 0.94856554, Validation Accuracy: 0.6029\n",
      "Epoch [61/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [61/10000], Validation Loss: 0.94860357, Validation Accuracy: 0.6029\n",
      "Epoch [62/10000], Training Loss: 0.58084221, Training Accuracy: 0.9706\n",
      "Epoch [62/10000], Validation Loss: 0.94868264, Validation Accuracy: 0.6029\n",
      "Epoch [63/10000], Training Loss: 0.58459445, Training Accuracy: 0.9664\n",
      "Epoch [63/10000], Validation Loss: 0.94893155, Validation Accuracy: 0.6029\n",
      "Epoch [64/10000], Training Loss: 0.59970413, Training Accuracy: 0.9496\n",
      "Epoch [64/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [65/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [65/10000], Validation Loss: 0.94850641, Validation Accuracy: 0.6029\n",
      "Epoch [66/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [66/10000], Validation Loss: 0.94855893, Validation Accuracy: 0.6029\n",
      "Epoch [67/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [67/10000], Validation Loss: 0.96343076, Validation Accuracy: 0.5882\n",
      "Epoch [68/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [68/10000], Validation Loss: 0.96366617, Validation Accuracy: 0.5882\n",
      "Epoch [69/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [69/10000], Validation Loss: 0.96383753, Validation Accuracy: 0.5882\n",
      "Epoch [70/10000], Training Loss: 0.57245452, Training Accuracy: 0.9790\n",
      "Epoch [70/10000], Validation Loss: 0.96393254, Validation Accuracy: 0.5882\n",
      "Epoch [71/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [71/10000], Validation Loss: 0.96397877, Validation Accuracy: 0.5882\n",
      "Epoch [72/10000], Training Loss: 0.58086273, Training Accuracy: 0.9706\n",
      "Epoch [72/10000], Validation Loss: 0.96395978, Validation Accuracy: 0.5882\n",
      "Epoch [73/10000], Training Loss: 0.56825047, Training Accuracy: 0.9832\n",
      "Epoch [73/10000], Validation Loss: 0.96379918, Validation Accuracy: 0.5882\n",
      "Epoch [74/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [74/10000], Validation Loss: 0.96373507, Validation Accuracy: 0.5882\n",
      "Epoch [75/10000], Training Loss: 0.58507080, Training Accuracy: 0.9664\n",
      "Epoch [75/10000], Validation Loss: 0.96342480, Validation Accuracy: 0.5882\n",
      "Epoch [76/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [76/10000], Validation Loss: 0.96329856, Validation Accuracy: 0.5882\n",
      "Epoch [77/10000], Training Loss: 0.57654844, Training Accuracy: 0.9748\n",
      "Epoch [77/10000], Validation Loss: 0.96330523, Validation Accuracy: 0.5882\n",
      "Epoch [78/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [78/10000], Validation Loss: 0.96332306, Validation Accuracy: 0.5882\n",
      "Epoch [79/10000], Training Loss: 0.57245207, Training Accuracy: 0.9790\n",
      "Epoch [79/10000], Validation Loss: 0.96332845, Validation Accuracy: 0.5882\n",
      "Epoch [80/10000], Training Loss: 0.57665484, Training Accuracy: 0.9748\n",
      "Epoch [80/10000], Validation Loss: 0.96333012, Validation Accuracy: 0.5882\n",
      "Epoch [81/10000], Training Loss: 0.57752383, Training Accuracy: 0.9748\n",
      "Epoch [81/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [82/10000], Training Loss: 0.59766333, Training Accuracy: 0.9538\n",
      "Epoch [82/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [83/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [83/10000], Validation Loss: 0.94848937, Validation Accuracy: 0.6029\n",
      "Epoch [84/10000], Training Loss: 0.58085669, Training Accuracy: 0.9706\n",
      "Epoch [84/10000], Validation Loss: 0.93379954, Validation Accuracy: 0.6176\n",
      "Epoch [85/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [85/10000], Validation Loss: 0.93374175, Validation Accuracy: 0.6176\n",
      "Epoch [86/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [86/10000], Validation Loss: 0.93342385, Validation Accuracy: 0.6176\n",
      "Epoch [87/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [87/10000], Validation Loss: 0.93300501, Validation Accuracy: 0.6176\n",
      "Epoch [88/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [88/10000], Validation Loss: 0.93275633, Validation Accuracy: 0.6176\n",
      "Epoch [89/10000], Training Loss: 0.57665499, Training Accuracy: 0.9748\n",
      "Epoch [89/10000], Validation Loss: 0.93263847, Validation Accuracy: 0.6176\n",
      "Epoch [90/10000], Training Loss: 0.57665970, Training Accuracy: 0.9748\n",
      "Epoch [90/10000], Validation Loss: 0.93262678, Validation Accuracy: 0.6176\n",
      "Epoch [91/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [91/10000], Validation Loss: 0.93262663, Validation Accuracy: 0.6176\n",
      "Epoch [92/10000], Training Loss: 0.59357469, Training Accuracy: 0.9580\n",
      "Epoch [92/10000], Validation Loss: 0.93347237, Validation Accuracy: 0.6176\n",
      "Epoch [93/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [93/10000], Validation Loss: 0.93379286, Validation Accuracy: 0.6176\n",
      "Epoch [94/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [94/10000], Validation Loss: 0.93343160, Validation Accuracy: 0.6176\n",
      "Epoch [95/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [95/10000], Validation Loss: 0.93051934, Validation Accuracy: 0.6176\n",
      "Epoch [96/10000], Training Loss: 0.58086000, Training Accuracy: 0.9706\n",
      "Epoch [96/10000], Validation Loss: 0.92723265, Validation Accuracy: 0.6176\n",
      "Epoch [97/10000], Training Loss: 0.58085723, Training Accuracy: 0.9706\n",
      "Epoch [97/10000], Validation Loss: 0.92517337, Validation Accuracy: 0.6176\n",
      "Epoch [98/10000], Training Loss: 0.57662543, Training Accuracy: 0.9748\n",
      "Epoch [98/10000], Validation Loss: 0.92326054, Validation Accuracy: 0.6324\n",
      "Epoch [99/10000], Training Loss: 0.58926541, Training Accuracy: 0.9622\n",
      "Epoch [99/10000], Validation Loss: 0.92210802, Validation Accuracy: 0.6324\n",
      "Epoch [100/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [100/10000], Validation Loss: 0.92168754, Validation Accuracy: 0.6324\n",
      "Epoch [101/10000], Training Loss: 0.58505848, Training Accuracy: 0.9664\n",
      "Epoch [101/10000], Validation Loss: 0.92150477, Validation Accuracy: 0.6324\n",
      "Epoch [102/10000], Training Loss: 0.57245429, Training Accuracy: 0.9790\n",
      "Epoch [102/10000], Validation Loss: 0.92141023, Validation Accuracy: 0.6324\n",
      "Epoch [103/10000], Training Loss: 0.57245338, Training Accuracy: 0.9790\n",
      "Epoch [103/10000], Validation Loss: 0.92130843, Validation Accuracy: 0.6324\n",
      "Epoch [104/10000], Training Loss: 0.60205629, Training Accuracy: 0.9496\n",
      "Epoch [104/10000], Validation Loss: 0.91908637, Validation Accuracy: 0.6324\n",
      "Epoch [105/10000], Training Loss: 0.58569217, Training Accuracy: 0.9664\n",
      "Epoch [105/10000], Validation Loss: 0.91908962, Validation Accuracy: 0.6324\n",
      "Epoch [106/10000], Training Loss: 0.57245221, Training Accuracy: 0.9790\n",
      "Epoch [106/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [107/10000], Training Loss: 0.58505838, Training Accuracy: 0.9664\n",
      "Epoch [107/10000], Validation Loss: 0.90438628, Validation Accuracy: 0.6471\n",
      "Epoch [108/10000], Training Loss: 0.58923078, Training Accuracy: 0.9622\n",
      "Epoch [108/10000], Validation Loss: 0.88966301, Validation Accuracy: 0.6618\n",
      "Epoch [109/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [109/10000], Validation Loss: 0.87506393, Validation Accuracy: 0.6765\n",
      "Epoch [110/10000], Training Loss: 0.58909317, Training Accuracy: 0.9622\n",
      "Epoch [110/10000], Validation Loss: 0.87651974, Validation Accuracy: 0.6765\n",
      "Epoch [111/10000], Training Loss: 0.58926024, Training Accuracy: 0.9622\n",
      "Epoch [111/10000], Validation Loss: 0.88964942, Validation Accuracy: 0.6618\n",
      "Epoch [112/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [112/10000], Validation Loss: 0.88967919, Validation Accuracy: 0.6618\n",
      "Epoch [113/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [113/10000], Validation Loss: 0.88967997, Validation Accuracy: 0.6618\n",
      "Epoch [114/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [114/10000], Validation Loss: 0.88968003, Validation Accuracy: 0.6618\n",
      "Epoch [115/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [115/10000], Validation Loss: 0.88968006, Validation Accuracy: 0.6618\n",
      "Epoch [116/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [116/10000], Validation Loss: 0.88968006, Validation Accuracy: 0.6618\n",
      "Epoch [117/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [117/10000], Validation Loss: 0.88968000, Validation Accuracy: 0.6618\n",
      "Epoch [118/10000], Training Loss: 0.57508228, Training Accuracy: 0.9748\n",
      "Epoch [118/10000], Validation Loss: 0.91907439, Validation Accuracy: 0.6324\n",
      "Epoch [119/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [119/10000], Validation Loss: 0.91614953, Validation Accuracy: 0.6324\n",
      "Epoch [120/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [120/10000], Validation Loss: 0.90736124, Validation Accuracy: 0.6471\n",
      "Epoch [121/10000], Training Loss: 0.57222274, Training Accuracy: 0.9790\n",
      "Epoch [121/10000], Validation Loss: 0.91579235, Validation Accuracy: 0.6324\n",
      "Epoch [122/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [122/10000], Validation Loss: 0.91795412, Validation Accuracy: 0.6324\n",
      "Epoch [123/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [123/10000], Validation Loss: 0.91843799, Validation Accuracy: 0.6324\n",
      "Epoch [124/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [124/10000], Validation Loss: 0.91860348, Validation Accuracy: 0.6324\n",
      "Epoch [125/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [125/10000], Validation Loss: 0.91897702, Validation Accuracy: 0.6324\n",
      "Epoch [126/10000], Training Loss: 0.56825167, Training Accuracy: 0.9832\n",
      "Epoch [126/10000], Validation Loss: 0.92020607, Validation Accuracy: 0.6324\n",
      "Epoch [127/10000], Training Loss: 0.57661269, Training Accuracy: 0.9748\n",
      "Epoch [127/10000], Validation Loss: 0.91293734, Validation Accuracy: 0.6324\n",
      "Epoch [128/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [128/10000], Validation Loss: 0.90439889, Validation Accuracy: 0.6471\n",
      "Epoch [129/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [129/10000], Validation Loss: 0.90438646, Validation Accuracy: 0.6471\n",
      "Epoch [130/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [130/10000], Validation Loss: 0.90438619, Validation Accuracy: 0.6471\n",
      "Epoch [131/10000], Training Loss: 0.56850726, Training Accuracy: 0.9832\n",
      "Epoch [131/10000], Validation Loss: 0.91058767, Validation Accuracy: 0.6324\n",
      "Epoch [132/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [132/10000], Validation Loss: 0.92701718, Validation Accuracy: 0.6176\n",
      "Epoch [133/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [133/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [134/10000], Training Loss: 0.59346071, Training Accuracy: 0.9580\n",
      "Epoch [134/10000], Validation Loss: 0.93379775, Validation Accuracy: 0.6176\n",
      "Epoch [135/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [135/10000], Validation Loss: 0.93379751, Validation Accuracy: 0.6176\n",
      "Epoch [136/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [136/10000], Validation Loss: 0.93379736, Validation Accuracy: 0.6176\n",
      "Epoch [137/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [137/10000], Validation Loss: 0.93379724, Validation Accuracy: 0.6176\n",
      "Epoch [138/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [138/10000], Validation Loss: 0.93379718, Validation Accuracy: 0.6176\n",
      "Epoch [139/10000], Training Loss: 0.59594302, Training Accuracy: 0.9538\n",
      "Epoch [139/10000], Validation Loss: 0.88963345, Validation Accuracy: 0.6618\n",
      "Epoch [140/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [140/10000], Validation Loss: 0.93379825, Validation Accuracy: 0.6176\n",
      "Epoch [141/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [141/10000], Validation Loss: 0.93380612, Validation Accuracy: 0.6176\n",
      "Epoch [142/10000], Training Loss: 0.62282636, Training Accuracy: 0.9286\n",
      "Epoch [142/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [143/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [143/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [144/10000], Training Loss: 0.60194210, Training Accuracy: 0.9496\n",
      "Epoch [144/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [145/10000], Training Loss: 0.61867638, Training Accuracy: 0.9328\n",
      "Epoch [145/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [146/10000], Training Loss: 0.63127694, Training Accuracy: 0.9202\n",
      "Epoch [146/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [147/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [147/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [148/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [148/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [149/10000], Training Loss: 0.61452385, Training Accuracy: 0.9370\n",
      "Epoch [149/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [150/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [150/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [151/10000], Training Loss: 0.61025820, Training Accuracy: 0.9412\n",
      "Epoch [151/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [152/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [152/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [153/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [153/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [154/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [154/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [155/10000], Training Loss: 0.62691894, Training Accuracy: 0.9244\n",
      "Epoch [155/10000], Validation Loss: 0.92990720, Validation Accuracy: 0.6176\n",
      "Epoch [156/10000], Training Loss: 0.58925175, Training Accuracy: 0.9622\n",
      "Epoch [156/10000], Validation Loss: 0.94849887, Validation Accuracy: 0.6029\n",
      "Epoch [157/10000], Training Loss: 0.59766306, Training Accuracy: 0.9538\n",
      "Epoch [157/10000], Validation Loss: 0.93379283, Validation Accuracy: 0.6176\n",
      "Epoch [158/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [158/10000], Validation Loss: 0.91910225, Validation Accuracy: 0.6324\n",
      "Epoch [159/10000], Training Loss: 0.58925847, Training Accuracy: 0.9622\n",
      "Epoch [159/10000], Validation Loss: 0.91909209, Validation Accuracy: 0.6324\n",
      "Epoch [160/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [160/10000], Validation Loss: 0.91909203, Validation Accuracy: 0.6324\n",
      "Epoch [161/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [161/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [162/10000], Training Loss: 0.58927705, Training Accuracy: 0.9622\n",
      "Epoch [162/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [163/10000], Training Loss: 0.58948074, Training Accuracy: 0.9622\n",
      "Epoch [163/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [164/10000], Training Loss: 0.58085682, Training Accuracy: 0.9706\n",
      "Epoch [164/10000], Validation Loss: 0.94846913, Validation Accuracy: 0.6029\n",
      "Epoch [165/10000], Training Loss: 0.59011697, Training Accuracy: 0.9622\n",
      "Epoch [165/10000], Validation Loss: 0.96318689, Validation Accuracy: 0.5882\n",
      "Epoch [166/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [166/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [167/10000], Training Loss: 0.58505847, Training Accuracy: 0.9664\n",
      "Epoch [167/10000], Validation Loss: 0.95490041, Validation Accuracy: 0.5882\n",
      "Epoch [168/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [168/10000], Validation Loss: 0.94833601, Validation Accuracy: 0.6029\n",
      "Epoch [169/10000], Training Loss: 0.58373901, Training Accuracy: 0.9664\n",
      "Epoch [169/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [170/10000], Training Loss: 0.58505480, Training Accuracy: 0.9664\n",
      "Epoch [170/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [171/10000], Training Loss: 0.58585346, Training Accuracy: 0.9664\n",
      "Epoch [171/10000], Validation Loss: 0.99239591, Validation Accuracy: 0.5588\n",
      "Epoch [172/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [172/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [173/10000], Training Loss: 0.62283985, Training Accuracy: 0.9286\n",
      "Epoch [173/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [174/10000], Training Loss: 0.63131128, Training Accuracy: 0.9202\n",
      "Epoch [174/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [175/10000], Training Loss: 0.65225187, Training Accuracy: 0.8992\n",
      "Epoch [175/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [176/10000], Training Loss: 0.63693827, Training Accuracy: 0.9160\n",
      "Epoch [176/10000], Validation Loss: 0.99287170, Validation Accuracy: 0.5588\n",
      "Epoch [177/10000], Training Loss: 0.61830556, Training Accuracy: 0.9328\n",
      "Epoch [177/10000], Validation Loss: 1.02202806, Validation Accuracy: 0.5294\n",
      "Epoch [178/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [178/10000], Validation Loss: 1.03672725, Validation Accuracy: 0.5147\n",
      "Epoch [179/10000], Training Loss: 0.61867214, Training Accuracy: 0.9328\n",
      "Epoch [179/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [180/10000], Training Loss: 0.60601929, Training Accuracy: 0.9454\n",
      "Epoch [180/10000], Validation Loss: 1.03666696, Validation Accuracy: 0.5147\n",
      "Epoch [181/10000], Training Loss: 0.60202084, Training Accuracy: 0.9496\n",
      "Epoch [181/10000], Validation Loss: 1.04056132, Validation Accuracy: 0.5147\n",
      "Epoch [182/10000], Training Loss: 0.60186490, Training Accuracy: 0.9496\n",
      "Epoch [182/10000], Validation Loss: 1.03690195, Validation Accuracy: 0.5147\n",
      "Epoch [183/10000], Training Loss: 0.63682495, Training Accuracy: 0.9160\n",
      "Epoch [183/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [184/10000], Training Loss: 0.63106474, Training Accuracy: 0.9202\n",
      "Epoch [184/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [185/10000], Training Loss: 0.60606683, Training Accuracy: 0.9454\n",
      "Epoch [185/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [186/10000], Training Loss: 0.61449366, Training Accuracy: 0.9370\n",
      "Epoch [186/10000], Validation Loss: 1.09553719, Validation Accuracy: 0.4559\n",
      "Epoch [187/10000], Training Loss: 0.60605730, Training Accuracy: 0.9454\n",
      "Epoch [187/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [188/10000], Training Loss: 0.61026842, Training Accuracy: 0.9412\n",
      "Epoch [188/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [189/10000], Training Loss: 0.60965831, Training Accuracy: 0.9412\n",
      "Epoch [189/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [190/10000], Training Loss: 0.61867189, Training Accuracy: 0.9328\n",
      "Epoch [190/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [191/10000], Training Loss: 0.60186518, Training Accuracy: 0.9496\n",
      "Epoch [191/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [192/10000], Training Loss: 0.63127480, Training Accuracy: 0.9202\n",
      "Epoch [192/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [193/10000], Training Loss: 0.61447069, Training Accuracy: 0.9370\n",
      "Epoch [193/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [194/10000], Training Loss: 0.62474695, Training Accuracy: 0.9244\n",
      "Epoch [194/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [195/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [195/10000], Validation Loss: 1.09042788, Validation Accuracy: 0.4559\n",
      "Epoch [196/10000], Training Loss: 0.63589443, Training Accuracy: 0.9160\n",
      "Epoch [196/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [197/10000], Training Loss: 0.61867189, Training Accuracy: 0.9328\n",
      "Epoch [197/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [198/10000], Training Loss: 0.61446792, Training Accuracy: 0.9370\n",
      "Epoch [198/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [199/10000], Training Loss: 0.62707460, Training Accuracy: 0.9244\n",
      "Epoch [199/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [200/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [200/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [201/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [201/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [202/10000], Training Loss: 0.62458032, Training Accuracy: 0.9244\n",
      "Epoch [202/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [203/10000], Training Loss: 0.61206726, Training Accuracy: 0.9370\n",
      "Epoch [203/10000], Validation Loss: 1.00700977, Validation Accuracy: 0.5441\n",
      "Epoch [204/10000], Training Loss: 0.60673067, Training Accuracy: 0.9454\n",
      "Epoch [204/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [205/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [205/10000], Validation Loss: 0.94850010, Validation Accuracy: 0.6029\n",
      "Epoch [206/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [206/10000], Validation Loss: 0.96321616, Validation Accuracy: 0.5882\n",
      "Epoch [207/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [207/10000], Validation Loss: 0.97778118, Validation Accuracy: 0.5735\n",
      "Epoch [208/10000], Training Loss: 0.59766343, Training Accuracy: 0.9538\n",
      "Epoch [208/10000], Validation Loss: 0.97706434, Validation Accuracy: 0.5735\n",
      "Epoch [209/10000], Training Loss: 0.59344992, Training Accuracy: 0.9580\n",
      "Epoch [209/10000], Validation Loss: 0.97790843, Validation Accuracy: 0.5735\n",
      "Epoch [210/10000], Training Loss: 0.59346544, Training Accuracy: 0.9580\n",
      "Epoch [210/10000], Validation Loss: 0.97790885, Validation Accuracy: 0.5735\n",
      "Epoch [211/10000], Training Loss: 0.59032670, Training Accuracy: 0.9622\n",
      "Epoch [211/10000], Validation Loss: 0.97784406, Validation Accuracy: 0.5735\n",
      "Epoch [212/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [212/10000], Validation Loss: 1.03659528, Validation Accuracy: 0.5147\n",
      "Epoch [213/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [213/10000], Validation Loss: 1.05141896, Validation Accuracy: 0.5000\n",
      "Epoch [214/10000], Training Loss: 0.59766335, Training Accuracy: 0.9538\n",
      "Epoch [214/10000], Validation Loss: 1.05448568, Validation Accuracy: 0.5000\n",
      "Epoch [215/10000], Training Loss: 0.60187255, Training Accuracy: 0.9496\n",
      "Epoch [215/10000], Validation Loss: 1.08065981, Validation Accuracy: 0.4706\n",
      "Epoch [216/10000], Training Loss: 0.61447262, Training Accuracy: 0.9370\n",
      "Epoch [216/10000], Validation Loss: 1.09555435, Validation Accuracy: 0.4559\n",
      "Epoch [217/10000], Training Loss: 0.61426510, Training Accuracy: 0.9370\n",
      "Epoch [217/10000], Validation Loss: 1.09537804, Validation Accuracy: 0.4559\n",
      "Epoch [218/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [218/10000], Validation Loss: 1.07176536, Validation Accuracy: 0.4853\n",
      "Epoch [219/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [219/10000], Validation Loss: 1.06447178, Validation Accuracy: 0.4853\n",
      "Epoch [220/10000], Training Loss: 0.60183786, Training Accuracy: 0.9496\n",
      "Epoch [220/10000], Validation Loss: 1.06723595, Validation Accuracy: 0.4853\n",
      "Epoch [221/10000], Training Loss: 0.58510290, Training Accuracy: 0.9664\n",
      "Epoch [221/10000], Validation Loss: 1.08093089, Validation Accuracy: 0.4706\n",
      "Epoch [222/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [222/10000], Validation Loss: 1.07887113, Validation Accuracy: 0.4706\n",
      "Epoch [223/10000], Training Loss: 0.60606695, Training Accuracy: 0.9454\n",
      "Epoch [223/10000], Validation Loss: 1.07410747, Validation Accuracy: 0.4706\n",
      "Epoch [224/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [224/10000], Validation Loss: 1.08578998, Validation Accuracy: 0.4706\n",
      "Epoch [225/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [225/10000], Validation Loss: 1.08427709, Validation Accuracy: 0.4706\n",
      "Epoch [226/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [226/10000], Validation Loss: 1.08337367, Validation Accuracy: 0.4706\n",
      "Epoch [227/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [227/10000], Validation Loss: 1.08284032, Validation Accuracy: 0.4706\n",
      "Epoch [228/10000], Training Loss: 0.58214292, Training Accuracy: 0.9706\n",
      "Epoch [228/10000], Validation Loss: 1.05152100, Validation Accuracy: 0.5000\n",
      "Epoch [229/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [229/10000], Validation Loss: 1.00732765, Validation Accuracy: 0.5441\n",
      "Epoch [230/10000], Training Loss: 0.61066533, Training Accuracy: 0.9412\n",
      "Epoch [230/10000], Validation Loss: 1.00732791, Validation Accuracy: 0.5441\n",
      "Epoch [231/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [231/10000], Validation Loss: 1.02161738, Validation Accuracy: 0.5294\n",
      "Epoch [232/10000], Training Loss: 0.60600124, Training Accuracy: 0.9454\n",
      "Epoch [232/10000], Validation Loss: 1.03673330, Validation Accuracy: 0.5147\n",
      "Epoch [233/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [233/10000], Validation Loss: 1.02203172, Validation Accuracy: 0.5294\n",
      "Epoch [234/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [234/10000], Validation Loss: 1.02203235, Validation Accuracy: 0.5294\n",
      "Epoch [235/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [235/10000], Validation Loss: 1.02203250, Validation Accuracy: 0.5294\n",
      "Epoch [236/10000], Training Loss: 0.58175389, Training Accuracy: 0.9706\n",
      "Epoch [236/10000], Validation Loss: 1.03644946, Validation Accuracy: 0.5147\n",
      "Epoch [237/10000], Training Loss: 0.59728342, Training Accuracy: 0.9538\n",
      "Epoch [237/10000], Validation Loss: 1.05154485, Validation Accuracy: 0.5000\n",
      "Epoch [238/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [238/10000], Validation Loss: 1.03592631, Validation Accuracy: 0.5147\n",
      "Epoch [239/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [239/10000], Validation Loss: 1.01170135, Validation Accuracy: 0.5441\n",
      "Epoch [240/10000], Training Loss: 0.60587930, Training Accuracy: 0.9454\n",
      "Epoch [240/10000], Validation Loss: 1.00732920, Validation Accuracy: 0.5441\n",
      "Epoch [241/10000], Training Loss: 0.62247814, Training Accuracy: 0.9286\n",
      "Epoch [241/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [242/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [242/10000], Validation Loss: 1.02202326, Validation Accuracy: 0.5294\n",
      "Epoch [243/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [243/10000], Validation Loss: 1.00166079, Validation Accuracy: 0.5441\n",
      "Epoch [244/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [244/10000], Validation Loss: 0.99267367, Validation Accuracy: 0.5588\n",
      "Epoch [245/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [245/10000], Validation Loss: 0.99262422, Validation Accuracy: 0.5588\n",
      "Epoch [246/10000], Training Loss: 0.60606417, Training Accuracy: 0.9454\n",
      "Epoch [246/10000], Validation Loss: 0.99262223, Validation Accuracy: 0.5588\n",
      "Epoch [247/10000], Training Loss: 0.59766312, Training Accuracy: 0.9538\n",
      "Epoch [247/10000], Validation Loss: 0.99262187, Validation Accuracy: 0.5588\n",
      "Epoch [248/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [248/10000], Validation Loss: 0.99262175, Validation Accuracy: 0.5588\n",
      "Epoch [249/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [249/10000], Validation Loss: 0.99262172, Validation Accuracy: 0.5588\n",
      "Epoch [250/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [250/10000], Validation Loss: 0.99262169, Validation Accuracy: 0.5588\n",
      "Epoch [251/10000], Training Loss: 0.60603992, Training Accuracy: 0.9454\n",
      "Epoch [251/10000], Validation Loss: 0.99262205, Validation Accuracy: 0.5588\n",
      "Epoch [252/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [252/10000], Validation Loss: 0.99262232, Validation Accuracy: 0.5588\n",
      "Epoch [253/10000], Training Loss: 0.60195219, Training Accuracy: 0.9496\n",
      "Epoch [253/10000], Validation Loss: 0.99325359, Validation Accuracy: 0.5588\n",
      "Epoch [254/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [254/10000], Validation Loss: 0.99974683, Validation Accuracy: 0.5441\n",
      "Epoch [255/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [255/10000], Validation Loss: 1.00440648, Validation Accuracy: 0.5441\n",
      "Epoch [256/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [256/10000], Validation Loss: 1.00570023, Validation Accuracy: 0.5441\n",
      "Epoch [257/10000], Training Loss: 0.59766563, Training Accuracy: 0.9538\n",
      "Epoch [257/10000], Validation Loss: 1.00611153, Validation Accuracy: 0.5441\n",
      "Epoch [258/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [258/10000], Validation Loss: 1.00625482, Validation Accuracy: 0.5441\n",
      "Epoch [259/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [259/10000], Validation Loss: 1.00631779, Validation Accuracy: 0.5441\n",
      "Epoch [260/10000], Training Loss: 0.58382813, Training Accuracy: 0.9664\n",
      "Epoch [260/10000], Validation Loss: 1.00732747, Validation Accuracy: 0.5441\n",
      "Epoch [261/10000], Training Loss: 0.60599754, Training Accuracy: 0.9454\n",
      "Epoch [261/10000], Validation Loss: 1.06538504, Validation Accuracy: 0.4853\n",
      "Epoch [262/10000], Training Loss: 0.61447499, Training Accuracy: 0.9370\n",
      "Epoch [262/10000], Validation Loss: 1.05216321, Validation Accuracy: 0.5000\n",
      "Epoch [263/10000], Training Loss: 0.59346134, Training Accuracy: 0.9580\n",
      "Epoch [263/10000], Validation Loss: 1.06615117, Validation Accuracy: 0.4853\n",
      "Epoch [264/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [264/10000], Validation Loss: 1.08085936, Validation Accuracy: 0.4706\n",
      "Epoch [265/10000], Training Loss: 0.59766056, Training Accuracy: 0.9538\n",
      "Epoch [265/10000], Validation Loss: 1.08086360, Validation Accuracy: 0.4706\n",
      "Epoch [266/10000], Training Loss: 0.58931940, Training Accuracy: 0.9622\n",
      "Epoch [266/10000], Validation Loss: 1.08086556, Validation Accuracy: 0.4706\n",
      "Epoch [267/10000], Training Loss: 0.59766379, Training Accuracy: 0.9538\n",
      "Epoch [267/10000], Validation Loss: 1.08086139, Validation Accuracy: 0.4706\n",
      "Epoch [268/10000], Training Loss: 0.61446809, Training Accuracy: 0.9370\n",
      "Epoch [268/10000], Validation Loss: 1.08086008, Validation Accuracy: 0.4706\n",
      "Epoch [269/10000], Training Loss: 0.59765329, Training Accuracy: 0.9538\n",
      "Epoch [269/10000], Validation Loss: 1.08085889, Validation Accuracy: 0.4706\n",
      "Epoch [270/10000], Training Loss: 0.61447165, Training Accuracy: 0.9370\n",
      "Epoch [270/10000], Validation Loss: 1.08085805, Validation Accuracy: 0.4706\n",
      "Epoch [271/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [271/10000], Validation Loss: 1.08085752, Validation Accuracy: 0.4706\n",
      "Epoch [272/10000], Training Loss: 0.60244450, Training Accuracy: 0.9496\n",
      "Epoch [272/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [273/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [273/10000], Validation Loss: 1.06605661, Validation Accuracy: 0.4853\n",
      "Epoch [274/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [274/10000], Validation Loss: 1.06614965, Validation Accuracy: 0.4853\n",
      "Epoch [275/10000], Training Loss: 0.60189416, Training Accuracy: 0.9496\n",
      "Epoch [275/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [276/10000], Training Loss: 0.58940795, Training Accuracy: 0.9622\n",
      "Epoch [276/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [277/10000], Training Loss: 0.58926014, Training Accuracy: 0.9622\n",
      "Epoch [277/10000], Validation Loss: 1.06614798, Validation Accuracy: 0.4853\n",
      "Epoch [278/10000], Training Loss: 0.59450850, Training Accuracy: 0.9580\n",
      "Epoch [278/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [279/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [279/10000], Validation Loss: 1.06615925, Validation Accuracy: 0.4853\n",
      "Epoch [280/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [280/10000], Validation Loss: 1.06608260, Validation Accuracy: 0.4853\n",
      "Epoch [281/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [281/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [282/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [282/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [283/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [283/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [284/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [284/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [285/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [285/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [286/10000], Training Loss: 0.58505816, Training Accuracy: 0.9664\n",
      "Epoch [286/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [287/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [287/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [288/10000], Training Loss: 0.59036137, Training Accuracy: 0.9622\n",
      "Epoch [288/10000], Validation Loss: 1.06614214, Validation Accuracy: 0.4853\n",
      "Epoch [289/10000], Training Loss: 0.58505818, Training Accuracy: 0.9664\n",
      "Epoch [289/10000], Validation Loss: 1.05173111, Validation Accuracy: 0.5000\n",
      "Epoch [290/10000], Training Loss: 0.57665513, Training Accuracy: 0.9748\n",
      "Epoch [290/10000], Validation Loss: 1.02203426, Validation Accuracy: 0.5294\n",
      "Epoch [291/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [291/10000], Validation Loss: 1.02203324, Validation Accuracy: 0.5294\n",
      "Epoch [292/10000], Training Loss: 0.58925923, Training Accuracy: 0.9622\n",
      "Epoch [292/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [293/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [293/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [294/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [294/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [295/10000], Training Loss: 0.56405996, Training Accuracy: 0.9874\n",
      "Epoch [295/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [296/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [296/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [297/10000], Training Loss: 0.57665779, Training Accuracy: 0.9748\n",
      "Epoch [297/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [298/10000], Training Loss: 0.57980402, Training Accuracy: 0.9706\n",
      "Epoch [298/10000], Validation Loss: 1.03673911, Validation Accuracy: 0.5147\n",
      "Epoch [299/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [299/10000], Validation Loss: 1.02203336, Validation Accuracy: 0.5294\n",
      "Epoch [300/10000], Training Loss: 0.57256212, Training Accuracy: 0.9790\n",
      "Epoch [300/10000], Validation Loss: 1.02203235, Validation Accuracy: 0.5294\n",
      "Epoch [301/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [301/10000], Validation Loss: 1.02203295, Validation Accuracy: 0.5294\n",
      "Epoch [302/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [302/10000], Validation Loss: 1.02203307, Validation Accuracy: 0.5294\n",
      "Epoch [303/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [303/10000], Validation Loss: 1.02203307, Validation Accuracy: 0.5294\n",
      "Epoch [304/10000], Training Loss: 0.57665516, Training Accuracy: 0.9748\n",
      "Epoch [304/10000], Validation Loss: 1.02203307, Validation Accuracy: 0.5294\n",
      "Epoch [305/10000], Training Loss: 0.58473163, Training Accuracy: 0.9664\n",
      "Epoch [305/10000], Validation Loss: 1.02191976, Validation Accuracy: 0.5294\n",
      "Epoch [306/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [306/10000], Validation Loss: 1.00732780, Validation Accuracy: 0.5441\n",
      "Epoch [307/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [307/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [308/10000], Training Loss: 0.58925947, Training Accuracy: 0.9622\n",
      "Epoch [308/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [309/10000], Training Loss: 0.59359231, Training Accuracy: 0.9580\n",
      "Epoch [309/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [310/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [310/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [311/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [311/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [312/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [312/10000], Validation Loss: 1.00732684, Validation Accuracy: 0.5441\n",
      "Epoch [313/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [313/10000], Validation Loss: 1.00732434, Validation Accuracy: 0.5441\n",
      "Epoch [314/10000], Training Loss: 0.58925903, Training Accuracy: 0.9622\n",
      "Epoch [314/10000], Validation Loss: 1.00731978, Validation Accuracy: 0.5441\n",
      "Epoch [315/10000], Training Loss: 0.59146955, Training Accuracy: 0.9580\n",
      "Epoch [315/10000], Validation Loss: 0.97733024, Validation Accuracy: 0.5735\n",
      "Epoch [316/10000], Training Loss: 0.57334406, Training Accuracy: 0.9790\n",
      "Epoch [316/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [317/10000], Training Loss: 0.60467998, Training Accuracy: 0.9454\n",
      "Epoch [317/10000], Validation Loss: 0.91905984, Validation Accuracy: 0.6324\n",
      "Epoch [318/10000], Training Loss: 0.59346170, Training Accuracy: 0.9580\n",
      "Epoch [318/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [319/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [319/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [320/10000], Training Loss: 0.57642181, Training Accuracy: 0.9748\n",
      "Epoch [320/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [321/10000], Training Loss: 0.57665454, Training Accuracy: 0.9748\n",
      "Epoch [321/10000], Validation Loss: 0.94849539, Validation Accuracy: 0.6029\n",
      "Epoch [322/10000], Training Loss: 0.57665506, Training Accuracy: 0.9748\n",
      "Epoch [322/10000], Validation Loss: 0.96303797, Validation Accuracy: 0.5882\n",
      "Epoch [323/10000], Training Loss: 0.58501207, Training Accuracy: 0.9664\n",
      "Epoch [323/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [324/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [324/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [325/10000], Training Loss: 0.59132460, Training Accuracy: 0.9580\n",
      "Epoch [325/10000], Validation Loss: 0.96186644, Validation Accuracy: 0.5882\n",
      "Epoch [326/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [326/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [327/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [327/10000], Validation Loss: 0.96322396, Validation Accuracy: 0.5882\n",
      "Epoch [328/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [328/10000], Validation Loss: 0.96495464, Validation Accuracy: 0.5882\n",
      "Epoch [329/10000], Training Loss: 0.58926010, Training Accuracy: 0.9622\n",
      "Epoch [329/10000], Validation Loss: 0.97180685, Validation Accuracy: 0.5735\n",
      "Epoch [330/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [330/10000], Validation Loss: 0.97509819, Validation Accuracy: 0.5735\n",
      "Epoch [331/10000], Training Loss: 0.59766339, Training Accuracy: 0.9538\n",
      "Epoch [331/10000], Validation Loss: 0.97609517, Validation Accuracy: 0.5735\n",
      "Epoch [332/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [332/10000], Validation Loss: 0.97645202, Validation Accuracy: 0.5735\n",
      "Epoch [333/10000], Training Loss: 0.58053043, Training Accuracy: 0.9706\n",
      "Epoch [333/10000], Validation Loss: 0.96237791, Validation Accuracy: 0.5882\n",
      "Epoch [334/10000], Training Loss: 0.58852522, Training Accuracy: 0.9622\n",
      "Epoch [334/10000], Validation Loss: 0.99258295, Validation Accuracy: 0.5588\n",
      "Epoch [335/10000], Training Loss: 0.58426034, Training Accuracy: 0.9664\n",
      "Epoch [335/10000], Validation Loss: 0.94806793, Validation Accuracy: 0.6029\n",
      "Epoch [336/10000], Training Loss: 0.59761961, Training Accuracy: 0.9538\n",
      "Epoch [336/10000], Validation Loss: 0.93254563, Validation Accuracy: 0.6176\n",
      "Epoch [337/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [337/10000], Validation Loss: 0.94609565, Validation Accuracy: 0.6029\n",
      "Epoch [338/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [338/10000], Validation Loss: 0.95758942, Validation Accuracy: 0.5882\n",
      "Epoch [339/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [339/10000], Validation Loss: 0.95531332, Validation Accuracy: 0.5882\n",
      "Epoch [340/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [340/10000], Validation Loss: 0.95420465, Validation Accuracy: 0.6029\n",
      "Epoch [341/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [341/10000], Validation Loss: 0.95369253, Validation Accuracy: 0.6029\n",
      "Epoch [342/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [342/10000], Validation Loss: 0.95345354, Validation Accuracy: 0.6029\n",
      "Epoch [343/10000], Training Loss: 0.62991695, Training Accuracy: 0.9202\n",
      "Epoch [343/10000], Validation Loss: 0.97791421, Validation Accuracy: 0.5735\n",
      "Epoch [344/10000], Training Loss: 0.62287295, Training Accuracy: 0.9286\n",
      "Epoch [344/10000], Validation Loss: 1.01344031, Validation Accuracy: 0.5294\n",
      "Epoch [345/10000], Training Loss: 0.61447617, Training Accuracy: 0.9370\n",
      "Epoch [345/10000], Validation Loss: 1.02204570, Validation Accuracy: 0.5294\n",
      "Epoch [346/10000], Training Loss: 0.62460073, Training Accuracy: 0.9244\n",
      "Epoch [346/10000], Validation Loss: 1.01507691, Validation Accuracy: 0.5294\n",
      "Epoch [347/10000], Training Loss: 0.61914209, Training Accuracy: 0.9328\n",
      "Epoch [347/10000], Validation Loss: 0.99261144, Validation Accuracy: 0.5588\n",
      "Epoch [348/10000], Training Loss: 0.60565496, Training Accuracy: 0.9454\n",
      "Epoch [348/10000], Validation Loss: 0.97784650, Validation Accuracy: 0.5735\n",
      "Epoch [349/10000], Training Loss: 0.61442580, Training Accuracy: 0.9370\n",
      "Epoch [349/10000], Validation Loss: 0.94850370, Validation Accuracy: 0.6029\n",
      "Epoch [350/10000], Training Loss: 0.61272680, Training Accuracy: 0.9370\n",
      "Epoch [350/10000], Validation Loss: 0.96273923, Validation Accuracy: 0.5882\n",
      "Epoch [351/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [351/10000], Validation Loss: 1.00427788, Validation Accuracy: 0.5441\n",
      "Epoch [352/10000], Training Loss: 0.59766431, Training Accuracy: 0.9538\n",
      "Epoch [352/10000], Validation Loss: 1.00732714, Validation Accuracy: 0.5441\n",
      "Epoch [353/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [353/10000], Validation Loss: 1.00728709, Validation Accuracy: 0.5441\n",
      "Epoch [354/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [354/10000], Validation Loss: 1.00596857, Validation Accuracy: 0.5441\n",
      "Epoch [355/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [355/10000], Validation Loss: 1.00699329, Validation Accuracy: 0.5441\n",
      "Epoch [356/10000], Training Loss: 0.61942706, Training Accuracy: 0.9328\n",
      "Epoch [356/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [357/10000], Training Loss: 0.59362490, Training Accuracy: 0.9580\n",
      "Epoch [357/10000], Validation Loss: 1.03673887, Validation Accuracy: 0.5147\n",
      "Epoch [358/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [358/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [359/10000], Training Loss: 0.61027686, Training Accuracy: 0.9412\n",
      "Epoch [359/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [360/10000], Training Loss: 0.59766385, Training Accuracy: 0.9538\n",
      "Epoch [360/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [361/10000], Training Loss: 0.59759426, Training Accuracy: 0.9538\n",
      "Epoch [361/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [362/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [362/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [363/10000], Training Loss: 0.59347149, Training Accuracy: 0.9580\n",
      "Epoch [363/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [364/10000], Training Loss: 0.61448182, Training Accuracy: 0.9370\n",
      "Epoch [364/10000], Validation Loss: 1.02203304, Validation Accuracy: 0.5294\n",
      "Epoch [365/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [365/10000], Validation Loss: 1.02199817, Validation Accuracy: 0.5294\n",
      "Epoch [366/10000], Training Loss: 0.60606268, Training Accuracy: 0.9454\n",
      "Epoch [366/10000], Validation Loss: 1.01995134, Validation Accuracy: 0.5294\n",
      "Epoch [367/10000], Training Loss: 0.59332837, Training Accuracy: 0.9580\n",
      "Epoch [367/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [368/10000], Training Loss: 0.62689232, Training Accuracy: 0.9244\n",
      "Epoch [368/10000], Validation Loss: 1.02203280, Validation Accuracy: 0.5294\n",
      "Epoch [369/10000], Training Loss: 0.61049604, Training Accuracy: 0.9412\n",
      "Epoch [369/10000], Validation Loss: 1.00732541, Validation Accuracy: 0.5441\n",
      "Epoch [370/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [370/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [371/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [371/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [372/10000], Training Loss: 0.58688151, Training Accuracy: 0.9622\n",
      "Epoch [372/10000], Validation Loss: 1.00692689, Validation Accuracy: 0.5441\n",
      "Epoch [373/10000], Training Loss: 0.58505846, Training Accuracy: 0.9664\n",
      "Epoch [373/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [374/10000], Training Loss: 0.60178847, Training Accuracy: 0.9496\n",
      "Epoch [374/10000], Validation Loss: 1.08028209, Validation Accuracy: 0.4706\n",
      "Epoch [375/10000], Training Loss: 0.61023447, Training Accuracy: 0.9412\n",
      "Epoch [375/10000], Validation Loss: 1.06615132, Validation Accuracy: 0.4853\n",
      "Epoch [376/10000], Training Loss: 0.59343834, Training Accuracy: 0.9580\n",
      "Epoch [376/10000], Validation Loss: 1.06615037, Validation Accuracy: 0.4853\n",
      "Epoch [377/10000], Training Loss: 0.59766331, Training Accuracy: 0.9538\n",
      "Epoch [377/10000], Validation Loss: 1.06614912, Validation Accuracy: 0.4853\n",
      "Epoch [378/10000], Training Loss: 0.59342515, Training Accuracy: 0.9580\n",
      "Epoch [378/10000], Validation Loss: 1.06614971, Validation Accuracy: 0.4853\n",
      "Epoch [379/10000], Training Loss: 0.59127073, Training Accuracy: 0.9580\n",
      "Epoch [379/10000], Validation Loss: 1.05144852, Validation Accuracy: 0.5000\n",
      "Epoch [380/10000], Training Loss: 0.59346152, Training Accuracy: 0.9580\n",
      "Epoch [380/10000], Validation Loss: 1.01775816, Validation Accuracy: 0.5294\n",
      "Epoch [381/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [381/10000], Validation Loss: 1.02201247, Validation Accuracy: 0.5294\n",
      "Epoch [382/10000], Training Loss: 0.60588732, Training Accuracy: 0.9454\n",
      "Epoch [382/10000], Validation Loss: 1.03673786, Validation Accuracy: 0.5147\n",
      "Epoch [383/10000], Training Loss: 0.61265656, Training Accuracy: 0.9370\n",
      "Epoch [383/10000], Validation Loss: 1.05054206, Validation Accuracy: 0.5000\n",
      "Epoch [384/10000], Training Loss: 0.63950651, Training Accuracy: 0.9118\n",
      "Epoch [384/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [385/10000], Training Loss: 0.61866508, Training Accuracy: 0.9328\n",
      "Epoch [385/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [386/10000], Training Loss: 0.61867608, Training Accuracy: 0.9328\n",
      "Epoch [386/10000], Validation Loss: 1.02203172, Validation Accuracy: 0.5294\n",
      "Epoch [387/10000], Training Loss: 0.61867128, Training Accuracy: 0.9328\n",
      "Epoch [387/10000], Validation Loss: 1.02200288, Validation Accuracy: 0.5294\n",
      "Epoch [388/10000], Training Loss: 0.61446998, Training Accuracy: 0.9370\n",
      "Epoch [388/10000], Validation Loss: 1.02187103, Validation Accuracy: 0.5294\n",
      "Epoch [389/10000], Training Loss: 0.63967890, Training Accuracy: 0.9118\n",
      "Epoch [389/10000], Validation Loss: 1.02147865, Validation Accuracy: 0.5294\n",
      "Epoch [390/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [390/10000], Validation Loss: 1.00726101, Validation Accuracy: 0.5441\n",
      "Epoch [391/10000], Training Loss: 0.61769904, Training Accuracy: 0.9328\n",
      "Epoch [391/10000], Validation Loss: 0.99241078, Validation Accuracy: 0.5588\n",
      "Epoch [392/10000], Training Loss: 0.62711321, Training Accuracy: 0.9244\n",
      "Epoch [392/10000], Validation Loss: 0.97749063, Validation Accuracy: 0.5735\n",
      "Epoch [393/10000], Training Loss: 0.63958758, Training Accuracy: 0.9118\n",
      "Epoch [393/10000], Validation Loss: 0.97184014, Validation Accuracy: 0.5735\n",
      "Epoch [394/10000], Training Loss: 0.61867172, Training Accuracy: 0.9328\n",
      "Epoch [394/10000], Validation Loss: 0.96315974, Validation Accuracy: 0.5882\n",
      "Epoch [395/10000], Training Loss: 0.62282045, Training Accuracy: 0.9286\n",
      "Epoch [395/10000], Validation Loss: 0.96382374, Validation Accuracy: 0.5882\n",
      "Epoch [396/10000], Training Loss: 0.64361108, Training Accuracy: 0.9076\n",
      "Epoch [396/10000], Validation Loss: 0.97791001, Validation Accuracy: 0.5735\n",
      "Epoch [397/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [397/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [398/10000], Training Loss: 0.61828509, Training Accuracy: 0.9328\n",
      "Epoch [398/10000], Validation Loss: 0.96320957, Validation Accuracy: 0.5882\n",
      "Epoch [399/10000], Training Loss: 0.62708810, Training Accuracy: 0.9244\n",
      "Epoch [399/10000], Validation Loss: 0.96320772, Validation Accuracy: 0.5882\n",
      "Epoch [400/10000], Training Loss: 0.63538753, Training Accuracy: 0.9160\n",
      "Epoch [400/10000], Validation Loss: 0.97790790, Validation Accuracy: 0.5735\n",
      "Epoch [401/10000], Training Loss: 0.63965393, Training Accuracy: 0.9118\n",
      "Epoch [401/10000], Validation Loss: 0.97667664, Validation Accuracy: 0.5735\n",
      "Epoch [402/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [402/10000], Validation Loss: 0.96225017, Validation Accuracy: 0.5882\n",
      "Epoch [403/10000], Training Loss: 0.61867174, Training Accuracy: 0.9328\n",
      "Epoch [403/10000], Validation Loss: 0.97739428, Validation Accuracy: 0.5735\n",
      "Epoch [404/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [404/10000], Validation Loss: 0.96284312, Validation Accuracy: 0.5882\n",
      "Epoch [405/10000], Training Loss: 0.63544690, Training Accuracy: 0.9160\n",
      "Epoch [405/10000], Validation Loss: 0.96262577, Validation Accuracy: 0.5882\n",
      "Epoch [406/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [406/10000], Validation Loss: 0.96187118, Validation Accuracy: 0.5882\n",
      "Epoch [407/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [407/10000], Validation Loss: 0.96190971, Validation Accuracy: 0.5882\n",
      "Epoch [408/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [408/10000], Validation Loss: 0.96205860, Validation Accuracy: 0.5882\n",
      "Epoch [409/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [409/10000], Validation Loss: 0.96214741, Validation Accuracy: 0.5882\n",
      "Epoch [410/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [410/10000], Validation Loss: 0.96219230, Validation Accuracy: 0.5882\n",
      "Epoch [411/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [411/10000], Validation Loss: 0.96221417, Validation Accuracy: 0.5882\n",
      "Epoch [412/10000], Training Loss: 0.62261259, Training Accuracy: 0.9286\n",
      "Epoch [412/10000], Validation Loss: 0.96198028, Validation Accuracy: 0.5882\n",
      "Epoch [413/10000], Training Loss: 0.63568154, Training Accuracy: 0.9160\n",
      "Epoch [413/10000], Validation Loss: 0.97743288, Validation Accuracy: 0.5735\n",
      "Epoch [414/10000], Training Loss: 0.63246481, Training Accuracy: 0.9202\n",
      "Epoch [414/10000], Validation Loss: 0.97677708, Validation Accuracy: 0.5735\n",
      "Epoch [415/10000], Training Loss: 0.62685307, Training Accuracy: 0.9244\n",
      "Epoch [415/10000], Validation Loss: 0.99271882, Validation Accuracy: 0.5588\n",
      "Epoch [416/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [416/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [417/10000], Training Loss: 0.61866186, Training Accuracy: 0.9328\n",
      "Epoch [417/10000], Validation Loss: 0.99165511, Validation Accuracy: 0.5588\n",
      "Epoch [418/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [418/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [419/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [419/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [420/10000], Training Loss: 0.61626347, Training Accuracy: 0.9328\n",
      "Epoch [420/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [421/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [421/10000], Validation Loss: 1.02194864, Validation Accuracy: 0.5294\n",
      "Epoch [422/10000], Training Loss: 0.63681634, Training Accuracy: 0.9160\n",
      "Epoch [422/10000], Validation Loss: 1.00731918, Validation Accuracy: 0.5441\n",
      "Epoch [423/10000], Training Loss: 0.63207742, Training Accuracy: 0.9202\n",
      "Epoch [423/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [424/10000], Training Loss: 0.63040178, Training Accuracy: 0.9202\n",
      "Epoch [424/10000], Validation Loss: 0.97881430, Validation Accuracy: 0.5735\n",
      "Epoch [425/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [425/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [426/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [426/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [427/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [427/10000], Validation Loss: 0.99262065, Validation Accuracy: 0.5588\n",
      "Epoch [428/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [428/10000], Validation Loss: 0.99261934, Validation Accuracy: 0.5588\n",
      "Epoch [429/10000], Training Loss: 0.61867187, Training Accuracy: 0.9328\n",
      "Epoch [429/10000], Validation Loss: 0.99261805, Validation Accuracy: 0.5588\n",
      "Epoch [430/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [430/10000], Validation Loss: 0.99261722, Validation Accuracy: 0.5588\n",
      "Epoch [431/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [431/10000], Validation Loss: 0.99261671, Validation Accuracy: 0.5588\n",
      "Epoch [432/10000], Training Loss: 0.62287350, Training Accuracy: 0.9286\n",
      "Epoch [432/10000], Validation Loss: 0.99261642, Validation Accuracy: 0.5588\n",
      "Epoch [433/10000], Training Loss: 0.61751051, Training Accuracy: 0.9328\n",
      "Epoch [433/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [434/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [434/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [435/10000], Training Loss: 0.61025149, Training Accuracy: 0.9412\n",
      "Epoch [435/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [436/10000], Training Loss: 0.60604756, Training Accuracy: 0.9454\n",
      "Epoch [436/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [437/10000], Training Loss: 0.61447199, Training Accuracy: 0.9370\n",
      "Epoch [437/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [438/10000], Training Loss: 0.63130294, Training Accuracy: 0.9202\n",
      "Epoch [438/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [439/10000], Training Loss: 0.61457392, Training Accuracy: 0.9370\n",
      "Epoch [439/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [440/10000], Training Loss: 0.63547870, Training Accuracy: 0.9160\n",
      "Epoch [440/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [441/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [441/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [442/10000], Training Loss: 0.59766386, Training Accuracy: 0.9538\n",
      "Epoch [442/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [443/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [443/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [444/10000], Training Loss: 0.61026238, Training Accuracy: 0.9412\n",
      "Epoch [444/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [445/10000], Training Loss: 0.63441432, Training Accuracy: 0.9160\n",
      "Epoch [445/10000], Validation Loss: 0.97791591, Validation Accuracy: 0.5735\n",
      "Epoch [446/10000], Training Loss: 0.62287596, Training Accuracy: 0.9286\n",
      "Epoch [446/10000], Validation Loss: 0.97793680, Validation Accuracy: 0.5735\n",
      "Epoch [447/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [447/10000], Validation Loss: 0.99196219, Validation Accuracy: 0.5588\n",
      "Epoch [448/10000], Training Loss: 0.61922744, Training Accuracy: 0.9328\n",
      "Epoch [448/10000], Validation Loss: 1.00722337, Validation Accuracy: 0.5441\n",
      "Epoch [449/10000], Training Loss: 0.60896707, Training Accuracy: 0.9412\n",
      "Epoch [449/10000], Validation Loss: 1.02204421, Validation Accuracy: 0.5294\n",
      "Epoch [450/10000], Training Loss: 0.60606686, Training Accuracy: 0.9454\n",
      "Epoch [450/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [451/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [451/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [452/10000], Training Loss: 0.60187147, Training Accuracy: 0.9496\n",
      "Epoch [452/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [453/10000], Training Loss: 0.61055986, Training Accuracy: 0.9412\n",
      "Epoch [453/10000], Validation Loss: 1.05143672, Validation Accuracy: 0.5000\n",
      "Epoch [454/10000], Training Loss: 0.59719436, Training Accuracy: 0.9538\n",
      "Epoch [454/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [455/10000], Training Loss: 0.63062466, Training Accuracy: 0.9202\n",
      "Epoch [455/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [456/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [456/10000], Validation Loss: 1.05139929, Validation Accuracy: 0.5000\n",
      "Epoch [457/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [457/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [458/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [458/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [459/10000], Training Loss: 0.60602774, Training Accuracy: 0.9454\n",
      "Epoch [459/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [460/10000], Training Loss: 0.60185984, Training Accuracy: 0.9496\n",
      "Epoch [460/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [461/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [461/10000], Validation Loss: 1.03673890, Validation Accuracy: 0.5147\n",
      "Epoch [462/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [462/10000], Validation Loss: 1.03673884, Validation Accuracy: 0.5147\n",
      "Epoch [463/10000], Training Loss: 0.59784511, Training Accuracy: 0.9538\n",
      "Epoch [463/10000], Validation Loss: 1.03673723, Validation Accuracy: 0.5147\n",
      "Epoch [464/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [464/10000], Validation Loss: 1.03672192, Validation Accuracy: 0.5147\n",
      "Epoch [465/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [465/10000], Validation Loss: 1.03666911, Validation Accuracy: 0.5147\n",
      "Epoch [466/10000], Training Loss: 0.59752419, Training Accuracy: 0.9538\n",
      "Epoch [466/10000], Validation Loss: 1.03591380, Validation Accuracy: 0.5147\n",
      "Epoch [467/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [467/10000], Validation Loss: 1.02926740, Validation Accuracy: 0.5147\n",
      "Epoch [468/10000], Training Loss: 0.63118685, Training Accuracy: 0.9202\n",
      "Epoch [468/10000], Validation Loss: 1.02394196, Validation Accuracy: 0.5294\n",
      "Epoch [469/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [469/10000], Validation Loss: 1.02215633, Validation Accuracy: 0.5294\n",
      "Epoch [470/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [470/10000], Validation Loss: 1.02206442, Validation Accuracy: 0.5294\n",
      "Epoch [471/10000], Training Loss: 0.61026874, Training Accuracy: 0.9412\n",
      "Epoch [471/10000], Validation Loss: 1.02204904, Validation Accuracy: 0.5294\n",
      "Epoch [472/10000], Training Loss: 0.59324806, Training Accuracy: 0.9580\n",
      "Epoch [472/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [473/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [473/10000], Validation Loss: 1.02203193, Validation Accuracy: 0.5294\n",
      "Epoch [474/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [474/10000], Validation Loss: 1.02200422, Validation Accuracy: 0.5294\n",
      "Epoch [475/10000], Training Loss: 0.60186576, Training Accuracy: 0.9496\n",
      "Epoch [475/10000], Validation Loss: 1.02189597, Validation Accuracy: 0.5294\n",
      "Epoch [476/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [476/10000], Validation Loss: 1.02174410, Validation Accuracy: 0.5294\n",
      "Epoch [477/10000], Training Loss: 0.61023239, Training Accuracy: 0.9412\n",
      "Epoch [477/10000], Validation Loss: 1.02078030, Validation Accuracy: 0.5294\n",
      "Epoch [478/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [478/10000], Validation Loss: 1.01811573, Validation Accuracy: 0.5294\n",
      "Epoch [479/10000], Training Loss: 0.61026748, Training Accuracy: 0.9412\n",
      "Epoch [479/10000], Validation Loss: 1.01608047, Validation Accuracy: 0.5294\n",
      "Epoch [480/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [480/10000], Validation Loss: 1.01510212, Validation Accuracy: 0.5294\n",
      "Epoch [481/10000], Training Loss: 0.58085668, Training Accuracy: 0.9706\n",
      "Epoch [481/10000], Validation Loss: 1.01462498, Validation Accuracy: 0.5294\n",
      "Epoch [482/10000], Training Loss: 0.60606741, Training Accuracy: 0.9454\n",
      "Epoch [482/10000], Validation Loss: 1.01434132, Validation Accuracy: 0.5294\n",
      "Epoch [483/10000], Training Loss: 0.59223848, Training Accuracy: 0.9580\n",
      "Epoch [483/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [484/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [484/10000], Validation Loss: 1.00843516, Validation Accuracy: 0.5441\n",
      "Epoch [485/10000], Training Loss: 0.59769638, Training Accuracy: 0.9538\n",
      "Epoch [485/10000], Validation Loss: 0.99252671, Validation Accuracy: 0.5588\n",
      "Epoch [486/10000], Training Loss: 0.60605471, Training Accuracy: 0.9454\n",
      "Epoch [486/10000], Validation Loss: 0.98970464, Validation Accuracy: 0.5588\n",
      "Epoch [487/10000], Training Loss: 0.59780352, Training Accuracy: 0.9538\n",
      "Epoch [487/10000], Validation Loss: 0.98316887, Validation Accuracy: 0.5735\n",
      "Epoch [488/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [488/10000], Validation Loss: 0.98187459, Validation Accuracy: 0.5735\n",
      "Epoch [489/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [489/10000], Validation Loss: 0.98132762, Validation Accuracy: 0.5735\n",
      "Epoch [490/10000], Training Loss: 0.59759919, Training Accuracy: 0.9538\n",
      "Epoch [490/10000], Validation Loss: 0.99212432, Validation Accuracy: 0.5588\n",
      "Epoch [491/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [491/10000], Validation Loss: 0.99742496, Validation Accuracy: 0.5588\n",
      "Epoch [492/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [492/10000], Validation Loss: 1.00317144, Validation Accuracy: 0.5441\n",
      "Epoch [493/10000], Training Loss: 0.59825368, Training Accuracy: 0.9538\n",
      "Epoch [493/10000], Validation Loss: 1.02187699, Validation Accuracy: 0.5294\n",
      "Epoch [494/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [494/10000], Validation Loss: 1.01932538, Validation Accuracy: 0.5294\n",
      "Epoch [495/10000], Training Loss: 0.59766306, Training Accuracy: 0.9538\n",
      "Epoch [495/10000], Validation Loss: 1.01262730, Validation Accuracy: 0.5441\n",
      "Epoch [496/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [496/10000], Validation Loss: 1.01010689, Validation Accuracy: 0.5441\n",
      "Epoch [497/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [497/10000], Validation Loss: 1.01279467, Validation Accuracy: 0.5441\n",
      "Epoch [498/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [498/10000], Validation Loss: 1.01762906, Validation Accuracy: 0.5294\n",
      "Epoch [499/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [499/10000], Validation Loss: 1.01973546, Validation Accuracy: 0.5294\n",
      "Epoch [500/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [500/10000], Validation Loss: 1.02051005, Validation Accuracy: 0.5294\n",
      "Epoch [501/10000], Training Loss: 0.61013785, Training Accuracy: 0.9412\n",
      "Epoch [501/10000], Validation Loss: 1.01529965, Validation Accuracy: 0.5441\n",
      "Epoch [502/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [502/10000], Validation Loss: 1.01975790, Validation Accuracy: 0.5294\n",
      "Epoch [503/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [503/10000], Validation Loss: 1.02104849, Validation Accuracy: 0.5294\n",
      "Epoch [504/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [504/10000], Validation Loss: 1.02139127, Validation Accuracy: 0.5294\n",
      "Epoch [505/10000], Training Loss: 0.60198533, Training Accuracy: 0.9496\n",
      "Epoch [505/10000], Validation Loss: 1.03003973, Validation Accuracy: 0.5147\n",
      "Epoch [506/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [506/10000], Validation Loss: 1.02676487, Validation Accuracy: 0.5294\n",
      "Epoch [507/10000], Training Loss: 0.59766132, Training Accuracy: 0.9538\n",
      "Epoch [507/10000], Validation Loss: 1.02502772, Validation Accuracy: 0.5294\n",
      "Epoch [508/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [508/10000], Validation Loss: 1.02436230, Validation Accuracy: 0.5294\n",
      "Epoch [509/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [509/10000], Validation Loss: 1.02408892, Validation Accuracy: 0.5294\n",
      "Epoch [510/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [510/10000], Validation Loss: 1.02396768, Validation Accuracy: 0.5294\n",
      "Epoch [511/10000], Training Loss: 0.60185857, Training Accuracy: 0.9496\n",
      "Epoch [511/10000], Validation Loss: 1.02369434, Validation Accuracy: 0.5294\n",
      "Epoch [512/10000], Training Loss: 0.59346288, Training Accuracy: 0.9580\n",
      "Epoch [512/10000], Validation Loss: 1.02349597, Validation Accuracy: 0.5294\n",
      "Epoch [513/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [513/10000], Validation Loss: 1.02341047, Validation Accuracy: 0.5294\n",
      "Epoch [514/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [514/10000], Validation Loss: 1.02337104, Validation Accuracy: 0.5294\n",
      "Epoch [515/10000], Training Loss: 0.61044644, Training Accuracy: 0.9412\n",
      "Epoch [515/10000], Validation Loss: 1.00732848, Validation Accuracy: 0.5441\n",
      "Epoch [516/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [516/10000], Validation Loss: 0.99260107, Validation Accuracy: 0.5588\n",
      "Epoch [517/10000], Training Loss: 0.60069322, Training Accuracy: 0.9496\n",
      "Epoch [517/10000], Validation Loss: 1.00732774, Validation Accuracy: 0.5441\n",
      "Epoch [518/10000], Training Loss: 0.58938376, Training Accuracy: 0.9622\n",
      "Epoch [518/10000], Validation Loss: 1.02205512, Validation Accuracy: 0.5294\n",
      "Epoch [519/10000], Training Loss: 0.59798324, Training Accuracy: 0.9538\n",
      "Epoch [519/10000], Validation Loss: 1.04674542, Validation Accuracy: 0.5000\n",
      "Epoch [520/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [520/10000], Validation Loss: 1.03770885, Validation Accuracy: 0.5147\n",
      "Epoch [521/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [521/10000], Validation Loss: 1.03673846, Validation Accuracy: 0.5147\n",
      "Epoch [522/10000], Training Loss: 0.60557496, Training Accuracy: 0.9454\n",
      "Epoch [522/10000], Validation Loss: 1.04326510, Validation Accuracy: 0.5000\n",
      "Epoch [523/10000], Training Loss: 0.61867204, Training Accuracy: 0.9328\n",
      "Epoch [523/10000], Validation Loss: 1.03498355, Validation Accuracy: 0.5147\n",
      "Epoch [524/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [524/10000], Validation Loss: 1.03195348, Validation Accuracy: 0.5147\n",
      "Epoch [525/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [525/10000], Validation Loss: 1.02978003, Validation Accuracy: 0.5147\n",
      "Epoch [526/10000], Training Loss: 0.59766350, Training Accuracy: 0.9538\n",
      "Epoch [526/10000], Validation Loss: 1.02867678, Validation Accuracy: 0.5147\n",
      "Epoch [527/10000], Training Loss: 0.60606641, Training Accuracy: 0.9454\n",
      "Epoch [527/10000], Validation Loss: 1.02818346, Validation Accuracy: 0.5147\n",
      "Epoch [528/10000], Training Loss: 0.61225974, Training Accuracy: 0.9370\n",
      "Epoch [528/10000], Validation Loss: 1.02203184, Validation Accuracy: 0.5294\n",
      "Epoch [529/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [529/10000], Validation Loss: 1.03673881, Validation Accuracy: 0.5147\n",
      "Epoch [530/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [530/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [531/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [531/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [532/10000], Training Loss: 0.58085832, Training Accuracy: 0.9706\n",
      "Epoch [532/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [533/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [533/10000], Validation Loss: 1.06615293, Validation Accuracy: 0.4853\n",
      "Epoch [534/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [534/10000], Validation Loss: 1.06618005, Validation Accuracy: 0.4853\n",
      "Epoch [535/10000], Training Loss: 0.60587600, Training Accuracy: 0.9454\n",
      "Epoch [535/10000], Validation Loss: 1.03561112, Validation Accuracy: 0.5147\n",
      "Epoch [536/10000], Training Loss: 0.59314494, Training Accuracy: 0.9580\n",
      "Epoch [536/10000], Validation Loss: 1.03716561, Validation Accuracy: 0.5147\n",
      "Epoch [537/10000], Training Loss: 0.58733923, Training Accuracy: 0.9622\n",
      "Epoch [537/10000], Validation Loss: 1.02161556, Validation Accuracy: 0.5294\n",
      "Epoch [538/10000], Training Loss: 0.61447034, Training Accuracy: 0.9370\n",
      "Epoch [538/10000], Validation Loss: 1.06184745, Validation Accuracy: 0.4853\n",
      "Epoch [539/10000], Training Loss: 0.63971283, Training Accuracy: 0.9118\n",
      "Epoch [539/10000], Validation Loss: 1.09350461, Validation Accuracy: 0.4559\n",
      "Epoch [540/10000], Training Loss: 0.63968023, Training Accuracy: 0.9118\n",
      "Epoch [540/10000], Validation Loss: 1.09425139, Validation Accuracy: 0.4559\n",
      "Epoch [541/10000], Training Loss: 0.64429307, Training Accuracy: 0.9076\n",
      "Epoch [541/10000], Validation Loss: 1.08754081, Validation Accuracy: 0.4559\n",
      "Epoch [542/10000], Training Loss: 0.60389124, Training Accuracy: 0.9454\n",
      "Epoch [542/10000], Validation Loss: 1.02176735, Validation Accuracy: 0.5294\n",
      "Epoch [543/10000], Training Loss: 0.58507020, Training Accuracy: 0.9664\n",
      "Epoch [543/10000], Validation Loss: 1.03673387, Validation Accuracy: 0.5147\n",
      "Epoch [544/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [544/10000], Validation Loss: 1.03673768, Validation Accuracy: 0.5147\n",
      "Epoch [545/10000], Training Loss: 0.60192249, Training Accuracy: 0.9496\n",
      "Epoch [545/10000], Validation Loss: 1.05143899, Validation Accuracy: 0.5000\n",
      "Epoch [546/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [546/10000], Validation Loss: 1.05144697, Validation Accuracy: 0.5000\n",
      "Epoch [547/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [547/10000], Validation Loss: 1.05960041, Validation Accuracy: 0.4853\n",
      "Epoch [548/10000], Training Loss: 0.59580202, Training Accuracy: 0.9538\n",
      "Epoch [548/10000], Validation Loss: 1.06286621, Validation Accuracy: 0.4853\n",
      "Epoch [549/10000], Training Loss: 0.59796462, Training Accuracy: 0.9538\n",
      "Epoch [549/10000], Validation Loss: 1.05144614, Validation Accuracy: 0.5000\n",
      "Epoch [550/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [550/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [551/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [551/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [552/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [552/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [553/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [553/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [554/10000], Training Loss: 0.59346180, Training Accuracy: 0.9580\n",
      "Epoch [554/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [555/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [555/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [556/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [556/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [557/10000], Training Loss: 0.61446905, Training Accuracy: 0.9370\n",
      "Epoch [557/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [558/10000], Training Loss: 0.61023762, Training Accuracy: 0.9412\n",
      "Epoch [558/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [559/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [559/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [560/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [560/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [561/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [561/10000], Validation Loss: 1.03677851, Validation Accuracy: 0.5147\n",
      "Epoch [562/10000], Training Loss: 0.60393628, Training Accuracy: 0.9454\n",
      "Epoch [562/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [563/10000], Training Loss: 0.59770679, Training Accuracy: 0.9538\n",
      "Epoch [563/10000], Validation Loss: 1.03674042, Validation Accuracy: 0.5147\n",
      "Epoch [564/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [564/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [565/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [565/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [566/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [566/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [567/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [567/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [568/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [568/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [569/10000], Training Loss: 0.59082403, Training Accuracy: 0.9622\n",
      "Epoch [569/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [570/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [570/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [571/10000], Training Loss: 0.58547674, Training Accuracy: 0.9664\n",
      "Epoch [571/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [572/10000], Training Loss: 0.58926016, Training Accuracy: 0.9622\n",
      "Epoch [572/10000], Validation Loss: 1.00686833, Validation Accuracy: 0.5441\n",
      "Epoch [573/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [573/10000], Validation Loss: 0.99265110, Validation Accuracy: 0.5588\n",
      "Epoch [574/10000], Training Loss: 0.59766339, Training Accuracy: 0.9538\n",
      "Epoch [574/10000], Validation Loss: 0.99262169, Validation Accuracy: 0.5588\n",
      "Epoch [575/10000], Training Loss: 0.58926205, Training Accuracy: 0.9622\n",
      "Epoch [575/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [576/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [576/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [577/10000], Training Loss: 0.59766372, Training Accuracy: 0.9538\n",
      "Epoch [577/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [578/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [578/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [579/10000], Training Loss: 0.60179668, Training Accuracy: 0.9496\n",
      "Epoch [579/10000], Validation Loss: 1.02188140, Validation Accuracy: 0.5294\n",
      "Epoch [580/10000], Training Loss: 0.60186522, Training Accuracy: 0.9496\n",
      "Epoch [580/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [581/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [581/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [582/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [582/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [583/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [583/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [584/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [584/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [585/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [585/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [586/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [586/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [587/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [587/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [588/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [588/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [589/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [589/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [590/10000], Training Loss: 0.59583554, Training Accuracy: 0.9538\n",
      "Epoch [590/10000], Validation Loss: 1.05142248, Validation Accuracy: 0.5000\n",
      "Epoch [591/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [591/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [592/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [592/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [593/10000], Training Loss: 0.60123018, Training Accuracy: 0.9496\n",
      "Epoch [593/10000], Validation Loss: 1.05015102, Validation Accuracy: 0.5000\n",
      "Epoch [594/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [594/10000], Validation Loss: 1.05143782, Validation Accuracy: 0.5000\n",
      "Epoch [595/10000], Training Loss: 0.60482821, Training Accuracy: 0.9454\n",
      "Epoch [595/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [596/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [596/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [597/10000], Training Loss: 0.58505569, Training Accuracy: 0.9664\n",
      "Epoch [597/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [598/10000], Training Loss: 0.59346267, Training Accuracy: 0.9580\n",
      "Epoch [598/10000], Validation Loss: 1.01672325, Validation Accuracy: 0.5294\n",
      "Epoch [599/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [599/10000], Validation Loss: 1.00736973, Validation Accuracy: 0.5441\n",
      "Epoch [600/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [600/10000], Validation Loss: 1.00732914, Validation Accuracy: 0.5441\n",
      "Epoch [601/10000], Training Loss: 0.59766342, Training Accuracy: 0.9538\n",
      "Epoch [601/10000], Validation Loss: 1.00732771, Validation Accuracy: 0.5441\n",
      "Epoch [602/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [602/10000], Validation Loss: 1.00732747, Validation Accuracy: 0.5441\n",
      "Epoch [603/10000], Training Loss: 0.58505838, Training Accuracy: 0.9664\n",
      "Epoch [603/10000], Validation Loss: 1.00732741, Validation Accuracy: 0.5441\n",
      "Epoch [604/10000], Training Loss: 0.59337011, Training Accuracy: 0.9580\n",
      "Epoch [604/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [605/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [605/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [606/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [606/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [607/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [607/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [608/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [608/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [609/10000], Training Loss: 0.57665644, Training Accuracy: 0.9748\n",
      "Epoch [609/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [610/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [610/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [611/10000], Training Loss: 0.60585090, Training Accuracy: 0.9454\n",
      "Epoch [611/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [612/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [612/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [613/10000], Training Loss: 0.58085684, Training Accuracy: 0.9706\n",
      "Epoch [613/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [614/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [614/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [615/10000], Training Loss: 0.58926438, Training Accuracy: 0.9622\n",
      "Epoch [615/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [616/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [616/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [617/10000], Training Loss: 0.57668016, Training Accuracy: 0.9748\n",
      "Epoch [617/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [618/10000], Training Loss: 0.58090133, Training Accuracy: 0.9706\n",
      "Epoch [618/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [619/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [619/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [620/10000], Training Loss: 0.60606677, Training Accuracy: 0.9454\n",
      "Epoch [620/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [621/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [621/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [622/10000], Training Loss: 0.58926127, Training Accuracy: 0.9622\n",
      "Epoch [622/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [623/10000], Training Loss: 0.57665466, Training Accuracy: 0.9748\n",
      "Epoch [623/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [624/10000], Training Loss: 0.59765243, Training Accuracy: 0.9538\n",
      "Epoch [624/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [625/10000], Training Loss: 0.57374126, Training Accuracy: 0.9790\n",
      "Epoch [625/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [626/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [626/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [627/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [627/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [628/10000], Training Loss: 0.58085188, Training Accuracy: 0.9706\n",
      "Epoch [628/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [629/10000], Training Loss: 0.58092991, Training Accuracy: 0.9706\n",
      "Epoch [629/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [630/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [630/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [631/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [631/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [632/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [632/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [633/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [633/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [634/10000], Training Loss: 0.59263097, Training Accuracy: 0.9580\n",
      "Epoch [634/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [635/10000], Training Loss: 0.58056082, Training Accuracy: 0.9706\n",
      "Epoch [635/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [636/10000], Training Loss: 0.58928274, Training Accuracy: 0.9622\n",
      "Epoch [636/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [637/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [637/10000], Validation Loss: 0.99206334, Validation Accuracy: 0.5588\n",
      "Epoch [638/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [638/10000], Validation Loss: 0.99261993, Validation Accuracy: 0.5588\n",
      "Epoch [639/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [639/10000], Validation Loss: 0.99262154, Validation Accuracy: 0.5588\n",
      "Epoch [640/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [640/10000], Validation Loss: 0.99262214, Validation Accuracy: 0.5588\n",
      "Epoch [641/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [641/10000], Validation Loss: 0.99264163, Validation Accuracy: 0.5588\n",
      "Epoch [642/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [642/10000], Validation Loss: 1.00732279, Validation Accuracy: 0.5441\n",
      "Epoch [643/10000], Training Loss: 0.57666032, Training Accuracy: 0.9748\n",
      "Epoch [643/10000], Validation Loss: 0.99303108, Validation Accuracy: 0.5588\n",
      "Epoch [644/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [644/10000], Validation Loss: 0.99264097, Validation Accuracy: 0.5588\n",
      "Epoch [645/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [645/10000], Validation Loss: 0.99266934, Validation Accuracy: 0.5588\n",
      "Epoch [646/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [646/10000], Validation Loss: 0.99269485, Validation Accuracy: 0.5588\n",
      "Epoch [647/10000], Training Loss: 0.58505843, Training Accuracy: 0.9664\n",
      "Epoch [647/10000], Validation Loss: 0.99271125, Validation Accuracy: 0.5588\n",
      "Epoch [648/10000], Training Loss: 0.59346144, Training Accuracy: 0.9580\n",
      "Epoch [648/10000], Validation Loss: 0.99271929, Validation Accuracy: 0.5588\n",
      "Epoch [649/10000], Training Loss: 0.57754487, Training Accuracy: 0.9748\n",
      "Epoch [649/10000], Validation Loss: 1.00659966, Validation Accuracy: 0.5441\n",
      "Epoch [650/10000], Training Loss: 0.58496645, Training Accuracy: 0.9664\n",
      "Epoch [650/10000], Validation Loss: 0.97791463, Validation Accuracy: 0.5735\n",
      "Epoch [651/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [651/10000], Validation Loss: 0.96320781, Validation Accuracy: 0.5882\n",
      "Epoch [652/10000], Training Loss: 0.59766167, Training Accuracy: 0.9538\n",
      "Epoch [652/10000], Validation Loss: 0.93524644, Validation Accuracy: 0.6176\n",
      "Epoch [653/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [653/10000], Validation Loss: 0.94648629, Validation Accuracy: 0.6029\n",
      "Epoch [654/10000], Training Loss: 0.61447005, Training Accuracy: 0.9370\n",
      "Epoch [654/10000], Validation Loss: 0.94842082, Validation Accuracy: 0.6029\n",
      "Epoch [655/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [655/10000], Validation Loss: 0.94848731, Validation Accuracy: 0.6029\n",
      "Epoch [656/10000], Training Loss: 0.59346166, Training Accuracy: 0.9580\n",
      "Epoch [656/10000], Validation Loss: 0.94849735, Validation Accuracy: 0.6029\n",
      "Epoch [657/10000], Training Loss: 0.58505759, Training Accuracy: 0.9664\n",
      "Epoch [657/10000], Validation Loss: 0.94849977, Validation Accuracy: 0.6029\n",
      "Epoch [658/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [658/10000], Validation Loss: 0.94850037, Validation Accuracy: 0.6029\n",
      "Epoch [659/10000], Training Loss: 0.59346003, Training Accuracy: 0.9580\n",
      "Epoch [659/10000], Validation Loss: 0.94849977, Validation Accuracy: 0.6029\n",
      "Epoch [660/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [660/10000], Validation Loss: 0.94849807, Validation Accuracy: 0.6029\n",
      "Epoch [661/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [661/10000], Validation Loss: 0.94849724, Validation Accuracy: 0.6029\n",
      "Epoch [662/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [662/10000], Validation Loss: 0.94849682, Validation Accuracy: 0.6029\n",
      "Epoch [663/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [663/10000], Validation Loss: 0.94849664, Validation Accuracy: 0.6029\n",
      "Epoch [664/10000], Training Loss: 0.58505756, Training Accuracy: 0.9664\n",
      "Epoch [664/10000], Validation Loss: 0.94849640, Validation Accuracy: 0.6029\n",
      "Epoch [665/10000], Training Loss: 0.61026836, Training Accuracy: 0.9412\n",
      "Epoch [665/10000], Validation Loss: 0.94849545, Validation Accuracy: 0.6029\n",
      "Epoch [666/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [666/10000], Validation Loss: 0.94849491, Validation Accuracy: 0.6029\n",
      "Epoch [667/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [667/10000], Validation Loss: 0.94849467, Validation Accuracy: 0.6029\n",
      "Epoch [668/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [668/10000], Validation Loss: 0.94849449, Validation Accuracy: 0.6029\n",
      "Epoch [669/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [669/10000], Validation Loss: 0.94849443, Validation Accuracy: 0.6029\n",
      "Epoch [670/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [670/10000], Validation Loss: 0.94849443, Validation Accuracy: 0.6029\n",
      "Epoch [671/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [671/10000], Validation Loss: 0.94849443, Validation Accuracy: 0.6029\n",
      "Epoch [672/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [672/10000], Validation Loss: 0.94849443, Validation Accuracy: 0.6029\n",
      "Epoch [673/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [673/10000], Validation Loss: 0.94849443, Validation Accuracy: 0.6029\n",
      "Epoch [674/10000], Training Loss: 0.60606664, Training Accuracy: 0.9454\n",
      "Epoch [674/10000], Validation Loss: 0.94849423, Validation Accuracy: 0.6029\n",
      "Epoch [675/10000], Training Loss: 0.59346160, Training Accuracy: 0.9580\n",
      "Epoch [675/10000], Validation Loss: 0.94849399, Validation Accuracy: 0.6029\n",
      "Epoch [676/10000], Training Loss: 0.60606608, Training Accuracy: 0.9454\n",
      "Epoch [676/10000], Validation Loss: 0.94849807, Validation Accuracy: 0.6029\n",
      "Epoch [677/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [677/10000], Validation Loss: 0.94849998, Validation Accuracy: 0.6029\n",
      "Epoch [678/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [678/10000], Validation Loss: 0.94850075, Validation Accuracy: 0.6029\n",
      "Epoch [679/10000], Training Loss: 0.60602461, Training Accuracy: 0.9454\n",
      "Epoch [679/10000], Validation Loss: 0.94849917, Validation Accuracy: 0.6029\n",
      "Epoch [680/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [680/10000], Validation Loss: 0.94847661, Validation Accuracy: 0.6029\n",
      "Epoch [681/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [681/10000], Validation Loss: 0.94821119, Validation Accuracy: 0.6029\n",
      "Epoch [682/10000], Training Loss: 0.58507442, Training Accuracy: 0.9664\n",
      "Epoch [682/10000], Validation Loss: 0.94751173, Validation Accuracy: 0.6029\n",
      "Epoch [683/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [683/10000], Validation Loss: 0.94571704, Validation Accuracy: 0.6029\n",
      "Epoch [684/10000], Training Loss: 0.59252032, Training Accuracy: 0.9580\n",
      "Epoch [684/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [685/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [685/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [686/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [686/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [687/10000], Training Loss: 0.60220980, Training Accuracy: 0.9496\n",
      "Epoch [687/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [688/10000], Training Loss: 0.58884622, Training Accuracy: 0.9622\n",
      "Epoch [688/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [689/10000], Training Loss: 0.58517518, Training Accuracy: 0.9664\n",
      "Epoch [689/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [690/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [690/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [691/10000], Training Loss: 0.61026962, Training Accuracy: 0.9412\n",
      "Epoch [691/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [692/10000], Training Loss: 0.59807334, Training Accuracy: 0.9538\n",
      "Epoch [692/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [693/10000], Training Loss: 0.64469666, Training Accuracy: 0.9076\n",
      "Epoch [693/10000], Validation Loss: 0.97791553, Validation Accuracy: 0.5735\n",
      "Epoch [694/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [694/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [695/10000], Training Loss: 0.58085677, Training Accuracy: 0.9706\n",
      "Epoch [695/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [696/10000], Training Loss: 0.60506325, Training Accuracy: 0.9454\n",
      "Epoch [696/10000], Validation Loss: 1.00702766, Validation Accuracy: 0.5441\n",
      "Epoch [697/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [697/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [698/10000], Training Loss: 0.61020453, Training Accuracy: 0.9412\n",
      "Epoch [698/10000], Validation Loss: 0.97791594, Validation Accuracy: 0.5735\n",
      "Epoch [699/10000], Training Loss: 0.60605060, Training Accuracy: 0.9454\n",
      "Epoch [699/10000], Validation Loss: 0.97791412, Validation Accuracy: 0.5735\n",
      "Epoch [700/10000], Training Loss: 0.61449954, Training Accuracy: 0.9370\n",
      "Epoch [700/10000], Validation Loss: 0.97791210, Validation Accuracy: 0.5735\n",
      "Epoch [701/10000], Training Loss: 0.60066511, Training Accuracy: 0.9496\n",
      "Epoch [701/10000], Validation Loss: 1.00706971, Validation Accuracy: 0.5441\n",
      "Epoch [702/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [702/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [703/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [703/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [704/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [704/10000], Validation Loss: 1.00711140, Validation Accuracy: 0.5441\n",
      "Epoch [705/10000], Training Loss: 0.59756914, Training Accuracy: 0.9538\n",
      "Epoch [705/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [706/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [706/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [707/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [707/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [708/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [708/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [709/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [709/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [710/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [710/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [711/10000], Training Loss: 0.59346179, Training Accuracy: 0.9580\n",
      "Epoch [711/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [712/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [712/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [713/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [713/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [714/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [714/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [715/10000], Training Loss: 0.58512844, Training Accuracy: 0.9664\n",
      "Epoch [715/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [716/10000], Training Loss: 0.58925864, Training Accuracy: 0.9622\n",
      "Epoch [716/10000], Validation Loss: 0.98063806, Validation Accuracy: 0.5735\n",
      "Epoch [717/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [717/10000], Validation Loss: 0.97791851, Validation Accuracy: 0.5735\n",
      "Epoch [718/10000], Training Loss: 0.60246982, Training Accuracy: 0.9496\n",
      "Epoch [718/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [719/10000], Training Loss: 0.58086023, Training Accuracy: 0.9706\n",
      "Epoch [719/10000], Validation Loss: 1.00732714, Validation Accuracy: 0.5441\n",
      "Epoch [720/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [720/10000], Validation Loss: 1.00732663, Validation Accuracy: 0.5441\n",
      "Epoch [721/10000], Training Loss: 0.58527654, Training Accuracy: 0.9664\n",
      "Epoch [721/10000], Validation Loss: 0.99327001, Validation Accuracy: 0.5588\n",
      "Epoch [722/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [722/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [723/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [723/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [724/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [724/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [725/10000], Training Loss: 0.59037501, Training Accuracy: 0.9580\n",
      "Epoch [725/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [726/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [726/10000], Validation Loss: 0.99262127, Validation Accuracy: 0.5588\n",
      "Epoch [727/10000], Training Loss: 0.57961339, Training Accuracy: 0.9706\n",
      "Epoch [727/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [728/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [728/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [729/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [729/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [730/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [730/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [731/10000], Training Loss: 0.59019342, Training Accuracy: 0.9622\n",
      "Epoch [731/10000], Validation Loss: 1.00728095, Validation Accuracy: 0.5441\n",
      "Epoch [732/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [732/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [733/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [733/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [734/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [734/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [735/10000], Training Loss: 0.59688335, Training Accuracy: 0.9538\n",
      "Epoch [735/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [736/10000], Training Loss: 0.59767053, Training Accuracy: 0.9538\n",
      "Epoch [736/10000], Validation Loss: 1.03673184, Validation Accuracy: 0.5147\n",
      "Epoch [737/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [737/10000], Validation Loss: 1.05145156, Validation Accuracy: 0.5000\n",
      "Epoch [738/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [738/10000], Validation Loss: 1.06614298, Validation Accuracy: 0.4853\n",
      "Epoch [739/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [739/10000], Validation Loss: 1.06612283, Validation Accuracy: 0.4853\n",
      "Epoch [740/10000], Training Loss: 0.59695853, Training Accuracy: 0.9538\n",
      "Epoch [740/10000], Validation Loss: 1.06519890, Validation Accuracy: 0.4853\n",
      "Epoch [741/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [741/10000], Validation Loss: 1.06604826, Validation Accuracy: 0.4853\n",
      "Epoch [742/10000], Training Loss: 0.58902311, Training Accuracy: 0.9622\n",
      "Epoch [742/10000], Validation Loss: 1.05026346, Validation Accuracy: 0.5000\n",
      "Epoch [743/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [743/10000], Validation Loss: 1.03673762, Validation Accuracy: 0.5147\n",
      "Epoch [744/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [744/10000], Validation Loss: 1.03673834, Validation Accuracy: 0.5147\n",
      "Epoch [745/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [745/10000], Validation Loss: 1.03673857, Validation Accuracy: 0.5147\n",
      "Epoch [746/10000], Training Loss: 0.59345177, Training Accuracy: 0.9580\n",
      "Epoch [746/10000], Validation Loss: 1.03673851, Validation Accuracy: 0.5147\n",
      "Epoch [747/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [747/10000], Validation Loss: 1.03673840, Validation Accuracy: 0.5147\n",
      "Epoch [748/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [748/10000], Validation Loss: 1.03673828, Validation Accuracy: 0.5147\n",
      "Epoch [749/10000], Training Loss: 0.58799950, Training Accuracy: 0.9622\n",
      "Epoch [749/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [750/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [750/10000], Validation Loss: 1.03673911, Validation Accuracy: 0.5147\n",
      "Epoch [751/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [751/10000], Validation Loss: 1.03676069, Validation Accuracy: 0.5147\n",
      "Epoch [752/10000], Training Loss: 0.58510441, Training Accuracy: 0.9664\n",
      "Epoch [752/10000], Validation Loss: 1.03802758, Validation Accuracy: 0.5147\n",
      "Epoch [753/10000], Training Loss: 0.61441944, Training Accuracy: 0.9370\n",
      "Epoch [753/10000], Validation Loss: 1.05065298, Validation Accuracy: 0.5000\n",
      "Epoch [754/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [754/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [755/10000], Training Loss: 0.59346222, Training Accuracy: 0.9580\n",
      "Epoch [755/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [756/10000], Training Loss: 0.58926007, Training Accuracy: 0.9622\n",
      "Epoch [756/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [757/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [757/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [758/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [758/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [759/10000], Training Loss: 0.59345862, Training Accuracy: 0.9580\n",
      "Epoch [759/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [760/10000], Training Loss: 0.59346001, Training Accuracy: 0.9580\n",
      "Epoch [760/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [761/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [761/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [762/10000], Training Loss: 0.59766302, Training Accuracy: 0.9538\n",
      "Epoch [762/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [763/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [763/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [764/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [764/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [765/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [765/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [766/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [766/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [767/10000], Training Loss: 0.59868302, Training Accuracy: 0.9538\n",
      "Epoch [767/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [768/10000], Training Loss: 0.58923924, Training Accuracy: 0.9622\n",
      "Epoch [768/10000], Validation Loss: 1.12489611, Validation Accuracy: 0.4265\n",
      "Epoch [769/10000], Training Loss: 0.60459523, Training Accuracy: 0.9454\n",
      "Epoch [769/10000], Validation Loss: 1.09904140, Validation Accuracy: 0.4559\n",
      "Epoch [770/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [770/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [771/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [771/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [772/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [772/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [773/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [773/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [774/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [774/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [775/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [775/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [776/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [776/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [777/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [777/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [778/10000], Training Loss: 0.58926004, Training Accuracy: 0.9622\n",
      "Epoch [778/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [779/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [779/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [780/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [780/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [781/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [781/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [782/10000], Training Loss: 0.60186499, Training Accuracy: 0.9496\n",
      "Epoch [782/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [783/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [783/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [784/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [784/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [785/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [785/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [786/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [786/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [787/10000], Training Loss: 0.58927860, Training Accuracy: 0.9622\n",
      "Epoch [787/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [788/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [788/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [789/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [789/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [790/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [790/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [791/10000], Training Loss: 0.58505797, Training Accuracy: 0.9664\n",
      "Epoch [791/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [792/10000], Training Loss: 0.58519340, Training Accuracy: 0.9664\n",
      "Epoch [792/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [793/10000], Training Loss: 0.59442679, Training Accuracy: 0.9580\n",
      "Epoch [793/10000], Validation Loss: 1.10804927, Validation Accuracy: 0.4412\n",
      "Epoch [794/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [794/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [795/10000], Training Loss: 0.58511553, Training Accuracy: 0.9664\n",
      "Epoch [795/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [796/10000], Training Loss: 0.60684374, Training Accuracy: 0.9454\n",
      "Epoch [796/10000], Validation Loss: 1.08003229, Validation Accuracy: 0.4706\n",
      "Epoch [797/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [797/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [798/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [798/10000], Validation Loss: 1.05489910, Validation Accuracy: 0.5000\n",
      "Epoch [799/10000], Training Loss: 0.58926241, Training Accuracy: 0.9622\n",
      "Epoch [799/10000], Validation Loss: 1.05144531, Validation Accuracy: 0.5000\n",
      "Epoch [800/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [800/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [801/10000], Training Loss: 0.59718697, Training Accuracy: 0.9538\n",
      "Epoch [801/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [802/10000], Training Loss: 0.58087038, Training Accuracy: 0.9706\n",
      "Epoch [802/10000], Validation Loss: 1.02659923, Validation Accuracy: 0.5294\n",
      "Epoch [803/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [803/10000], Validation Loss: 1.02203232, Validation Accuracy: 0.5294\n",
      "Epoch [804/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [804/10000], Validation Loss: 1.02096510, Validation Accuracy: 0.5294\n",
      "Epoch [805/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [805/10000], Validation Loss: 1.01076287, Validation Accuracy: 0.5441\n",
      "Epoch [806/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [806/10000], Validation Loss: 1.00801936, Validation Accuracy: 0.5441\n",
      "Epoch [807/10000], Training Loss: 0.57245505, Training Accuracy: 0.9790\n",
      "Epoch [807/10000], Validation Loss: 1.00765485, Validation Accuracy: 0.5441\n",
      "Epoch [808/10000], Training Loss: 0.58676659, Training Accuracy: 0.9664\n",
      "Epoch [808/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [809/10000], Training Loss: 0.58924944, Training Accuracy: 0.9622\n",
      "Epoch [809/10000], Validation Loss: 1.08076543, Validation Accuracy: 0.4706\n",
      "Epoch [810/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [810/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [811/10000], Training Loss: 0.59763195, Training Accuracy: 0.9538\n",
      "Epoch [811/10000], Validation Loss: 1.08085847, Validation Accuracy: 0.4706\n",
      "Epoch [812/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [812/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [813/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [813/10000], Validation Loss: 1.08085650, Validation Accuracy: 0.4706\n",
      "Epoch [814/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [814/10000], Validation Loss: 1.08085608, Validation Accuracy: 0.4706\n",
      "Epoch [815/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [815/10000], Validation Loss: 1.08085561, Validation Accuracy: 0.4706\n",
      "Epoch [816/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [816/10000], Validation Loss: 1.08085537, Validation Accuracy: 0.4706\n",
      "Epoch [817/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [817/10000], Validation Loss: 1.08085519, Validation Accuracy: 0.4706\n",
      "Epoch [818/10000], Training Loss: 0.60619035, Training Accuracy: 0.9454\n",
      "Epoch [818/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [819/10000], Training Loss: 0.58571828, Training Accuracy: 0.9664\n",
      "Epoch [819/10000], Validation Loss: 1.06592321, Validation Accuracy: 0.4853\n",
      "Epoch [820/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [820/10000], Validation Loss: 1.05139244, Validation Accuracy: 0.5000\n",
      "Epoch [821/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [821/10000], Validation Loss: 1.05136108, Validation Accuracy: 0.5000\n",
      "Epoch [822/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [822/10000], Validation Loss: 1.05144173, Validation Accuracy: 0.5000\n",
      "Epoch [823/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [823/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [824/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [824/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [825/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [825/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [826/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [826/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [827/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [827/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [828/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [828/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [829/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [829/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [830/10000], Training Loss: 0.57665506, Training Accuracy: 0.9748\n",
      "Epoch [830/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [831/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [831/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [832/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [832/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [833/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [833/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [834/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [834/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [835/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [835/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [836/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [836/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [837/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [837/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [838/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [838/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [839/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [839/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [840/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [840/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [841/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [841/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [842/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [842/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [843/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [843/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [844/10000], Training Loss: 0.57245340, Training Accuracy: 0.9790\n",
      "Epoch [844/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [845/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [845/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [846/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [846/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [847/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [847/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [848/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [848/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [849/10000], Training Loss: 0.58085721, Training Accuracy: 0.9706\n",
      "Epoch [849/10000], Validation Loss: 1.05144465, Validation Accuracy: 0.5000\n",
      "Epoch [850/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [850/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [851/10000], Training Loss: 0.57245352, Training Accuracy: 0.9790\n",
      "Epoch [851/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [852/10000], Training Loss: 0.58786654, Training Accuracy: 0.9622\n",
      "Epoch [852/10000], Validation Loss: 1.06114584, Validation Accuracy: 0.4853\n",
      "Epoch [853/10000], Training Loss: 0.59346128, Training Accuracy: 0.9580\n",
      "Epoch [853/10000], Validation Loss: 1.06614459, Validation Accuracy: 0.4853\n",
      "Epoch [854/10000], Training Loss: 0.58737551, Training Accuracy: 0.9622\n",
      "Epoch [854/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [855/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [855/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [856/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [856/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [857/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [857/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [858/10000], Training Loss: 0.59759565, Training Accuracy: 0.9538\n",
      "Epoch [858/10000], Validation Loss: 0.96317047, Validation Accuracy: 0.5882\n",
      "Epoch [859/10000], Training Loss: 0.59346713, Training Accuracy: 0.9580\n",
      "Epoch [859/10000], Validation Loss: 0.95677888, Validation Accuracy: 0.5882\n",
      "Epoch [860/10000], Training Loss: 0.60606651, Training Accuracy: 0.9454\n",
      "Epoch [860/10000], Validation Loss: 0.94953072, Validation Accuracy: 0.6029\n",
      "Epoch [861/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [861/10000], Validation Loss: 0.94878563, Validation Accuracy: 0.6029\n",
      "Epoch [862/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [862/10000], Validation Loss: 0.94865337, Validation Accuracy: 0.6029\n",
      "Epoch [863/10000], Training Loss: 0.59766347, Training Accuracy: 0.9538\n",
      "Epoch [863/10000], Validation Loss: 0.94861406, Validation Accuracy: 0.6029\n",
      "Epoch [864/10000], Training Loss: 0.60606815, Training Accuracy: 0.9454\n",
      "Epoch [864/10000], Validation Loss: 0.94860011, Validation Accuracy: 0.6029\n",
      "Epoch [865/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [865/10000], Validation Loss: 0.94859448, Validation Accuracy: 0.6029\n",
      "Epoch [866/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [866/10000], Validation Loss: 0.94859189, Validation Accuracy: 0.6029\n",
      "Epoch [867/10000], Training Loss: 0.60188065, Training Accuracy: 0.9496\n",
      "Epoch [867/10000], Validation Loss: 0.94888744, Validation Accuracy: 0.6029\n",
      "Epoch [868/10000], Training Loss: 0.61805481, Training Accuracy: 0.9328\n",
      "Epoch [868/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [869/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [869/10000], Validation Loss: 1.05144265, Validation Accuracy: 0.5000\n",
      "Epoch [870/10000], Training Loss: 0.58100558, Training Accuracy: 0.9706\n",
      "Epoch [870/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [871/10000], Training Loss: 0.57681575, Training Accuracy: 0.9748\n",
      "Epoch [871/10000], Validation Loss: 1.05124146, Validation Accuracy: 0.5000\n",
      "Epoch [872/10000], Training Loss: 0.59312607, Training Accuracy: 0.9580\n",
      "Epoch [872/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [873/10000], Training Loss: 0.58926056, Training Accuracy: 0.9622\n",
      "Epoch [873/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [874/10000], Training Loss: 0.58922490, Training Accuracy: 0.9622\n",
      "Epoch [874/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [875/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [875/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [876/10000], Training Loss: 0.59346195, Training Accuracy: 0.9580\n",
      "Epoch [876/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [877/10000], Training Loss: 0.58505773, Training Accuracy: 0.9664\n",
      "Epoch [877/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [878/10000], Training Loss: 0.61028036, Training Accuracy: 0.9412\n",
      "Epoch [878/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [879/10000], Training Loss: 0.58926128, Training Accuracy: 0.9622\n",
      "Epoch [879/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [880/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [880/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [881/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [881/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [882/10000], Training Loss: 0.58533822, Training Accuracy: 0.9664\n",
      "Epoch [882/10000], Validation Loss: 1.06615084, Validation Accuracy: 0.4853\n",
      "Epoch [883/10000], Training Loss: 0.59769158, Training Accuracy: 0.9538\n",
      "Epoch [883/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [884/10000], Training Loss: 0.58926222, Training Accuracy: 0.9622\n",
      "Epoch [884/10000], Validation Loss: 1.06615043, Validation Accuracy: 0.4853\n",
      "Epoch [885/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [885/10000], Validation Loss: 1.06582963, Validation Accuracy: 0.4853\n",
      "Epoch [886/10000], Training Loss: 0.59346160, Training Accuracy: 0.9580\n",
      "Epoch [886/10000], Validation Loss: 1.06052583, Validation Accuracy: 0.4853\n",
      "Epoch [887/10000], Training Loss: 0.59197520, Training Accuracy: 0.9580\n",
      "Epoch [887/10000], Validation Loss: 1.06614959, Validation Accuracy: 0.4853\n",
      "Epoch [888/10000], Training Loss: 0.58086371, Training Accuracy: 0.9706\n",
      "Epoch [888/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [889/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [889/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [890/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [890/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [891/10000], Training Loss: 0.58504804, Training Accuracy: 0.9664\n",
      "Epoch [891/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [892/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [892/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [893/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [893/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [894/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [894/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [895/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [895/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [896/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [896/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [897/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [897/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [898/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [898/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [899/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [899/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [900/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [900/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [901/10000], Training Loss: 0.58085666, Training Accuracy: 0.9706\n",
      "Epoch [901/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [902/10000], Training Loss: 0.58505828, Training Accuracy: 0.9664\n",
      "Epoch [902/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [903/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [903/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [904/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [904/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [905/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [905/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [906/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [906/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [907/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [907/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [908/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [908/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [909/10000], Training Loss: 0.57919530, Training Accuracy: 0.9706\n",
      "Epoch [909/10000], Validation Loss: 1.06559217, Validation Accuracy: 0.4853\n",
      "Epoch [910/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [910/10000], Validation Loss: 1.06559002, Validation Accuracy: 0.4853\n",
      "Epoch [911/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [911/10000], Validation Loss: 1.06611651, Validation Accuracy: 0.4853\n",
      "Epoch [912/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [912/10000], Validation Loss: 1.06614190, Validation Accuracy: 0.4853\n",
      "Epoch [913/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [913/10000], Validation Loss: 1.06614608, Validation Accuracy: 0.4853\n",
      "Epoch [914/10000], Training Loss: 0.59346179, Training Accuracy: 0.9580\n",
      "Epoch [914/10000], Validation Loss: 1.06614733, Validation Accuracy: 0.4853\n",
      "Epoch [915/10000], Training Loss: 0.59766760, Training Accuracy: 0.9538\n",
      "Epoch [915/10000], Validation Loss: 1.06614804, Validation Accuracy: 0.4853\n",
      "Epoch [916/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [916/10000], Validation Loss: 1.06614858, Validation Accuracy: 0.4853\n",
      "Epoch [917/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [917/10000], Validation Loss: 1.06614876, Validation Accuracy: 0.4853\n",
      "Epoch [918/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [918/10000], Validation Loss: 1.06614888, Validation Accuracy: 0.4853\n",
      "Epoch [919/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [919/10000], Validation Loss: 1.06614894, Validation Accuracy: 0.4853\n",
      "Epoch [920/10000], Training Loss: 0.60186272, Training Accuracy: 0.9496\n",
      "Epoch [920/10000], Validation Loss: 1.06614894, Validation Accuracy: 0.4853\n",
      "Epoch [921/10000], Training Loss: 0.60606795, Training Accuracy: 0.9454\n",
      "Epoch [921/10000], Validation Loss: 1.06614882, Validation Accuracy: 0.4853\n",
      "Epoch [922/10000], Training Loss: 0.60621767, Training Accuracy: 0.9454\n",
      "Epoch [922/10000], Validation Loss: 1.06613696, Validation Accuracy: 0.4853\n",
      "Epoch [923/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [923/10000], Validation Loss: 1.06609076, Validation Accuracy: 0.4853\n",
      "Epoch [924/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [924/10000], Validation Loss: 1.06602913, Validation Accuracy: 0.4853\n",
      "Epoch [925/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [925/10000], Validation Loss: 1.06598014, Validation Accuracy: 0.4853\n",
      "Epoch [926/10000], Training Loss: 0.58925890, Training Accuracy: 0.9622\n",
      "Epoch [926/10000], Validation Loss: 1.06593025, Validation Accuracy: 0.4853\n",
      "Epoch [927/10000], Training Loss: 0.58707581, Training Accuracy: 0.9622\n",
      "Epoch [927/10000], Validation Loss: 1.06173676, Validation Accuracy: 0.4853\n",
      "Epoch [928/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [928/10000], Validation Loss: 1.03707740, Validation Accuracy: 0.5147\n",
      "Epoch [929/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [929/10000], Validation Loss: 1.02207267, Validation Accuracy: 0.5294\n",
      "Epoch [930/10000], Training Loss: 0.58957853, Training Accuracy: 0.9622\n",
      "Epoch [930/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [931/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [931/10000], Validation Loss: 0.99260899, Validation Accuracy: 0.5588\n",
      "Epoch [932/10000], Training Loss: 0.59346179, Training Accuracy: 0.9580\n",
      "Epoch [932/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [933/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [933/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [934/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [934/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [935/10000], Training Loss: 0.61015488, Training Accuracy: 0.9412\n",
      "Epoch [935/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [936/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [936/10000], Validation Loss: 0.99246898, Validation Accuracy: 0.5588\n",
      "Epoch [937/10000], Training Loss: 0.59326955, Training Accuracy: 0.9580\n",
      "Epoch [937/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [938/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [938/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [939/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [939/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [940/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [940/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [941/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [941/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [942/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [942/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [943/10000], Training Loss: 0.61472189, Training Accuracy: 0.9370\n",
      "Epoch [943/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [944/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [944/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [945/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [945/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [946/10000], Training Loss: 0.58926013, Training Accuracy: 0.9622\n",
      "Epoch [946/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [947/10000], Training Loss: 0.61026709, Training Accuracy: 0.9412\n",
      "Epoch [947/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [948/10000], Training Loss: 0.59355868, Training Accuracy: 0.9580\n",
      "Epoch [948/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [949/10000], Training Loss: 0.60186509, Training Accuracy: 0.9496\n",
      "Epoch [949/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [950/10000], Training Loss: 0.59766351, Training Accuracy: 0.9538\n",
      "Epoch [950/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [951/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [951/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [952/10000], Training Loss: 0.60595259, Training Accuracy: 0.9454\n",
      "Epoch [952/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [953/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [953/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [954/10000], Training Loss: 0.60871903, Training Accuracy: 0.9412\n",
      "Epoch [954/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [955/10000], Training Loss: 0.58928045, Training Accuracy: 0.9622\n",
      "Epoch [955/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [956/10000], Training Loss: 0.61447031, Training Accuracy: 0.9370\n",
      "Epoch [956/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [957/10000], Training Loss: 0.61444722, Training Accuracy: 0.9370\n",
      "Epoch [957/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [958/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [958/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [959/10000], Training Loss: 0.59744698, Training Accuracy: 0.9538\n",
      "Epoch [959/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [960/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [960/10000], Validation Loss: 0.97791451, Validation Accuracy: 0.5735\n",
      "Epoch [961/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [961/10000], Validation Loss: 0.97769201, Validation Accuracy: 0.5735\n",
      "Epoch [962/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [962/10000], Validation Loss: 0.96216235, Validation Accuracy: 0.5882\n",
      "Epoch [963/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [963/10000], Validation Loss: 0.96285784, Validation Accuracy: 0.5882\n",
      "Epoch [964/10000], Training Loss: 0.61848860, Training Accuracy: 0.9328\n",
      "Epoch [964/10000], Validation Loss: 0.96316734, Validation Accuracy: 0.5882\n",
      "Epoch [965/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [965/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [966/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [966/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [967/10000], Training Loss: 0.62286596, Training Accuracy: 0.9286\n",
      "Epoch [967/10000], Validation Loss: 0.96321100, Validation Accuracy: 0.5882\n",
      "Epoch [968/10000], Training Loss: 0.61452164, Training Accuracy: 0.9370\n",
      "Epoch [968/10000], Validation Loss: 0.97495076, Validation Accuracy: 0.5735\n",
      "Epoch [969/10000], Training Loss: 0.61447068, Training Accuracy: 0.9370\n",
      "Epoch [969/10000], Validation Loss: 0.97786862, Validation Accuracy: 0.5735\n",
      "Epoch [970/10000], Training Loss: 0.60187387, Training Accuracy: 0.9496\n",
      "Epoch [970/10000], Validation Loss: 0.97790378, Validation Accuracy: 0.5735\n",
      "Epoch [971/10000], Training Loss: 0.62318359, Training Accuracy: 0.9286\n",
      "Epoch [971/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [972/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [972/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [973/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [973/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [974/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [974/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [975/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [975/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [976/10000], Training Loss: 0.61837466, Training Accuracy: 0.9328\n",
      "Epoch [976/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [977/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [977/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [978/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [978/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [979/10000], Training Loss: 0.61383817, Training Accuracy: 0.9370\n",
      "Epoch [979/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [980/10000], Training Loss: 0.60603384, Training Accuracy: 0.9454\n",
      "Epoch [980/10000], Validation Loss: 0.96321353, Validation Accuracy: 0.5882\n",
      "Epoch [981/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [981/10000], Validation Loss: 0.97791508, Validation Accuracy: 0.5735\n",
      "Epoch [982/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [982/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [983/10000], Training Loss: 0.60190003, Training Accuracy: 0.9496\n",
      "Epoch [983/10000], Validation Loss: 0.96319118, Validation Accuracy: 0.5882\n",
      "Epoch [984/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [984/10000], Validation Loss: 0.96281165, Validation Accuracy: 0.5882\n",
      "Epoch [985/10000], Training Loss: 0.61035447, Training Accuracy: 0.9412\n",
      "Epoch [985/10000], Validation Loss: 0.96206942, Validation Accuracy: 0.5882\n",
      "Epoch [986/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [986/10000], Validation Loss: 0.96320224, Validation Accuracy: 0.5882\n",
      "Epoch [987/10000], Training Loss: 0.60606907, Training Accuracy: 0.9454\n",
      "Epoch [987/10000], Validation Loss: 0.96320939, Validation Accuracy: 0.5882\n",
      "Epoch [988/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [988/10000], Validation Loss: 0.96320936, Validation Accuracy: 0.5882\n",
      "Epoch [989/10000], Training Loss: 0.60186515, Training Accuracy: 0.9496\n",
      "Epoch [989/10000], Validation Loss: 0.96320891, Validation Accuracy: 0.5882\n",
      "Epoch [990/10000], Training Loss: 0.61270592, Training Accuracy: 0.9370\n",
      "Epoch [990/10000], Validation Loss: 0.97791120, Validation Accuracy: 0.5735\n",
      "Epoch [991/10000], Training Loss: 0.58506472, Training Accuracy: 0.9664\n",
      "Epoch [991/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [992/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [992/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [993/10000], Training Loss: 0.60186727, Training Accuracy: 0.9496\n",
      "Epoch [993/10000], Validation Loss: 0.97791526, Validation Accuracy: 0.5735\n",
      "Epoch [994/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [994/10000], Validation Loss: 0.97791153, Validation Accuracy: 0.5735\n",
      "Epoch [995/10000], Training Loss: 0.59346205, Training Accuracy: 0.9580\n",
      "Epoch [995/10000], Validation Loss: 0.97790065, Validation Accuracy: 0.5735\n",
      "Epoch [996/10000], Training Loss: 0.62353877, Training Accuracy: 0.9286\n",
      "Epoch [996/10000], Validation Loss: 0.96526870, Validation Accuracy: 0.5882\n",
      "Epoch [997/10000], Training Loss: 0.61867200, Training Accuracy: 0.9328\n",
      "Epoch [997/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [998/10000], Training Loss: 0.61026842, Training Accuracy: 0.9412\n",
      "Epoch [998/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [999/10000], Training Loss: 0.62093481, Training Accuracy: 0.9286\n",
      "Epoch [999/10000], Validation Loss: 1.00337759, Validation Accuracy: 0.5441\n",
      "Epoch [1000/10000], Training Loss: 0.60606840, Training Accuracy: 0.9454\n",
      "Epoch [1000/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1001/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1001/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [1002/10000], Training Loss: 0.61867181, Training Accuracy: 0.9328\n",
      "Epoch [1002/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1003/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [1003/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1004/10000], Training Loss: 0.61026902, Training Accuracy: 0.9412\n",
      "Epoch [1004/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1005/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [1005/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1006/10000], Training Loss: 0.62704165, Training Accuracy: 0.9244\n",
      "Epoch [1006/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1007/10000], Training Loss: 0.62421731, Training Accuracy: 0.9286\n",
      "Epoch [1007/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1008/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1008/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1009/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1009/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1010/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1010/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1011/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1011/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1012/10000], Training Loss: 0.59764223, Training Accuracy: 0.9538\n",
      "Epoch [1012/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1013/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1013/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1014/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1014/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1015/10000], Training Loss: 0.59336557, Training Accuracy: 0.9580\n",
      "Epoch [1015/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1016/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1016/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1017/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1017/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1018/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1018/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1019/10000], Training Loss: 0.58926002, Training Accuracy: 0.9622\n",
      "Epoch [1019/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1020/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1020/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1021/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1021/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1022/10000], Training Loss: 0.58527643, Training Accuracy: 0.9664\n",
      "Epoch [1022/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1023/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1023/10000], Validation Loss: 1.00732741, Validation Accuracy: 0.5441\n",
      "Epoch [1024/10000], Training Loss: 0.58926012, Training Accuracy: 0.9622\n",
      "Epoch [1024/10000], Validation Loss: 0.99319583, Validation Accuracy: 0.5588\n",
      "Epoch [1025/10000], Training Loss: 0.58926011, Training Accuracy: 0.9622\n",
      "Epoch [1025/10000], Validation Loss: 1.00299162, Validation Accuracy: 0.5441\n",
      "Epoch [1026/10000], Training Loss: 0.58536415, Training Accuracy: 0.9664\n",
      "Epoch [1026/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [1027/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1027/10000], Validation Loss: 1.00732678, Validation Accuracy: 0.5441\n",
      "Epoch [1028/10000], Training Loss: 0.56825173, Training Accuracy: 0.9832\n",
      "Epoch [1028/10000], Validation Loss: 1.00598526, Validation Accuracy: 0.5441\n",
      "Epoch [1029/10000], Training Loss: 0.58494155, Training Accuracy: 0.9664\n",
      "Epoch [1029/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1030/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [1030/10000], Validation Loss: 1.00727704, Validation Accuracy: 0.5441\n",
      "Epoch [1031/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1031/10000], Validation Loss: 0.99262029, Validation Accuracy: 0.5588\n",
      "Epoch [1032/10000], Training Loss: 0.61060922, Training Accuracy: 0.9412\n",
      "Epoch [1032/10000], Validation Loss: 0.99262145, Validation Accuracy: 0.5588\n",
      "Epoch [1033/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [1033/10000], Validation Loss: 0.99280623, Validation Accuracy: 0.5588\n",
      "Epoch [1034/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1034/10000], Validation Loss: 0.99880841, Validation Accuracy: 0.5441\n",
      "Epoch [1035/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1035/10000], Validation Loss: 1.00480971, Validation Accuracy: 0.5441\n",
      "Epoch [1036/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1036/10000], Validation Loss: 1.00617197, Validation Accuracy: 0.5441\n",
      "Epoch [1037/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1037/10000], Validation Loss: 1.00654766, Validation Accuracy: 0.5441\n",
      "Epoch [1038/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1038/10000], Validation Loss: 1.00668356, Validation Accuracy: 0.5441\n",
      "Epoch [1039/10000], Training Loss: 0.58505456, Training Accuracy: 0.9664\n",
      "Epoch [1039/10000], Validation Loss: 1.00720075, Validation Accuracy: 0.5441\n",
      "Epoch [1040/10000], Training Loss: 0.58505856, Training Accuracy: 0.9664\n",
      "Epoch [1040/10000], Validation Loss: 1.00732699, Validation Accuracy: 0.5441\n",
      "Epoch [1041/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [1041/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1042/10000], Training Loss: 0.56405003, Training Accuracy: 0.9874\n",
      "Epoch [1042/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1043/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1043/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1044/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [1044/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1045/10000], Training Loss: 0.59766137, Training Accuracy: 0.9538\n",
      "Epoch [1045/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1046/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1046/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1047/10000], Training Loss: 0.58709846, Training Accuracy: 0.9622\n",
      "Epoch [1047/10000], Validation Loss: 1.00638407, Validation Accuracy: 0.5441\n",
      "Epoch [1048/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1048/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1049/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1049/10000], Validation Loss: 0.94850308, Validation Accuracy: 0.6029\n",
      "Epoch [1050/10000], Training Loss: 0.58925687, Training Accuracy: 0.9622\n",
      "Epoch [1050/10000], Validation Loss: 0.94840750, Validation Accuracy: 0.6029\n",
      "Epoch [1051/10000], Training Loss: 0.58891330, Training Accuracy: 0.9622\n",
      "Epoch [1051/10000], Validation Loss: 0.97758099, Validation Accuracy: 0.5735\n",
      "Epoch [1052/10000], Training Loss: 0.58504963, Training Accuracy: 0.9664\n",
      "Epoch [1052/10000], Validation Loss: 0.98505276, Validation Accuracy: 0.5588\n",
      "Epoch [1053/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1053/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [1054/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1054/10000], Validation Loss: 0.99262092, Validation Accuracy: 0.5588\n",
      "Epoch [1055/10000], Training Loss: 0.57245334, Training Accuracy: 0.9790\n",
      "Epoch [1055/10000], Validation Loss: 1.00735119, Validation Accuracy: 0.5441\n",
      "Epoch [1056/10000], Training Loss: 0.59341913, Training Accuracy: 0.9580\n",
      "Epoch [1056/10000], Validation Loss: 1.00732258, Validation Accuracy: 0.5441\n",
      "Epoch [1057/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1057/10000], Validation Loss: 1.00719228, Validation Accuracy: 0.5441\n",
      "Epoch [1058/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1058/10000], Validation Loss: 1.00674987, Validation Accuracy: 0.5441\n",
      "Epoch [1059/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1059/10000], Validation Loss: 1.00634748, Validation Accuracy: 0.5441\n",
      "Epoch [1060/10000], Training Loss: 0.59757624, Training Accuracy: 0.9538\n",
      "Epoch [1060/10000], Validation Loss: 1.00670975, Validation Accuracy: 0.5441\n",
      "Epoch [1061/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1061/10000], Validation Loss: 1.00697359, Validation Accuracy: 0.5441\n",
      "Epoch [1062/10000], Training Loss: 0.58556251, Training Accuracy: 0.9664\n",
      "Epoch [1062/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1063/10000], Training Loss: 0.60186290, Training Accuracy: 0.9496\n",
      "Epoch [1063/10000], Validation Loss: 1.00657752, Validation Accuracy: 0.5441\n",
      "Epoch [1064/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1064/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1065/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1065/10000], Validation Loss: 0.99262238, Validation Accuracy: 0.5588\n",
      "Epoch [1066/10000], Training Loss: 0.59346830, Training Accuracy: 0.9580\n",
      "Epoch [1066/10000], Validation Loss: 0.99261495, Validation Accuracy: 0.5588\n",
      "Epoch [1067/10000], Training Loss: 0.58085666, Training Accuracy: 0.9706\n",
      "Epoch [1067/10000], Validation Loss: 0.98476678, Validation Accuracy: 0.5588\n",
      "Epoch [1068/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1068/10000], Validation Loss: 0.97821942, Validation Accuracy: 0.5735\n",
      "Epoch [1069/10000], Training Loss: 0.59733562, Training Accuracy: 0.9538\n",
      "Epoch [1069/10000], Validation Loss: 0.97629374, Validation Accuracy: 0.5735\n",
      "Epoch [1070/10000], Training Loss: 0.58883813, Training Accuracy: 0.9622\n",
      "Epoch [1070/10000], Validation Loss: 0.97791049, Validation Accuracy: 0.5735\n",
      "Epoch [1071/10000], Training Loss: 0.60570162, Training Accuracy: 0.9454\n",
      "Epoch [1071/10000], Validation Loss: 0.97273073, Validation Accuracy: 0.5735\n",
      "Epoch [1072/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1072/10000], Validation Loss: 0.97776118, Validation Accuracy: 0.5735\n",
      "Epoch [1073/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [1073/10000], Validation Loss: 0.96323124, Validation Accuracy: 0.5882\n",
      "Epoch [1074/10000], Training Loss: 0.58074473, Training Accuracy: 0.9706\n",
      "Epoch [1074/10000], Validation Loss: 0.97749156, Validation Accuracy: 0.5735\n",
      "Epoch [1075/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1075/10000], Validation Loss: 0.99261630, Validation Accuracy: 0.5588\n",
      "Epoch [1076/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [1076/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1077/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1077/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1078/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [1078/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1079/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1079/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1080/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1080/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1081/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1081/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1082/10000], Training Loss: 0.57245308, Training Accuracy: 0.9790\n",
      "Epoch [1082/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1083/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1083/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1084/10000], Training Loss: 0.58085676, Training Accuracy: 0.9706\n",
      "Epoch [1084/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1085/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1085/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1086/10000], Training Loss: 0.57665506, Training Accuracy: 0.9748\n",
      "Epoch [1086/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1087/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1087/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1088/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1088/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1089/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1089/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1090/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1090/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1091/10000], Training Loss: 0.59766591, Training Accuracy: 0.9538\n",
      "Epoch [1091/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1092/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1092/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1093/10000], Training Loss: 0.58085345, Training Accuracy: 0.9706\n",
      "Epoch [1093/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1094/10000], Training Loss: 0.57623155, Training Accuracy: 0.9748\n",
      "Epoch [1094/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [1095/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1095/10000], Validation Loss: 0.97791547, Validation Accuracy: 0.5735\n",
      "Epoch [1096/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1096/10000], Validation Loss: 0.97773331, Validation Accuracy: 0.5735\n",
      "Epoch [1097/10000], Training Loss: 0.57663860, Training Accuracy: 0.9748\n",
      "Epoch [1097/10000], Validation Loss: 0.97791532, Validation Accuracy: 0.5735\n",
      "Epoch [1098/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1098/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1099/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1099/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1100/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1100/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1101/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1101/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1102/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1102/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1103/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1103/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1104/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1104/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1105/10000], Training Loss: 0.58085675, Training Accuracy: 0.9706\n",
      "Epoch [1105/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1106/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1106/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1107/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1107/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1108/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1108/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1109/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1109/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1110/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1110/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1111/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1111/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1112/10000], Training Loss: 0.58123487, Training Accuracy: 0.9706\n",
      "Epoch [1112/10000], Validation Loss: 0.97791585, Validation Accuracy: 0.5735\n",
      "Epoch [1113/10000], Training Loss: 0.59304298, Training Accuracy: 0.9580\n",
      "Epoch [1113/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [1114/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1114/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1115/10000], Training Loss: 0.56825226, Training Accuracy: 0.9832\n",
      "Epoch [1115/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1116/10000], Training Loss: 0.58926562, Training Accuracy: 0.9622\n",
      "Epoch [1116/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1117/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1117/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1118/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1118/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1119/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [1119/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1120/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1120/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1121/10000], Training Loss: 0.58505831, Training Accuracy: 0.9664\n",
      "Epoch [1121/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1122/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1122/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1123/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1123/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1124/10000], Training Loss: 0.58497865, Training Accuracy: 0.9664\n",
      "Epoch [1124/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1125/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1125/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1126/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1126/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1127/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1127/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1128/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1128/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1129/10000], Training Loss: 0.57665331, Training Accuracy: 0.9748\n",
      "Epoch [1129/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1130/10000], Training Loss: 0.56840673, Training Accuracy: 0.9832\n",
      "Epoch [1130/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1131/10000], Training Loss: 0.59350160, Training Accuracy: 0.9580\n",
      "Epoch [1131/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1132/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1132/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1133/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1133/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1134/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1134/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1135/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1135/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1136/10000], Training Loss: 0.58503280, Training Accuracy: 0.9664\n",
      "Epoch [1136/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1137/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1137/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1138/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1138/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1139/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1139/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1140/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [1140/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1141/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1141/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1142/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1142/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1143/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1143/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1144/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1144/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1145/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1145/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1146/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [1146/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1147/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1147/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1148/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1148/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1149/10000], Training Loss: 0.58513648, Training Accuracy: 0.9664\n",
      "Epoch [1149/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1150/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1150/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1151/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1151/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1152/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1152/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1153/10000], Training Loss: 0.57665017, Training Accuracy: 0.9748\n",
      "Epoch [1153/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1154/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1154/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1155/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1155/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1156/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1156/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1157/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1157/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1158/10000], Training Loss: 0.57245339, Training Accuracy: 0.9790\n",
      "Epoch [1158/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1159/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [1159/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1160/10000], Training Loss: 0.59346331, Training Accuracy: 0.9580\n",
      "Epoch [1160/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1161/10000], Training Loss: 0.58926025, Training Accuracy: 0.9622\n",
      "Epoch [1161/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1162/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [1162/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1163/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [1163/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1164/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1164/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1165/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1165/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1166/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [1166/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1167/10000], Training Loss: 0.57665499, Training Accuracy: 0.9748\n",
      "Epoch [1167/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1168/10000], Training Loss: 0.57669224, Training Accuracy: 0.9748\n",
      "Epoch [1168/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1169/10000], Training Loss: 0.58085603, Training Accuracy: 0.9706\n",
      "Epoch [1169/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1170/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1170/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1171/10000], Training Loss: 0.57664780, Training Accuracy: 0.9748\n",
      "Epoch [1171/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1172/10000], Training Loss: 0.56790044, Training Accuracy: 0.9832\n",
      "Epoch [1172/10000], Validation Loss: 1.03673893, Validation Accuracy: 0.5147\n",
      "Epoch [1173/10000], Training Loss: 0.57665500, Training Accuracy: 0.9748\n",
      "Epoch [1173/10000], Validation Loss: 1.03673831, Validation Accuracy: 0.5147\n",
      "Epoch [1174/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1174/10000], Validation Loss: 1.03673753, Validation Accuracy: 0.5147\n",
      "Epoch [1175/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [1175/10000], Validation Loss: 1.03673685, Validation Accuracy: 0.5147\n",
      "Epoch [1176/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1176/10000], Validation Loss: 1.03673646, Validation Accuracy: 0.5147\n",
      "Epoch [1177/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1177/10000], Validation Loss: 1.03673622, Validation Accuracy: 0.5147\n",
      "Epoch [1178/10000], Training Loss: 0.58925353, Training Accuracy: 0.9622\n",
      "Epoch [1178/10000], Validation Loss: 1.03673634, Validation Accuracy: 0.5147\n",
      "Epoch [1179/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1179/10000], Validation Loss: 1.03673658, Validation Accuracy: 0.5147\n",
      "Epoch [1180/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1180/10000], Validation Loss: 1.03673667, Validation Accuracy: 0.5147\n",
      "Epoch [1181/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1181/10000], Validation Loss: 1.03673673, Validation Accuracy: 0.5147\n",
      "Epoch [1182/10000], Training Loss: 0.57658548, Training Accuracy: 0.9748\n",
      "Epoch [1182/10000], Validation Loss: 1.03669786, Validation Accuracy: 0.5147\n",
      "Epoch [1183/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1183/10000], Validation Loss: 1.03615016, Validation Accuracy: 0.5147\n",
      "Epoch [1184/10000], Training Loss: 0.58505654, Training Accuracy: 0.9664\n",
      "Epoch [1184/10000], Validation Loss: 1.03547475, Validation Accuracy: 0.5147\n",
      "Epoch [1185/10000], Training Loss: 0.57665514, Training Accuracy: 0.9748\n",
      "Epoch [1185/10000], Validation Loss: 1.03536749, Validation Accuracy: 0.5147\n",
      "Epoch [1186/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1186/10000], Validation Loss: 1.03541866, Validation Accuracy: 0.5147\n",
      "Epoch [1187/10000], Training Loss: 0.57886629, Training Accuracy: 0.9706\n",
      "Epoch [1187/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1188/10000], Training Loss: 0.59350439, Training Accuracy: 0.9580\n",
      "Epoch [1188/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1189/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [1189/10000], Validation Loss: 0.94848073, Validation Accuracy: 0.6029\n",
      "Epoch [1190/10000], Training Loss: 0.63963509, Training Accuracy: 0.9118\n",
      "Epoch [1190/10000], Validation Loss: 0.94988236, Validation Accuracy: 0.6029\n",
      "Epoch [1191/10000], Training Loss: 0.63547017, Training Accuracy: 0.9160\n",
      "Epoch [1191/10000], Validation Loss: 0.94889989, Validation Accuracy: 0.6029\n",
      "Epoch [1192/10000], Training Loss: 0.63968791, Training Accuracy: 0.9118\n",
      "Epoch [1192/10000], Validation Loss: 0.93403652, Validation Accuracy: 0.6176\n",
      "Epoch [1193/10000], Training Loss: 0.63547968, Training Accuracy: 0.9160\n",
      "Epoch [1193/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [1194/10000], Training Loss: 0.64388254, Training Accuracy: 0.9076\n",
      "Epoch [1194/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [1195/10000], Training Loss: 0.63547871, Training Accuracy: 0.9160\n",
      "Epoch [1195/10000], Validation Loss: 0.93379778, Validation Accuracy: 0.6176\n",
      "Epoch [1196/10000], Training Loss: 0.63121911, Training Accuracy: 0.9202\n",
      "Epoch [1196/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [1197/10000], Training Loss: 0.65227492, Training Accuracy: 0.8992\n",
      "Epoch [1197/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [1198/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [1198/10000], Validation Loss: 0.93450356, Validation Accuracy: 0.6176\n",
      "Epoch [1199/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [1199/10000], Validation Loss: 0.94844142, Validation Accuracy: 0.6029\n",
      "Epoch [1200/10000], Training Loss: 0.64387040, Training Accuracy: 0.9076\n",
      "Epoch [1200/10000], Validation Loss: 0.94827193, Validation Accuracy: 0.6029\n",
      "Epoch [1201/10000], Training Loss: 0.62208838, Training Accuracy: 0.9286\n",
      "Epoch [1201/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1202/10000], Training Loss: 0.62707544, Training Accuracy: 0.9244\n",
      "Epoch [1202/10000], Validation Loss: 0.96345422, Validation Accuracy: 0.5882\n",
      "Epoch [1203/10000], Training Loss: 0.61446324, Training Accuracy: 0.9370\n",
      "Epoch [1203/10000], Validation Loss: 0.98937941, Validation Accuracy: 0.5588\n",
      "Epoch [1204/10000], Training Loss: 0.62717283, Training Accuracy: 0.9244\n",
      "Epoch [1204/10000], Validation Loss: 0.99260357, Validation Accuracy: 0.5588\n",
      "Epoch [1205/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1205/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1206/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [1206/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1207/10000], Training Loss: 0.61165191, Training Accuracy: 0.9412\n",
      "Epoch [1207/10000], Validation Loss: 0.96333867, Validation Accuracy: 0.5882\n",
      "Epoch [1208/10000], Training Loss: 0.63127748, Training Accuracy: 0.9202\n",
      "Epoch [1208/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1209/10000], Training Loss: 0.66912216, Training Accuracy: 0.8824\n",
      "Epoch [1209/10000], Validation Loss: 0.94850048, Validation Accuracy: 0.6029\n",
      "Epoch [1210/10000], Training Loss: 0.69049830, Training Accuracy: 0.8613\n",
      "Epoch [1210/10000], Validation Loss: 0.91725525, Validation Accuracy: 0.6324\n",
      "Epoch [1211/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [1211/10000], Validation Loss: 0.92613393, Validation Accuracy: 0.6176\n",
      "Epoch [1212/10000], Training Loss: 0.67470297, Training Accuracy: 0.8782\n",
      "Epoch [1212/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1213/10000], Training Loss: 0.63565293, Training Accuracy: 0.9160\n",
      "Epoch [1213/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1214/10000], Training Loss: 0.62303309, Training Accuracy: 0.9286\n",
      "Epoch [1214/10000], Validation Loss: 0.99259561, Validation Accuracy: 0.5588\n",
      "Epoch [1215/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [1215/10000], Validation Loss: 1.00325871, Validation Accuracy: 0.5441\n",
      "Epoch [1216/10000], Training Loss: 0.61866957, Training Accuracy: 0.9328\n",
      "Epoch [1216/10000], Validation Loss: 0.99243903, Validation Accuracy: 0.5588\n",
      "Epoch [1217/10000], Training Loss: 0.62262754, Training Accuracy: 0.9286\n",
      "Epoch [1217/10000], Validation Loss: 0.96098858, Validation Accuracy: 0.5882\n",
      "Epoch [1218/10000], Training Loss: 0.61943303, Training Accuracy: 0.9328\n",
      "Epoch [1218/10000], Validation Loss: 0.91904777, Validation Accuracy: 0.6324\n",
      "Epoch [1219/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1219/10000], Validation Loss: 0.92115468, Validation Accuracy: 0.6324\n",
      "Epoch [1220/10000], Training Loss: 0.59346168, Training Accuracy: 0.9580\n",
      "Epoch [1220/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1221/10000], Training Loss: 0.59345158, Training Accuracy: 0.9580\n",
      "Epoch [1221/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1222/10000], Training Loss: 0.58095889, Training Accuracy: 0.9706\n",
      "Epoch [1222/10000], Validation Loss: 0.93340331, Validation Accuracy: 0.6176\n",
      "Epoch [1223/10000], Training Loss: 0.59012382, Training Accuracy: 0.9622\n",
      "Epoch [1223/10000], Validation Loss: 0.95095831, Validation Accuracy: 0.5882\n",
      "Epoch [1224/10000], Training Loss: 0.59766277, Training Accuracy: 0.9538\n",
      "Epoch [1224/10000], Validation Loss: 0.96305904, Validation Accuracy: 0.5882\n",
      "Epoch [1225/10000], Training Loss: 0.61446956, Training Accuracy: 0.9370\n",
      "Epoch [1225/10000], Validation Loss: 0.96317804, Validation Accuracy: 0.5882\n",
      "Epoch [1226/10000], Training Loss: 0.58926005, Training Accuracy: 0.9622\n",
      "Epoch [1226/10000], Validation Loss: 0.96318009, Validation Accuracy: 0.5882\n",
      "Epoch [1227/10000], Training Loss: 0.57665613, Training Accuracy: 0.9748\n",
      "Epoch [1227/10000], Validation Loss: 0.94956553, Validation Accuracy: 0.6029\n",
      "Epoch [1228/10000], Training Loss: 0.59766847, Training Accuracy: 0.9538\n",
      "Epoch [1228/10000], Validation Loss: 0.96315542, Validation Accuracy: 0.5882\n",
      "Epoch [1229/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1229/10000], Validation Loss: 0.96320736, Validation Accuracy: 0.5882\n",
      "Epoch [1230/10000], Training Loss: 0.59345961, Training Accuracy: 0.9580\n",
      "Epoch [1230/10000], Validation Loss: 0.96320879, Validation Accuracy: 0.5882\n",
      "Epoch [1231/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1231/10000], Validation Loss: 0.96320894, Validation Accuracy: 0.5882\n",
      "Epoch [1232/10000], Training Loss: 0.60642961, Training Accuracy: 0.9454\n",
      "Epoch [1232/10000], Validation Loss: 0.96320528, Validation Accuracy: 0.5882\n",
      "Epoch [1233/10000], Training Loss: 0.58466112, Training Accuracy: 0.9664\n",
      "Epoch [1233/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1234/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1234/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1235/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1235/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [1236/10000], Training Loss: 0.57994243, Training Accuracy: 0.9706\n",
      "Epoch [1236/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [1237/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1237/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1238/10000], Training Loss: 0.59761198, Training Accuracy: 0.9538\n",
      "Epoch [1238/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1239/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1239/10000], Validation Loss: 0.98830611, Validation Accuracy: 0.5588\n",
      "Epoch [1240/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1240/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1241/10000], Training Loss: 0.58507850, Training Accuracy: 0.9664\n",
      "Epoch [1241/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [1242/10000], Training Loss: 0.58082569, Training Accuracy: 0.9706\n",
      "Epoch [1242/10000], Validation Loss: 0.99262181, Validation Accuracy: 0.5588\n",
      "Epoch [1243/10000], Training Loss: 0.57665371, Training Accuracy: 0.9748\n",
      "Epoch [1243/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1244/10000], Training Loss: 0.58772876, Training Accuracy: 0.9622\n",
      "Epoch [1244/10000], Validation Loss: 1.03289053, Validation Accuracy: 0.5147\n",
      "Epoch [1245/10000], Training Loss: 0.59766298, Training Accuracy: 0.9538\n",
      "Epoch [1245/10000], Validation Loss: 1.07988352, Validation Accuracy: 0.4706\n",
      "Epoch [1246/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [1246/10000], Validation Loss: 1.06325829, Validation Accuracy: 0.4853\n",
      "Epoch [1247/10000], Training Loss: 0.62287381, Training Accuracy: 0.9286\n",
      "Epoch [1247/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1248/10000], Training Loss: 0.59574211, Training Accuracy: 0.9538\n",
      "Epoch [1248/10000], Validation Loss: 1.05098596, Validation Accuracy: 0.5000\n",
      "Epoch [1249/10000], Training Loss: 0.60597693, Training Accuracy: 0.9454\n",
      "Epoch [1249/10000], Validation Loss: 1.00569519, Validation Accuracy: 0.5441\n",
      "Epoch [1250/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1250/10000], Validation Loss: 0.97754008, Validation Accuracy: 0.5735\n",
      "Epoch [1251/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1251/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1252/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1252/10000], Validation Loss: 0.95125023, Validation Accuracy: 0.6029\n",
      "Epoch [1253/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1253/10000], Validation Loss: 0.93384078, Validation Accuracy: 0.6176\n",
      "Epoch [1254/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1254/10000], Validation Loss: 0.93381453, Validation Accuracy: 0.6176\n",
      "Epoch [1255/10000], Training Loss: 0.58505843, Training Accuracy: 0.9664\n",
      "Epoch [1255/10000], Validation Loss: 0.93380952, Validation Accuracy: 0.6176\n",
      "Epoch [1256/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1256/10000], Validation Loss: 0.93380773, Validation Accuracy: 0.6176\n",
      "Epoch [1257/10000], Training Loss: 0.57245321, Training Accuracy: 0.9790\n",
      "Epoch [1257/10000], Validation Loss: 0.93380710, Validation Accuracy: 0.6176\n",
      "Epoch [1258/10000], Training Loss: 0.57665502, Training Accuracy: 0.9748\n",
      "Epoch [1258/10000], Validation Loss: 0.93380690, Validation Accuracy: 0.6176\n",
      "Epoch [1259/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1259/10000], Validation Loss: 0.93380678, Validation Accuracy: 0.6176\n",
      "Epoch [1260/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1260/10000], Validation Loss: 0.93380672, Validation Accuracy: 0.6176\n",
      "Epoch [1261/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1261/10000], Validation Loss: 0.93380672, Validation Accuracy: 0.6176\n",
      "Epoch [1262/10000], Training Loss: 0.57337287, Training Accuracy: 0.9790\n",
      "Epoch [1262/10000], Validation Loss: 0.93379858, Validation Accuracy: 0.6176\n",
      "Epoch [1263/10000], Training Loss: 0.57245322, Training Accuracy: 0.9790\n",
      "Epoch [1263/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1264/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1264/10000], Validation Loss: 0.91936812, Validation Accuracy: 0.6324\n",
      "Epoch [1265/10000], Training Loss: 0.57677625, Training Accuracy: 0.9748\n",
      "Epoch [1265/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1266/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1266/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1267/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1267/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1268/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1268/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1269/10000], Training Loss: 0.57626252, Training Accuracy: 0.9748\n",
      "Epoch [1269/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1270/10000], Training Loss: 0.57665328, Training Accuracy: 0.9748\n",
      "Epoch [1270/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1271/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1271/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1272/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1272/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1273/10000], Training Loss: 0.58925710, Training Accuracy: 0.9622\n",
      "Epoch [1273/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1274/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1274/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1275/10000], Training Loss: 0.56825129, Training Accuracy: 0.9832\n",
      "Epoch [1275/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1276/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1276/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1277/10000], Training Loss: 0.61272864, Training Accuracy: 0.9370\n",
      "Epoch [1277/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1278/10000], Training Loss: 0.57253448, Training Accuracy: 0.9790\n",
      "Epoch [1278/10000], Validation Loss: 0.94850180, Validation Accuracy: 0.6029\n",
      "Epoch [1279/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1279/10000], Validation Loss: 0.93382430, Validation Accuracy: 0.6176\n",
      "Epoch [1280/10000], Training Loss: 0.57664882, Training Accuracy: 0.9748\n",
      "Epoch [1280/10000], Validation Loss: 0.93379632, Validation Accuracy: 0.6176\n",
      "Epoch [1281/10000], Training Loss: 0.59754603, Training Accuracy: 0.9538\n",
      "Epoch [1281/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1282/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1282/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1283/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1283/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1284/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1284/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1285/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [1285/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1286/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1286/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1287/10000], Training Loss: 0.58085661, Training Accuracy: 0.9706\n",
      "Epoch [1287/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1288/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1288/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1289/10000], Training Loss: 0.58926012, Training Accuracy: 0.9622\n",
      "Epoch [1289/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1290/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1290/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1291/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1291/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1292/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1292/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1293/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1293/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1294/10000], Training Loss: 0.56405000, Training Accuracy: 0.9874\n",
      "Epoch [1294/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1295/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1295/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1296/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1296/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1297/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1297/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1298/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [1298/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1299/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1299/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1300/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1300/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1301/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1301/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1302/10000], Training Loss: 0.58926033, Training Accuracy: 0.9622\n",
      "Epoch [1302/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1303/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1303/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1304/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1304/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1305/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1305/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1306/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1306/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1307/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1307/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1308/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1308/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1309/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1309/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1310/10000], Training Loss: 0.55984832, Training Accuracy: 0.9916\n",
      "Epoch [1310/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1311/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1311/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1312/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1312/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1313/10000], Training Loss: 0.57665506, Training Accuracy: 0.9748\n",
      "Epoch [1313/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1314/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1314/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1315/10000], Training Loss: 0.58085641, Training Accuracy: 0.9706\n",
      "Epoch [1315/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1316/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1316/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1317/10000], Training Loss: 0.57245332, Training Accuracy: 0.9790\n",
      "Epoch [1317/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1318/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [1318/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1319/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1319/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1320/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1320/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1321/10000], Training Loss: 0.58846819, Training Accuracy: 0.9622\n",
      "Epoch [1321/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [1322/10000], Training Loss: 0.57668081, Training Accuracy: 0.9748\n",
      "Epoch [1322/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1323/10000], Training Loss: 0.58068264, Training Accuracy: 0.9706\n",
      "Epoch [1323/10000], Validation Loss: 0.91909164, Validation Accuracy: 0.6324\n",
      "Epoch [1324/10000], Training Loss: 0.58924819, Training Accuracy: 0.9622\n",
      "Epoch [1324/10000], Validation Loss: 0.91894045, Validation Accuracy: 0.6324\n",
      "Epoch [1325/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [1325/10000], Validation Loss: 0.91908988, Validation Accuracy: 0.6324\n",
      "Epoch [1326/10000], Training Loss: 0.57665501, Training Accuracy: 0.9748\n",
      "Epoch [1326/10000], Validation Loss: 0.91909176, Validation Accuracy: 0.6324\n",
      "Epoch [1327/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1327/10000], Validation Loss: 0.91909191, Validation Accuracy: 0.6324\n",
      "Epoch [1328/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [1328/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [1329/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1329/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1330/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1330/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1331/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [1331/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1332/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1332/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1333/10000], Training Loss: 0.59346174, Training Accuracy: 0.9580\n",
      "Epoch [1333/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1334/10000], Training Loss: 0.57550197, Training Accuracy: 0.9748\n",
      "Epoch [1334/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1335/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1335/10000], Validation Loss: 0.99315718, Validation Accuracy: 0.5588\n",
      "Epoch [1336/10000], Training Loss: 0.57670672, Training Accuracy: 0.9748\n",
      "Epoch [1336/10000], Validation Loss: 0.99261811, Validation Accuracy: 0.5588\n",
      "Epoch [1337/10000], Training Loss: 0.57245297, Training Accuracy: 0.9790\n",
      "Epoch [1337/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1338/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1338/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1339/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1339/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1340/10000], Training Loss: 0.58505844, Training Accuracy: 0.9664\n",
      "Epoch [1340/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1341/10000], Training Loss: 0.58921535, Training Accuracy: 0.9622\n",
      "Epoch [1341/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1342/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1342/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1343/10000], Training Loss: 0.59766453, Training Accuracy: 0.9538\n",
      "Epoch [1343/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1344/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1344/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1345/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1345/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1346/10000], Training Loss: 0.59766333, Training Accuracy: 0.9538\n",
      "Epoch [1346/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1347/10000], Training Loss: 0.58925949, Training Accuracy: 0.9622\n",
      "Epoch [1347/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1348/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1348/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1349/10000], Training Loss: 0.59345324, Training Accuracy: 0.9580\n",
      "Epoch [1349/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1350/10000], Training Loss: 0.59767698, Training Accuracy: 0.9538\n",
      "Epoch [1350/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1351/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1351/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1352/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1352/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1353/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1353/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1354/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1354/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1355/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1355/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1356/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1356/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1357/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1357/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1358/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1358/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1359/10000], Training Loss: 0.58926004, Training Accuracy: 0.9622\n",
      "Epoch [1359/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1360/10000], Training Loss: 0.60178547, Training Accuracy: 0.9496\n",
      "Epoch [1360/10000], Validation Loss: 0.97791532, Validation Accuracy: 0.5735\n",
      "Epoch [1361/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1361/10000], Validation Loss: 0.96338233, Validation Accuracy: 0.5882\n",
      "Epoch [1362/10000], Training Loss: 0.57658167, Training Accuracy: 0.9748\n",
      "Epoch [1362/10000], Validation Loss: 0.96321163, Validation Accuracy: 0.5882\n",
      "Epoch [1363/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1363/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1364/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1364/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1365/10000], Training Loss: 0.57338396, Training Accuracy: 0.9790\n",
      "Epoch [1365/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1366/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [1366/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1367/10000], Training Loss: 0.58505829, Training Accuracy: 0.9664\n",
      "Epoch [1367/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1368/10000], Training Loss: 0.58506585, Training Accuracy: 0.9664\n",
      "Epoch [1368/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1369/10000], Training Loss: 0.60186866, Training Accuracy: 0.9496\n",
      "Epoch [1369/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1370/10000], Training Loss: 0.58085988, Training Accuracy: 0.9706\n",
      "Epoch [1370/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1371/10000], Training Loss: 0.61446352, Training Accuracy: 0.9370\n",
      "Epoch [1371/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1372/10000], Training Loss: 0.59346708, Training Accuracy: 0.9580\n",
      "Epoch [1372/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1373/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [1373/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1374/10000], Training Loss: 0.58501473, Training Accuracy: 0.9664\n",
      "Epoch [1374/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1375/10000], Training Loss: 0.60644882, Training Accuracy: 0.9454\n",
      "Epoch [1375/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1376/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [1376/10000], Validation Loss: 0.99226981, Validation Accuracy: 0.5588\n",
      "Epoch [1377/10000], Training Loss: 0.58925796, Training Accuracy: 0.9622\n",
      "Epoch [1377/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1378/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1378/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1379/10000], Training Loss: 0.57245368, Training Accuracy: 0.9790\n",
      "Epoch [1379/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1380/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1380/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1381/10000], Training Loss: 0.59259992, Training Accuracy: 0.9580\n",
      "Epoch [1381/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1382/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1382/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [1383/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [1383/10000], Validation Loss: 0.99261835, Validation Accuracy: 0.5588\n",
      "Epoch [1384/10000], Training Loss: 0.58925949, Training Accuracy: 0.9622\n",
      "Epoch [1384/10000], Validation Loss: 0.99259630, Validation Accuracy: 0.5588\n",
      "Epoch [1385/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1385/10000], Validation Loss: 0.99255267, Validation Accuracy: 0.5588\n",
      "Epoch [1386/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1386/10000], Validation Loss: 0.99250981, Validation Accuracy: 0.5588\n",
      "Epoch [1387/10000], Training Loss: 0.58925984, Training Accuracy: 0.9622\n",
      "Epoch [1387/10000], Validation Loss: 0.99248019, Validation Accuracy: 0.5588\n",
      "Epoch [1388/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1388/10000], Validation Loss: 0.99246302, Validation Accuracy: 0.5588\n",
      "Epoch [1389/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1389/10000], Validation Loss: 0.99245408, Validation Accuracy: 0.5588\n",
      "Epoch [1390/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [1390/10000], Validation Loss: 0.99244961, Validation Accuracy: 0.5588\n",
      "Epoch [1391/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [1391/10000], Validation Loss: 0.99244747, Validation Accuracy: 0.5588\n",
      "Epoch [1392/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1392/10000], Validation Loss: 0.99244645, Validation Accuracy: 0.5588\n",
      "Epoch [1393/10000], Training Loss: 0.58085665, Training Accuracy: 0.9706\n",
      "Epoch [1393/10000], Validation Loss: 0.99244550, Validation Accuracy: 0.5588\n",
      "Epoch [1394/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1394/10000], Validation Loss: 0.99244455, Validation Accuracy: 0.5588\n",
      "Epoch [1395/10000], Training Loss: 0.60147259, Training Accuracy: 0.9496\n",
      "Epoch [1395/10000], Validation Loss: 0.99236992, Validation Accuracy: 0.5588\n",
      "Epoch [1396/10000], Training Loss: 0.58926019, Training Accuracy: 0.9622\n",
      "Epoch [1396/10000], Validation Loss: 0.99232921, Validation Accuracy: 0.5588\n",
      "Epoch [1397/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1397/10000], Validation Loss: 0.99231061, Validation Accuracy: 0.5588\n",
      "Epoch [1398/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [1398/10000], Validation Loss: 0.99230132, Validation Accuracy: 0.5588\n",
      "Epoch [1399/10000], Training Loss: 0.59444665, Training Accuracy: 0.9580\n",
      "Epoch [1399/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1400/10000], Training Loss: 0.58925963, Training Accuracy: 0.9622\n",
      "Epoch [1400/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1401/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1401/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1402/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [1402/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1403/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1403/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1404/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1404/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1405/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1405/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1406/10000], Training Loss: 0.58084715, Training Accuracy: 0.9706\n",
      "Epoch [1406/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1407/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1407/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1408/10000], Training Loss: 0.58919538, Training Accuracy: 0.9622\n",
      "Epoch [1408/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1409/10000], Training Loss: 0.60182639, Training Accuracy: 0.9496\n",
      "Epoch [1409/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1410/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1410/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1411/10000], Training Loss: 0.58926023, Training Accuracy: 0.9622\n",
      "Epoch [1411/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1412/10000], Training Loss: 0.58085689, Training Accuracy: 0.9706\n",
      "Epoch [1412/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1413/10000], Training Loss: 0.58505910, Training Accuracy: 0.9664\n",
      "Epoch [1413/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1414/10000], Training Loss: 0.58085651, Training Accuracy: 0.9706\n",
      "Epoch [1414/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [1415/10000], Training Loss: 0.60781837, Training Accuracy: 0.9454\n",
      "Epoch [1415/10000], Validation Loss: 0.99593639, Validation Accuracy: 0.5588\n",
      "Epoch [1416/10000], Training Loss: 0.70269780, Training Accuracy: 0.8487\n",
      "Epoch [1416/10000], Validation Loss: 1.12489617, Validation Accuracy: 0.4265\n",
      "Epoch [1417/10000], Training Loss: 0.76578555, Training Accuracy: 0.7857\n",
      "Epoch [1417/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [1418/10000], Training Loss: 0.80354736, Training Accuracy: 0.7479\n",
      "Epoch [1418/10000], Validation Loss: 1.18379784, Validation Accuracy: 0.3676\n",
      "Epoch [1419/10000], Training Loss: 0.78683447, Training Accuracy: 0.7647\n",
      "Epoch [1419/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [1420/10000], Training Loss: 0.78711942, Training Accuracy: 0.7647\n",
      "Epoch [1420/10000], Validation Loss: 1.18379784, Validation Accuracy: 0.3676\n",
      "Epoch [1421/10000], Training Loss: 0.77266492, Training Accuracy: 0.7773\n",
      "Epoch [1421/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [1422/10000], Training Loss: 0.73994234, Training Accuracy: 0.8109\n",
      "Epoch [1422/10000], Validation Loss: 1.05144495, Validation Accuracy: 0.5000\n",
      "Epoch [1423/10000], Training Loss: 0.67332829, Training Accuracy: 0.8782\n",
      "Epoch [1423/10000], Validation Loss: 1.00732735, Validation Accuracy: 0.5441\n",
      "Epoch [1424/10000], Training Loss: 0.66060743, Training Accuracy: 0.8908\n",
      "Epoch [1424/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1425/10000], Training Loss: 0.62755273, Training Accuracy: 0.9244\n",
      "Epoch [1425/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1426/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [1426/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1427/10000], Training Loss: 0.60965692, Training Accuracy: 0.9412\n",
      "Epoch [1427/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1428/10000], Training Loss: 0.61030340, Training Accuracy: 0.9412\n",
      "Epoch [1428/10000], Validation Loss: 0.97791573, Validation Accuracy: 0.5735\n",
      "Epoch [1429/10000], Training Loss: 0.61437993, Training Accuracy: 0.9370\n",
      "Epoch [1429/10000], Validation Loss: 0.97808075, Validation Accuracy: 0.5735\n",
      "Epoch [1430/10000], Training Loss: 0.62701041, Training Accuracy: 0.9244\n",
      "Epoch [1430/10000], Validation Loss: 0.97862375, Validation Accuracy: 0.5735\n",
      "Epoch [1431/10000], Training Loss: 0.62706508, Training Accuracy: 0.9244\n",
      "Epoch [1431/10000], Validation Loss: 0.97791892, Validation Accuracy: 0.5735\n",
      "Epoch [1432/10000], Training Loss: 0.61871316, Training Accuracy: 0.9286\n",
      "Epoch [1432/10000], Validation Loss: 0.96189299, Validation Accuracy: 0.5882\n",
      "Epoch [1433/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [1433/10000], Validation Loss: 0.97777569, Validation Accuracy: 0.5735\n",
      "Epoch [1434/10000], Training Loss: 0.64188272, Training Accuracy: 0.9076\n",
      "Epoch [1434/10000], Validation Loss: 0.96320966, Validation Accuracy: 0.5882\n",
      "Epoch [1435/10000], Training Loss: 0.61026718, Training Accuracy: 0.9412\n",
      "Epoch [1435/10000], Validation Loss: 0.93377721, Validation Accuracy: 0.6176\n",
      "Epoch [1436/10000], Training Loss: 0.61059449, Training Accuracy: 0.9412\n",
      "Epoch [1436/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1437/10000], Training Loss: 0.61867020, Training Accuracy: 0.9328\n",
      "Epoch [1437/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1438/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [1438/10000], Validation Loss: 0.87881497, Validation Accuracy: 0.6765\n",
      "Epoch [1439/10000], Training Loss: 0.60585082, Training Accuracy: 0.9454\n",
      "Epoch [1439/10000], Validation Loss: 0.88968030, Validation Accuracy: 0.6618\n",
      "Epoch [1440/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1440/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1441/10000], Training Loss: 0.59346237, Training Accuracy: 0.9580\n",
      "Epoch [1441/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1442/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [1442/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1443/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [1443/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1444/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [1444/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1445/10000], Training Loss: 0.61446993, Training Accuracy: 0.9370\n",
      "Epoch [1445/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1446/10000], Training Loss: 0.62334760, Training Accuracy: 0.9286\n",
      "Epoch [1446/10000], Validation Loss: 0.88968027, Validation Accuracy: 0.6618\n",
      "Epoch [1447/10000], Training Loss: 0.62495076, Training Accuracy: 0.9244\n",
      "Epoch [1447/10000], Validation Loss: 0.87691012, Validation Accuracy: 0.6765\n",
      "Epoch [1448/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [1448/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1449/10000], Training Loss: 0.61867293, Training Accuracy: 0.9328\n",
      "Epoch [1449/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1450/10000], Training Loss: 0.61843771, Training Accuracy: 0.9328\n",
      "Epoch [1450/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1451/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [1451/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [1452/10000], Training Loss: 0.62287187, Training Accuracy: 0.9286\n",
      "Epoch [1452/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1453/10000], Training Loss: 0.64388199, Training Accuracy: 0.9076\n",
      "Epoch [1453/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1454/10000], Training Loss: 0.60655036, Training Accuracy: 0.9454\n",
      "Epoch [1454/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1455/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1455/10000], Validation Loss: 0.90438196, Validation Accuracy: 0.6471\n",
      "Epoch [1456/10000], Training Loss: 0.61026820, Training Accuracy: 0.9412\n",
      "Epoch [1456/10000], Validation Loss: 0.90399808, Validation Accuracy: 0.6471\n",
      "Epoch [1457/10000], Training Loss: 0.60606704, Training Accuracy: 0.9454\n",
      "Epoch [1457/10000], Validation Loss: 0.90085718, Validation Accuracy: 0.6471\n",
      "Epoch [1458/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [1458/10000], Validation Loss: 0.89684355, Validation Accuracy: 0.6471\n",
      "Epoch [1459/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1459/10000], Validation Loss: 0.89477885, Validation Accuracy: 0.6618\n",
      "Epoch [1460/10000], Training Loss: 0.62241886, Training Accuracy: 0.9286\n",
      "Epoch [1460/10000], Validation Loss: 0.90438595, Validation Accuracy: 0.6471\n",
      "Epoch [1461/10000], Training Loss: 0.61310714, Training Accuracy: 0.9370\n",
      "Epoch [1461/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1462/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [1462/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1463/10000], Training Loss: 0.61904048, Training Accuracy: 0.9328\n",
      "Epoch [1463/10000], Validation Loss: 0.93378943, Validation Accuracy: 0.6176\n",
      "Epoch [1464/10000], Training Loss: 0.60729967, Training Accuracy: 0.9454\n",
      "Epoch [1464/10000], Validation Loss: 0.87390077, Validation Accuracy: 0.6765\n",
      "Epoch [1465/10000], Training Loss: 0.61797710, Training Accuracy: 0.9328\n",
      "Epoch [1465/10000], Validation Loss: 0.90411887, Validation Accuracy: 0.6471\n",
      "Epoch [1466/10000], Training Loss: 0.60987610, Training Accuracy: 0.9412\n",
      "Epoch [1466/10000], Validation Loss: 0.90432099, Validation Accuracy: 0.6471\n",
      "Epoch [1467/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1467/10000], Validation Loss: 0.90434790, Validation Accuracy: 0.6471\n",
      "Epoch [1468/10000], Training Loss: 0.61447091, Training Accuracy: 0.9370\n",
      "Epoch [1468/10000], Validation Loss: 0.90435567, Validation Accuracy: 0.6471\n",
      "Epoch [1469/10000], Training Loss: 0.61445958, Training Accuracy: 0.9370\n",
      "Epoch [1469/10000], Validation Loss: 0.90436316, Validation Accuracy: 0.6471\n",
      "Epoch [1470/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1470/10000], Validation Loss: 0.90436777, Validation Accuracy: 0.6471\n",
      "Epoch [1471/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [1471/10000], Validation Loss: 0.90436962, Validation Accuracy: 0.6471\n",
      "Epoch [1472/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1472/10000], Validation Loss: 0.90437037, Validation Accuracy: 0.6471\n",
      "Epoch [1473/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [1473/10000], Validation Loss: 0.90437073, Validation Accuracy: 0.6471\n",
      "Epoch [1474/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1474/10000], Validation Loss: 0.90437090, Validation Accuracy: 0.6471\n",
      "Epoch [1475/10000], Training Loss: 0.62281863, Training Accuracy: 0.9286\n",
      "Epoch [1475/10000], Validation Loss: 0.90438604, Validation Accuracy: 0.6471\n",
      "Epoch [1476/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1476/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1477/10000], Training Loss: 0.59347374, Training Accuracy: 0.9580\n",
      "Epoch [1477/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1478/10000], Training Loss: 0.60606672, Training Accuracy: 0.9454\n",
      "Epoch [1478/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1479/10000], Training Loss: 0.60186507, Training Accuracy: 0.9496\n",
      "Epoch [1479/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1480/10000], Training Loss: 0.59779311, Training Accuracy: 0.9538\n",
      "Epoch [1480/10000], Validation Loss: 0.90437835, Validation Accuracy: 0.6471\n",
      "Epoch [1481/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1481/10000], Validation Loss: 0.90336585, Validation Accuracy: 0.6471\n",
      "Epoch [1482/10000], Training Loss: 0.59733017, Training Accuracy: 0.9538\n",
      "Epoch [1482/10000], Validation Loss: 0.90438342, Validation Accuracy: 0.6471\n",
      "Epoch [1483/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [1483/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1484/10000], Training Loss: 0.60606683, Training Accuracy: 0.9454\n",
      "Epoch [1484/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1485/10000], Training Loss: 0.60579094, Training Accuracy: 0.9454\n",
      "Epoch [1485/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [1486/10000], Training Loss: 0.61342967, Training Accuracy: 0.9370\n",
      "Epoch [1486/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [1487/10000], Training Loss: 0.61299990, Training Accuracy: 0.9370\n",
      "Epoch [1487/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1488/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1488/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1489/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1489/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1490/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1490/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1491/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1491/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1492/10000], Training Loss: 0.59340166, Training Accuracy: 0.9580\n",
      "Epoch [1492/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1493/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1493/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1494/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1494/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1495/10000], Training Loss: 0.59766488, Training Accuracy: 0.9538\n",
      "Epoch [1495/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1496/10000], Training Loss: 0.59352497, Training Accuracy: 0.9580\n",
      "Epoch [1496/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1497/10000], Training Loss: 0.60604216, Training Accuracy: 0.9454\n",
      "Epoch [1497/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1498/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1498/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1499/10000], Training Loss: 0.60606724, Training Accuracy: 0.9454\n",
      "Epoch [1499/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1500/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [1500/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1501/10000], Training Loss: 0.60277024, Training Accuracy: 0.9496\n",
      "Epoch [1501/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1502/10000], Training Loss: 0.61860716, Training Accuracy: 0.9328\n",
      "Epoch [1502/10000], Validation Loss: 0.96320984, Validation Accuracy: 0.5882\n",
      "Epoch [1503/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1503/10000], Validation Loss: 0.96323204, Validation Accuracy: 0.5882\n",
      "Epoch [1504/10000], Training Loss: 0.60095664, Training Accuracy: 0.9496\n",
      "Epoch [1504/10000], Validation Loss: 0.94847867, Validation Accuracy: 0.6029\n",
      "Epoch [1505/10000], Training Loss: 0.62287347, Training Accuracy: 0.9286\n",
      "Epoch [1505/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1506/10000], Training Loss: 0.61627612, Training Accuracy: 0.9370\n",
      "Epoch [1506/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1507/10000], Training Loss: 0.60186441, Training Accuracy: 0.9496\n",
      "Epoch [1507/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1508/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1508/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1509/10000], Training Loss: 0.60181456, Training Accuracy: 0.9496\n",
      "Epoch [1509/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1510/10000], Training Loss: 0.59820320, Training Accuracy: 0.9538\n",
      "Epoch [1510/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1511/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1511/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [1512/10000], Training Loss: 0.58926017, Training Accuracy: 0.9622\n",
      "Epoch [1512/10000], Validation Loss: 0.91794008, Validation Accuracy: 0.6324\n",
      "Epoch [1513/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1513/10000], Validation Loss: 0.90438697, Validation Accuracy: 0.6471\n",
      "Epoch [1514/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1514/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1515/10000], Training Loss: 0.59766413, Training Accuracy: 0.9538\n",
      "Epoch [1515/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1516/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1516/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1517/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1517/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1518/10000], Training Loss: 0.61026803, Training Accuracy: 0.9412\n",
      "Epoch [1518/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1519/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1519/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1520/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [1520/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1521/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [1521/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1522/10000], Training Loss: 0.60186947, Training Accuracy: 0.9496\n",
      "Epoch [1522/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1523/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1523/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1524/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1524/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1525/10000], Training Loss: 0.60186396, Training Accuracy: 0.9496\n",
      "Epoch [1525/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1526/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [1526/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1527/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [1527/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1528/10000], Training Loss: 0.60185715, Training Accuracy: 0.9496\n",
      "Epoch [1528/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1529/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1529/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1530/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [1530/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1531/10000], Training Loss: 0.59766343, Training Accuracy: 0.9538\n",
      "Epoch [1531/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1532/10000], Training Loss: 0.60189446, Training Accuracy: 0.9496\n",
      "Epoch [1532/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1533/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1533/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1534/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1534/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1535/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1535/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [1536/10000], Training Loss: 0.60578026, Training Accuracy: 0.9454\n",
      "Epoch [1536/10000], Validation Loss: 0.91905031, Validation Accuracy: 0.6324\n",
      "Epoch [1537/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [1537/10000], Validation Loss: 0.91885358, Validation Accuracy: 0.6324\n",
      "Epoch [1538/10000], Training Loss: 0.60606678, Training Accuracy: 0.9454\n",
      "Epoch [1538/10000], Validation Loss: 0.93379775, Validation Accuracy: 0.6176\n",
      "Epoch [1539/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1539/10000], Validation Loss: 0.93379793, Validation Accuracy: 0.6176\n",
      "Epoch [1540/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1540/10000], Validation Loss: 0.93379810, Validation Accuracy: 0.6176\n",
      "Epoch [1541/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1541/10000], Validation Loss: 0.93379858, Validation Accuracy: 0.6176\n",
      "Epoch [1542/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1542/10000], Validation Loss: 0.93379906, Validation Accuracy: 0.6176\n",
      "Epoch [1543/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [1543/10000], Validation Loss: 0.93379945, Validation Accuracy: 0.6176\n",
      "Epoch [1544/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1544/10000], Validation Loss: 0.93379962, Validation Accuracy: 0.6176\n",
      "Epoch [1545/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1545/10000], Validation Loss: 0.93379974, Validation Accuracy: 0.6176\n",
      "Epoch [1546/10000], Training Loss: 0.58488717, Training Accuracy: 0.9664\n",
      "Epoch [1546/10000], Validation Loss: 0.93556741, Validation Accuracy: 0.6176\n",
      "Epoch [1547/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1547/10000], Validation Loss: 0.94839850, Validation Accuracy: 0.6029\n",
      "Epoch [1548/10000], Training Loss: 0.60186776, Training Accuracy: 0.9496\n",
      "Epoch [1548/10000], Validation Loss: 0.94849887, Validation Accuracy: 0.6029\n",
      "Epoch [1549/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1549/10000], Validation Loss: 0.94850263, Validation Accuracy: 0.6029\n",
      "Epoch [1550/10000], Training Loss: 0.62280693, Training Accuracy: 0.9286\n",
      "Epoch [1550/10000], Validation Loss: 0.94849607, Validation Accuracy: 0.6029\n",
      "Epoch [1551/10000], Training Loss: 0.60556723, Training Accuracy: 0.9454\n",
      "Epoch [1551/10000], Validation Loss: 0.93379810, Validation Accuracy: 0.6176\n",
      "Epoch [1552/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1552/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [1553/10000], Training Loss: 0.59398407, Training Accuracy: 0.9580\n",
      "Epoch [1553/10000], Validation Loss: 0.95856902, Validation Accuracy: 0.5882\n",
      "Epoch [1554/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1554/10000], Validation Loss: 0.96254167, Validation Accuracy: 0.5882\n",
      "Epoch [1555/10000], Training Loss: 0.58926006, Training Accuracy: 0.9622\n",
      "Epoch [1555/10000], Validation Loss: 0.96238539, Validation Accuracy: 0.5882\n",
      "Epoch [1556/10000], Training Loss: 0.59761491, Training Accuracy: 0.9538\n",
      "Epoch [1556/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [1557/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1557/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [1558/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1558/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1559/10000], Training Loss: 0.59766342, Training Accuracy: 0.9538\n",
      "Epoch [1559/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1560/10000], Training Loss: 0.58925968, Training Accuracy: 0.9622\n",
      "Epoch [1560/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1561/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1561/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1562/10000], Training Loss: 0.59752109, Training Accuracy: 0.9538\n",
      "Epoch [1562/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1563/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1563/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1564/10000], Training Loss: 0.60186846, Training Accuracy: 0.9496\n",
      "Epoch [1564/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1565/10000], Training Loss: 0.60186451, Training Accuracy: 0.9496\n",
      "Epoch [1565/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1566/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [1566/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1567/10000], Training Loss: 0.59346017, Training Accuracy: 0.9580\n",
      "Epoch [1567/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [1568/10000], Training Loss: 0.59783251, Training Accuracy: 0.9538\n",
      "Epoch [1568/10000], Validation Loss: 0.93377388, Validation Accuracy: 0.6176\n",
      "Epoch [1569/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1569/10000], Validation Loss: 0.93377516, Validation Accuracy: 0.6176\n",
      "Epoch [1570/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [1570/10000], Validation Loss: 0.93379775, Validation Accuracy: 0.6176\n",
      "Epoch [1571/10000], Training Loss: 0.59864615, Training Accuracy: 0.9538\n",
      "Epoch [1571/10000], Validation Loss: 0.93379670, Validation Accuracy: 0.6176\n",
      "Epoch [1572/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1572/10000], Validation Loss: 0.93584883, Validation Accuracy: 0.6176\n",
      "Epoch [1573/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [1573/10000], Validation Loss: 0.94850343, Validation Accuracy: 0.6029\n",
      "Epoch [1574/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1574/10000], Validation Loss: 0.96320328, Validation Accuracy: 0.5882\n",
      "Epoch [1575/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1575/10000], Validation Loss: 0.96320781, Validation Accuracy: 0.5882\n",
      "Epoch [1576/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1576/10000], Validation Loss: 0.96320856, Validation Accuracy: 0.5882\n",
      "Epoch [1577/10000], Training Loss: 0.58268742, Training Accuracy: 0.9664\n",
      "Epoch [1577/10000], Validation Loss: 0.96989235, Validation Accuracy: 0.5735\n",
      "Epoch [1578/10000], Training Loss: 0.58927034, Training Accuracy: 0.9622\n",
      "Epoch [1578/10000], Validation Loss: 0.99174401, Validation Accuracy: 0.5588\n",
      "Epoch [1579/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1579/10000], Validation Loss: 0.99254793, Validation Accuracy: 0.5588\n",
      "Epoch [1580/10000], Training Loss: 0.59346094, Training Accuracy: 0.9580\n",
      "Epoch [1580/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [1581/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1581/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1582/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1582/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1583/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1583/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1584/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [1584/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1585/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1585/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1586/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1586/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1587/10000], Training Loss: 0.61026843, Training Accuracy: 0.9412\n",
      "Epoch [1587/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1588/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [1588/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1589/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [1589/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1590/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1590/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1591/10000], Training Loss: 0.59481789, Training Accuracy: 0.9580\n",
      "Epoch [1591/10000], Validation Loss: 1.00729987, Validation Accuracy: 0.5441\n",
      "Epoch [1592/10000], Training Loss: 0.61337444, Training Accuracy: 0.9370\n",
      "Epoch [1592/10000], Validation Loss: 1.00771853, Validation Accuracy: 0.5441\n",
      "Epoch [1593/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1593/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [1594/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [1594/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [1595/10000], Training Loss: 0.59321017, Training Accuracy: 0.9580\n",
      "Epoch [1595/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [1596/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1596/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [1597/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1597/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [1598/10000], Training Loss: 0.60314511, Training Accuracy: 0.9496\n",
      "Epoch [1598/10000], Validation Loss: 1.00731811, Validation Accuracy: 0.5441\n",
      "Epoch [1599/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1599/10000], Validation Loss: 1.02188632, Validation Accuracy: 0.5294\n",
      "Epoch [1600/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1600/10000], Validation Loss: 1.02149251, Validation Accuracy: 0.5294\n",
      "Epoch [1601/10000], Training Loss: 0.61456827, Training Accuracy: 0.9370\n",
      "Epoch [1601/10000], Validation Loss: 1.02007154, Validation Accuracy: 0.5294\n",
      "Epoch [1602/10000], Training Loss: 0.60186521, Training Accuracy: 0.9496\n",
      "Epoch [1602/10000], Validation Loss: 1.00913221, Validation Accuracy: 0.5441\n",
      "Epoch [1603/10000], Training Loss: 0.62286922, Training Accuracy: 0.9286\n",
      "Epoch [1603/10000], Validation Loss: 1.00765446, Validation Accuracy: 0.5441\n",
      "Epoch [1604/10000], Training Loss: 0.59770120, Training Accuracy: 0.9538\n",
      "Epoch [1604/10000], Validation Loss: 1.01039150, Validation Accuracy: 0.5441\n",
      "Epoch [1605/10000], Training Loss: 0.60252292, Training Accuracy: 0.9496\n",
      "Epoch [1605/10000], Validation Loss: 1.01639780, Validation Accuracy: 0.5294\n",
      "Epoch [1606/10000], Training Loss: 0.60184882, Training Accuracy: 0.9496\n",
      "Epoch [1606/10000], Validation Loss: 1.01364046, Validation Accuracy: 0.5294\n",
      "Epoch [1607/10000], Training Loss: 0.60186503, Training Accuracy: 0.9496\n",
      "Epoch [1607/10000], Validation Loss: 1.00363100, Validation Accuracy: 0.5441\n",
      "Epoch [1608/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1608/10000], Validation Loss: 1.00371429, Validation Accuracy: 0.5441\n",
      "Epoch [1609/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1609/10000], Validation Loss: 1.00376233, Validation Accuracy: 0.5441\n",
      "Epoch [1610/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1610/10000], Validation Loss: 1.00378501, Validation Accuracy: 0.5441\n",
      "Epoch [1611/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1611/10000], Validation Loss: 1.00379583, Validation Accuracy: 0.5441\n",
      "Epoch [1612/10000], Training Loss: 0.58925671, Training Accuracy: 0.9622\n",
      "Epoch [1612/10000], Validation Loss: 1.00394499, Validation Accuracy: 0.5441\n",
      "Epoch [1613/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1613/10000], Validation Loss: 1.00405326, Validation Accuracy: 0.5441\n",
      "Epoch [1614/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [1614/10000], Validation Loss: 1.00410455, Validation Accuracy: 0.5441\n",
      "Epoch [1615/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1615/10000], Validation Loss: 1.00412890, Validation Accuracy: 0.5441\n",
      "Epoch [1616/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1616/10000], Validation Loss: 1.00414094, Validation Accuracy: 0.5441\n",
      "Epoch [1617/10000], Training Loss: 0.58925394, Training Accuracy: 0.9622\n",
      "Epoch [1617/10000], Validation Loss: 1.00414672, Validation Accuracy: 0.5441\n",
      "Epoch [1618/10000], Training Loss: 0.61026784, Training Accuracy: 0.9412\n",
      "Epoch [1618/10000], Validation Loss: 1.00417271, Validation Accuracy: 0.5441\n",
      "Epoch [1619/10000], Training Loss: 0.58505871, Training Accuracy: 0.9664\n",
      "Epoch [1619/10000], Validation Loss: 1.00415710, Validation Accuracy: 0.5441\n",
      "Epoch [1620/10000], Training Loss: 0.60604775, Training Accuracy: 0.9454\n",
      "Epoch [1620/10000], Validation Loss: 1.00389996, Validation Accuracy: 0.5441\n",
      "Epoch [1621/10000], Training Loss: 0.58930252, Training Accuracy: 0.9622\n",
      "Epoch [1621/10000], Validation Loss: 1.00419587, Validation Accuracy: 0.5441\n",
      "Epoch [1622/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1622/10000], Validation Loss: 1.00433072, Validation Accuracy: 0.5441\n",
      "Epoch [1623/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [1623/10000], Validation Loss: 1.00439352, Validation Accuracy: 0.5441\n",
      "Epoch [1624/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1624/10000], Validation Loss: 1.00442138, Validation Accuracy: 0.5441\n",
      "Epoch [1625/10000], Training Loss: 0.58085420, Training Accuracy: 0.9706\n",
      "Epoch [1625/10000], Validation Loss: 0.98973384, Validation Accuracy: 0.5588\n",
      "Epoch [1626/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1626/10000], Validation Loss: 0.98974422, Validation Accuracy: 0.5588\n",
      "Epoch [1627/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1627/10000], Validation Loss: 0.98974890, Validation Accuracy: 0.5588\n",
      "Epoch [1628/10000], Training Loss: 0.60606723, Training Accuracy: 0.9454\n",
      "Epoch [1628/10000], Validation Loss: 0.98975191, Validation Accuracy: 0.5588\n",
      "Epoch [1629/10000], Training Loss: 0.60981311, Training Accuracy: 0.9412\n",
      "Epoch [1629/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1630/10000], Training Loss: 0.59694707, Training Accuracy: 0.9538\n",
      "Epoch [1630/10000], Validation Loss: 1.00732467, Validation Accuracy: 0.5441\n",
      "Epoch [1631/10000], Training Loss: 0.60192620, Training Accuracy: 0.9496\n",
      "Epoch [1631/10000], Validation Loss: 1.00730619, Validation Accuracy: 0.5441\n",
      "Epoch [1632/10000], Training Loss: 0.61027844, Training Accuracy: 0.9412\n",
      "Epoch [1632/10000], Validation Loss: 1.00722015, Validation Accuracy: 0.5441\n",
      "Epoch [1633/10000], Training Loss: 0.61447004, Training Accuracy: 0.9370\n",
      "Epoch [1633/10000], Validation Loss: 1.02140141, Validation Accuracy: 0.5294\n",
      "Epoch [1634/10000], Training Loss: 0.59433905, Training Accuracy: 0.9580\n",
      "Epoch [1634/10000], Validation Loss: 1.02082837, Validation Accuracy: 0.5294\n",
      "Epoch [1635/10000], Training Loss: 0.61840252, Training Accuracy: 0.9328\n",
      "Epoch [1635/10000], Validation Loss: 1.03064579, Validation Accuracy: 0.5147\n",
      "Epoch [1636/10000], Training Loss: 0.62286925, Training Accuracy: 0.9286\n",
      "Epoch [1636/10000], Validation Loss: 1.03243464, Validation Accuracy: 0.5147\n",
      "Epoch [1637/10000], Training Loss: 0.61867255, Training Accuracy: 0.9328\n",
      "Epoch [1637/10000], Validation Loss: 1.03322583, Validation Accuracy: 0.5147\n",
      "Epoch [1638/10000], Training Loss: 0.62287849, Training Accuracy: 0.9286\n",
      "Epoch [1638/10000], Validation Loss: 1.03361267, Validation Accuracy: 0.5147\n",
      "Epoch [1639/10000], Training Loss: 0.61543033, Training Accuracy: 0.9370\n",
      "Epoch [1639/10000], Validation Loss: 1.03655124, Validation Accuracy: 0.5147\n",
      "Epoch [1640/10000], Training Loss: 0.61026708, Training Accuracy: 0.9412\n",
      "Epoch [1640/10000], Validation Loss: 1.02200627, Validation Accuracy: 0.5294\n",
      "Epoch [1641/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [1641/10000], Validation Loss: 1.00732568, Validation Accuracy: 0.5441\n",
      "Epoch [1642/10000], Training Loss: 0.61438755, Training Accuracy: 0.9370\n",
      "Epoch [1642/10000], Validation Loss: 1.00732693, Validation Accuracy: 0.5441\n",
      "Epoch [1643/10000], Training Loss: 0.60605814, Training Accuracy: 0.9454\n",
      "Epoch [1643/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [1644/10000], Training Loss: 0.60006217, Training Accuracy: 0.9496\n",
      "Epoch [1644/10000], Validation Loss: 0.99471706, Validation Accuracy: 0.5588\n",
      "Epoch [1645/10000], Training Loss: 0.60436631, Training Accuracy: 0.9454\n",
      "Epoch [1645/10000], Validation Loss: 0.99273759, Validation Accuracy: 0.5588\n",
      "Epoch [1646/10000], Training Loss: 0.59345949, Training Accuracy: 0.9580\n",
      "Epoch [1646/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1647/10000], Training Loss: 0.59507145, Training Accuracy: 0.9580\n",
      "Epoch [1647/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [1648/10000], Training Loss: 0.60615035, Training Accuracy: 0.9454\n",
      "Epoch [1648/10000], Validation Loss: 0.99262109, Validation Accuracy: 0.5588\n",
      "Epoch [1649/10000], Training Loss: 0.60679845, Training Accuracy: 0.9454\n",
      "Epoch [1649/10000], Validation Loss: 0.96415311, Validation Accuracy: 0.5882\n",
      "Epoch [1650/10000], Training Loss: 0.61014267, Training Accuracy: 0.9412\n",
      "Epoch [1650/10000], Validation Loss: 0.97772825, Validation Accuracy: 0.5735\n",
      "Epoch [1651/10000], Training Loss: 0.62287235, Training Accuracy: 0.9286\n",
      "Epoch [1651/10000], Validation Loss: 0.97786838, Validation Accuracy: 0.5735\n",
      "Epoch [1652/10000], Training Loss: 0.61110406, Training Accuracy: 0.9370\n",
      "Epoch [1652/10000], Validation Loss: 0.94846481, Validation Accuracy: 0.6029\n",
      "Epoch [1653/10000], Training Loss: 0.60432718, Training Accuracy: 0.9454\n",
      "Epoch [1653/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1654/10000], Training Loss: 0.58925423, Training Accuracy: 0.9622\n",
      "Epoch [1654/10000], Validation Loss: 0.97791517, Validation Accuracy: 0.5735\n",
      "Epoch [1655/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1655/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [1656/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1656/10000], Validation Loss: 0.97791532, Validation Accuracy: 0.5735\n",
      "Epoch [1657/10000], Training Loss: 0.60186510, Training Accuracy: 0.9496\n",
      "Epoch [1657/10000], Validation Loss: 0.97791514, Validation Accuracy: 0.5735\n",
      "Epoch [1658/10000], Training Loss: 0.62206037, Training Accuracy: 0.9286\n",
      "Epoch [1658/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1659/10000], Training Loss: 0.60186507, Training Accuracy: 0.9496\n",
      "Epoch [1659/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1660/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1660/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1661/10000], Training Loss: 0.59766341, Training Accuracy: 0.9538\n",
      "Epoch [1661/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1662/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1662/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1663/10000], Training Loss: 0.59315503, Training Accuracy: 0.9580\n",
      "Epoch [1663/10000], Validation Loss: 0.97791532, Validation Accuracy: 0.5735\n",
      "Epoch [1664/10000], Training Loss: 0.59371185, Training Accuracy: 0.9580\n",
      "Epoch [1664/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1665/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1665/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1666/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1666/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1667/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1667/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1668/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1668/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1669/10000], Training Loss: 0.58929936, Training Accuracy: 0.9622\n",
      "Epoch [1669/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1670/10000], Training Loss: 0.59766460, Training Accuracy: 0.9538\n",
      "Epoch [1670/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1671/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1671/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1672/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1672/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1673/10000], Training Loss: 0.60186516, Training Accuracy: 0.9496\n",
      "Epoch [1673/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1674/10000], Training Loss: 0.60606786, Training Accuracy: 0.9454\n",
      "Epoch [1674/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1675/10000], Training Loss: 0.62151243, Training Accuracy: 0.9286\n",
      "Epoch [1675/10000], Validation Loss: 0.94850290, Validation Accuracy: 0.6029\n",
      "Epoch [1676/10000], Training Loss: 0.61486888, Training Accuracy: 0.9370\n",
      "Epoch [1676/10000], Validation Loss: 0.90438607, Validation Accuracy: 0.6471\n",
      "Epoch [1677/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [1677/10000], Validation Loss: 0.96320862, Validation Accuracy: 0.5882\n",
      "Epoch [1678/10000], Training Loss: 0.60606942, Training Accuracy: 0.9454\n",
      "Epoch [1678/10000], Validation Loss: 0.99260536, Validation Accuracy: 0.5588\n",
      "Epoch [1679/10000], Training Loss: 0.61420126, Training Accuracy: 0.9370\n",
      "Epoch [1679/10000], Validation Loss: 0.99254712, Validation Accuracy: 0.5588\n",
      "Epoch [1680/10000], Training Loss: 0.60167987, Training Accuracy: 0.9496\n",
      "Epoch [1680/10000], Validation Loss: 0.98874918, Validation Accuracy: 0.5588\n",
      "Epoch [1681/10000], Training Loss: 0.60606555, Training Accuracy: 0.9454\n",
      "Epoch [1681/10000], Validation Loss: 0.99261934, Validation Accuracy: 0.5588\n",
      "Epoch [1682/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1682/10000], Validation Loss: 0.99247274, Validation Accuracy: 0.5588\n",
      "Epoch [1683/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1683/10000], Validation Loss: 0.99180660, Validation Accuracy: 0.5588\n",
      "Epoch [1684/10000], Training Loss: 0.59345752, Training Accuracy: 0.9580\n",
      "Epoch [1684/10000], Validation Loss: 0.99135572, Validation Accuracy: 0.5588\n",
      "Epoch [1685/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [1685/10000], Validation Loss: 0.99128953, Validation Accuracy: 0.5588\n",
      "Epoch [1686/10000], Training Loss: 0.60598080, Training Accuracy: 0.9454\n",
      "Epoch [1686/10000], Validation Loss: 0.99182838, Validation Accuracy: 0.5588\n",
      "Epoch [1687/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1687/10000], Validation Loss: 0.99215722, Validation Accuracy: 0.5588\n",
      "Epoch [1688/10000], Training Loss: 0.58926082, Training Accuracy: 0.9622\n",
      "Epoch [1688/10000], Validation Loss: 0.99227503, Validation Accuracy: 0.5588\n",
      "Epoch [1689/10000], Training Loss: 0.60119498, Training Accuracy: 0.9496\n",
      "Epoch [1689/10000], Validation Loss: 1.00732636, Validation Accuracy: 0.5441\n",
      "Epoch [1690/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1690/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1691/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1691/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1692/10000], Training Loss: 0.61447013, Training Accuracy: 0.9370\n",
      "Epoch [1692/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1693/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1693/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1694/10000], Training Loss: 0.59766084, Training Accuracy: 0.9538\n",
      "Epoch [1694/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1695/10000], Training Loss: 0.61031319, Training Accuracy: 0.9412\n",
      "Epoch [1695/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1696/10000], Training Loss: 0.62250013, Training Accuracy: 0.9286\n",
      "Epoch [1696/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [1697/10000], Training Loss: 0.61706276, Training Accuracy: 0.9328\n",
      "Epoch [1697/10000], Validation Loss: 1.00729626, Validation Accuracy: 0.5441\n",
      "Epoch [1698/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1698/10000], Validation Loss: 0.98595646, Validation Accuracy: 0.5588\n",
      "Epoch [1699/10000], Training Loss: 0.59766279, Training Accuracy: 0.9538\n",
      "Epoch [1699/10000], Validation Loss: 0.97763067, Validation Accuracy: 0.5735\n",
      "Epoch [1700/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [1700/10000], Validation Loss: 0.97785720, Validation Accuracy: 0.5735\n",
      "Epoch [1701/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1701/10000], Validation Loss: 0.97788733, Validation Accuracy: 0.5735\n",
      "Epoch [1702/10000], Training Loss: 0.60606042, Training Accuracy: 0.9454\n",
      "Epoch [1702/10000], Validation Loss: 0.97784999, Validation Accuracy: 0.5735\n",
      "Epoch [1703/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1703/10000], Validation Loss: 0.97777927, Validation Accuracy: 0.5735\n",
      "Epoch [1704/10000], Training Loss: 0.60186436, Training Accuracy: 0.9496\n",
      "Epoch [1704/10000], Validation Loss: 0.97771788, Validation Accuracy: 0.5735\n",
      "Epoch [1705/10000], Training Loss: 0.60186510, Training Accuracy: 0.9496\n",
      "Epoch [1705/10000], Validation Loss: 0.97767892, Validation Accuracy: 0.5735\n",
      "Epoch [1706/10000], Training Loss: 0.59769079, Training Accuracy: 0.9538\n",
      "Epoch [1706/10000], Validation Loss: 0.97755417, Validation Accuracy: 0.5735\n",
      "Epoch [1707/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1707/10000], Validation Loss: 0.97745618, Validation Accuracy: 0.5735\n",
      "Epoch [1708/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1708/10000], Validation Loss: 0.97740030, Validation Accuracy: 0.5735\n",
      "Epoch [1709/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1709/10000], Validation Loss: 0.97737119, Validation Accuracy: 0.5735\n",
      "Epoch [1710/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1710/10000], Validation Loss: 0.97735667, Validation Accuracy: 0.5735\n",
      "Epoch [1711/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1711/10000], Validation Loss: 0.97734946, Validation Accuracy: 0.5735\n",
      "Epoch [1712/10000], Training Loss: 0.59763832, Training Accuracy: 0.9538\n",
      "Epoch [1712/10000], Validation Loss: 0.97730750, Validation Accuracy: 0.5735\n",
      "Epoch [1713/10000], Training Loss: 0.61446720, Training Accuracy: 0.9370\n",
      "Epoch [1713/10000], Validation Loss: 0.97708720, Validation Accuracy: 0.5735\n",
      "Epoch [1714/10000], Training Loss: 0.61027673, Training Accuracy: 0.9412\n",
      "Epoch [1714/10000], Validation Loss: 0.97691143, Validation Accuracy: 0.5735\n",
      "Epoch [1715/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1715/10000], Validation Loss: 0.97681296, Validation Accuracy: 0.5735\n",
      "Epoch [1716/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1716/10000], Validation Loss: 0.97676256, Validation Accuracy: 0.5735\n",
      "Epoch [1717/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1717/10000], Validation Loss: 0.97673771, Validation Accuracy: 0.5735\n",
      "Epoch [1718/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1718/10000], Validation Loss: 0.97672570, Validation Accuracy: 0.5735\n",
      "Epoch [1719/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1719/10000], Validation Loss: 0.97671965, Validation Accuracy: 0.5735\n",
      "Epoch [1720/10000], Training Loss: 0.60186707, Training Accuracy: 0.9496\n",
      "Epoch [1720/10000], Validation Loss: 0.97663960, Validation Accuracy: 0.5735\n",
      "Epoch [1721/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1721/10000], Validation Loss: 0.97644863, Validation Accuracy: 0.5735\n",
      "Epoch [1722/10000], Training Loss: 0.58926041, Training Accuracy: 0.9622\n",
      "Epoch [1722/10000], Validation Loss: 0.97634754, Validation Accuracy: 0.5735\n",
      "Epoch [1723/10000], Training Loss: 0.58926014, Training Accuracy: 0.9622\n",
      "Epoch [1723/10000], Validation Loss: 0.97629467, Validation Accuracy: 0.5735\n",
      "Epoch [1724/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1724/10000], Validation Loss: 0.97626868, Validation Accuracy: 0.5735\n",
      "Epoch [1725/10000], Training Loss: 0.59752279, Training Accuracy: 0.9538\n",
      "Epoch [1725/10000], Validation Loss: 0.97295517, Validation Accuracy: 0.5735\n",
      "Epoch [1726/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1726/10000], Validation Loss: 0.96779883, Validation Accuracy: 0.5882\n",
      "Epoch [1727/10000], Training Loss: 0.61026852, Training Accuracy: 0.9412\n",
      "Epoch [1727/10000], Validation Loss: 0.96589765, Validation Accuracy: 0.5882\n",
      "Epoch [1728/10000], Training Loss: 0.60151557, Training Accuracy: 0.9496\n",
      "Epoch [1728/10000], Validation Loss: 0.97669676, Validation Accuracy: 0.5735\n",
      "Epoch [1729/10000], Training Loss: 0.60589368, Training Accuracy: 0.9454\n",
      "Epoch [1729/10000], Validation Loss: 0.97775620, Validation Accuracy: 0.5735\n",
      "Epoch [1730/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1730/10000], Validation Loss: 0.97784302, Validation Accuracy: 0.5735\n",
      "Epoch [1731/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1731/10000], Validation Loss: 0.97786537, Validation Accuracy: 0.5735\n",
      "Epoch [1732/10000], Training Loss: 0.60182408, Training Accuracy: 0.9496\n",
      "Epoch [1732/10000], Validation Loss: 0.97784948, Validation Accuracy: 0.5735\n",
      "Epoch [1733/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1733/10000], Validation Loss: 0.97782806, Validation Accuracy: 0.5735\n",
      "Epoch [1734/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1734/10000], Validation Loss: 0.97781533, Validation Accuracy: 0.5735\n",
      "Epoch [1735/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1735/10000], Validation Loss: 0.97780856, Validation Accuracy: 0.5735\n",
      "Epoch [1736/10000], Training Loss: 0.60259386, Training Accuracy: 0.9496\n",
      "Epoch [1736/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [1737/10000], Training Loss: 0.59766340, Training Accuracy: 0.9538\n",
      "Epoch [1737/10000], Validation Loss: 0.99262133, Validation Accuracy: 0.5588\n",
      "Epoch [1738/10000], Training Loss: 0.60015624, Training Accuracy: 0.9496\n",
      "Epoch [1738/10000], Validation Loss: 1.00176781, Validation Accuracy: 0.5441\n",
      "Epoch [1739/10000], Training Loss: 0.58505844, Training Accuracy: 0.9664\n",
      "Epoch [1739/10000], Validation Loss: 0.97792086, Validation Accuracy: 0.5735\n",
      "Epoch [1740/10000], Training Loss: 0.59753678, Training Accuracy: 0.9538\n",
      "Epoch [1740/10000], Validation Loss: 0.97794288, Validation Accuracy: 0.5735\n",
      "Epoch [1741/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [1741/10000], Validation Loss: 0.97038174, Validation Accuracy: 0.5735\n",
      "Epoch [1742/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1742/10000], Validation Loss: 0.96321335, Validation Accuracy: 0.5882\n",
      "Epoch [1743/10000], Training Loss: 0.57681769, Training Accuracy: 0.9748\n",
      "Epoch [1743/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1744/10000], Training Loss: 0.61279818, Training Accuracy: 0.9370\n",
      "Epoch [1744/10000], Validation Loss: 0.99259797, Validation Accuracy: 0.5588\n",
      "Epoch [1745/10000], Training Loss: 0.59766357, Training Accuracy: 0.9538\n",
      "Epoch [1745/10000], Validation Loss: 0.99262807, Validation Accuracy: 0.5588\n",
      "Epoch [1746/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1746/10000], Validation Loss: 1.03630641, Validation Accuracy: 0.5147\n",
      "Epoch [1747/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1747/10000], Validation Loss: 1.03670818, Validation Accuracy: 0.5147\n",
      "Epoch [1748/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [1748/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1749/10000], Training Loss: 0.59346829, Training Accuracy: 0.9580\n",
      "Epoch [1749/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1750/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1750/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [1751/10000], Training Loss: 0.59329506, Training Accuracy: 0.9580\n",
      "Epoch [1751/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1752/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1752/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [1753/10000], Training Loss: 0.58926119, Training Accuracy: 0.9622\n",
      "Epoch [1753/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1754/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1754/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1755/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1755/10000], Validation Loss: 1.03673914, Validation Accuracy: 0.5147\n",
      "Epoch [1756/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1756/10000], Validation Loss: 1.03673914, Validation Accuracy: 0.5147\n",
      "Epoch [1757/10000], Training Loss: 0.58907019, Training Accuracy: 0.9622\n",
      "Epoch [1757/10000], Validation Loss: 1.03724459, Validation Accuracy: 0.5147\n",
      "Epoch [1758/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [1758/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1759/10000], Training Loss: 0.61431955, Training Accuracy: 0.9370\n",
      "Epoch [1759/10000], Validation Loss: 1.05144477, Validation Accuracy: 0.5000\n",
      "Epoch [1760/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1760/10000], Validation Loss: 1.05096716, Validation Accuracy: 0.5000\n",
      "Epoch [1761/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [1761/10000], Validation Loss: 1.04181284, Validation Accuracy: 0.5147\n",
      "Epoch [1762/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [1762/10000], Validation Loss: 1.03776151, Validation Accuracy: 0.5147\n",
      "Epoch [1763/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1763/10000], Validation Loss: 1.03716195, Validation Accuracy: 0.5147\n",
      "Epoch [1764/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1764/10000], Validation Loss: 1.03701335, Validation Accuracy: 0.5147\n",
      "Epoch [1765/10000], Training Loss: 0.60185992, Training Accuracy: 0.9496\n",
      "Epoch [1765/10000], Validation Loss: 1.03693193, Validation Accuracy: 0.5147\n",
      "Epoch [1766/10000], Training Loss: 0.59766352, Training Accuracy: 0.9538\n",
      "Epoch [1766/10000], Validation Loss: 1.03688622, Validation Accuracy: 0.5147\n",
      "Epoch [1767/10000], Training Loss: 0.59367337, Training Accuracy: 0.9580\n",
      "Epoch [1767/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1768/10000], Training Loss: 0.59765742, Training Accuracy: 0.9538\n",
      "Epoch [1768/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1769/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1769/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1770/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1770/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1771/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1771/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1772/10000], Training Loss: 0.59340234, Training Accuracy: 0.9580\n",
      "Epoch [1772/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1773/10000], Training Loss: 0.58061458, Training Accuracy: 0.9706\n",
      "Epoch [1773/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1774/10000], Training Loss: 0.61026817, Training Accuracy: 0.9412\n",
      "Epoch [1774/10000], Validation Loss: 1.00748116, Validation Accuracy: 0.5441\n",
      "Epoch [1775/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1775/10000], Validation Loss: 1.00730032, Validation Accuracy: 0.5441\n",
      "Epoch [1776/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1776/10000], Validation Loss: 0.99427080, Validation Accuracy: 0.5588\n",
      "Epoch [1777/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1777/10000], Validation Loss: 0.99266195, Validation Accuracy: 0.5588\n",
      "Epoch [1778/10000], Training Loss: 0.61026839, Training Accuracy: 0.9412\n",
      "Epoch [1778/10000], Validation Loss: 0.99262819, Validation Accuracy: 0.5588\n",
      "Epoch [1779/10000], Training Loss: 0.58929648, Training Accuracy: 0.9622\n",
      "Epoch [1779/10000], Validation Loss: 0.99262151, Validation Accuracy: 0.5588\n",
      "Epoch [1780/10000], Training Loss: 0.58505843, Training Accuracy: 0.9664\n",
      "Epoch [1780/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1781/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1781/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1782/10000], Training Loss: 0.58926037, Training Accuracy: 0.9622\n",
      "Epoch [1782/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1783/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1783/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1784/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1784/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1785/10000], Training Loss: 0.58085684, Training Accuracy: 0.9706\n",
      "Epoch [1785/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1786/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [1786/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1787/10000], Training Loss: 0.59332000, Training Accuracy: 0.9580\n",
      "Epoch [1787/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [1788/10000], Training Loss: 0.59766284, Training Accuracy: 0.9538\n",
      "Epoch [1788/10000], Validation Loss: 0.99778965, Validation Accuracy: 0.5588\n",
      "Epoch [1789/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1789/10000], Validation Loss: 1.00597531, Validation Accuracy: 0.5441\n",
      "Epoch [1790/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1790/10000], Validation Loss: 1.01959062, Validation Accuracy: 0.5294\n",
      "Epoch [1791/10000], Training Loss: 0.60214347, Training Accuracy: 0.9496\n",
      "Epoch [1791/10000], Validation Loss: 0.99261820, Validation Accuracy: 0.5588\n",
      "Epoch [1792/10000], Training Loss: 0.58193945, Training Accuracy: 0.9706\n",
      "Epoch [1792/10000], Validation Loss: 0.97728565, Validation Accuracy: 0.5735\n",
      "Epoch [1793/10000], Training Loss: 0.60170226, Training Accuracy: 0.9496\n",
      "Epoch [1793/10000], Validation Loss: 0.96320999, Validation Accuracy: 0.5882\n",
      "Epoch [1794/10000], Training Loss: 0.58085539, Training Accuracy: 0.9706\n",
      "Epoch [1794/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1795/10000], Training Loss: 0.60606342, Training Accuracy: 0.9454\n",
      "Epoch [1795/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [1796/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1796/10000], Validation Loss: 0.96275008, Validation Accuracy: 0.5882\n",
      "Epoch [1797/10000], Training Loss: 0.59915828, Training Accuracy: 0.9496\n",
      "Epoch [1797/10000], Validation Loss: 0.97792545, Validation Accuracy: 0.5735\n",
      "Epoch [1798/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1798/10000], Validation Loss: 1.03476655, Validation Accuracy: 0.5147\n",
      "Epoch [1799/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1799/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1800/10000], Training Loss: 0.58085726, Training Accuracy: 0.9706\n",
      "Epoch [1800/10000], Validation Loss: 1.03613049, Validation Accuracy: 0.5147\n",
      "Epoch [1801/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1801/10000], Validation Loss: 1.05093610, Validation Accuracy: 0.5000\n",
      "Epoch [1802/10000], Training Loss: 0.58926010, Training Accuracy: 0.9622\n",
      "Epoch [1802/10000], Validation Loss: 1.05143762, Validation Accuracy: 0.5000\n",
      "Epoch [1803/10000], Training Loss: 0.60186527, Training Accuracy: 0.9496\n",
      "Epoch [1803/10000], Validation Loss: 1.06614989, Validation Accuracy: 0.4853\n",
      "Epoch [1804/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1804/10000], Validation Loss: 1.06615043, Validation Accuracy: 0.4853\n",
      "Epoch [1805/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1805/10000], Validation Loss: 1.06615055, Validation Accuracy: 0.4853\n",
      "Epoch [1806/10000], Training Loss: 0.58362814, Training Accuracy: 0.9664\n",
      "Epoch [1806/10000], Validation Loss: 1.02619690, Validation Accuracy: 0.5294\n",
      "Epoch [1807/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1807/10000], Validation Loss: 1.05138892, Validation Accuracy: 0.5000\n",
      "Epoch [1808/10000], Training Loss: 0.59789826, Training Accuracy: 0.9538\n",
      "Epoch [1808/10000], Validation Loss: 1.05141670, Validation Accuracy: 0.5000\n",
      "Epoch [1809/10000], Training Loss: 0.61867163, Training Accuracy: 0.9328\n",
      "Epoch [1809/10000], Validation Loss: 1.05142844, Validation Accuracy: 0.5000\n",
      "Epoch [1810/10000], Training Loss: 0.59852970, Training Accuracy: 0.9538\n",
      "Epoch [1810/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [1811/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1811/10000], Validation Loss: 1.02223542, Validation Accuracy: 0.5294\n",
      "Epoch [1812/10000], Training Loss: 0.58846052, Training Accuracy: 0.9622\n",
      "Epoch [1812/10000], Validation Loss: 1.04765862, Validation Accuracy: 0.5000\n",
      "Epoch [1813/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1813/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1814/10000], Training Loss: 0.57245350, Training Accuracy: 0.9790\n",
      "Epoch [1814/10000], Validation Loss: 1.03674060, Validation Accuracy: 0.5147\n",
      "Epoch [1815/10000], Training Loss: 0.57669237, Training Accuracy: 0.9748\n",
      "Epoch [1815/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1816/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [1816/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [1817/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1817/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [1818/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1818/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [1819/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1819/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [1820/10000], Training Loss: 0.58923683, Training Accuracy: 0.9622\n",
      "Epoch [1820/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [1821/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1821/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1822/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1822/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1823/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1823/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1824/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1824/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1825/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1825/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1826/10000], Training Loss: 0.57665479, Training Accuracy: 0.9748\n",
      "Epoch [1826/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1827/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1827/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1828/10000], Training Loss: 0.59766082, Training Accuracy: 0.9538\n",
      "Epoch [1828/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1829/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1829/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1830/10000], Training Loss: 0.58093303, Training Accuracy: 0.9706\n",
      "Epoch [1830/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1831/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1831/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1832/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1832/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1833/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1833/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1834/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1834/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1835/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [1835/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1836/10000], Training Loss: 0.59346231, Training Accuracy: 0.9580\n",
      "Epoch [1836/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1837/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [1837/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1838/10000], Training Loss: 0.58926010, Training Accuracy: 0.9622\n",
      "Epoch [1838/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1839/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [1839/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1840/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1840/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1841/10000], Training Loss: 0.59766376, Training Accuracy: 0.9538\n",
      "Epoch [1841/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1842/10000], Training Loss: 0.58079062, Training Accuracy: 0.9706\n",
      "Epoch [1842/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1843/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1843/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [1844/10000], Training Loss: 0.58677384, Training Accuracy: 0.9622\n",
      "Epoch [1844/10000], Validation Loss: 1.03582960, Validation Accuracy: 0.5147\n",
      "Epoch [1845/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1845/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1846/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [1846/10000], Validation Loss: 1.02307841, Validation Accuracy: 0.5294\n",
      "Epoch [1847/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1847/10000], Validation Loss: 1.03670639, Validation Accuracy: 0.5147\n",
      "Epoch [1848/10000], Training Loss: 0.58532226, Training Accuracy: 0.9664\n",
      "Epoch [1848/10000], Validation Loss: 1.00584614, Validation Accuracy: 0.5441\n",
      "Epoch [1849/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1849/10000], Validation Loss: 0.99263120, Validation Accuracy: 0.5588\n",
      "Epoch [1850/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1850/10000], Validation Loss: 0.99262568, Validation Accuracy: 0.5588\n",
      "Epoch [1851/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1851/10000], Validation Loss: 0.99267298, Validation Accuracy: 0.5588\n",
      "Epoch [1852/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1852/10000], Validation Loss: 0.99284735, Validation Accuracy: 0.5588\n",
      "Epoch [1853/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1853/10000], Validation Loss: 0.99309728, Validation Accuracy: 0.5588\n",
      "Epoch [1854/10000], Training Loss: 0.61026938, Training Accuracy: 0.9412\n",
      "Epoch [1854/10000], Validation Loss: 0.99327540, Validation Accuracy: 0.5588\n",
      "Epoch [1855/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1855/10000], Validation Loss: 0.99332696, Validation Accuracy: 0.5588\n",
      "Epoch [1856/10000], Training Loss: 0.59346199, Training Accuracy: 0.9580\n",
      "Epoch [1856/10000], Validation Loss: 0.99335024, Validation Accuracy: 0.5588\n",
      "Epoch [1857/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1857/10000], Validation Loss: 0.99335361, Validation Accuracy: 0.5588\n",
      "Epoch [1858/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [1858/10000], Validation Loss: 0.99335784, Validation Accuracy: 0.5588\n",
      "Epoch [1859/10000], Training Loss: 0.59538238, Training Accuracy: 0.9538\n",
      "Epoch [1859/10000], Validation Loss: 1.02203307, Validation Accuracy: 0.5294\n",
      "Epoch [1860/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1860/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1861/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1861/10000], Validation Loss: 1.02556738, Validation Accuracy: 0.5294\n",
      "Epoch [1862/10000], Training Loss: 0.59346196, Training Accuracy: 0.9580\n",
      "Epoch [1862/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1863/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1863/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1864/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1864/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1865/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1865/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1866/10000], Training Loss: 0.58926007, Training Accuracy: 0.9622\n",
      "Epoch [1866/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1867/10000], Training Loss: 0.60186509, Training Accuracy: 0.9496\n",
      "Epoch [1867/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1868/10000], Training Loss: 0.59766207, Training Accuracy: 0.9538\n",
      "Epoch [1868/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1869/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1869/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1870/10000], Training Loss: 0.58926020, Training Accuracy: 0.9622\n",
      "Epoch [1870/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1871/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1871/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1872/10000], Training Loss: 0.59343227, Training Accuracy: 0.9580\n",
      "Epoch [1872/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1873/10000], Training Loss: 0.59346042, Training Accuracy: 0.9580\n",
      "Epoch [1873/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1874/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1874/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1875/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [1875/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1876/10000], Training Loss: 0.59766293, Training Accuracy: 0.9538\n",
      "Epoch [1876/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1877/10000], Training Loss: 0.57665508, Training Accuracy: 0.9748\n",
      "Epoch [1877/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1878/10000], Training Loss: 0.59338083, Training Accuracy: 0.9580\n",
      "Epoch [1878/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1879/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1879/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1880/10000], Training Loss: 0.60308863, Training Accuracy: 0.9496\n",
      "Epoch [1880/10000], Validation Loss: 1.03673971, Validation Accuracy: 0.5147\n",
      "Epoch [1881/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1881/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [1882/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1882/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [1883/10000], Training Loss: 0.58505853, Training Accuracy: 0.9664\n",
      "Epoch [1883/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [1884/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [1884/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [1885/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1885/10000], Validation Loss: 1.05144486, Validation Accuracy: 0.5000\n",
      "Epoch [1886/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [1886/10000], Validation Loss: 1.05144486, Validation Accuracy: 0.5000\n",
      "Epoch [1887/10000], Training Loss: 0.58085680, Training Accuracy: 0.9706\n",
      "Epoch [1887/10000], Validation Loss: 1.05144480, Validation Accuracy: 0.5000\n",
      "Epoch [1888/10000], Training Loss: 0.59399370, Training Accuracy: 0.9580\n",
      "Epoch [1888/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [1889/10000], Training Loss: 0.59346173, Training Accuracy: 0.9580\n",
      "Epoch [1889/10000], Validation Loss: 1.03999743, Validation Accuracy: 0.5147\n",
      "Epoch [1890/10000], Training Loss: 0.59339222, Training Accuracy: 0.9580\n",
      "Epoch [1890/10000], Validation Loss: 1.05144578, Validation Accuracy: 0.5000\n",
      "Epoch [1891/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1891/10000], Validation Loss: 1.05144495, Validation Accuracy: 0.5000\n",
      "Epoch [1892/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1892/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1893/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1893/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1894/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1894/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1895/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1895/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1896/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1896/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1897/10000], Training Loss: 0.58504956, Training Accuracy: 0.9664\n",
      "Epoch [1897/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1898/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1898/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1899/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1899/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1900/10000], Training Loss: 0.58926103, Training Accuracy: 0.9622\n",
      "Epoch [1900/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1901/10000], Training Loss: 0.58505958, Training Accuracy: 0.9664\n",
      "Epoch [1901/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1902/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1902/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1903/10000], Training Loss: 0.61026575, Training Accuracy: 0.9412\n",
      "Epoch [1903/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1904/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1904/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1905/10000], Training Loss: 0.61455948, Training Accuracy: 0.9370\n",
      "Epoch [1905/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1906/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1906/10000], Validation Loss: 1.02203324, Validation Accuracy: 0.5294\n",
      "Epoch [1907/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1907/10000], Validation Loss: 1.02203342, Validation Accuracy: 0.5294\n",
      "Epoch [1908/10000], Training Loss: 0.59757003, Training Accuracy: 0.9538\n",
      "Epoch [1908/10000], Validation Loss: 1.02203342, Validation Accuracy: 0.5294\n",
      "Epoch [1909/10000], Training Loss: 0.59348464, Training Accuracy: 0.9580\n",
      "Epoch [1909/10000], Validation Loss: 1.02203324, Validation Accuracy: 0.5294\n",
      "Epoch [1910/10000], Training Loss: 0.58926329, Training Accuracy: 0.9622\n",
      "Epoch [1910/10000], Validation Loss: 1.02203324, Validation Accuracy: 0.5294\n",
      "Epoch [1911/10000], Training Loss: 0.59331621, Training Accuracy: 0.9580\n",
      "Epoch [1911/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1912/10000], Training Loss: 0.58933460, Training Accuracy: 0.9622\n",
      "Epoch [1912/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1913/10000], Training Loss: 0.59770583, Training Accuracy: 0.9538\n",
      "Epoch [1913/10000], Validation Loss: 1.03673929, Validation Accuracy: 0.5147\n",
      "Epoch [1914/10000], Training Loss: 0.59768605, Training Accuracy: 0.9538\n",
      "Epoch [1914/10000], Validation Loss: 1.03673914, Validation Accuracy: 0.5147\n",
      "Epoch [1915/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1915/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1916/10000], Training Loss: 0.58931126, Training Accuracy: 0.9622\n",
      "Epoch [1916/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1917/10000], Training Loss: 0.59345974, Training Accuracy: 0.9580\n",
      "Epoch [1917/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1918/10000], Training Loss: 0.59345532, Training Accuracy: 0.9580\n",
      "Epoch [1918/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [1919/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1919/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1920/10000], Training Loss: 0.58923684, Training Accuracy: 0.9622\n",
      "Epoch [1920/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1921/10000], Training Loss: 0.57665462, Training Accuracy: 0.9748\n",
      "Epoch [1921/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [1922/10000], Training Loss: 0.58447392, Training Accuracy: 0.9664\n",
      "Epoch [1922/10000], Validation Loss: 1.03618869, Validation Accuracy: 0.5147\n",
      "Epoch [1923/10000], Training Loss: 0.58083292, Training Accuracy: 0.9706\n",
      "Epoch [1923/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1924/10000], Training Loss: 0.58085674, Training Accuracy: 0.9706\n",
      "Epoch [1924/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1925/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1925/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1926/10000], Training Loss: 0.60361816, Training Accuracy: 0.9454\n",
      "Epoch [1926/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [1927/10000], Training Loss: 0.58087112, Training Accuracy: 0.9706\n",
      "Epoch [1927/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1928/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1928/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1929/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1929/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1930/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1930/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1931/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1931/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1932/10000], Training Loss: 0.59887528, Training Accuracy: 0.9538\n",
      "Epoch [1932/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [1933/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1933/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [1934/10000], Training Loss: 0.59753050, Training Accuracy: 0.9538\n",
      "Epoch [1934/10000], Validation Loss: 1.05144501, Validation Accuracy: 0.5000\n",
      "Epoch [1935/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1935/10000], Validation Loss: 1.03605640, Validation Accuracy: 0.5147\n",
      "Epoch [1936/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1936/10000], Validation Loss: 1.03681749, Validation Accuracy: 0.5147\n",
      "Epoch [1937/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1937/10000], Validation Loss: 1.05157739, Validation Accuracy: 0.5000\n",
      "Epoch [1938/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [1938/10000], Validation Loss: 1.05183923, Validation Accuracy: 0.5000\n",
      "Epoch [1939/10000], Training Loss: 0.58957955, Training Accuracy: 0.9622\n",
      "Epoch [1939/10000], Validation Loss: 1.03670943, Validation Accuracy: 0.5147\n",
      "Epoch [1940/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1940/10000], Validation Loss: 1.03469747, Validation Accuracy: 0.5147\n",
      "Epoch [1941/10000], Training Loss: 0.58085654, Training Accuracy: 0.9706\n",
      "Epoch [1941/10000], Validation Loss: 1.03635430, Validation Accuracy: 0.5147\n",
      "Epoch [1942/10000], Training Loss: 0.59445911, Training Accuracy: 0.9580\n",
      "Epoch [1942/10000], Validation Loss: 1.02203232, Validation Accuracy: 0.5294\n",
      "Epoch [1943/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1943/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1944/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1944/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1945/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1945/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1946/10000], Training Loss: 0.58505781, Training Accuracy: 0.9664\n",
      "Epoch [1946/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1947/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1947/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1948/10000], Training Loss: 0.58085678, Training Accuracy: 0.9706\n",
      "Epoch [1948/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1949/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [1949/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1950/10000], Training Loss: 0.58853715, Training Accuracy: 0.9622\n",
      "Epoch [1950/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1951/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1951/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1952/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1952/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1953/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [1953/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1954/10000], Training Loss: 0.58505843, Training Accuracy: 0.9664\n",
      "Epoch [1954/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1955/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1955/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1956/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1956/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1957/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1957/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1958/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [1958/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1959/10000], Training Loss: 0.59363680, Training Accuracy: 0.9580\n",
      "Epoch [1959/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1960/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [1960/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1961/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [1961/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1962/10000], Training Loss: 0.58510726, Training Accuracy: 0.9664\n",
      "Epoch [1962/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [1963/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1963/10000], Validation Loss: 1.02203286, Validation Accuracy: 0.5294\n",
      "Epoch [1964/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [1964/10000], Validation Loss: 1.02203137, Validation Accuracy: 0.5294\n",
      "Epoch [1965/10000], Training Loss: 0.56825168, Training Accuracy: 0.9832\n",
      "Epoch [1965/10000], Validation Loss: 1.02202886, Validation Accuracy: 0.5294\n",
      "Epoch [1966/10000], Training Loss: 0.58925634, Training Accuracy: 0.9622\n",
      "Epoch [1966/10000], Validation Loss: 1.02202648, Validation Accuracy: 0.5294\n",
      "Epoch [1967/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1967/10000], Validation Loss: 1.02202493, Validation Accuracy: 0.5294\n",
      "Epoch [1968/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1968/10000], Validation Loss: 1.02202404, Validation Accuracy: 0.5294\n",
      "Epoch [1969/10000], Training Loss: 0.57245427, Training Accuracy: 0.9790\n",
      "Epoch [1969/10000], Validation Loss: 1.02202350, Validation Accuracy: 0.5294\n",
      "Epoch [1970/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [1970/10000], Validation Loss: 1.02202326, Validation Accuracy: 0.5294\n",
      "Epoch [1971/10000], Training Loss: 0.57245383, Training Accuracy: 0.9790\n",
      "Epoch [1971/10000], Validation Loss: 1.02202314, Validation Accuracy: 0.5294\n",
      "Epoch [1972/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1972/10000], Validation Loss: 1.02202308, Validation Accuracy: 0.5294\n",
      "Epoch [1973/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [1973/10000], Validation Loss: 1.02202308, Validation Accuracy: 0.5294\n",
      "Epoch [1974/10000], Training Loss: 0.58499117, Training Accuracy: 0.9664\n",
      "Epoch [1974/10000], Validation Loss: 1.02164888, Validation Accuracy: 0.5294\n",
      "Epoch [1975/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1975/10000], Validation Loss: 1.02070045, Validation Accuracy: 0.5294\n",
      "Epoch [1976/10000], Training Loss: 0.58085699, Training Accuracy: 0.9706\n",
      "Epoch [1976/10000], Validation Loss: 1.02131921, Validation Accuracy: 0.5294\n",
      "Epoch [1977/10000], Training Loss: 0.58505808, Training Accuracy: 0.9664\n",
      "Epoch [1977/10000], Validation Loss: 1.02159494, Validation Accuracy: 0.5294\n",
      "Epoch [1978/10000], Training Loss: 0.59766351, Training Accuracy: 0.9538\n",
      "Epoch [1978/10000], Validation Loss: 1.02169013, Validation Accuracy: 0.5294\n",
      "Epoch [1979/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1979/10000], Validation Loss: 1.02172840, Validation Accuracy: 0.5294\n",
      "Epoch [1980/10000], Training Loss: 0.59311239, Training Accuracy: 0.9580\n",
      "Epoch [1980/10000], Validation Loss: 1.02199095, Validation Accuracy: 0.5294\n",
      "Epoch [1981/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1981/10000], Validation Loss: 1.02201688, Validation Accuracy: 0.5294\n",
      "Epoch [1982/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1982/10000], Validation Loss: 1.02202278, Validation Accuracy: 0.5294\n",
      "Epoch [1983/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1983/10000], Validation Loss: 1.02202481, Validation Accuracy: 0.5294\n",
      "Epoch [1984/10000], Training Loss: 0.58380895, Training Accuracy: 0.9664\n",
      "Epoch [1984/10000], Validation Loss: 1.00805971, Validation Accuracy: 0.5441\n",
      "Epoch [1985/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1985/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1986/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [1986/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1987/10000], Training Loss: 0.59765034, Training Accuracy: 0.9538\n",
      "Epoch [1987/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1988/10000], Training Loss: 0.56825249, Training Accuracy: 0.9832\n",
      "Epoch [1988/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1989/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [1989/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1990/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [1990/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1991/10000], Training Loss: 0.58085573, Training Accuracy: 0.9706\n",
      "Epoch [1991/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1992/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1992/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1993/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [1993/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1994/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [1994/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1995/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [1995/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1996/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [1996/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1997/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [1997/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1998/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [1998/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [1999/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [1999/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2000/10000], Training Loss: 0.57656510, Training Accuracy: 0.9748\n",
      "Epoch [2000/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2001/10000], Training Loss: 0.58505912, Training Accuracy: 0.9664\n",
      "Epoch [2001/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2002/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2002/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2003/10000], Training Loss: 0.58080496, Training Accuracy: 0.9706\n",
      "Epoch [2003/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2004/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2004/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2005/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2005/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2006/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2006/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2007/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2007/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2008/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2008/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2009/10000], Training Loss: 0.60986617, Training Accuracy: 0.9412\n",
      "Epoch [2009/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2010/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [2010/10000], Validation Loss: 1.00732794, Validation Accuracy: 0.5441\n",
      "Epoch [2011/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2011/10000], Validation Loss: 1.00742945, Validation Accuracy: 0.5441\n",
      "Epoch [2012/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2012/10000], Validation Loss: 1.00842652, Validation Accuracy: 0.5441\n",
      "Epoch [2013/10000], Training Loss: 0.57363883, Training Accuracy: 0.9790\n",
      "Epoch [2013/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2014/10000], Training Loss: 0.56785930, Training Accuracy: 0.9832\n",
      "Epoch [2014/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2015/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [2015/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2016/10000], Training Loss: 0.58926253, Training Accuracy: 0.9622\n",
      "Epoch [2016/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2017/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2017/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2018/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2018/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2019/10000], Training Loss: 0.57245341, Training Accuracy: 0.9790\n",
      "Epoch [2019/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2020/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2020/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2021/10000], Training Loss: 0.57256994, Training Accuracy: 0.9790\n",
      "Epoch [2021/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2022/10000], Training Loss: 0.57663191, Training Accuracy: 0.9748\n",
      "Epoch [2022/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2023/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [2023/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2024/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2024/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2025/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2025/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2026/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [2026/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2027/10000], Training Loss: 0.57663574, Training Accuracy: 0.9748\n",
      "Epoch [2027/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2028/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2028/10000], Validation Loss: 1.02203390, Validation Accuracy: 0.5294\n",
      "Epoch [2029/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2029/10000], Validation Loss: 1.02203885, Validation Accuracy: 0.5294\n",
      "Epoch [2030/10000], Training Loss: 0.58505823, Training Accuracy: 0.9664\n",
      "Epoch [2030/10000], Validation Loss: 1.02204582, Validation Accuracy: 0.5294\n",
      "Epoch [2031/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2031/10000], Validation Loss: 1.02205083, Validation Accuracy: 0.5294\n",
      "Epoch [2032/10000], Training Loss: 0.57245340, Training Accuracy: 0.9790\n",
      "Epoch [2032/10000], Validation Loss: 1.02205387, Validation Accuracy: 0.5294\n",
      "Epoch [2033/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2033/10000], Validation Loss: 1.02205560, Validation Accuracy: 0.5294\n",
      "Epoch [2034/10000], Training Loss: 0.58505843, Training Accuracy: 0.9664\n",
      "Epoch [2034/10000], Validation Loss: 1.02206090, Validation Accuracy: 0.5294\n",
      "Epoch [2035/10000], Training Loss: 0.57665509, Training Accuracy: 0.9748\n",
      "Epoch [2035/10000], Validation Loss: 0.99265778, Validation Accuracy: 0.5588\n",
      "Epoch [2036/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2036/10000], Validation Loss: 0.99266315, Validation Accuracy: 0.5588\n",
      "Epoch [2037/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2037/10000], Validation Loss: 0.99266601, Validation Accuracy: 0.5588\n",
      "Epoch [2038/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2038/10000], Validation Loss: 0.99266738, Validation Accuracy: 0.5588\n",
      "Epoch [2039/10000], Training Loss: 0.58085669, Training Accuracy: 0.9706\n",
      "Epoch [2039/10000], Validation Loss: 0.99266803, Validation Accuracy: 0.5588\n",
      "Epoch [2040/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2040/10000], Validation Loss: 0.99266839, Validation Accuracy: 0.5588\n",
      "Epoch [2041/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2041/10000], Validation Loss: 0.99266857, Validation Accuracy: 0.5588\n",
      "Epoch [2042/10000], Training Loss: 0.58067615, Training Accuracy: 0.9706\n",
      "Epoch [2042/10000], Validation Loss: 0.99298656, Validation Accuracy: 0.5588\n",
      "Epoch [2043/10000], Training Loss: 0.58085665, Training Accuracy: 0.9706\n",
      "Epoch [2043/10000], Validation Loss: 0.99356848, Validation Accuracy: 0.5588\n",
      "Epoch [2044/10000], Training Loss: 0.58505832, Training Accuracy: 0.9664\n",
      "Epoch [2044/10000], Validation Loss: 0.99410266, Validation Accuracy: 0.5588\n",
      "Epoch [2045/10000], Training Loss: 0.58918621, Training Accuracy: 0.9622\n",
      "Epoch [2045/10000], Validation Loss: 1.00106543, Validation Accuracy: 0.5441\n",
      "Epoch [2046/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2046/10000], Validation Loss: 1.00920188, Validation Accuracy: 0.5441\n",
      "Epoch [2047/10000], Training Loss: 0.57302483, Training Accuracy: 0.9790\n",
      "Epoch [2047/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2048/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2048/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2049/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [2049/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2050/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2050/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2051/10000], Training Loss: 0.58177283, Training Accuracy: 0.9706\n",
      "Epoch [2051/10000], Validation Loss: 1.01985571, Validation Accuracy: 0.5294\n",
      "Epoch [2052/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2052/10000], Validation Loss: 0.99262112, Validation Accuracy: 0.5588\n",
      "Epoch [2053/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2053/10000], Validation Loss: 0.97793630, Validation Accuracy: 0.5735\n",
      "Epoch [2054/10000], Training Loss: 0.58085900, Training Accuracy: 0.9706\n",
      "Epoch [2054/10000], Validation Loss: 0.97791541, Validation Accuracy: 0.5735\n",
      "Epoch [2055/10000], Training Loss: 0.58153406, Training Accuracy: 0.9706\n",
      "Epoch [2055/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2056/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2056/10000], Validation Loss: 0.99262148, Validation Accuracy: 0.5588\n",
      "Epoch [2057/10000], Training Loss: 0.56405000, Training Accuracy: 0.9874\n",
      "Epoch [2057/10000], Validation Loss: 0.99285224, Validation Accuracy: 0.5588\n",
      "Epoch [2058/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2058/10000], Validation Loss: 0.99942881, Validation Accuracy: 0.5441\n",
      "Epoch [2059/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2059/10000], Validation Loss: 1.00515404, Validation Accuracy: 0.5441\n",
      "Epoch [2060/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [2060/10000], Validation Loss: 1.00635880, Validation Accuracy: 0.5441\n",
      "Epoch [2061/10000], Training Loss: 0.57665523, Training Accuracy: 0.9748\n",
      "Epoch [2061/10000], Validation Loss: 1.00679868, Validation Accuracy: 0.5441\n",
      "Epoch [2062/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2062/10000], Validation Loss: 1.00697276, Validation Accuracy: 0.5441\n",
      "Epoch [2063/10000], Training Loss: 0.58085848, Training Accuracy: 0.9706\n",
      "Epoch [2063/10000], Validation Loss: 1.00702688, Validation Accuracy: 0.5441\n",
      "Epoch [2064/10000], Training Loss: 0.58926057, Training Accuracy: 0.9622\n",
      "Epoch [2064/10000], Validation Loss: 1.00704956, Validation Accuracy: 0.5441\n",
      "Epoch [2065/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2065/10000], Validation Loss: 1.00706005, Validation Accuracy: 0.5441\n",
      "Epoch [2066/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2066/10000], Validation Loss: 1.00706494, Validation Accuracy: 0.5441\n",
      "Epoch [2067/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2067/10000], Validation Loss: 1.00706723, Validation Accuracy: 0.5441\n",
      "Epoch [2068/10000], Training Loss: 0.59346162, Training Accuracy: 0.9580\n",
      "Epoch [2068/10000], Validation Loss: 1.00706834, Validation Accuracy: 0.5441\n",
      "Epoch [2069/10000], Training Loss: 0.60155740, Training Accuracy: 0.9496\n",
      "Epoch [2069/10000], Validation Loss: 1.00717768, Validation Accuracy: 0.5441\n",
      "Epoch [2070/10000], Training Loss: 0.58501305, Training Accuracy: 0.9664\n",
      "Epoch [2070/10000], Validation Loss: 1.00722817, Validation Accuracy: 0.5441\n",
      "Epoch [2071/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2071/10000], Validation Loss: 1.00724742, Validation Accuracy: 0.5441\n",
      "Epoch [2072/10000], Training Loss: 0.58505771, Training Accuracy: 0.9664\n",
      "Epoch [2072/10000], Validation Loss: 1.00725493, Validation Accuracy: 0.5441\n",
      "Epoch [2073/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [2073/10000], Validation Loss: 1.00725663, Validation Accuracy: 0.5441\n",
      "Epoch [2074/10000], Training Loss: 0.58966257, Training Accuracy: 0.9622\n",
      "Epoch [2074/10000], Validation Loss: 1.00725904, Validation Accuracy: 0.5441\n",
      "Epoch [2075/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2075/10000], Validation Loss: 1.00726032, Validation Accuracy: 0.5441\n",
      "Epoch [2076/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [2076/10000], Validation Loss: 1.00726098, Validation Accuracy: 0.5441\n",
      "Epoch [2077/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2077/10000], Validation Loss: 1.00726134, Validation Accuracy: 0.5441\n",
      "Epoch [2078/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2078/10000], Validation Loss: 1.00726146, Validation Accuracy: 0.5441\n",
      "Epoch [2079/10000], Training Loss: 0.57664532, Training Accuracy: 0.9748\n",
      "Epoch [2079/10000], Validation Loss: 1.00661132, Validation Accuracy: 0.5441\n",
      "Epoch [2080/10000], Training Loss: 0.58507682, Training Accuracy: 0.9664\n",
      "Epoch [2080/10000], Validation Loss: 1.00258446, Validation Accuracy: 0.5441\n",
      "Epoch [2081/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [2081/10000], Validation Loss: 0.99852988, Validation Accuracy: 0.5588\n",
      "Epoch [2082/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2082/10000], Validation Loss: 0.99673131, Validation Accuracy: 0.5588\n",
      "Epoch [2083/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2083/10000], Validation Loss: 0.99598387, Validation Accuracy: 0.5588\n",
      "Epoch [2084/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2084/10000], Validation Loss: 0.99566135, Validation Accuracy: 0.5588\n",
      "Epoch [2085/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2085/10000], Validation Loss: 0.99551487, Validation Accuracy: 0.5588\n",
      "Epoch [2086/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2086/10000], Validation Loss: 0.99544665, Validation Accuracy: 0.5588\n",
      "Epoch [2087/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [2087/10000], Validation Loss: 0.99541435, Validation Accuracy: 0.5588\n",
      "Epoch [2088/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2088/10000], Validation Loss: 0.99539897, Validation Accuracy: 0.5588\n",
      "Epoch [2089/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [2089/10000], Validation Loss: 0.99539167, Validation Accuracy: 0.5588\n",
      "Epoch [2090/10000], Training Loss: 0.58085763, Training Accuracy: 0.9706\n",
      "Epoch [2090/10000], Validation Loss: 0.99562448, Validation Accuracy: 0.5588\n",
      "Epoch [2091/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [2091/10000], Validation Loss: 0.99574119, Validation Accuracy: 0.5588\n",
      "Epoch [2092/10000], Training Loss: 0.59719590, Training Accuracy: 0.9538\n",
      "Epoch [2092/10000], Validation Loss: 1.02344167, Validation Accuracy: 0.5294\n",
      "Epoch [2093/10000], Training Loss: 0.56825169, Training Accuracy: 0.9832\n",
      "Epoch [2093/10000], Validation Loss: 1.03673846, Validation Accuracy: 0.5147\n",
      "Epoch [2094/10000], Training Loss: 0.57506188, Training Accuracy: 0.9748\n",
      "Epoch [2094/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [2095/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2095/10000], Validation Loss: 1.03673145, Validation Accuracy: 0.5147\n",
      "Epoch [2096/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2096/10000], Validation Loss: 1.02215949, Validation Accuracy: 0.5294\n",
      "Epoch [2097/10000], Training Loss: 0.58085514, Training Accuracy: 0.9706\n",
      "Epoch [2097/10000], Validation Loss: 1.02240300, Validation Accuracy: 0.5294\n",
      "Epoch [2098/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2098/10000], Validation Loss: 1.03535575, Validation Accuracy: 0.5147\n",
      "Epoch [2099/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [2099/10000], Validation Loss: 1.03665113, Validation Accuracy: 0.5147\n",
      "Epoch [2100/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2100/10000], Validation Loss: 1.03671670, Validation Accuracy: 0.5147\n",
      "Epoch [2101/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [2101/10000], Validation Loss: 1.03672749, Validation Accuracy: 0.5147\n",
      "Epoch [2102/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2102/10000], Validation Loss: 1.03673065, Validation Accuracy: 0.5147\n",
      "Epoch [2103/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2103/10000], Validation Loss: 1.03673184, Validation Accuracy: 0.5147\n",
      "Epoch [2104/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [2104/10000], Validation Loss: 1.03673232, Validation Accuracy: 0.5147\n",
      "Epoch [2105/10000], Training Loss: 0.58928489, Training Accuracy: 0.9622\n",
      "Epoch [2105/10000], Validation Loss: 1.03673053, Validation Accuracy: 0.5147\n",
      "Epoch [2106/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2106/10000], Validation Loss: 1.03672922, Validation Accuracy: 0.5147\n",
      "Epoch [2107/10000], Training Loss: 0.58926006, Training Accuracy: 0.9622\n",
      "Epoch [2107/10000], Validation Loss: 1.03672844, Validation Accuracy: 0.5147\n",
      "Epoch [2108/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2108/10000], Validation Loss: 1.03672814, Validation Accuracy: 0.5147\n",
      "Epoch [2109/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2109/10000], Validation Loss: 1.03672791, Validation Accuracy: 0.5147\n",
      "Epoch [2110/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [2110/10000], Validation Loss: 1.03672785, Validation Accuracy: 0.5147\n",
      "Epoch [2111/10000], Training Loss: 0.60186508, Training Accuracy: 0.9496\n",
      "Epoch [2111/10000], Validation Loss: 1.03672779, Validation Accuracy: 0.5147\n",
      "Epoch [2112/10000], Training Loss: 0.57245336, Training Accuracy: 0.9790\n",
      "Epoch [2112/10000], Validation Loss: 1.03672779, Validation Accuracy: 0.5147\n",
      "Epoch [2113/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2113/10000], Validation Loss: 1.03672779, Validation Accuracy: 0.5147\n",
      "Epoch [2114/10000], Training Loss: 0.58105539, Training Accuracy: 0.9706\n",
      "Epoch [2114/10000], Validation Loss: 1.02204648, Validation Accuracy: 0.5294\n",
      "Epoch [2115/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [2115/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [2116/10000], Training Loss: 0.60186618, Training Accuracy: 0.9496\n",
      "Epoch [2116/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [2117/10000], Training Loss: 0.58085779, Training Accuracy: 0.9706\n",
      "Epoch [2117/10000], Validation Loss: 1.02203324, Validation Accuracy: 0.5294\n",
      "Epoch [2118/10000], Training Loss: 0.59342912, Training Accuracy: 0.9580\n",
      "Epoch [2118/10000], Validation Loss: 1.02203330, Validation Accuracy: 0.5294\n",
      "Epoch [2119/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2119/10000], Validation Loss: 1.02203342, Validation Accuracy: 0.5294\n",
      "Epoch [2120/10000], Training Loss: 0.58516750, Training Accuracy: 0.9664\n",
      "Epoch [2120/10000], Validation Loss: 1.02206430, Validation Accuracy: 0.5294\n",
      "Epoch [2121/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2121/10000], Validation Loss: 1.03112671, Validation Accuracy: 0.5147\n",
      "Epoch [2122/10000], Training Loss: 0.57245337, Training Accuracy: 0.9790\n",
      "Epoch [2122/10000], Validation Loss: 1.03637847, Validation Accuracy: 0.5147\n",
      "Epoch [2123/10000], Training Loss: 0.58926010, Training Accuracy: 0.9622\n",
      "Epoch [2123/10000], Validation Loss: 1.03665942, Validation Accuracy: 0.5147\n",
      "Epoch [2124/10000], Training Loss: 0.58116272, Training Accuracy: 0.9706\n",
      "Epoch [2124/10000], Validation Loss: 1.01785719, Validation Accuracy: 0.5294\n",
      "Epoch [2125/10000], Training Loss: 0.58719752, Training Accuracy: 0.9622\n",
      "Epoch [2125/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [2126/10000], Training Loss: 0.58926186, Training Accuracy: 0.9622\n",
      "Epoch [2126/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [2127/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2127/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2128/10000], Training Loss: 0.61408342, Training Accuracy: 0.9370\n",
      "Epoch [2128/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [2129/10000], Training Loss: 0.60994073, Training Accuracy: 0.9412\n",
      "Epoch [2129/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [2130/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [2130/10000], Validation Loss: 0.99262127, Validation Accuracy: 0.5588\n",
      "Epoch [2131/10000], Training Loss: 0.60606731, Training Accuracy: 0.9454\n",
      "Epoch [2131/10000], Validation Loss: 0.99262103, Validation Accuracy: 0.5588\n",
      "Epoch [2132/10000], Training Loss: 0.60186516, Training Accuracy: 0.9496\n",
      "Epoch [2132/10000], Validation Loss: 0.99262074, Validation Accuracy: 0.5588\n",
      "Epoch [2133/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2133/10000], Validation Loss: 0.99262056, Validation Accuracy: 0.5588\n",
      "Epoch [2134/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2134/10000], Validation Loss: 0.99262044, Validation Accuracy: 0.5588\n",
      "Epoch [2135/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [2135/10000], Validation Loss: 0.99262038, Validation Accuracy: 0.5588\n",
      "Epoch [2136/10000], Training Loss: 0.59768493, Training Accuracy: 0.9538\n",
      "Epoch [2136/10000], Validation Loss: 0.99262080, Validation Accuracy: 0.5588\n",
      "Epoch [2137/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2137/10000], Validation Loss: 0.99262097, Validation Accuracy: 0.5588\n",
      "Epoch [2138/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2138/10000], Validation Loss: 0.99262097, Validation Accuracy: 0.5588\n",
      "Epoch [2139/10000], Training Loss: 0.59649803, Training Accuracy: 0.9538\n",
      "Epoch [2139/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [2140/10000], Training Loss: 0.59766489, Training Accuracy: 0.9538\n",
      "Epoch [2140/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [2141/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2141/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [2142/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2142/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [2143/10000], Training Loss: 0.61387063, Training Accuracy: 0.9370\n",
      "Epoch [2143/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [2144/10000], Training Loss: 0.60157269, Training Accuracy: 0.9496\n",
      "Epoch [2144/10000], Validation Loss: 0.96316162, Validation Accuracy: 0.5882\n",
      "Epoch [2145/10000], Training Loss: 0.59766342, Training Accuracy: 0.9538\n",
      "Epoch [2145/10000], Validation Loss: 0.94850415, Validation Accuracy: 0.6029\n",
      "Epoch [2146/10000], Training Loss: 0.59489759, Training Accuracy: 0.9580\n",
      "Epoch [2146/10000], Validation Loss: 0.99248561, Validation Accuracy: 0.5588\n",
      "Epoch [2147/10000], Training Loss: 0.61447012, Training Accuracy: 0.9370\n",
      "Epoch [2147/10000], Validation Loss: 0.94853812, Validation Accuracy: 0.6029\n",
      "Epoch [2148/10000], Training Loss: 0.63968015, Training Accuracy: 0.9118\n",
      "Epoch [2148/10000], Validation Loss: 0.93416268, Validation Accuracy: 0.6176\n",
      "Epoch [2149/10000], Training Loss: 0.63869805, Training Accuracy: 0.9118\n",
      "Epoch [2149/10000], Validation Loss: 0.93431807, Validation Accuracy: 0.6176\n",
      "Epoch [2150/10000], Training Loss: 0.63970034, Training Accuracy: 0.9118\n",
      "Epoch [2150/10000], Validation Loss: 0.94850385, Validation Accuracy: 0.6029\n",
      "Epoch [2151/10000], Training Loss: 0.62447496, Training Accuracy: 0.9286\n",
      "Epoch [2151/10000], Validation Loss: 0.96217483, Validation Accuracy: 0.5882\n",
      "Epoch [2152/10000], Training Loss: 0.62707551, Training Accuracy: 0.9244\n",
      "Epoch [2152/10000], Validation Loss: 0.94584143, Validation Accuracy: 0.6029\n",
      "Epoch [2153/10000], Training Loss: 0.64388269, Training Accuracy: 0.9076\n",
      "Epoch [2153/10000], Validation Loss: 0.97326729, Validation Accuracy: 0.5735\n",
      "Epoch [2154/10000], Training Loss: 0.63625158, Training Accuracy: 0.9160\n",
      "Epoch [2154/10000], Validation Loss: 0.97791538, Validation Accuracy: 0.5735\n",
      "Epoch [2155/10000], Training Loss: 0.65228297, Training Accuracy: 0.8992\n",
      "Epoch [2155/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2156/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [2156/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2157/10000], Training Loss: 0.66068842, Training Accuracy: 0.8908\n",
      "Epoch [2157/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2158/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2158/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2159/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2159/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2160/10000], Training Loss: 0.65648953, Training Accuracy: 0.8950\n",
      "Epoch [2160/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2161/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [2161/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2162/10000], Training Loss: 0.63917739, Training Accuracy: 0.9118\n",
      "Epoch [2162/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2163/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2163/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [2164/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2164/10000], Validation Loss: 0.96310431, Validation Accuracy: 0.5882\n",
      "Epoch [2165/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2165/10000], Validation Loss: 0.94851035, Validation Accuracy: 0.6029\n",
      "Epoch [2166/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [2166/10000], Validation Loss: 0.94699576, Validation Accuracy: 0.6029\n",
      "Epoch [2167/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [2167/10000], Validation Loss: 0.94935197, Validation Accuracy: 0.6029\n",
      "Epoch [2168/10000], Training Loss: 0.61866180, Training Accuracy: 0.9328\n",
      "Epoch [2168/10000], Validation Loss: 0.94860995, Validation Accuracy: 0.6029\n",
      "Epoch [2169/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2169/10000], Validation Loss: 0.94852367, Validation Accuracy: 0.6029\n",
      "Epoch [2170/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2170/10000], Validation Loss: 0.94851711, Validation Accuracy: 0.6029\n",
      "Epoch [2171/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [2171/10000], Validation Loss: 0.94851825, Validation Accuracy: 0.6029\n",
      "Epoch [2172/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2172/10000], Validation Loss: 0.94851995, Validation Accuracy: 0.6029\n",
      "Epoch [2173/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [2173/10000], Validation Loss: 0.94852102, Validation Accuracy: 0.6029\n",
      "Epoch [2174/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2174/10000], Validation Loss: 0.94852164, Validation Accuracy: 0.6029\n",
      "Epoch [2175/10000], Training Loss: 0.63597112, Training Accuracy: 0.9160\n",
      "Epoch [2175/10000], Validation Loss: 0.94854045, Validation Accuracy: 0.6029\n",
      "Epoch [2176/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2176/10000], Validation Loss: 0.96377546, Validation Accuracy: 0.5882\n",
      "Epoch [2177/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2177/10000], Validation Loss: 0.96321955, Validation Accuracy: 0.5882\n",
      "Epoch [2178/10000], Training Loss: 0.64149936, Training Accuracy: 0.9076\n",
      "Epoch [2178/10000], Validation Loss: 0.94850570, Validation Accuracy: 0.6029\n",
      "Epoch [2179/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2179/10000], Validation Loss: 0.96178600, Validation Accuracy: 0.5882\n",
      "Epoch [2180/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [2180/10000], Validation Loss: 0.96320575, Validation Accuracy: 0.5882\n",
      "Epoch [2181/10000], Training Loss: 0.65170068, Training Accuracy: 0.8992\n",
      "Epoch [2181/10000], Validation Loss: 0.96320951, Validation Accuracy: 0.5882\n",
      "Epoch [2182/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2182/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2183/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [2183/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2184/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [2184/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2185/10000], Training Loss: 0.65228404, Training Accuracy: 0.8992\n",
      "Epoch [2185/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2186/10000], Training Loss: 0.65650097, Training Accuracy: 0.8950\n",
      "Epoch [2186/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2187/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2187/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2188/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [2188/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2189/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [2189/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2190/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2190/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2191/10000], Training Loss: 0.65648661, Training Accuracy: 0.8950\n",
      "Epoch [2191/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2192/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2192/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2193/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2193/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2194/10000], Training Loss: 0.63075433, Training Accuracy: 0.9202\n",
      "Epoch [2194/10000], Validation Loss: 0.96631366, Validation Accuracy: 0.5882\n",
      "Epoch [2195/10000], Training Loss: 0.66042019, Training Accuracy: 0.8908\n",
      "Epoch [2195/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [2196/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2196/10000], Validation Loss: 0.94849041, Validation Accuracy: 0.6029\n",
      "Epoch [2197/10000], Training Loss: 0.64808341, Training Accuracy: 0.9034\n",
      "Epoch [2197/10000], Validation Loss: 0.93597093, Validation Accuracy: 0.6176\n",
      "Epoch [2198/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [2198/10000], Validation Loss: 0.93425515, Validation Accuracy: 0.6176\n",
      "Epoch [2199/10000], Training Loss: 0.65228525, Training Accuracy: 0.8992\n",
      "Epoch [2199/10000], Validation Loss: 0.93942991, Validation Accuracy: 0.6176\n",
      "Epoch [2200/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [2200/10000], Validation Loss: 0.94448900, Validation Accuracy: 0.6029\n",
      "Epoch [2201/10000], Training Loss: 0.63968031, Training Accuracy: 0.9118\n",
      "Epoch [2201/10000], Validation Loss: 0.94615132, Validation Accuracy: 0.6029\n",
      "Epoch [2202/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2202/10000], Validation Loss: 0.94672298, Validation Accuracy: 0.6029\n",
      "Epoch [2203/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2203/10000], Validation Loss: 0.94695160, Validation Accuracy: 0.6029\n",
      "Epoch [2204/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2204/10000], Validation Loss: 0.94705153, Validation Accuracy: 0.6029\n",
      "Epoch [2205/10000], Training Loss: 0.64387777, Training Accuracy: 0.9076\n",
      "Epoch [2205/10000], Validation Loss: 0.94661435, Validation Accuracy: 0.6029\n",
      "Epoch [2206/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2206/10000], Validation Loss: 0.94506270, Validation Accuracy: 0.6029\n",
      "Epoch [2207/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [2207/10000], Validation Loss: 0.94404820, Validation Accuracy: 0.6029\n",
      "Epoch [2208/10000], Training Loss: 0.64877767, Training Accuracy: 0.9034\n",
      "Epoch [2208/10000], Validation Loss: 0.95943055, Validation Accuracy: 0.5882\n",
      "Epoch [2209/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2209/10000], Validation Loss: 0.94851264, Validation Accuracy: 0.6029\n",
      "Epoch [2210/10000], Training Loss: 0.61446940, Training Accuracy: 0.9370\n",
      "Epoch [2210/10000], Validation Loss: 0.96133986, Validation Accuracy: 0.5882\n",
      "Epoch [2211/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2211/10000], Validation Loss: 0.96318859, Validation Accuracy: 0.5882\n",
      "Epoch [2212/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2212/10000], Validation Loss: 0.96320736, Validation Accuracy: 0.5882\n",
      "Epoch [2213/10000], Training Loss: 0.63548180, Training Accuracy: 0.9160\n",
      "Epoch [2213/10000], Validation Loss: 0.96320900, Validation Accuracy: 0.5882\n",
      "Epoch [2214/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2214/10000], Validation Loss: 0.96320933, Validation Accuracy: 0.5882\n",
      "Epoch [2215/10000], Training Loss: 0.62286115, Training Accuracy: 0.9286\n",
      "Epoch [2215/10000], Validation Loss: 0.96320495, Validation Accuracy: 0.5882\n",
      "Epoch [2216/10000], Training Loss: 0.62706574, Training Accuracy: 0.9244\n",
      "Epoch [2216/10000], Validation Loss: 0.96318847, Validation Accuracy: 0.5882\n",
      "Epoch [2217/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2217/10000], Validation Loss: 0.96318841, Validation Accuracy: 0.5882\n",
      "Epoch [2218/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2218/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2219/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2219/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2220/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2220/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2221/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2221/10000], Validation Loss: 0.96318829, Validation Accuracy: 0.5882\n",
      "Epoch [2222/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2222/10000], Validation Loss: 0.96318829, Validation Accuracy: 0.5882\n",
      "Epoch [2223/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [2223/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2224/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2224/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2225/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2225/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2226/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2226/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2227/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2227/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2228/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2228/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2229/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2229/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2230/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [2230/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2231/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2231/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2232/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2232/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2233/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2233/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2234/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2234/10000], Validation Loss: 0.96318835, Validation Accuracy: 0.5882\n",
      "Epoch [2235/10000], Training Loss: 0.63127707, Training Accuracy: 0.9202\n",
      "Epoch [2235/10000], Validation Loss: 0.96318817, Validation Accuracy: 0.5882\n",
      "Epoch [2236/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2236/10000], Validation Loss: 0.96318814, Validation Accuracy: 0.5882\n",
      "Epoch [2237/10000], Training Loss: 0.61871848, Training Accuracy: 0.9328\n",
      "Epoch [2237/10000], Validation Loss: 0.96310449, Validation Accuracy: 0.5882\n",
      "Epoch [2238/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2238/10000], Validation Loss: 0.96298522, Validation Accuracy: 0.5882\n",
      "Epoch [2239/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2239/10000], Validation Loss: 0.96288744, Validation Accuracy: 0.5882\n",
      "Epoch [2240/10000], Training Loss: 0.62707529, Training Accuracy: 0.9244\n",
      "Epoch [2240/10000], Validation Loss: 0.96282488, Validation Accuracy: 0.5882\n",
      "Epoch [2241/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2241/10000], Validation Loss: 0.96279079, Validation Accuracy: 0.5882\n",
      "Epoch [2242/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2242/10000], Validation Loss: 0.96277350, Validation Accuracy: 0.5882\n",
      "Epoch [2243/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2243/10000], Validation Loss: 0.96276498, Validation Accuracy: 0.5882\n",
      "Epoch [2244/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2244/10000], Validation Loss: 0.96276090, Validation Accuracy: 0.5882\n",
      "Epoch [2245/10000], Training Loss: 0.65228924, Training Accuracy: 0.8992\n",
      "Epoch [2245/10000], Validation Loss: 0.96267959, Validation Accuracy: 0.5882\n",
      "Epoch [2246/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2246/10000], Validation Loss: 0.96245000, Validation Accuracy: 0.5882\n",
      "Epoch [2247/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [2247/10000], Validation Loss: 0.96230862, Validation Accuracy: 0.5882\n",
      "Epoch [2248/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2248/10000], Validation Loss: 0.96223256, Validation Accuracy: 0.5882\n",
      "Epoch [2249/10000], Training Loss: 0.63928296, Training Accuracy: 0.9118\n",
      "Epoch [2249/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2250/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2250/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [2251/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2251/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2252/10000], Training Loss: 0.61446985, Training Accuracy: 0.9370\n",
      "Epoch [2252/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2253/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2253/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2254/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2254/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2255/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2255/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2256/10000], Training Loss: 0.62387833, Training Accuracy: 0.9286\n",
      "Epoch [2256/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2257/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2257/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2258/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2258/10000], Validation Loss: 0.96365932, Validation Accuracy: 0.5882\n",
      "Epoch [2259/10000], Training Loss: 0.63150232, Training Accuracy: 0.9202\n",
      "Epoch [2259/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2260/10000], Training Loss: 0.62707478, Training Accuracy: 0.9244\n",
      "Epoch [2260/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2261/10000], Training Loss: 0.61877268, Training Accuracy: 0.9328\n",
      "Epoch [2261/10000], Validation Loss: 0.97788239, Validation Accuracy: 0.5735\n",
      "Epoch [2262/10000], Training Loss: 0.61867187, Training Accuracy: 0.9328\n",
      "Epoch [2262/10000], Validation Loss: 0.98109552, Validation Accuracy: 0.5735\n",
      "Epoch [2263/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2263/10000], Validation Loss: 0.96365041, Validation Accuracy: 0.5882\n",
      "Epoch [2264/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2264/10000], Validation Loss: 0.96316004, Validation Accuracy: 0.5882\n",
      "Epoch [2265/10000], Training Loss: 0.60187630, Training Accuracy: 0.9496\n",
      "Epoch [2265/10000], Validation Loss: 0.96286184, Validation Accuracy: 0.5882\n",
      "Epoch [2266/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2266/10000], Validation Loss: 0.96251112, Validation Accuracy: 0.5882\n",
      "Epoch [2267/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2267/10000], Validation Loss: 0.96224287, Validation Accuracy: 0.5882\n",
      "Epoch [2268/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2268/10000], Validation Loss: 0.96208209, Validation Accuracy: 0.5882\n",
      "Epoch [2269/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2269/10000], Validation Loss: 0.96199647, Validation Accuracy: 0.5882\n",
      "Epoch [2270/10000], Training Loss: 0.62703130, Training Accuracy: 0.9244\n",
      "Epoch [2270/10000], Validation Loss: 0.95698041, Validation Accuracy: 0.5882\n",
      "Epoch [2271/10000], Training Loss: 0.63547848, Training Accuracy: 0.9160\n",
      "Epoch [2271/10000], Validation Loss: 0.95246094, Validation Accuracy: 0.6029\n",
      "Epoch [2272/10000], Training Loss: 0.61728290, Training Accuracy: 0.9328\n",
      "Epoch [2272/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2273/10000], Training Loss: 0.60186304, Training Accuracy: 0.9496\n",
      "Epoch [2273/10000], Validation Loss: 0.99258032, Validation Accuracy: 0.5588\n",
      "Epoch [2274/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2274/10000], Validation Loss: 1.00732964, Validation Accuracy: 0.5441\n",
      "Epoch [2275/10000], Training Loss: 0.61872086, Training Accuracy: 0.9328\n",
      "Epoch [2275/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2276/10000], Training Loss: 0.61445137, Training Accuracy: 0.9370\n",
      "Epoch [2276/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2277/10000], Training Loss: 0.60186518, Training Accuracy: 0.9496\n",
      "Epoch [2277/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2278/10000], Training Loss: 0.62248938, Training Accuracy: 0.9286\n",
      "Epoch [2278/10000], Validation Loss: 1.02203330, Validation Accuracy: 0.5294\n",
      "Epoch [2279/10000], Training Loss: 0.60602638, Training Accuracy: 0.9454\n",
      "Epoch [2279/10000], Validation Loss: 1.02203375, Validation Accuracy: 0.5294\n",
      "Epoch [2280/10000], Training Loss: 0.62707613, Training Accuracy: 0.9244\n",
      "Epoch [2280/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [2281/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2281/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2282/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2282/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2283/10000], Training Loss: 0.61448981, Training Accuracy: 0.9370\n",
      "Epoch [2283/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2284/10000], Training Loss: 0.59768483, Training Accuracy: 0.9538\n",
      "Epoch [2284/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2285/10000], Training Loss: 0.60471726, Training Accuracy: 0.9454\n",
      "Epoch [2285/10000], Validation Loss: 0.96320972, Validation Accuracy: 0.5882\n",
      "Epoch [2286/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2286/10000], Validation Loss: 0.96391842, Validation Accuracy: 0.5882\n",
      "Epoch [2287/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2287/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2288/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2288/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2289/10000], Training Loss: 0.60186630, Training Accuracy: 0.9496\n",
      "Epoch [2289/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2290/10000], Training Loss: 0.61026999, Training Accuracy: 0.9412\n",
      "Epoch [2290/10000], Validation Loss: 0.97791556, Validation Accuracy: 0.5735\n",
      "Epoch [2291/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2291/10000], Validation Loss: 0.97791567, Validation Accuracy: 0.5735\n",
      "Epoch [2292/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2292/10000], Validation Loss: 0.97791576, Validation Accuracy: 0.5735\n",
      "Epoch [2293/10000], Training Loss: 0.61108502, Training Accuracy: 0.9412\n",
      "Epoch [2293/10000], Validation Loss: 0.99262181, Validation Accuracy: 0.5588\n",
      "Epoch [2294/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [2294/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2295/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2295/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2296/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2296/10000], Validation Loss: 1.00713190, Validation Accuracy: 0.5441\n",
      "Epoch [2297/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2297/10000], Validation Loss: 0.99868193, Validation Accuracy: 0.5441\n",
      "Epoch [2298/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2298/10000], Validation Loss: 0.99363634, Validation Accuracy: 0.5588\n",
      "Epoch [2299/10000], Training Loss: 0.61849128, Training Accuracy: 0.9328\n",
      "Epoch [2299/10000], Validation Loss: 0.99262568, Validation Accuracy: 0.5588\n",
      "Epoch [2300/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2300/10000], Validation Loss: 0.97791433, Validation Accuracy: 0.5735\n",
      "Epoch [2301/10000], Training Loss: 0.61856392, Training Accuracy: 0.9328\n",
      "Epoch [2301/10000], Validation Loss: 1.00732645, Validation Accuracy: 0.5441\n",
      "Epoch [2302/10000], Training Loss: 0.60631029, Training Accuracy: 0.9454\n",
      "Epoch [2302/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2303/10000], Training Loss: 0.60453285, Training Accuracy: 0.9454\n",
      "Epoch [2303/10000], Validation Loss: 1.02203572, Validation Accuracy: 0.5294\n",
      "Epoch [2304/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2304/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2305/10000], Training Loss: 0.60042128, Training Accuracy: 0.9496\n",
      "Epoch [2305/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2306/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2306/10000], Validation Loss: 1.00730267, Validation Accuracy: 0.5441\n",
      "Epoch [2307/10000], Training Loss: 0.60606668, Training Accuracy: 0.9454\n",
      "Epoch [2307/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2308/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2308/10000], Validation Loss: 1.00732753, Validation Accuracy: 0.5441\n",
      "Epoch [2309/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2309/10000], Validation Loss: 1.00743690, Validation Accuracy: 0.5441\n",
      "Epoch [2310/10000], Training Loss: 0.61725817, Training Accuracy: 0.9328\n",
      "Epoch [2310/10000], Validation Loss: 1.02411461, Validation Accuracy: 0.5294\n",
      "Epoch [2311/10000], Training Loss: 0.61867773, Training Accuracy: 0.9328\n",
      "Epoch [2311/10000], Validation Loss: 1.02339250, Validation Accuracy: 0.5294\n",
      "Epoch [2312/10000], Training Loss: 0.61442538, Training Accuracy: 0.9370\n",
      "Epoch [2312/10000], Validation Loss: 1.02200109, Validation Accuracy: 0.5294\n",
      "Epoch [2313/10000], Training Loss: 0.60606630, Training Accuracy: 0.9454\n",
      "Epoch [2313/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2314/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2314/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2315/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2315/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2316/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2316/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2317/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2317/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2318/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2318/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2319/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2319/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2320/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2320/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2321/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2321/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2322/10000], Training Loss: 0.61026858, Training Accuracy: 0.9412\n",
      "Epoch [2322/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2323/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [2323/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2324/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2324/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2325/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2325/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2326/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2326/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2327/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2327/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2328/10000], Training Loss: 0.60606911, Training Accuracy: 0.9454\n",
      "Epoch [2328/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2329/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2329/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2330/10000], Training Loss: 0.59765083, Training Accuracy: 0.9538\n",
      "Epoch [2330/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2331/10000], Training Loss: 0.61867297, Training Accuracy: 0.9328\n",
      "Epoch [2331/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2332/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2332/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2333/10000], Training Loss: 0.59766322, Training Accuracy: 0.9538\n",
      "Epoch [2333/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2334/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2334/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2335/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2335/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2336/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2336/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2337/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2337/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2338/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2338/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2339/10000], Training Loss: 0.61447194, Training Accuracy: 0.9370\n",
      "Epoch [2339/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2340/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2340/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2341/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2341/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2342/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2342/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2343/10000], Training Loss: 0.60606638, Training Accuracy: 0.9454\n",
      "Epoch [2343/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2344/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [2344/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2345/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2345/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2346/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2346/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2347/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2347/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2348/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2348/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2349/10000], Training Loss: 0.61868368, Training Accuracy: 0.9328\n",
      "Epoch [2349/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2350/10000], Training Loss: 0.60186438, Training Accuracy: 0.9496\n",
      "Epoch [2350/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2351/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2351/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2352/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2352/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2353/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2353/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2354/10000], Training Loss: 0.59764545, Training Accuracy: 0.9538\n",
      "Epoch [2354/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2355/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2355/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2356/10000], Training Loss: 0.59346372, Training Accuracy: 0.9580\n",
      "Epoch [2356/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2357/10000], Training Loss: 0.60738201, Training Accuracy: 0.9454\n",
      "Epoch [2357/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2358/10000], Training Loss: 0.61857969, Training Accuracy: 0.9328\n",
      "Epoch [2358/10000], Validation Loss: 1.00733608, Validation Accuracy: 0.5441\n",
      "Epoch [2359/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2359/10000], Validation Loss: 1.00734243, Validation Accuracy: 0.5441\n",
      "Epoch [2360/10000], Training Loss: 0.60186529, Training Accuracy: 0.9496\n",
      "Epoch [2360/10000], Validation Loss: 1.02112210, Validation Accuracy: 0.5294\n",
      "Epoch [2361/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2361/10000], Validation Loss: 1.02179646, Validation Accuracy: 0.5294\n",
      "Epoch [2362/10000], Training Loss: 0.61447116, Training Accuracy: 0.9370\n",
      "Epoch [2362/10000], Validation Loss: 1.02195948, Validation Accuracy: 0.5294\n",
      "Epoch [2363/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2363/10000], Validation Loss: 1.02146274, Validation Accuracy: 0.5294\n",
      "Epoch [2364/10000], Training Loss: 0.60191000, Training Accuracy: 0.9496\n",
      "Epoch [2364/10000], Validation Loss: 1.00802711, Validation Accuracy: 0.5441\n",
      "Epoch [2365/10000], Training Loss: 0.62287388, Training Accuracy: 0.9286\n",
      "Epoch [2365/10000], Validation Loss: 1.00736919, Validation Accuracy: 0.5441\n",
      "Epoch [2366/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2366/10000], Validation Loss: 1.00733861, Validation Accuracy: 0.5441\n",
      "Epoch [2367/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2367/10000], Validation Loss: 0.99262747, Validation Accuracy: 0.5588\n",
      "Epoch [2368/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2368/10000], Validation Loss: 0.99262592, Validation Accuracy: 0.5588\n",
      "Epoch [2369/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2369/10000], Validation Loss: 0.99262530, Validation Accuracy: 0.5588\n",
      "Epoch [2370/10000], Training Loss: 0.61447005, Training Accuracy: 0.9370\n",
      "Epoch [2370/10000], Validation Loss: 0.99262530, Validation Accuracy: 0.5588\n",
      "Epoch [2371/10000], Training Loss: 0.61026759, Training Accuracy: 0.9412\n",
      "Epoch [2371/10000], Validation Loss: 0.99262556, Validation Accuracy: 0.5588\n",
      "Epoch [2372/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2372/10000], Validation Loss: 0.99262688, Validation Accuracy: 0.5588\n",
      "Epoch [2373/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [2373/10000], Validation Loss: 0.99262771, Validation Accuracy: 0.5588\n",
      "Epoch [2374/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2374/10000], Validation Loss: 0.99262810, Validation Accuracy: 0.5588\n",
      "Epoch [2375/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2375/10000], Validation Loss: 0.99262831, Validation Accuracy: 0.5588\n",
      "Epoch [2376/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2376/10000], Validation Loss: 0.99262837, Validation Accuracy: 0.5588\n",
      "Epoch [2377/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2377/10000], Validation Loss: 0.99262843, Validation Accuracy: 0.5588\n",
      "Epoch [2378/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2378/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2379/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [2379/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2380/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2380/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2381/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2381/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2382/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2382/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2383/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2383/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2384/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2384/10000], Validation Loss: 0.99262848, Validation Accuracy: 0.5588\n",
      "Epoch [2385/10000], Training Loss: 0.59344654, Training Accuracy: 0.9580\n",
      "Epoch [2385/10000], Validation Loss: 0.99423683, Validation Accuracy: 0.5588\n",
      "Epoch [2386/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2386/10000], Validation Loss: 1.00391975, Validation Accuracy: 0.5441\n",
      "Epoch [2387/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2387/10000], Validation Loss: 1.00640813, Validation Accuracy: 0.5441\n",
      "Epoch [2388/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2388/10000], Validation Loss: 1.00685975, Validation Accuracy: 0.5441\n",
      "Epoch [2389/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2389/10000], Validation Loss: 1.00699064, Validation Accuracy: 0.5441\n",
      "Epoch [2390/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2390/10000], Validation Loss: 1.00703993, Validation Accuracy: 0.5441\n",
      "Epoch [2391/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2391/10000], Validation Loss: 1.00706097, Validation Accuracy: 0.5441\n",
      "Epoch [2392/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2392/10000], Validation Loss: 1.00707051, Validation Accuracy: 0.5441\n",
      "Epoch [2393/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [2393/10000], Validation Loss: 1.00707504, Validation Accuracy: 0.5441\n",
      "Epoch [2394/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2394/10000], Validation Loss: 1.00707713, Validation Accuracy: 0.5441\n",
      "Epoch [2395/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2395/10000], Validation Loss: 1.00707814, Validation Accuracy: 0.5441\n",
      "Epoch [2396/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2396/10000], Validation Loss: 1.00707856, Validation Accuracy: 0.5441\n",
      "Epoch [2397/10000], Training Loss: 0.62772708, Training Accuracy: 0.9244\n",
      "Epoch [2397/10000], Validation Loss: 0.99262181, Validation Accuracy: 0.5588\n",
      "Epoch [2398/10000], Training Loss: 0.60084793, Training Accuracy: 0.9496\n",
      "Epoch [2398/10000], Validation Loss: 0.96320966, Validation Accuracy: 0.5882\n",
      "Epoch [2399/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2399/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2400/10000], Training Loss: 0.63544278, Training Accuracy: 0.9160\n",
      "Epoch [2400/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2401/10000], Training Loss: 0.64388150, Training Accuracy: 0.9076\n",
      "Epoch [2401/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2402/10000], Training Loss: 0.65648725, Training Accuracy: 0.8950\n",
      "Epoch [2402/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2403/10000], Training Loss: 0.60629738, Training Accuracy: 0.9454\n",
      "Epoch [2403/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2404/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [2404/10000], Validation Loss: 0.96321106, Validation Accuracy: 0.5882\n",
      "Epoch [2405/10000], Training Loss: 0.64027439, Training Accuracy: 0.9118\n",
      "Epoch [2405/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2406/10000], Training Loss: 0.63127681, Training Accuracy: 0.9202\n",
      "Epoch [2406/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2407/10000], Training Loss: 0.61447013, Training Accuracy: 0.9370\n",
      "Epoch [2407/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2408/10000], Training Loss: 0.61051802, Training Accuracy: 0.9412\n",
      "Epoch [2408/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2409/10000], Training Loss: 0.62707159, Training Accuracy: 0.9244\n",
      "Epoch [2409/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2410/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2410/10000], Validation Loss: 0.96052265, Validation Accuracy: 0.5882\n",
      "Epoch [2411/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2411/10000], Validation Loss: 0.94869858, Validation Accuracy: 0.6029\n",
      "Epoch [2412/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2412/10000], Validation Loss: 0.94849867, Validation Accuracy: 0.6029\n",
      "Epoch [2413/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [2413/10000], Validation Loss: 0.94842157, Validation Accuracy: 0.6029\n",
      "Epoch [2414/10000], Training Loss: 0.61542300, Training Accuracy: 0.9370\n",
      "Epoch [2414/10000], Validation Loss: 0.94837409, Validation Accuracy: 0.6029\n",
      "Epoch [2415/10000], Training Loss: 0.61206682, Training Accuracy: 0.9412\n",
      "Epoch [2415/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2416/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2416/10000], Validation Loss: 0.96745813, Validation Accuracy: 0.5882\n",
      "Epoch [2417/10000], Training Loss: 0.60608000, Training Accuracy: 0.9454\n",
      "Epoch [2417/10000], Validation Loss: 0.96367696, Validation Accuracy: 0.5882\n",
      "Epoch [2418/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [2418/10000], Validation Loss: 0.96321332, Validation Accuracy: 0.5882\n",
      "Epoch [2419/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2419/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [2420/10000], Training Loss: 0.59593600, Training Accuracy: 0.9538\n",
      "Epoch [2420/10000], Validation Loss: 0.96320978, Validation Accuracy: 0.5882\n",
      "Epoch [2421/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2421/10000], Validation Loss: 0.96321028, Validation Accuracy: 0.5882\n",
      "Epoch [2422/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2422/10000], Validation Loss: 0.96321091, Validation Accuracy: 0.5882\n",
      "Epoch [2423/10000], Training Loss: 0.60185302, Training Accuracy: 0.9496\n",
      "Epoch [2423/10000], Validation Loss: 0.96321332, Validation Accuracy: 0.5882\n",
      "Epoch [2424/10000], Training Loss: 0.60606728, Training Accuracy: 0.9454\n",
      "Epoch [2424/10000], Validation Loss: 0.97791252, Validation Accuracy: 0.5735\n",
      "Epoch [2425/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [2425/10000], Validation Loss: 0.97660586, Validation Accuracy: 0.5735\n",
      "Epoch [2426/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2426/10000], Validation Loss: 0.97783828, Validation Accuracy: 0.5735\n",
      "Epoch [2427/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2427/10000], Validation Loss: 0.97790268, Validation Accuracy: 0.5735\n",
      "Epoch [2428/10000], Training Loss: 0.62287327, Training Accuracy: 0.9286\n",
      "Epoch [2428/10000], Validation Loss: 0.97791043, Validation Accuracy: 0.5735\n",
      "Epoch [2429/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2429/10000], Validation Loss: 0.97791240, Validation Accuracy: 0.5735\n",
      "Epoch [2430/10000], Training Loss: 0.60605870, Training Accuracy: 0.9454\n",
      "Epoch [2430/10000], Validation Loss: 0.97791454, Validation Accuracy: 0.5735\n",
      "Epoch [2431/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2431/10000], Validation Loss: 0.97791526, Validation Accuracy: 0.5735\n",
      "Epoch [2432/10000], Training Loss: 0.60605938, Training Accuracy: 0.9454\n",
      "Epoch [2432/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [2433/10000], Training Loss: 0.60184193, Training Accuracy: 0.9496\n",
      "Epoch [2433/10000], Validation Loss: 0.97791234, Validation Accuracy: 0.5735\n",
      "Epoch [2434/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2434/10000], Validation Loss: 0.97672990, Validation Accuracy: 0.5735\n",
      "Epoch [2435/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2435/10000], Validation Loss: 0.97786865, Validation Accuracy: 0.5735\n",
      "Epoch [2436/10000], Training Loss: 0.60606415, Training Accuracy: 0.9454\n",
      "Epoch [2436/10000], Validation Loss: 0.97785366, Validation Accuracy: 0.5735\n",
      "Epoch [2437/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2437/10000], Validation Loss: 0.97778955, Validation Accuracy: 0.5735\n",
      "Epoch [2438/10000], Training Loss: 0.60185403, Training Accuracy: 0.9496\n",
      "Epoch [2438/10000], Validation Loss: 0.97791362, Validation Accuracy: 0.5735\n",
      "Epoch [2439/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2439/10000], Validation Loss: 0.97791538, Validation Accuracy: 0.5735\n",
      "Epoch [2440/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2440/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [2441/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2441/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [2442/10000], Training Loss: 0.59244134, Training Accuracy: 0.9580\n",
      "Epoch [2442/10000], Validation Loss: 1.00732556, Validation Accuracy: 0.5441\n",
      "Epoch [2443/10000], Training Loss: 0.61443980, Training Accuracy: 0.9370\n",
      "Epoch [2443/10000], Validation Loss: 1.00594884, Validation Accuracy: 0.5441\n",
      "Epoch [2444/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2444/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2445/10000], Training Loss: 0.60666053, Training Accuracy: 0.9454\n",
      "Epoch [2445/10000], Validation Loss: 0.99262020, Validation Accuracy: 0.5588\n",
      "Epoch [2446/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2446/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2447/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [2447/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2448/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2448/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2449/10000], Training Loss: 0.61027047, Training Accuracy: 0.9412\n",
      "Epoch [2449/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2450/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2450/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2451/10000], Training Loss: 0.61026519, Training Accuracy: 0.9412\n",
      "Epoch [2451/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2452/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2452/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2453/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2453/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2454/10000], Training Loss: 0.59768187, Training Accuracy: 0.9538\n",
      "Epoch [2454/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2455/10000], Training Loss: 0.61026394, Training Accuracy: 0.9412\n",
      "Epoch [2455/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [2456/10000], Training Loss: 0.59766469, Training Accuracy: 0.9538\n",
      "Epoch [2456/10000], Validation Loss: 0.99262211, Validation Accuracy: 0.5588\n",
      "Epoch [2457/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2457/10000], Validation Loss: 0.99262390, Validation Accuracy: 0.5588\n",
      "Epoch [2458/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2458/10000], Validation Loss: 0.99262595, Validation Accuracy: 0.5588\n",
      "Epoch [2459/10000], Training Loss: 0.59765271, Training Accuracy: 0.9538\n",
      "Epoch [2459/10000], Validation Loss: 0.99262473, Validation Accuracy: 0.5588\n",
      "Epoch [2460/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2460/10000], Validation Loss: 0.99262300, Validation Accuracy: 0.5588\n",
      "Epoch [2461/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2461/10000], Validation Loss: 0.99262249, Validation Accuracy: 0.5588\n",
      "Epoch [2462/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [2462/10000], Validation Loss: 0.99262232, Validation Accuracy: 0.5588\n",
      "Epoch [2463/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2463/10000], Validation Loss: 0.99262226, Validation Accuracy: 0.5588\n",
      "Epoch [2464/10000], Training Loss: 0.61018776, Training Accuracy: 0.9412\n",
      "Epoch [2464/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2465/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2465/10000], Validation Loss: 0.99211755, Validation Accuracy: 0.5588\n",
      "Epoch [2466/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2466/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [2467/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2467/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2468/10000], Training Loss: 0.59891874, Training Accuracy: 0.9538\n",
      "Epoch [2468/10000], Validation Loss: 0.99262103, Validation Accuracy: 0.5588\n",
      "Epoch [2469/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2469/10000], Validation Loss: 0.99199378, Validation Accuracy: 0.5588\n",
      "Epoch [2470/10000], Training Loss: 0.59475931, Training Accuracy: 0.9580\n",
      "Epoch [2470/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2471/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [2471/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2472/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2472/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2473/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2473/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2474/10000], Training Loss: 0.59346079, Training Accuracy: 0.9580\n",
      "Epoch [2474/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2475/10000], Training Loss: 0.61317518, Training Accuracy: 0.9370\n",
      "Epoch [2475/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2476/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [2476/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2477/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2477/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2478/10000], Training Loss: 0.61447023, Training Accuracy: 0.9370\n",
      "Epoch [2478/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2479/10000], Training Loss: 0.59393819, Training Accuracy: 0.9580\n",
      "Epoch [2479/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2480/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2480/10000], Validation Loss: 0.99227732, Validation Accuracy: 0.5588\n",
      "Epoch [2481/10000], Training Loss: 0.58926763, Training Accuracy: 0.9622\n",
      "Epoch [2481/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2482/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2482/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2483/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2483/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2484/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2484/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2485/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2485/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2486/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2486/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2487/10000], Training Loss: 0.60590832, Training Accuracy: 0.9454\n",
      "Epoch [2487/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2488/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2488/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2489/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2489/10000], Validation Loss: 0.99262810, Validation Accuracy: 0.5588\n",
      "Epoch [2490/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2490/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2491/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2491/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2492/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2492/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2493/10000], Training Loss: 0.58503262, Training Accuracy: 0.9664\n",
      "Epoch [2493/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2494/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2494/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2495/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2495/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2496/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2496/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2497/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2497/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2498/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2498/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2499/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2499/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2500/10000], Training Loss: 0.61025132, Training Accuracy: 0.9412\n",
      "Epoch [2500/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2501/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2501/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2502/10000], Training Loss: 0.59766758, Training Accuracy: 0.9538\n",
      "Epoch [2502/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2503/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2503/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2504/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2504/10000], Validation Loss: 1.02185333, Validation Accuracy: 0.5294\n",
      "Epoch [2505/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2505/10000], Validation Loss: 1.01097846, Validation Accuracy: 0.5441\n",
      "Epoch [2506/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2506/10000], Validation Loss: 1.00768059, Validation Accuracy: 0.5441\n",
      "Epoch [2507/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2507/10000], Validation Loss: 1.00743422, Validation Accuracy: 0.5441\n",
      "Epoch [2508/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2508/10000], Validation Loss: 1.00738725, Validation Accuracy: 0.5441\n",
      "Epoch [2509/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2509/10000], Validation Loss: 1.00737274, Validation Accuracy: 0.5441\n",
      "Epoch [2510/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2510/10000], Validation Loss: 1.00736710, Validation Accuracy: 0.5441\n",
      "Epoch [2511/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2511/10000], Validation Loss: 1.00736466, Validation Accuracy: 0.5441\n",
      "Epoch [2512/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2512/10000], Validation Loss: 1.00736359, Validation Accuracy: 0.5441\n",
      "Epoch [2513/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2513/10000], Validation Loss: 1.00736314, Validation Accuracy: 0.5441\n",
      "Epoch [2514/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2514/10000], Validation Loss: 1.00736296, Validation Accuracy: 0.5441\n",
      "Epoch [2515/10000], Training Loss: 0.57665506, Training Accuracy: 0.9748\n",
      "Epoch [2515/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2516/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2516/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2517/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2517/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2518/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2518/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2519/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [2519/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2520/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2520/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2521/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2521/10000], Validation Loss: 1.00736290, Validation Accuracy: 0.5441\n",
      "Epoch [2522/10000], Training Loss: 0.58506038, Training Accuracy: 0.9664\n",
      "Epoch [2522/10000], Validation Loss: 1.00734630, Validation Accuracy: 0.5441\n",
      "Epoch [2523/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2523/10000], Validation Loss: 1.00734046, Validation Accuracy: 0.5441\n",
      "Epoch [2524/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2524/10000], Validation Loss: 1.00733835, Validation Accuracy: 0.5441\n",
      "Epoch [2525/10000], Training Loss: 0.59345361, Training Accuracy: 0.9580\n",
      "Epoch [2525/10000], Validation Loss: 1.00733149, Validation Accuracy: 0.5441\n",
      "Epoch [2526/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2526/10000], Validation Loss: 1.00732785, Validation Accuracy: 0.5441\n",
      "Epoch [2527/10000], Training Loss: 0.58503575, Training Accuracy: 0.9664\n",
      "Epoch [2527/10000], Validation Loss: 1.00732735, Validation Accuracy: 0.5441\n",
      "Epoch [2528/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [2528/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2529/10000], Training Loss: 0.60151603, Training Accuracy: 0.9496\n",
      "Epoch [2529/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2530/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2530/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2531/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2531/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2532/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2532/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2533/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2533/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2534/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2534/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2535/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2535/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2536/10000], Training Loss: 0.60616690, Training Accuracy: 0.9454\n",
      "Epoch [2536/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2537/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [2537/10000], Validation Loss: 1.01975024, Validation Accuracy: 0.5294\n",
      "Epoch [2538/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2538/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2539/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [2539/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2540/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2540/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2541/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2541/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2542/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2542/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2543/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2543/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2544/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2544/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2545/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [2545/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2546/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2546/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2547/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2547/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2548/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [2548/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2549/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2549/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2550/10000], Training Loss: 0.59512153, Training Accuracy: 0.9580\n",
      "Epoch [2550/10000], Validation Loss: 1.03509551, Validation Accuracy: 0.5147\n",
      "Epoch [2551/10000], Training Loss: 0.61872809, Training Accuracy: 0.9328\n",
      "Epoch [2551/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2552/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2552/10000], Validation Loss: 1.05464441, Validation Accuracy: 0.5000\n",
      "Epoch [2553/10000], Training Loss: 0.63967927, Training Accuracy: 0.9118\n",
      "Epoch [2553/10000], Validation Loss: 1.02138197, Validation Accuracy: 0.5294\n",
      "Epoch [2554/10000], Training Loss: 0.65228510, Training Accuracy: 0.8992\n",
      "Epoch [2554/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2555/10000], Training Loss: 0.64388196, Training Accuracy: 0.9076\n",
      "Epoch [2555/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2556/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [2556/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2557/10000], Training Loss: 0.62774019, Training Accuracy: 0.9244\n",
      "Epoch [2557/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2558/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [2558/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2559/10000], Training Loss: 0.63082291, Training Accuracy: 0.9202\n",
      "Epoch [2559/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2560/10000], Training Loss: 0.64388159, Training Accuracy: 0.9076\n",
      "Epoch [2560/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2561/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2561/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2562/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2562/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2563/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [2563/10000], Validation Loss: 1.02203298, Validation Accuracy: 0.5294\n",
      "Epoch [2564/10000], Training Loss: 0.62786521, Training Accuracy: 0.9244\n",
      "Epoch [2564/10000], Validation Loss: 1.02203387, Validation Accuracy: 0.5294\n",
      "Epoch [2565/10000], Training Loss: 0.63546956, Training Accuracy: 0.9160\n",
      "Epoch [2565/10000], Validation Loss: 1.02278405, Validation Accuracy: 0.5294\n",
      "Epoch [2566/10000], Training Loss: 0.62287492, Training Accuracy: 0.9286\n",
      "Epoch [2566/10000], Validation Loss: 1.04470420, Validation Accuracy: 0.5000\n",
      "Epoch [2567/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2567/10000], Validation Loss: 1.04293078, Validation Accuracy: 0.5000\n",
      "Epoch [2568/10000], Training Loss: 0.61446971, Training Accuracy: 0.9370\n",
      "Epoch [2568/10000], Validation Loss: 1.03697628, Validation Accuracy: 0.5147\n",
      "Epoch [2569/10000], Training Loss: 0.62259220, Training Accuracy: 0.9286\n",
      "Epoch [2569/10000], Validation Loss: 1.03671217, Validation Accuracy: 0.5147\n",
      "Epoch [2570/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2570/10000], Validation Loss: 1.03813571, Validation Accuracy: 0.5147\n",
      "Epoch [2571/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2571/10000], Validation Loss: 1.04310447, Validation Accuracy: 0.5000\n",
      "Epoch [2572/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2572/10000], Validation Loss: 1.03702420, Validation Accuracy: 0.5147\n",
      "Epoch [2573/10000], Training Loss: 0.60692304, Training Accuracy: 0.9454\n",
      "Epoch [2573/10000], Validation Loss: 1.02203429, Validation Accuracy: 0.5294\n",
      "Epoch [2574/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2574/10000], Validation Loss: 1.02203530, Validation Accuracy: 0.5294\n",
      "Epoch [2575/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2575/10000], Validation Loss: 1.02199608, Validation Accuracy: 0.5294\n",
      "Epoch [2576/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2576/10000], Validation Loss: 1.02203554, Validation Accuracy: 0.5294\n",
      "Epoch [2577/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2577/10000], Validation Loss: 1.02204812, Validation Accuracy: 0.5294\n",
      "Epoch [2578/10000], Training Loss: 0.61447007, Training Accuracy: 0.9370\n",
      "Epoch [2578/10000], Validation Loss: 1.02447402, Validation Accuracy: 0.5294\n",
      "Epoch [2579/10000], Training Loss: 0.60246789, Training Accuracy: 0.9496\n",
      "Epoch [2579/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2580/10000], Training Loss: 0.63127898, Training Accuracy: 0.9202\n",
      "Epoch [2580/10000], Validation Loss: 1.05143726, Validation Accuracy: 0.5000\n",
      "Epoch [2581/10000], Training Loss: 0.63140578, Training Accuracy: 0.9202\n",
      "Epoch [2581/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2582/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2582/10000], Validation Loss: 1.05144453, Validation Accuracy: 0.5000\n",
      "Epoch [2583/10000], Training Loss: 0.64343534, Training Accuracy: 0.9076\n",
      "Epoch [2583/10000], Validation Loss: 1.03598225, Validation Accuracy: 0.5147\n",
      "Epoch [2584/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2584/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2585/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2585/10000], Validation Loss: 1.02203703, Validation Accuracy: 0.5294\n",
      "Epoch [2586/10000], Training Loss: 0.60186556, Training Accuracy: 0.9496\n",
      "Epoch [2586/10000], Validation Loss: 1.02233249, Validation Accuracy: 0.5294\n",
      "Epoch [2587/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2587/10000], Validation Loss: 1.02431691, Validation Accuracy: 0.5294\n",
      "Epoch [2588/10000], Training Loss: 0.62707542, Training Accuracy: 0.9244\n",
      "Epoch [2588/10000], Validation Loss: 1.02583176, Validation Accuracy: 0.5294\n",
      "Epoch [2589/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2589/10000], Validation Loss: 1.02864689, Validation Accuracy: 0.5147\n",
      "Epoch [2590/10000], Training Loss: 0.60457080, Training Accuracy: 0.9454\n",
      "Epoch [2590/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2591/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [2591/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2592/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2592/10000], Validation Loss: 1.03673875, Validation Accuracy: 0.5147\n",
      "Epoch [2593/10000], Training Loss: 0.60606402, Training Accuracy: 0.9454\n",
      "Epoch [2593/10000], Validation Loss: 1.03673804, Validation Accuracy: 0.5147\n",
      "Epoch [2594/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2594/10000], Validation Loss: 1.03673732, Validation Accuracy: 0.5147\n",
      "Epoch [2595/10000], Training Loss: 0.62707577, Training Accuracy: 0.9244\n",
      "Epoch [2595/10000], Validation Loss: 1.03673679, Validation Accuracy: 0.5147\n",
      "Epoch [2596/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2596/10000], Validation Loss: 1.03673649, Validation Accuracy: 0.5147\n",
      "Epoch [2597/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2597/10000], Validation Loss: 1.03673631, Validation Accuracy: 0.5147\n",
      "Epoch [2598/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [2598/10000], Validation Loss: 1.03673619, Validation Accuracy: 0.5147\n",
      "Epoch [2599/10000], Training Loss: 0.61009261, Training Accuracy: 0.9412\n",
      "Epoch [2599/10000], Validation Loss: 1.02203453, Validation Accuracy: 0.5294\n",
      "Epoch [2600/10000], Training Loss: 0.60605150, Training Accuracy: 0.9454\n",
      "Epoch [2600/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2601/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2601/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2602/10000], Training Loss: 0.60186871, Training Accuracy: 0.9496\n",
      "Epoch [2602/10000], Validation Loss: 1.02202207, Validation Accuracy: 0.5294\n",
      "Epoch [2603/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2603/10000], Validation Loss: 1.02079678, Validation Accuracy: 0.5294\n",
      "Epoch [2604/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2604/10000], Validation Loss: 1.02146763, Validation Accuracy: 0.5294\n",
      "Epoch [2605/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2605/10000], Validation Loss: 1.02184314, Validation Accuracy: 0.5294\n",
      "Epoch [2606/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [2606/10000], Validation Loss: 1.02192527, Validation Accuracy: 0.5294\n",
      "Epoch [2607/10000], Training Loss: 0.60185793, Training Accuracy: 0.9496\n",
      "Epoch [2607/10000], Validation Loss: 1.02194881, Validation Accuracy: 0.5294\n",
      "Epoch [2608/10000], Training Loss: 0.60988258, Training Accuracy: 0.9412\n",
      "Epoch [2608/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2609/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2609/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2610/10000], Training Loss: 0.60997528, Training Accuracy: 0.9412\n",
      "Epoch [2610/10000], Validation Loss: 1.00732717, Validation Accuracy: 0.5441\n",
      "Epoch [2611/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2611/10000], Validation Loss: 1.00726792, Validation Accuracy: 0.5441\n",
      "Epoch [2612/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [2612/10000], Validation Loss: 1.02028745, Validation Accuracy: 0.5294\n",
      "Epoch [2613/10000], Training Loss: 0.60205575, Training Accuracy: 0.9496\n",
      "Epoch [2613/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2614/10000], Training Loss: 0.59351202, Training Accuracy: 0.9580\n",
      "Epoch [2614/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2615/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2615/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2616/10000], Training Loss: 0.59866266, Training Accuracy: 0.9538\n",
      "Epoch [2616/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2617/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2617/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2618/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2618/10000], Validation Loss: 1.02203351, Validation Accuracy: 0.5294\n",
      "Epoch [2619/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2619/10000], Validation Loss: 1.03557456, Validation Accuracy: 0.5147\n",
      "Epoch [2620/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [2620/10000], Validation Loss: 1.03673631, Validation Accuracy: 0.5147\n",
      "Epoch [2621/10000], Training Loss: 0.60607182, Training Accuracy: 0.9454\n",
      "Epoch [2621/10000], Validation Loss: 1.03673881, Validation Accuracy: 0.5147\n",
      "Epoch [2622/10000], Training Loss: 0.61023682, Training Accuracy: 0.9412\n",
      "Epoch [2622/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2623/10000], Training Loss: 0.61867137, Training Accuracy: 0.9328\n",
      "Epoch [2623/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2624/10000], Training Loss: 0.59867178, Training Accuracy: 0.9496\n",
      "Epoch [2624/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [2625/10000], Training Loss: 0.61888896, Training Accuracy: 0.9328\n",
      "Epoch [2625/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2626/10000], Training Loss: 0.63547581, Training Accuracy: 0.9160\n",
      "Epoch [2626/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2627/10000], Training Loss: 0.63948018, Training Accuracy: 0.9118\n",
      "Epoch [2627/10000], Validation Loss: 1.06481591, Validation Accuracy: 0.4853\n",
      "Epoch [2628/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2628/10000], Validation Loss: 1.08085606, Validation Accuracy: 0.4706\n",
      "Epoch [2629/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [2629/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2630/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [2630/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2631/10000], Training Loss: 0.64802675, Training Accuracy: 0.9034\n",
      "Epoch [2631/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2632/10000], Training Loss: 0.63551328, Training Accuracy: 0.9160\n",
      "Epoch [2632/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2633/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [2633/10000], Validation Loss: 1.06615081, Validation Accuracy: 0.4853\n",
      "Epoch [2634/10000], Training Loss: 0.65228468, Training Accuracy: 0.8992\n",
      "Epoch [2634/10000], Validation Loss: 1.06615099, Validation Accuracy: 0.4853\n",
      "Epoch [2635/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [2635/10000], Validation Loss: 1.06615117, Validation Accuracy: 0.4853\n",
      "Epoch [2636/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2636/10000], Validation Loss: 1.06615141, Validation Accuracy: 0.4853\n",
      "Epoch [2637/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [2637/10000], Validation Loss: 1.06615153, Validation Accuracy: 0.4853\n",
      "Epoch [2638/10000], Training Loss: 0.64808358, Training Accuracy: 0.9034\n",
      "Epoch [2638/10000], Validation Loss: 1.06615159, Validation Accuracy: 0.4853\n",
      "Epoch [2639/10000], Training Loss: 0.63562182, Training Accuracy: 0.9160\n",
      "Epoch [2639/10000], Validation Loss: 1.06811848, Validation Accuracy: 0.4853\n",
      "Epoch [2640/10000], Training Loss: 0.63127693, Training Accuracy: 0.9202\n",
      "Epoch [2640/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2641/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [2641/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2642/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2642/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2643/10000], Training Loss: 0.66293716, Training Accuracy: 0.8866\n",
      "Epoch [2643/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2644/10000], Training Loss: 0.63500346, Training Accuracy: 0.9160\n",
      "Epoch [2644/10000], Validation Loss: 1.03677082, Validation Accuracy: 0.5147\n",
      "Epoch [2645/10000], Training Loss: 0.62707523, Training Accuracy: 0.9244\n",
      "Epoch [2645/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2646/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2646/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [2647/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2647/10000], Validation Loss: 1.03926027, Validation Accuracy: 0.5147\n",
      "Epoch [2648/10000], Training Loss: 0.64185954, Training Accuracy: 0.9076\n",
      "Epoch [2648/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2649/10000], Training Loss: 0.62287297, Training Accuracy: 0.9286\n",
      "Epoch [2649/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2650/10000], Training Loss: 0.61447041, Training Accuracy: 0.9370\n",
      "Epoch [2650/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2651/10000], Training Loss: 0.60606750, Training Accuracy: 0.9454\n",
      "Epoch [2651/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2652/10000], Training Loss: 0.61046482, Training Accuracy: 0.9412\n",
      "Epoch [2652/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2653/10000], Training Loss: 0.61443454, Training Accuracy: 0.9370\n",
      "Epoch [2653/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [2654/10000], Training Loss: 0.61447015, Training Accuracy: 0.9370\n",
      "Epoch [2654/10000], Validation Loss: 1.03676111, Validation Accuracy: 0.5147\n",
      "Epoch [2655/10000], Training Loss: 0.61448773, Training Accuracy: 0.9370\n",
      "Epoch [2655/10000], Validation Loss: 1.04386312, Validation Accuracy: 0.5000\n",
      "Epoch [2656/10000], Training Loss: 0.63127780, Training Accuracy: 0.9202\n",
      "Epoch [2656/10000], Validation Loss: 1.05106127, Validation Accuracy: 0.5000\n",
      "Epoch [2657/10000], Training Loss: 0.62287423, Training Accuracy: 0.9286\n",
      "Epoch [2657/10000], Validation Loss: 1.05139464, Validation Accuracy: 0.5000\n",
      "Epoch [2658/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2658/10000], Validation Loss: 1.05727917, Validation Accuracy: 0.5000\n",
      "Epoch [2659/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2659/10000], Validation Loss: 1.06489414, Validation Accuracy: 0.4853\n",
      "Epoch [2660/10000], Training Loss: 0.62707462, Training Accuracy: 0.9244\n",
      "Epoch [2660/10000], Validation Loss: 1.06521010, Validation Accuracy: 0.4853\n",
      "Epoch [2661/10000], Training Loss: 0.65298309, Training Accuracy: 0.8992\n",
      "Epoch [2661/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2662/10000], Training Loss: 0.63548963, Training Accuracy: 0.9160\n",
      "Epoch [2662/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2663/10000], Training Loss: 0.61496533, Training Accuracy: 0.9370\n",
      "Epoch [2663/10000], Validation Loss: 1.05233496, Validation Accuracy: 0.5000\n",
      "Epoch [2664/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2664/10000], Validation Loss: 1.09608936, Validation Accuracy: 0.4559\n",
      "Epoch [2665/10000], Training Loss: 0.62276153, Training Accuracy: 0.9286\n",
      "Epoch [2665/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2666/10000], Training Loss: 0.61021236, Training Accuracy: 0.9412\n",
      "Epoch [2666/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2667/10000], Training Loss: 0.61872286, Training Accuracy: 0.9328\n",
      "Epoch [2667/10000], Validation Loss: 1.06608599, Validation Accuracy: 0.4853\n",
      "Epoch [2668/10000], Training Loss: 0.60434265, Training Accuracy: 0.9454\n",
      "Epoch [2668/10000], Validation Loss: 1.06571776, Validation Accuracy: 0.4853\n",
      "Epoch [2669/10000], Training Loss: 0.63127694, Training Accuracy: 0.9202\n",
      "Epoch [2669/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2670/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2670/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2671/10000], Training Loss: 0.62278139, Training Accuracy: 0.9286\n",
      "Epoch [2671/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2672/10000], Training Loss: 0.60186476, Training Accuracy: 0.9496\n",
      "Epoch [2672/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2673/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2673/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2674/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2674/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2675/10000], Training Loss: 0.61453058, Training Accuracy: 0.9370\n",
      "Epoch [2675/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2676/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2676/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2677/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2677/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2678/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2678/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2679/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [2679/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2680/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2680/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2681/10000], Training Loss: 0.61026921, Training Accuracy: 0.9412\n",
      "Epoch [2681/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2682/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2682/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2683/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2683/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2684/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2684/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2685/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2685/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2686/10000], Training Loss: 0.62287312, Training Accuracy: 0.9286\n",
      "Epoch [2686/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2687/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [2687/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2688/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2688/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2689/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2689/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2690/10000], Training Loss: 0.62277058, Training Accuracy: 0.9286\n",
      "Epoch [2690/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2691/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2691/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2692/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2692/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2693/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [2693/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2694/10000], Training Loss: 0.62286662, Training Accuracy: 0.9286\n",
      "Epoch [2694/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2695/10000], Training Loss: 0.61965018, Training Accuracy: 0.9328\n",
      "Epoch [2695/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2696/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2696/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2697/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [2697/10000], Validation Loss: 1.05282348, Validation Accuracy: 0.5000\n",
      "Epoch [2698/10000], Training Loss: 0.61447099, Training Accuracy: 0.9370\n",
      "Epoch [2698/10000], Validation Loss: 1.03673893, Validation Accuracy: 0.5147\n",
      "Epoch [2699/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2699/10000], Validation Loss: 1.03673875, Validation Accuracy: 0.5147\n",
      "Epoch [2700/10000], Training Loss: 0.62255905, Training Accuracy: 0.9286\n",
      "Epoch [2700/10000], Validation Loss: 1.03673857, Validation Accuracy: 0.5147\n",
      "Epoch [2701/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2701/10000], Validation Loss: 1.03673846, Validation Accuracy: 0.5147\n",
      "Epoch [2702/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2702/10000], Validation Loss: 1.03673840, Validation Accuracy: 0.5147\n",
      "Epoch [2703/10000], Training Loss: 0.61122911, Training Accuracy: 0.9412\n",
      "Epoch [2703/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2704/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [2704/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2705/10000], Training Loss: 0.63423040, Training Accuracy: 0.9160\n",
      "Epoch [2705/10000], Validation Loss: 1.08015943, Validation Accuracy: 0.4706\n",
      "Epoch [2706/10000], Training Loss: 0.63084113, Training Accuracy: 0.9202\n",
      "Epoch [2706/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2707/10000], Training Loss: 0.62698985, Training Accuracy: 0.9244\n",
      "Epoch [2707/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [2708/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2708/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [2709/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2709/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [2710/10000], Training Loss: 0.62589616, Training Accuracy: 0.9244\n",
      "Epoch [2710/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [2711/10000], Training Loss: 0.61433188, Training Accuracy: 0.9370\n",
      "Epoch [2711/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2712/10000], Training Loss: 0.60186937, Training Accuracy: 0.9496\n",
      "Epoch [2712/10000], Validation Loss: 1.08084840, Validation Accuracy: 0.4706\n",
      "Epoch [2713/10000], Training Loss: 0.63968027, Training Accuracy: 0.9118\n",
      "Epoch [2713/10000], Validation Loss: 1.08657050, Validation Accuracy: 0.4706\n",
      "Epoch [2714/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [2714/10000], Validation Loss: 1.09554172, Validation Accuracy: 0.4559\n",
      "Epoch [2715/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2715/10000], Validation Loss: 1.09549946, Validation Accuracy: 0.4559\n",
      "Epoch [2716/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2716/10000], Validation Loss: 1.09523737, Validation Accuracy: 0.4559\n",
      "Epoch [2717/10000], Training Loss: 0.62671243, Training Accuracy: 0.9244\n",
      "Epoch [2717/10000], Validation Loss: 1.09361601, Validation Accuracy: 0.4559\n",
      "Epoch [2718/10000], Training Loss: 0.63978910, Training Accuracy: 0.9118\n",
      "Epoch [2718/10000], Validation Loss: 1.09226888, Validation Accuracy: 0.4559\n",
      "Epoch [2719/10000], Training Loss: 0.62716489, Training Accuracy: 0.9244\n",
      "Epoch [2719/10000], Validation Loss: 1.08294791, Validation Accuracy: 0.4706\n",
      "Epoch [2720/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2720/10000], Validation Loss: 1.08100903, Validation Accuracy: 0.4706\n",
      "Epoch [2721/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2721/10000], Validation Loss: 1.08089769, Validation Accuracy: 0.4706\n",
      "Epoch [2722/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2722/10000], Validation Loss: 1.08082920, Validation Accuracy: 0.4706\n",
      "Epoch [2723/10000], Training Loss: 0.61041294, Training Accuracy: 0.9412\n",
      "Epoch [2723/10000], Validation Loss: 1.06615102, Validation Accuracy: 0.4853\n",
      "Epoch [2724/10000], Training Loss: 0.62674319, Training Accuracy: 0.9244\n",
      "Epoch [2724/10000], Validation Loss: 1.08037877, Validation Accuracy: 0.4706\n",
      "Epoch [2725/10000], Training Loss: 0.63440292, Training Accuracy: 0.9160\n",
      "Epoch [2725/10000], Validation Loss: 1.06613433, Validation Accuracy: 0.4853\n",
      "Epoch [2726/10000], Training Loss: 0.65447069, Training Accuracy: 0.8950\n",
      "Epoch [2726/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2727/10000], Training Loss: 0.63587452, Training Accuracy: 0.9160\n",
      "Epoch [2727/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2728/10000], Training Loss: 0.63100617, Training Accuracy: 0.9202\n",
      "Epoch [2728/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2729/10000], Training Loss: 0.65648331, Training Accuracy: 0.8950\n",
      "Epoch [2729/10000], Validation Loss: 1.06615269, Validation Accuracy: 0.4853\n",
      "Epoch [2730/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [2730/10000], Validation Loss: 1.06614953, Validation Accuracy: 0.4853\n",
      "Epoch [2731/10000], Training Loss: 0.64022378, Training Accuracy: 0.9118\n",
      "Epoch [2731/10000], Validation Loss: 1.06615007, Validation Accuracy: 0.4853\n",
      "Epoch [2732/10000], Training Loss: 0.65415025, Training Accuracy: 0.8950\n",
      "Epoch [2732/10000], Validation Loss: 1.05101824, Validation Accuracy: 0.5000\n",
      "Epoch [2733/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2733/10000], Validation Loss: 1.02270246, Validation Accuracy: 0.5294\n",
      "Epoch [2734/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [2734/10000], Validation Loss: 1.04425019, Validation Accuracy: 0.5000\n",
      "Epoch [2735/10000], Training Loss: 0.64809710, Training Accuracy: 0.9034\n",
      "Epoch [2735/10000], Validation Loss: 1.03539097, Validation Accuracy: 0.5147\n",
      "Epoch [2736/10000], Training Loss: 0.62911767, Training Accuracy: 0.9202\n",
      "Epoch [2736/10000], Validation Loss: 1.05152148, Validation Accuracy: 0.5000\n",
      "Epoch [2737/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2737/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2738/10000], Training Loss: 0.63127783, Training Accuracy: 0.9202\n",
      "Epoch [2738/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2739/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2739/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2740/10000], Training Loss: 0.62303008, Training Accuracy: 0.9286\n",
      "Epoch [2740/10000], Validation Loss: 1.06642967, Validation Accuracy: 0.4853\n",
      "Epoch [2741/10000], Training Loss: 0.62707525, Training Accuracy: 0.9244\n",
      "Epoch [2741/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2742/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2742/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2743/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2743/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2744/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2744/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2745/10000], Training Loss: 0.61867259, Training Accuracy: 0.9328\n",
      "Epoch [2745/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2746/10000], Training Loss: 0.62708199, Training Accuracy: 0.9244\n",
      "Epoch [2746/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2747/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2747/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2748/10000], Training Loss: 0.63961667, Training Accuracy: 0.9118\n",
      "Epoch [2748/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2749/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2749/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2750/10000], Training Loss: 0.62707523, Training Accuracy: 0.9244\n",
      "Epoch [2750/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2751/10000], Training Loss: 0.61859429, Training Accuracy: 0.9328\n",
      "Epoch [2751/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2752/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2752/10000], Validation Loss: 1.08083874, Validation Accuracy: 0.4706\n",
      "Epoch [2753/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2753/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2754/10000], Training Loss: 0.62707565, Training Accuracy: 0.9244\n",
      "Epoch [2754/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [2755/10000], Training Loss: 0.64808256, Training Accuracy: 0.9034\n",
      "Epoch [2755/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [2756/10000], Training Loss: 0.62707147, Training Accuracy: 0.9244\n",
      "Epoch [2756/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [2757/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [2757/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [2758/10000], Training Loss: 0.61867422, Training Accuracy: 0.9328\n",
      "Epoch [2758/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [2759/10000], Training Loss: 0.62287899, Training Accuracy: 0.9286\n",
      "Epoch [2759/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2760/10000], Training Loss: 0.61447014, Training Accuracy: 0.9370\n",
      "Epoch [2760/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2761/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2761/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2762/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2762/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2763/10000], Training Loss: 0.63127687, Training Accuracy: 0.9202\n",
      "Epoch [2763/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [2764/10000], Training Loss: 0.63111233, Training Accuracy: 0.9202\n",
      "Epoch [2764/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2765/10000], Training Loss: 0.63547851, Training Accuracy: 0.9160\n",
      "Epoch [2765/10000], Validation Loss: 1.03892726, Validation Accuracy: 0.5147\n",
      "Epoch [2766/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2766/10000], Validation Loss: 1.03672272, Validation Accuracy: 0.5147\n",
      "Epoch [2767/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2767/10000], Validation Loss: 1.03428507, Validation Accuracy: 0.5147\n",
      "Epoch [2768/10000], Training Loss: 0.62709973, Training Accuracy: 0.9244\n",
      "Epoch [2768/10000], Validation Loss: 1.02452946, Validation Accuracy: 0.5294\n",
      "Epoch [2769/10000], Training Loss: 0.61867245, Training Accuracy: 0.9328\n",
      "Epoch [2769/10000], Validation Loss: 1.02274930, Validation Accuracy: 0.5294\n",
      "Epoch [2770/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2770/10000], Validation Loss: 1.02248603, Validation Accuracy: 0.5294\n",
      "Epoch [2771/10000], Training Loss: 0.61026880, Training Accuracy: 0.9412\n",
      "Epoch [2771/10000], Validation Loss: 1.02239543, Validation Accuracy: 0.5294\n",
      "Epoch [2772/10000], Training Loss: 0.64348732, Training Accuracy: 0.9076\n",
      "Epoch [2772/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2773/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [2773/10000], Validation Loss: 1.03718883, Validation Accuracy: 0.5147\n",
      "Epoch [2774/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2774/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2775/10000], Training Loss: 0.62756632, Training Accuracy: 0.9244\n",
      "Epoch [2775/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2776/10000], Training Loss: 0.63127692, Training Accuracy: 0.9202\n",
      "Epoch [2776/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2777/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2777/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2778/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [2778/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2779/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2779/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2780/10000], Training Loss: 0.63809342, Training Accuracy: 0.9118\n",
      "Epoch [2780/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2781/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2781/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [2782/10000], Training Loss: 0.61976967, Training Accuracy: 0.9328\n",
      "Epoch [2782/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [2783/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2783/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2784/10000], Training Loss: 0.61867187, Training Accuracy: 0.9328\n",
      "Epoch [2784/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2785/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2785/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [2786/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2786/10000], Validation Loss: 0.99125010, Validation Accuracy: 0.5588\n",
      "Epoch [2787/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2787/10000], Validation Loss: 0.99259803, Validation Accuracy: 0.5588\n",
      "Epoch [2788/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2788/10000], Validation Loss: 0.99261963, Validation Accuracy: 0.5588\n",
      "Epoch [2789/10000], Training Loss: 0.62698277, Training Accuracy: 0.9244\n",
      "Epoch [2789/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2790/10000], Training Loss: 0.62755079, Training Accuracy: 0.9244\n",
      "Epoch [2790/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2791/10000], Training Loss: 0.62637070, Training Accuracy: 0.9244\n",
      "Epoch [2791/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2792/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2792/10000], Validation Loss: 0.97790566, Validation Accuracy: 0.5735\n",
      "Epoch [2793/10000], Training Loss: 0.61867195, Training Accuracy: 0.9328\n",
      "Epoch [2793/10000], Validation Loss: 0.96330148, Validation Accuracy: 0.5882\n",
      "Epoch [2794/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2794/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2795/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [2795/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2796/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2796/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2797/10000], Training Loss: 0.61867178, Training Accuracy: 0.9328\n",
      "Epoch [2797/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2798/10000], Training Loss: 0.63126917, Training Accuracy: 0.9202\n",
      "Epoch [2798/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2799/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2799/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2800/10000], Training Loss: 0.63126928, Training Accuracy: 0.9202\n",
      "Epoch [2800/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2801/10000], Training Loss: 0.62288336, Training Accuracy: 0.9286\n",
      "Epoch [2801/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2802/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2802/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2803/10000], Training Loss: 0.61026891, Training Accuracy: 0.9412\n",
      "Epoch [2803/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2804/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2804/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2805/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2805/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2806/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [2806/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2807/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2807/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2808/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [2808/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2809/10000], Training Loss: 0.63545611, Training Accuracy: 0.9160\n",
      "Epoch [2809/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2810/10000], Training Loss: 0.60184784, Training Accuracy: 0.9496\n",
      "Epoch [2810/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [2811/10000], Training Loss: 0.61975754, Training Accuracy: 0.9328\n",
      "Epoch [2811/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [2812/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2812/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [2813/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2813/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [2814/10000], Training Loss: 0.62706998, Training Accuracy: 0.9244\n",
      "Epoch [2814/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [2815/10000], Training Loss: 0.60923248, Training Accuracy: 0.9412\n",
      "Epoch [2815/10000], Validation Loss: 1.00734109, Validation Accuracy: 0.5441\n",
      "Epoch [2816/10000], Training Loss: 0.62733792, Training Accuracy: 0.9244\n",
      "Epoch [2816/10000], Validation Loss: 1.02203292, Validation Accuracy: 0.5294\n",
      "Epoch [2817/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2817/10000], Validation Loss: 1.02194801, Validation Accuracy: 0.5294\n",
      "Epoch [2818/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2818/10000], Validation Loss: 0.99271861, Validation Accuracy: 0.5588\n",
      "Epoch [2819/10000], Training Loss: 0.61409943, Training Accuracy: 0.9370\n",
      "Epoch [2819/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [2820/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2820/10000], Validation Loss: 1.01958144, Validation Accuracy: 0.5294\n",
      "Epoch [2821/10000], Training Loss: 0.62300846, Training Accuracy: 0.9286\n",
      "Epoch [2821/10000], Validation Loss: 1.02203324, Validation Accuracy: 0.5294\n",
      "Epoch [2822/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2822/10000], Validation Loss: 1.02207661, Validation Accuracy: 0.5294\n",
      "Epoch [2823/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2823/10000], Validation Loss: 1.02250364, Validation Accuracy: 0.5294\n",
      "Epoch [2824/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2824/10000], Validation Loss: 1.02105927, Validation Accuracy: 0.5294\n",
      "Epoch [2825/10000], Training Loss: 0.61448366, Training Accuracy: 0.9370\n",
      "Epoch [2825/10000], Validation Loss: 1.01508534, Validation Accuracy: 0.5294\n",
      "Epoch [2826/10000], Training Loss: 0.63125673, Training Accuracy: 0.9202\n",
      "Epoch [2826/10000], Validation Loss: 1.00161451, Validation Accuracy: 0.5441\n",
      "Epoch [2827/10000], Training Loss: 0.63212944, Training Accuracy: 0.9202\n",
      "Epoch [2827/10000], Validation Loss: 1.00728807, Validation Accuracy: 0.5441\n",
      "Epoch [2828/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2828/10000], Validation Loss: 1.01198325, Validation Accuracy: 0.5441\n",
      "Epoch [2829/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2829/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2830/10000], Training Loss: 0.60607158, Training Accuracy: 0.9454\n",
      "Epoch [2830/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2831/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [2831/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [2832/10000], Training Loss: 0.61990805, Training Accuracy: 0.9328\n",
      "Epoch [2832/10000], Validation Loss: 1.00732005, Validation Accuracy: 0.5441\n",
      "Epoch [2833/10000], Training Loss: 0.60950509, Training Accuracy: 0.9412\n",
      "Epoch [2833/10000], Validation Loss: 1.00734845, Validation Accuracy: 0.5441\n",
      "Epoch [2834/10000], Training Loss: 0.61447014, Training Accuracy: 0.9370\n",
      "Epoch [2834/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [2835/10000], Training Loss: 0.61445251, Training Accuracy: 0.9370\n",
      "Epoch [2835/10000], Validation Loss: 1.02817532, Validation Accuracy: 0.5147\n",
      "Epoch [2836/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2836/10000], Validation Loss: 1.03668961, Validation Accuracy: 0.5147\n",
      "Epoch [2837/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2837/10000], Validation Loss: 1.03673598, Validation Accuracy: 0.5147\n",
      "Epoch [2838/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2838/10000], Validation Loss: 1.03673825, Validation Accuracy: 0.5147\n",
      "Epoch [2839/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2839/10000], Validation Loss: 1.03673860, Validation Accuracy: 0.5147\n",
      "Epoch [2840/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2840/10000], Validation Loss: 1.03673872, Validation Accuracy: 0.5147\n",
      "Epoch [2841/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2841/10000], Validation Loss: 1.03673872, Validation Accuracy: 0.5147\n",
      "Epoch [2842/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2842/10000], Validation Loss: 1.03673878, Validation Accuracy: 0.5147\n",
      "Epoch [2843/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2843/10000], Validation Loss: 1.03673878, Validation Accuracy: 0.5147\n",
      "Epoch [2844/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2844/10000], Validation Loss: 1.03673878, Validation Accuracy: 0.5147\n",
      "Epoch [2845/10000], Training Loss: 0.61430559, Training Accuracy: 0.9370\n",
      "Epoch [2845/10000], Validation Loss: 1.03673872, Validation Accuracy: 0.5147\n",
      "Epoch [2846/10000], Training Loss: 0.61027061, Training Accuracy: 0.9412\n",
      "Epoch [2846/10000], Validation Loss: 1.03673854, Validation Accuracy: 0.5147\n",
      "Epoch [2847/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2847/10000], Validation Loss: 1.03673849, Validation Accuracy: 0.5147\n",
      "Epoch [2848/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2848/10000], Validation Loss: 1.03673843, Validation Accuracy: 0.5147\n",
      "Epoch [2849/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2849/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2850/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2850/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2851/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2851/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2852/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2852/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2853/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2853/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2854/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2854/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2855/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2855/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2856/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2856/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2857/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2857/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2858/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2858/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2859/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [2859/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2860/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2860/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2861/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [2861/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2862/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2862/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2863/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2863/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2864/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2864/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2865/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2865/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2866/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2866/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2867/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2867/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2868/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2868/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2869/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2869/10000], Validation Loss: 1.03673837, Validation Accuracy: 0.5147\n",
      "Epoch [2870/10000], Training Loss: 0.61366453, Training Accuracy: 0.9370\n",
      "Epoch [2870/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [2871/10000], Training Loss: 0.61653017, Training Accuracy: 0.9328\n",
      "Epoch [2871/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [2872/10000], Training Loss: 0.62284609, Training Accuracy: 0.9286\n",
      "Epoch [2872/10000], Validation Loss: 1.03660950, Validation Accuracy: 0.5147\n",
      "Epoch [2873/10000], Training Loss: 0.60606096, Training Accuracy: 0.9454\n",
      "Epoch [2873/10000], Validation Loss: 1.02335927, Validation Accuracy: 0.5294\n",
      "Epoch [2874/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [2874/10000], Validation Loss: 1.02207640, Validation Accuracy: 0.5294\n",
      "Epoch [2875/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [2875/10000], Validation Loss: 1.02204093, Validation Accuracy: 0.5294\n",
      "Epoch [2876/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2876/10000], Validation Loss: 1.02203652, Validation Accuracy: 0.5294\n",
      "Epoch [2877/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [2877/10000], Validation Loss: 1.02203545, Validation Accuracy: 0.5294\n",
      "Epoch [2878/10000], Training Loss: 0.60606055, Training Accuracy: 0.9454\n",
      "Epoch [2878/10000], Validation Loss: 1.02203706, Validation Accuracy: 0.5294\n",
      "Epoch [2879/10000], Training Loss: 0.60606430, Training Accuracy: 0.9454\n",
      "Epoch [2879/10000], Validation Loss: 1.02208391, Validation Accuracy: 0.5294\n",
      "Epoch [2880/10000], Training Loss: 0.61642972, Training Accuracy: 0.9328\n",
      "Epoch [2880/10000], Validation Loss: 1.06527340, Validation Accuracy: 0.4853\n",
      "Epoch [2881/10000], Training Loss: 0.61867235, Training Accuracy: 0.9328\n",
      "Epoch [2881/10000], Validation Loss: 1.05113980, Validation Accuracy: 0.5000\n",
      "Epoch [2882/10000], Training Loss: 0.59346179, Training Accuracy: 0.9580\n",
      "Epoch [2882/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2883/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2883/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2884/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [2884/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2885/10000], Training Loss: 0.62695526, Training Accuracy: 0.9244\n",
      "Epoch [2885/10000], Validation Loss: 1.06495485, Validation Accuracy: 0.4853\n",
      "Epoch [2886/10000], Training Loss: 0.61452163, Training Accuracy: 0.9370\n",
      "Epoch [2886/10000], Validation Loss: 1.06615070, Validation Accuracy: 0.4853\n",
      "Epoch [2887/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2887/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2888/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2888/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [2889/10000], Training Loss: 0.61821944, Training Accuracy: 0.9328\n",
      "Epoch [2889/10000], Validation Loss: 1.06615064, Validation Accuracy: 0.4853\n",
      "Epoch [2890/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [2890/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2891/10000], Training Loss: 0.61026784, Training Accuracy: 0.9412\n",
      "Epoch [2891/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [2892/10000], Training Loss: 0.63184395, Training Accuracy: 0.9202\n",
      "Epoch [2892/10000], Validation Loss: 1.09510511, Validation Accuracy: 0.4559\n",
      "Epoch [2893/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [2893/10000], Validation Loss: 1.06150341, Validation Accuracy: 0.4853\n",
      "Epoch [2894/10000], Training Loss: 0.60606698, Training Accuracy: 0.9454\n",
      "Epoch [2894/10000], Validation Loss: 1.02934536, Validation Accuracy: 0.5147\n",
      "Epoch [2895/10000], Training Loss: 0.61026606, Training Accuracy: 0.9412\n",
      "Epoch [2895/10000], Validation Loss: 1.02152970, Validation Accuracy: 0.5294\n",
      "Epoch [2896/10000], Training Loss: 0.61025471, Training Accuracy: 0.9412\n",
      "Epoch [2896/10000], Validation Loss: 1.02077439, Validation Accuracy: 0.5294\n",
      "Epoch [2897/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2897/10000], Validation Loss: 1.02011827, Validation Accuracy: 0.5294\n",
      "Epoch [2898/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2898/10000], Validation Loss: 1.01970908, Validation Accuracy: 0.5294\n",
      "Epoch [2899/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2899/10000], Validation Loss: 1.01948801, Validation Accuracy: 0.5294\n",
      "Epoch [2900/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [2900/10000], Validation Loss: 1.01937625, Validation Accuracy: 0.5294\n",
      "Epoch [2901/10000], Training Loss: 0.62287355, Training Accuracy: 0.9286\n",
      "Epoch [2901/10000], Validation Loss: 1.01931801, Validation Accuracy: 0.5294\n",
      "Epoch [2902/10000], Training Loss: 0.60699351, Training Accuracy: 0.9454\n",
      "Epoch [2902/10000], Validation Loss: 0.99293098, Validation Accuracy: 0.5588\n",
      "Epoch [2903/10000], Training Loss: 0.62328604, Training Accuracy: 0.9286\n",
      "Epoch [2903/10000], Validation Loss: 0.97790787, Validation Accuracy: 0.5735\n",
      "Epoch [2904/10000], Training Loss: 0.61447021, Training Accuracy: 0.9370\n",
      "Epoch [2904/10000], Validation Loss: 0.94713452, Validation Accuracy: 0.6029\n",
      "Epoch [2905/10000], Training Loss: 0.60607410, Training Accuracy: 0.9454\n",
      "Epoch [2905/10000], Validation Loss: 0.94849712, Validation Accuracy: 0.6029\n",
      "Epoch [2906/10000], Training Loss: 0.62529894, Training Accuracy: 0.9244\n",
      "Epoch [2906/10000], Validation Loss: 0.94847330, Validation Accuracy: 0.6029\n",
      "Epoch [2907/10000], Training Loss: 0.61058488, Training Accuracy: 0.9412\n",
      "Epoch [2907/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [2908/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2908/10000], Validation Loss: 0.94476408, Validation Accuracy: 0.6029\n",
      "Epoch [2909/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2909/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2910/10000], Training Loss: 0.60606690, Training Accuracy: 0.9454\n",
      "Epoch [2910/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2911/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2911/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2912/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [2912/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2913/10000], Training Loss: 0.63127687, Training Accuracy: 0.9202\n",
      "Epoch [2913/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2914/10000], Training Loss: 0.62287351, Training Accuracy: 0.9286\n",
      "Epoch [2914/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2915/10000], Training Loss: 0.62237254, Training Accuracy: 0.9286\n",
      "Epoch [2915/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [2916/10000], Training Loss: 0.60187005, Training Accuracy: 0.9496\n",
      "Epoch [2916/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [2917/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2917/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [2918/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2918/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [2919/10000], Training Loss: 0.62287320, Training Accuracy: 0.9286\n",
      "Epoch [2919/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [2920/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [2920/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [2921/10000], Training Loss: 0.63844083, Training Accuracy: 0.9118\n",
      "Epoch [2921/10000], Validation Loss: 0.97791520, Validation Accuracy: 0.5735\n",
      "Epoch [2922/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [2922/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [2923/10000], Training Loss: 0.62707480, Training Accuracy: 0.9244\n",
      "Epoch [2923/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2924/10000], Training Loss: 0.61862915, Training Accuracy: 0.9328\n",
      "Epoch [2924/10000], Validation Loss: 1.05143327, Validation Accuracy: 0.5000\n",
      "Epoch [2925/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2925/10000], Validation Loss: 1.03710151, Validation Accuracy: 0.5147\n",
      "Epoch [2926/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [2926/10000], Validation Loss: 1.03352642, Validation Accuracy: 0.5147\n",
      "Epoch [2927/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2927/10000], Validation Loss: 1.02834576, Validation Accuracy: 0.5147\n",
      "Epoch [2928/10000], Training Loss: 0.64841682, Training Accuracy: 0.9034\n",
      "Epoch [2928/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2929/10000], Training Loss: 0.63980071, Training Accuracy: 0.9118\n",
      "Epoch [2929/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2930/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [2930/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2931/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2931/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2932/10000], Training Loss: 0.62711463, Training Accuracy: 0.9244\n",
      "Epoch [2932/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2933/10000], Training Loss: 0.62707869, Training Accuracy: 0.9244\n",
      "Epoch [2933/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2934/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2934/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2935/10000], Training Loss: 0.63968117, Training Accuracy: 0.9118\n",
      "Epoch [2935/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2936/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2936/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2937/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2937/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2938/10000], Training Loss: 0.62340084, Training Accuracy: 0.9286\n",
      "Epoch [2938/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2939/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [2939/10000], Validation Loss: 1.04765797, Validation Accuracy: 0.5000\n",
      "Epoch [2940/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2940/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2941/10000], Training Loss: 0.64388044, Training Accuracy: 0.9076\n",
      "Epoch [2941/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2942/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [2942/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2943/10000], Training Loss: 0.63547927, Training Accuracy: 0.9160\n",
      "Epoch [2943/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2944/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [2944/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2945/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2945/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2946/10000], Training Loss: 0.62286411, Training Accuracy: 0.9286\n",
      "Epoch [2946/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2947/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [2947/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2948/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [2948/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2949/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2949/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2950/10000], Training Loss: 0.62708070, Training Accuracy: 0.9244\n",
      "Epoch [2950/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2951/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2951/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2952/10000], Training Loss: 0.61867169, Training Accuracy: 0.9328\n",
      "Epoch [2952/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2953/10000], Training Loss: 0.62282956, Training Accuracy: 0.9286\n",
      "Epoch [2953/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2954/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2954/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2955/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2955/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2956/10000], Training Loss: 0.61864157, Training Accuracy: 0.9328\n",
      "Epoch [2956/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2957/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [2957/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2958/10000], Training Loss: 0.63092169, Training Accuracy: 0.9202\n",
      "Epoch [2958/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [2959/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [2959/10000], Validation Loss: 1.08049142, Validation Accuracy: 0.4706\n",
      "Epoch [2960/10000], Training Loss: 0.63547909, Training Accuracy: 0.9160\n",
      "Epoch [2960/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [2961/10000], Training Loss: 0.63957816, Training Accuracy: 0.9118\n",
      "Epoch [2961/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [2962/10000], Training Loss: 0.62773369, Training Accuracy: 0.9202\n",
      "Epoch [2962/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [2963/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [2963/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [2964/10000], Training Loss: 0.64743536, Training Accuracy: 0.9034\n",
      "Epoch [2964/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [2965/10000], Training Loss: 0.63546859, Training Accuracy: 0.9160\n",
      "Epoch [2965/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2966/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [2966/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [2967/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [2967/10000], Validation Loss: 1.02537429, Validation Accuracy: 0.5294\n",
      "Epoch [2968/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2968/10000], Validation Loss: 1.02203447, Validation Accuracy: 0.5294\n",
      "Epoch [2969/10000], Training Loss: 0.64389052, Training Accuracy: 0.9076\n",
      "Epoch [2969/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [2970/10000], Training Loss: 0.64659709, Training Accuracy: 0.9034\n",
      "Epoch [2970/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2971/10000], Training Loss: 0.64808359, Training Accuracy: 0.9034\n",
      "Epoch [2971/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [2972/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2972/10000], Validation Loss: 1.02203304, Validation Accuracy: 0.5294\n",
      "Epoch [2973/10000], Training Loss: 0.62287507, Training Accuracy: 0.9286\n",
      "Epoch [2973/10000], Validation Loss: 1.02200246, Validation Accuracy: 0.5294\n",
      "Epoch [2974/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [2974/10000], Validation Loss: 1.02154469, Validation Accuracy: 0.5294\n",
      "Epoch [2975/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [2975/10000], Validation Loss: 1.02030909, Validation Accuracy: 0.5294\n",
      "Epoch [2976/10000], Training Loss: 0.64388312, Training Accuracy: 0.9076\n",
      "Epoch [2976/10000], Validation Loss: 1.01946265, Validation Accuracy: 0.5294\n",
      "Epoch [2977/10000], Training Loss: 0.62709291, Training Accuracy: 0.9244\n",
      "Epoch [2977/10000], Validation Loss: 1.01955581, Validation Accuracy: 0.5294\n",
      "Epoch [2978/10000], Training Loss: 0.63575175, Training Accuracy: 0.9160\n",
      "Epoch [2978/10000], Validation Loss: 1.01893371, Validation Accuracy: 0.5294\n",
      "Epoch [2979/10000], Training Loss: 0.64133015, Training Accuracy: 0.9118\n",
      "Epoch [2979/10000], Validation Loss: 1.02203420, Validation Accuracy: 0.5294\n",
      "Epoch [2980/10000], Training Loss: 0.65648700, Training Accuracy: 0.8950\n",
      "Epoch [2980/10000], Validation Loss: 1.04604959, Validation Accuracy: 0.5000\n",
      "Epoch [2981/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [2981/10000], Validation Loss: 1.03695542, Validation Accuracy: 0.5147\n",
      "Epoch [2982/10000], Training Loss: 0.63967999, Training Accuracy: 0.9118\n",
      "Epoch [2982/10000], Validation Loss: 1.03676265, Validation Accuracy: 0.5147\n",
      "Epoch [2983/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [2983/10000], Validation Loss: 1.03674722, Validation Accuracy: 0.5147\n",
      "Epoch [2984/10000], Training Loss: 0.64016499, Training Accuracy: 0.9118\n",
      "Epoch [2984/10000], Validation Loss: 1.02203476, Validation Accuracy: 0.5294\n",
      "Epoch [2985/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2985/10000], Validation Loss: 1.02203238, Validation Accuracy: 0.5294\n",
      "Epoch [2986/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2986/10000], Validation Loss: 1.00681362, Validation Accuracy: 0.5441\n",
      "Epoch [2987/10000], Training Loss: 0.65648087, Training Accuracy: 0.8950\n",
      "Epoch [2987/10000], Validation Loss: 0.99262241, Validation Accuracy: 0.5588\n",
      "Epoch [2988/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [2988/10000], Validation Loss: 0.99262366, Validation Accuracy: 0.5588\n",
      "Epoch [2989/10000], Training Loss: 0.62287364, Training Accuracy: 0.9286\n",
      "Epoch [2989/10000], Validation Loss: 0.99262491, Validation Accuracy: 0.5588\n",
      "Epoch [2990/10000], Training Loss: 0.64808365, Training Accuracy: 0.9034\n",
      "Epoch [2990/10000], Validation Loss: 0.99262574, Validation Accuracy: 0.5588\n",
      "Epoch [2991/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [2991/10000], Validation Loss: 0.99262622, Validation Accuracy: 0.5588\n",
      "Epoch [2992/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [2992/10000], Validation Loss: 0.99262652, Validation Accuracy: 0.5588\n",
      "Epoch [2993/10000], Training Loss: 0.64136197, Training Accuracy: 0.9118\n",
      "Epoch [2993/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [2994/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [2994/10000], Validation Loss: 1.06614214, Validation Accuracy: 0.4853\n",
      "Epoch [2995/10000], Training Loss: 0.63547803, Training Accuracy: 0.9160\n",
      "Epoch [2995/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2996/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [2996/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [2997/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [2997/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [2998/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [2998/10000], Validation Loss: 1.06614614, Validation Accuracy: 0.4853\n",
      "Epoch [2999/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [2999/10000], Validation Loss: 1.06611842, Validation Accuracy: 0.4853\n",
      "Epoch [3000/10000], Training Loss: 0.63564852, Training Accuracy: 0.9160\n",
      "Epoch [3000/10000], Validation Loss: 1.05264574, Validation Accuracy: 0.5000\n",
      "Epoch [3001/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3001/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3002/10000], Training Loss: 0.63968031, Training Accuracy: 0.9118\n",
      "Epoch [3002/10000], Validation Loss: 1.04089135, Validation Accuracy: 0.5147\n",
      "Epoch [3003/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [3003/10000], Validation Loss: 1.05147111, Validation Accuracy: 0.5000\n",
      "Epoch [3004/10000], Training Loss: 0.63969816, Training Accuracy: 0.9118\n",
      "Epoch [3004/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3005/10000], Training Loss: 0.63547855, Training Accuracy: 0.9160\n",
      "Epoch [3005/10000], Validation Loss: 1.05144507, Validation Accuracy: 0.5000\n",
      "Epoch [3006/10000], Training Loss: 0.64808353, Training Accuracy: 0.9034\n",
      "Epoch [3006/10000], Validation Loss: 1.06615025, Validation Accuracy: 0.4853\n",
      "Epoch [3007/10000], Training Loss: 0.62677477, Training Accuracy: 0.9244\n",
      "Epoch [3007/10000], Validation Loss: 1.05152750, Validation Accuracy: 0.5000\n",
      "Epoch [3008/10000], Training Loss: 0.64808358, Training Accuracy: 0.9034\n",
      "Epoch [3008/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3009/10000], Training Loss: 0.61867187, Training Accuracy: 0.9328\n",
      "Epoch [3009/10000], Validation Loss: 1.06574625, Validation Accuracy: 0.4853\n",
      "Epoch [3010/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3010/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3011/10000], Training Loss: 0.61587627, Training Accuracy: 0.9370\n",
      "Epoch [3011/10000], Validation Loss: 1.06640375, Validation Accuracy: 0.4853\n",
      "Epoch [3012/10000], Training Loss: 0.62287351, Training Accuracy: 0.9286\n",
      "Epoch [3012/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3013/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3013/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3014/10000], Training Loss: 0.63968027, Training Accuracy: 0.9118\n",
      "Epoch [3014/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3015/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [3015/10000], Validation Loss: 1.03673959, Validation Accuracy: 0.5147\n",
      "Epoch [3016/10000], Training Loss: 0.62287444, Training Accuracy: 0.9286\n",
      "Epoch [3016/10000], Validation Loss: 1.03698701, Validation Accuracy: 0.5147\n",
      "Epoch [3017/10000], Training Loss: 0.63547909, Training Accuracy: 0.9160\n",
      "Epoch [3017/10000], Validation Loss: 1.04040962, Validation Accuracy: 0.5147\n",
      "Epoch [3018/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3018/10000], Validation Loss: 1.04537356, Validation Accuracy: 0.5000\n",
      "Epoch [3019/10000], Training Loss: 0.63127678, Training Accuracy: 0.9202\n",
      "Epoch [3019/10000], Validation Loss: 1.04762930, Validation Accuracy: 0.5000\n",
      "Epoch [3020/10000], Training Loss: 0.63533411, Training Accuracy: 0.9160\n",
      "Epoch [3020/10000], Validation Loss: 1.04248923, Validation Accuracy: 0.5147\n",
      "Epoch [3021/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3021/10000], Validation Loss: 1.03755385, Validation Accuracy: 0.5147\n",
      "Epoch [3022/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3022/10000], Validation Loss: 1.03701776, Validation Accuracy: 0.5147\n",
      "Epoch [3023/10000], Training Loss: 0.62400757, Training Accuracy: 0.9244\n",
      "Epoch [3023/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3024/10000], Training Loss: 0.62918795, Training Accuracy: 0.9202\n",
      "Epoch [3024/10000], Validation Loss: 1.08085364, Validation Accuracy: 0.4706\n",
      "Epoch [3025/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [3025/10000], Validation Loss: 1.09518915, Validation Accuracy: 0.4559\n",
      "Epoch [3026/10000], Training Loss: 0.63127937, Training Accuracy: 0.9202\n",
      "Epoch [3026/10000], Validation Loss: 1.12496221, Validation Accuracy: 0.4265\n",
      "Epoch [3027/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [3027/10000], Validation Loss: 1.12497407, Validation Accuracy: 0.4265\n",
      "Epoch [3028/10000], Training Loss: 0.62707588, Training Accuracy: 0.9244\n",
      "Epoch [3028/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3029/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3029/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3030/10000], Training Loss: 0.62290093, Training Accuracy: 0.9286\n",
      "Epoch [3030/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3031/10000], Training Loss: 0.62233169, Training Accuracy: 0.9286\n",
      "Epoch [3031/10000], Validation Loss: 1.11026621, Validation Accuracy: 0.4412\n",
      "Epoch [3032/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3032/10000], Validation Loss: 1.09544390, Validation Accuracy: 0.4559\n",
      "Epoch [3033/10000], Training Loss: 0.63127687, Training Accuracy: 0.9202\n",
      "Epoch [3033/10000], Validation Loss: 1.10760456, Validation Accuracy: 0.4412\n",
      "Epoch [3034/10000], Training Loss: 0.64565449, Training Accuracy: 0.9034\n",
      "Epoch [3034/10000], Validation Loss: 1.09556448, Validation Accuracy: 0.4559\n",
      "Epoch [3035/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3035/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3036/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3036/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3037/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3037/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3038/10000], Training Loss: 0.64808363, Training Accuracy: 0.9034\n",
      "Epoch [3038/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3039/10000], Training Loss: 0.61867188, Training Accuracy: 0.9328\n",
      "Epoch [3039/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3040/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3040/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3041/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [3041/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3042/10000], Training Loss: 0.62707458, Training Accuracy: 0.9244\n",
      "Epoch [3042/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3043/10000], Training Loss: 0.62288375, Training Accuracy: 0.9286\n",
      "Epoch [3043/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3044/10000], Training Loss: 0.63545706, Training Accuracy: 0.9160\n",
      "Epoch [3044/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3045/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3045/10000], Validation Loss: 1.11026835, Validation Accuracy: 0.4412\n",
      "Epoch [3046/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3046/10000], Validation Loss: 1.11026835, Validation Accuracy: 0.4412\n",
      "Epoch [3047/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [3047/10000], Validation Loss: 1.11026835, Validation Accuracy: 0.4412\n",
      "Epoch [3048/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [3048/10000], Validation Loss: 1.11026835, Validation Accuracy: 0.4412\n",
      "Epoch [3049/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3049/10000], Validation Loss: 1.11026835, Validation Accuracy: 0.4412\n",
      "Epoch [3050/10000], Training Loss: 0.63140959, Training Accuracy: 0.9202\n",
      "Epoch [3050/10000], Validation Loss: 1.11026835, Validation Accuracy: 0.4412\n",
      "Epoch [3051/10000], Training Loss: 0.61446993, Training Accuracy: 0.9370\n",
      "Epoch [3051/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3052/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3052/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3053/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3053/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3054/10000], Training Loss: 0.61637535, Training Accuracy: 0.9328\n",
      "Epoch [3054/10000], Validation Loss: 1.09556228, Validation Accuracy: 0.4559\n",
      "Epoch [3055/10000], Training Loss: 0.62340803, Training Accuracy: 0.9286\n",
      "Epoch [3055/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3056/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3056/10000], Validation Loss: 1.06614929, Validation Accuracy: 0.4853\n",
      "Epoch [3057/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3057/10000], Validation Loss: 1.03676504, Validation Accuracy: 0.5147\n",
      "Epoch [3058/10000], Training Loss: 0.63547865, Training Accuracy: 0.9160\n",
      "Epoch [3058/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [3059/10000], Training Loss: 0.62708890, Training Accuracy: 0.9244\n",
      "Epoch [3059/10000], Validation Loss: 1.03673854, Validation Accuracy: 0.5147\n",
      "Epoch [3060/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3060/10000], Validation Loss: 1.03670695, Validation Accuracy: 0.5147\n",
      "Epoch [3061/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3061/10000], Validation Loss: 1.03651330, Validation Accuracy: 0.5147\n",
      "Epoch [3062/10000], Training Loss: 0.63547870, Training Accuracy: 0.9160\n",
      "Epoch [3062/10000], Validation Loss: 1.03621212, Validation Accuracy: 0.5147\n",
      "Epoch [3063/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3063/10000], Validation Loss: 1.03598776, Validation Accuracy: 0.5147\n",
      "Epoch [3064/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3064/10000], Validation Loss: 1.03586748, Validation Accuracy: 0.5147\n",
      "Epoch [3065/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3065/10000], Validation Loss: 1.03580835, Validation Accuracy: 0.5147\n",
      "Epoch [3066/10000], Training Loss: 0.63127671, Training Accuracy: 0.9202\n",
      "Epoch [3066/10000], Validation Loss: 1.03577539, Validation Accuracy: 0.5147\n",
      "Epoch [3067/10000], Training Loss: 0.62271617, Training Accuracy: 0.9286\n",
      "Epoch [3067/10000], Validation Loss: 1.03672752, Validation Accuracy: 0.5147\n",
      "Epoch [3068/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3068/10000], Validation Loss: 1.02203470, Validation Accuracy: 0.5294\n",
      "Epoch [3069/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3069/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3070/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3070/10000], Validation Loss: 1.02203518, Validation Accuracy: 0.5294\n",
      "Epoch [3071/10000], Training Loss: 0.62707180, Training Accuracy: 0.9244\n",
      "Epoch [3071/10000], Validation Loss: 1.02215827, Validation Accuracy: 0.5294\n",
      "Epoch [3072/10000], Training Loss: 0.61867194, Training Accuracy: 0.9328\n",
      "Epoch [3072/10000], Validation Loss: 1.02285188, Validation Accuracy: 0.5294\n",
      "Epoch [3073/10000], Training Loss: 0.63127505, Training Accuracy: 0.9202\n",
      "Epoch [3073/10000], Validation Loss: 1.02376902, Validation Accuracy: 0.5294\n",
      "Epoch [3074/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3074/10000], Validation Loss: 1.02444500, Validation Accuracy: 0.5294\n",
      "Epoch [3075/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3075/10000], Validation Loss: 1.02484012, Validation Accuracy: 0.5294\n",
      "Epoch [3076/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3076/10000], Validation Loss: 1.02504689, Validation Accuracy: 0.5294\n",
      "Epoch [3077/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3077/10000], Validation Loss: 1.02515090, Validation Accuracy: 0.5294\n",
      "Epoch [3078/10000], Training Loss: 0.62709210, Training Accuracy: 0.9244\n",
      "Epoch [3078/10000], Validation Loss: 1.02591705, Validation Accuracy: 0.5294\n",
      "Epoch [3079/10000], Training Loss: 0.61883979, Training Accuracy: 0.9328\n",
      "Epoch [3079/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3080/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [3080/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3081/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3081/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3082/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3082/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3083/10000], Training Loss: 0.61537927, Training Accuracy: 0.9370\n",
      "Epoch [3083/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3084/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [3084/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3085/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3085/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3086/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3086/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3087/10000], Training Loss: 0.62707689, Training Accuracy: 0.9244\n",
      "Epoch [3087/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3088/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3088/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3089/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3089/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3090/10000], Training Loss: 0.64808279, Training Accuracy: 0.9034\n",
      "Epoch [3090/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3091/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3091/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3092/10000], Training Loss: 0.62685304, Training Accuracy: 0.9244\n",
      "Epoch [3092/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3093/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3093/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3094/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3094/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3095/10000], Training Loss: 0.63968208, Training Accuracy: 0.9118\n",
      "Epoch [3095/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3096/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3096/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3097/10000], Training Loss: 0.64276316, Training Accuracy: 0.9076\n",
      "Epoch [3097/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3098/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3098/10000], Validation Loss: 1.05031258, Validation Accuracy: 0.5000\n",
      "Epoch [3099/10000], Training Loss: 0.63541270, Training Accuracy: 0.9160\n",
      "Epoch [3099/10000], Validation Loss: 1.03695264, Validation Accuracy: 0.5147\n",
      "Epoch [3100/10000], Training Loss: 0.65228528, Training Accuracy: 0.8992\n",
      "Epoch [3100/10000], Validation Loss: 1.03783152, Validation Accuracy: 0.5147\n",
      "Epoch [3101/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3101/10000], Validation Loss: 1.02452856, Validation Accuracy: 0.5294\n",
      "Epoch [3102/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3102/10000], Validation Loss: 1.02525973, Validation Accuracy: 0.5294\n",
      "Epoch [3103/10000], Training Loss: 0.63168802, Training Accuracy: 0.9202\n",
      "Epoch [3103/10000], Validation Loss: 1.03787687, Validation Accuracy: 0.5147\n",
      "Epoch [3104/10000], Training Loss: 0.63109500, Training Accuracy: 0.9202\n",
      "Epoch [3104/10000], Validation Loss: 1.03673914, Validation Accuracy: 0.5147\n",
      "Epoch [3105/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3105/10000], Validation Loss: 1.03704789, Validation Accuracy: 0.5147\n",
      "Epoch [3106/10000], Training Loss: 0.61859574, Training Accuracy: 0.9328\n",
      "Epoch [3106/10000], Validation Loss: 1.04051095, Validation Accuracy: 0.5147\n",
      "Epoch [3107/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3107/10000], Validation Loss: 1.03867587, Validation Accuracy: 0.5147\n",
      "Epoch [3108/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3108/10000], Validation Loss: 1.03809938, Validation Accuracy: 0.5147\n",
      "Epoch [3109/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3109/10000], Validation Loss: 1.03786960, Validation Accuracy: 0.5147\n",
      "Epoch [3110/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3110/10000], Validation Loss: 1.03775659, Validation Accuracy: 0.5147\n",
      "Epoch [3111/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3111/10000], Validation Loss: 1.03769654, Validation Accuracy: 0.5147\n",
      "Epoch [3112/10000], Training Loss: 0.64388375, Training Accuracy: 0.9076\n",
      "Epoch [3112/10000], Validation Loss: 1.03764910, Validation Accuracy: 0.5147\n",
      "Epoch [3113/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3113/10000], Validation Loss: 1.03759930, Validation Accuracy: 0.5147\n",
      "Epoch [3114/10000], Training Loss: 0.63547579, Training Accuracy: 0.9160\n",
      "Epoch [3114/10000], Validation Loss: 1.03750435, Validation Accuracy: 0.5147\n",
      "Epoch [3115/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3115/10000], Validation Loss: 1.03731567, Validation Accuracy: 0.5147\n",
      "Epoch [3116/10000], Training Loss: 0.63973756, Training Accuracy: 0.9118\n",
      "Epoch [3116/10000], Validation Loss: 1.05319852, Validation Accuracy: 0.5000\n",
      "Epoch [3117/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3117/10000], Validation Loss: 1.06616193, Validation Accuracy: 0.4853\n",
      "Epoch [3118/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3118/10000], Validation Loss: 1.06615484, Validation Accuracy: 0.4853\n",
      "Epoch [3119/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3119/10000], Validation Loss: 1.06615323, Validation Accuracy: 0.4853\n",
      "Epoch [3120/10000], Training Loss: 0.63968087, Training Accuracy: 0.9118\n",
      "Epoch [3120/10000], Validation Loss: 1.06615198, Validation Accuracy: 0.4853\n",
      "Epoch [3121/10000], Training Loss: 0.62841934, Training Accuracy: 0.9244\n",
      "Epoch [3121/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3122/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3122/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [3123/10000], Training Loss: 0.62287511, Training Accuracy: 0.9286\n",
      "Epoch [3123/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3124/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [3124/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3125/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3125/10000], Validation Loss: 1.02193734, Validation Accuracy: 0.5294\n",
      "Epoch [3126/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3126/10000], Validation Loss: 1.02203307, Validation Accuracy: 0.5294\n",
      "Epoch [3127/10000], Training Loss: 0.61595616, Training Accuracy: 0.9370\n",
      "Epoch [3127/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [3128/10000], Training Loss: 0.63127734, Training Accuracy: 0.9202\n",
      "Epoch [3128/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3129/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3129/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3130/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3130/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3131/10000], Training Loss: 0.62707527, Training Accuracy: 0.9244\n",
      "Epoch [3131/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3132/10000], Training Loss: 0.61448581, Training Accuracy: 0.9370\n",
      "Epoch [3132/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3133/10000], Training Loss: 0.62278858, Training Accuracy: 0.9286\n",
      "Epoch [3133/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3134/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [3134/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3135/10000], Training Loss: 0.61866267, Training Accuracy: 0.9328\n",
      "Epoch [3135/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3136/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [3136/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3137/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3137/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3138/10000], Training Loss: 0.61738406, Training Accuracy: 0.9328\n",
      "Epoch [3138/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3139/10000], Training Loss: 0.63128447, Training Accuracy: 0.9202\n",
      "Epoch [3139/10000], Validation Loss: 1.07943857, Validation Accuracy: 0.4706\n",
      "Epoch [3140/10000], Training Loss: 0.63098784, Training Accuracy: 0.9202\n",
      "Epoch [3140/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3141/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3141/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3142/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3142/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3143/10000], Training Loss: 0.62277613, Training Accuracy: 0.9286\n",
      "Epoch [3143/10000], Validation Loss: 1.05144411, Validation Accuracy: 0.5000\n",
      "Epoch [3144/10000], Training Loss: 0.62287206, Training Accuracy: 0.9286\n",
      "Epoch [3144/10000], Validation Loss: 1.05138004, Validation Accuracy: 0.5000\n",
      "Epoch [3145/10000], Training Loss: 0.61835731, Training Accuracy: 0.9328\n",
      "Epoch [3145/10000], Validation Loss: 1.04115236, Validation Accuracy: 0.5147\n",
      "Epoch [3146/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3146/10000], Validation Loss: 1.03674698, Validation Accuracy: 0.5147\n",
      "Epoch [3147/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3147/10000], Validation Loss: 1.03673935, Validation Accuracy: 0.5147\n",
      "Epoch [3148/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3148/10000], Validation Loss: 1.03673911, Validation Accuracy: 0.5147\n",
      "Epoch [3149/10000], Training Loss: 0.62707500, Training Accuracy: 0.9244\n",
      "Epoch [3149/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3150/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3150/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3151/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [3151/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3152/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3152/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3153/10000], Training Loss: 0.63547862, Training Accuracy: 0.9160\n",
      "Epoch [3153/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3154/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3154/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3155/10000], Training Loss: 0.63547837, Training Accuracy: 0.9160\n",
      "Epoch [3155/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3156/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3156/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3157/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [3157/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3158/10000], Training Loss: 0.63088490, Training Accuracy: 0.9202\n",
      "Epoch [3158/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3159/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3159/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3160/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3160/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3161/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3161/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3162/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3162/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3163/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3163/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3164/10000], Training Loss: 0.61866507, Training Accuracy: 0.9328\n",
      "Epoch [3164/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3165/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [3165/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3166/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3166/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3167/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3167/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3168/10000], Training Loss: 0.62689897, Training Accuracy: 0.9244\n",
      "Epoch [3168/10000], Validation Loss: 1.03673929, Validation Accuracy: 0.5147\n",
      "Epoch [3169/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3169/10000], Validation Loss: 1.03673995, Validation Accuracy: 0.5147\n",
      "Epoch [3170/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3170/10000], Validation Loss: 1.03674066, Validation Accuracy: 0.5147\n",
      "Epoch [3171/10000], Training Loss: 0.61454825, Training Accuracy: 0.9370\n",
      "Epoch [3171/10000], Validation Loss: 1.03674018, Validation Accuracy: 0.5147\n",
      "Epoch [3172/10000], Training Loss: 0.64805878, Training Accuracy: 0.9034\n",
      "Epoch [3172/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3173/10000], Training Loss: 0.61867142, Training Accuracy: 0.9328\n",
      "Epoch [3173/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3174/10000], Training Loss: 0.62695786, Training Accuracy: 0.9244\n",
      "Epoch [3174/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3175/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3175/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3176/10000], Training Loss: 0.61867175, Training Accuracy: 0.9328\n",
      "Epoch [3176/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3177/10000], Training Loss: 0.62290741, Training Accuracy: 0.9286\n",
      "Epoch [3177/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3178/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3178/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3179/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [3179/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3180/10000], Training Loss: 0.62699847, Training Accuracy: 0.9244\n",
      "Epoch [3180/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3181/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3181/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3182/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3182/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3183/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3183/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3184/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3184/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3185/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3185/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3186/10000], Training Loss: 0.62286354, Training Accuracy: 0.9286\n",
      "Epoch [3186/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3187/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3187/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3188/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3188/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3189/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3189/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3190/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3190/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3191/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3191/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3192/10000], Training Loss: 0.63962759, Training Accuracy: 0.9118\n",
      "Epoch [3192/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3193/10000], Training Loss: 0.61867187, Training Accuracy: 0.9328\n",
      "Epoch [3193/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3194/10000], Training Loss: 0.62284866, Training Accuracy: 0.9286\n",
      "Epoch [3194/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3195/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3195/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3196/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3196/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3197/10000], Training Loss: 0.61865791, Training Accuracy: 0.9328\n",
      "Epoch [3197/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3198/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3198/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3199/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3199/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3200/10000], Training Loss: 0.62287377, Training Accuracy: 0.9286\n",
      "Epoch [3200/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3201/10000], Training Loss: 0.62287356, Training Accuracy: 0.9286\n",
      "Epoch [3201/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3202/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3202/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3203/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3203/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3204/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3204/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3205/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3205/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3206/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3206/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3207/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3207/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3208/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [3208/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3209/10000], Training Loss: 0.64384988, Training Accuracy: 0.9076\n",
      "Epoch [3209/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3210/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3210/10000], Validation Loss: 1.03673953, Validation Accuracy: 0.5147\n",
      "Epoch [3211/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3211/10000], Validation Loss: 1.03679049, Validation Accuracy: 0.5147\n",
      "Epoch [3212/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3212/10000], Validation Loss: 1.03722852, Validation Accuracy: 0.5147\n",
      "Epoch [3213/10000], Training Loss: 0.62674998, Training Accuracy: 0.9244\n",
      "Epoch [3213/10000], Validation Loss: 1.04644585, Validation Accuracy: 0.5000\n",
      "Epoch [3214/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3214/10000], Validation Loss: 1.05118477, Validation Accuracy: 0.5000\n",
      "Epoch [3215/10000], Training Loss: 0.61446970, Training Accuracy: 0.9370\n",
      "Epoch [3215/10000], Validation Loss: 1.05138987, Validation Accuracy: 0.5000\n",
      "Epoch [3216/10000], Training Loss: 0.61867182, Training Accuracy: 0.9328\n",
      "Epoch [3216/10000], Validation Loss: 1.05141860, Validation Accuracy: 0.5000\n",
      "Epoch [3217/10000], Training Loss: 0.61871562, Training Accuracy: 0.9328\n",
      "Epoch [3217/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3218/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [3218/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3219/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3219/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3220/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3220/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3221/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3221/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3222/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [3222/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3223/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3223/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3224/10000], Training Loss: 0.62107400, Training Accuracy: 0.9286\n",
      "Epoch [3224/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3225/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [3225/10000], Validation Loss: 1.02637637, Validation Accuracy: 0.5294\n",
      "Epoch [3226/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3226/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3227/10000], Training Loss: 0.63127681, Training Accuracy: 0.9202\n",
      "Epoch [3227/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3228/10000], Training Loss: 0.60222716, Training Accuracy: 0.9496\n",
      "Epoch [3228/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3229/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3229/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3230/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3230/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3231/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3231/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3232/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3232/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3233/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [3233/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3234/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3234/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3235/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3235/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3236/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3236/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3237/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3237/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3238/10000], Training Loss: 0.62287357, Training Accuracy: 0.9286\n",
      "Epoch [3238/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3239/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3239/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3240/10000], Training Loss: 0.61420939, Training Accuracy: 0.9370\n",
      "Epoch [3240/10000], Validation Loss: 1.03669405, Validation Accuracy: 0.5147\n",
      "Epoch [3241/10000], Training Loss: 0.61014263, Training Accuracy: 0.9412\n",
      "Epoch [3241/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3242/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3242/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3243/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3243/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3244/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3244/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3245/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3245/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3246/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3246/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3247/10000], Training Loss: 0.60247523, Training Accuracy: 0.9496\n",
      "Epoch [3247/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3248/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3248/10000], Validation Loss: 1.03673846, Validation Accuracy: 0.5147\n",
      "Epoch [3249/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3249/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3250/10000], Training Loss: 0.61446785, Training Accuracy: 0.9370\n",
      "Epoch [3250/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3251/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [3251/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3252/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3252/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3253/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [3253/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3254/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3254/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3255/10000], Training Loss: 0.62670289, Training Accuracy: 0.9244\n",
      "Epoch [3255/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3256/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3256/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3257/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3257/10000], Validation Loss: 1.03675354, Validation Accuracy: 0.5147\n",
      "Epoch [3258/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3258/10000], Validation Loss: 1.03774101, Validation Accuracy: 0.5147\n",
      "Epoch [3259/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3259/10000], Validation Loss: 1.04234266, Validation Accuracy: 0.5147\n",
      "Epoch [3260/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3260/10000], Validation Loss: 1.04605311, Validation Accuracy: 0.5000\n",
      "Epoch [3261/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3261/10000], Validation Loss: 1.04760092, Validation Accuracy: 0.5000\n",
      "Epoch [3262/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3262/10000], Validation Loss: 1.04823011, Validation Accuracy: 0.5000\n",
      "Epoch [3263/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3263/10000], Validation Loss: 1.04850417, Validation Accuracy: 0.5000\n",
      "Epoch [3264/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3264/10000], Validation Loss: 1.04862851, Validation Accuracy: 0.5000\n",
      "Epoch [3265/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3265/10000], Validation Loss: 1.04868692, Validation Accuracy: 0.5000\n",
      "Epoch [3266/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3266/10000], Validation Loss: 1.04871422, Validation Accuracy: 0.5000\n",
      "Epoch [3267/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3267/10000], Validation Loss: 1.04872704, Validation Accuracy: 0.5000\n",
      "Epoch [3268/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [3268/10000], Validation Loss: 1.04873264, Validation Accuracy: 0.5000\n",
      "Epoch [3269/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [3269/10000], Validation Loss: 1.04873484, Validation Accuracy: 0.5000\n",
      "Epoch [3270/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3270/10000], Validation Loss: 1.04873568, Validation Accuracy: 0.5000\n",
      "Epoch [3271/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [3271/10000], Validation Loss: 1.04873598, Validation Accuracy: 0.5000\n",
      "Epoch [3272/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3272/10000], Validation Loss: 1.04873610, Validation Accuracy: 0.5000\n",
      "Epoch [3273/10000], Training Loss: 0.61838950, Training Accuracy: 0.9328\n",
      "Epoch [3273/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3274/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3274/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3275/10000], Training Loss: 0.62707701, Training Accuracy: 0.9244\n",
      "Epoch [3275/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3276/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3276/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3277/10000], Training Loss: 0.63547854, Training Accuracy: 0.9160\n",
      "Epoch [3277/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3278/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3278/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3279/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3279/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3280/10000], Training Loss: 0.61026846, Training Accuracy: 0.9412\n",
      "Epoch [3280/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3281/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [3281/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3282/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3282/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3283/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [3283/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3284/10000], Training Loss: 0.61037205, Training Accuracy: 0.9412\n",
      "Epoch [3284/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3285/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3285/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3286/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3286/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3287/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [3287/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3288/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3288/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3289/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [3289/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3290/10000], Training Loss: 0.61478920, Training Accuracy: 0.9370\n",
      "Epoch [3290/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3291/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3291/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3292/10000], Training Loss: 0.60606676, Training Accuracy: 0.9454\n",
      "Epoch [3292/10000], Validation Loss: 1.01977313, Validation Accuracy: 0.5294\n",
      "Epoch [3293/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [3293/10000], Validation Loss: 1.00762427, Validation Accuracy: 0.5441\n",
      "Epoch [3294/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3294/10000], Validation Loss: 1.00734991, Validation Accuracy: 0.5441\n",
      "Epoch [3295/10000], Training Loss: 0.61426261, Training Accuracy: 0.9370\n",
      "Epoch [3295/10000], Validation Loss: 1.00732851, Validation Accuracy: 0.5441\n",
      "Epoch [3296/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3296/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3297/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3297/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3298/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3298/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3299/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [3299/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3300/10000], Training Loss: 0.62699757, Training Accuracy: 0.9244\n",
      "Epoch [3300/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3301/10000], Training Loss: 0.61028469, Training Accuracy: 0.9412\n",
      "Epoch [3301/10000], Validation Loss: 1.00732869, Validation Accuracy: 0.5441\n",
      "Epoch [3302/10000], Training Loss: 0.59766356, Training Accuracy: 0.9538\n",
      "Epoch [3302/10000], Validation Loss: 1.00747740, Validation Accuracy: 0.5441\n",
      "Epoch [3303/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3303/10000], Validation Loss: 1.00870115, Validation Accuracy: 0.5441\n",
      "Epoch [3304/10000], Training Loss: 0.60598209, Training Accuracy: 0.9454\n",
      "Epoch [3304/10000], Validation Loss: 1.02007335, Validation Accuracy: 0.5294\n",
      "Epoch [3305/10000], Training Loss: 0.62129578, Training Accuracy: 0.9286\n",
      "Epoch [3305/10000], Validation Loss: 1.00739858, Validation Accuracy: 0.5441\n",
      "Epoch [3306/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3306/10000], Validation Loss: 1.02203253, Validation Accuracy: 0.5294\n",
      "Epoch [3307/10000], Training Loss: 0.62289399, Training Accuracy: 0.9286\n",
      "Epoch [3307/10000], Validation Loss: 1.02122885, Validation Accuracy: 0.5294\n",
      "Epoch [3308/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3308/10000], Validation Loss: 1.03622258, Validation Accuracy: 0.5147\n",
      "Epoch [3309/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3309/10000], Validation Loss: 1.03673333, Validation Accuracy: 0.5147\n",
      "Epoch [3310/10000], Training Loss: 0.61867175, Training Accuracy: 0.9328\n",
      "Epoch [3310/10000], Validation Loss: 1.03673834, Validation Accuracy: 0.5147\n",
      "Epoch [3311/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3311/10000], Validation Loss: 1.03673875, Validation Accuracy: 0.5147\n",
      "Epoch [3312/10000], Training Loss: 0.61079525, Training Accuracy: 0.9412\n",
      "Epoch [3312/10000], Validation Loss: 1.02864343, Validation Accuracy: 0.5147\n",
      "Epoch [3313/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3313/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3314/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3314/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3315/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3315/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3316/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3316/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3317/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3317/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3318/10000], Training Loss: 0.61867210, Training Accuracy: 0.9328\n",
      "Epoch [3318/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3319/10000], Training Loss: 0.62287519, Training Accuracy: 0.9286\n",
      "Epoch [3319/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3320/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3320/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3321/10000], Training Loss: 0.63059026, Training Accuracy: 0.9202\n",
      "Epoch [3321/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3322/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3322/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3323/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [3323/10000], Validation Loss: 1.06615132, Validation Accuracy: 0.4853\n",
      "Epoch [3324/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3324/10000], Validation Loss: 1.06657898, Validation Accuracy: 0.4853\n",
      "Epoch [3325/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [3325/10000], Validation Loss: 1.07288414, Validation Accuracy: 0.4706\n",
      "Epoch [3326/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [3326/10000], Validation Loss: 1.07805103, Validation Accuracy: 0.4706\n",
      "Epoch [3327/10000], Training Loss: 0.62287928, Training Accuracy: 0.9286\n",
      "Epoch [3327/10000], Validation Loss: 1.07950950, Validation Accuracy: 0.4706\n",
      "Epoch [3328/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3328/10000], Validation Loss: 1.07993007, Validation Accuracy: 0.4706\n",
      "Epoch [3329/10000], Training Loss: 0.61865952, Training Accuracy: 0.9328\n",
      "Epoch [3329/10000], Validation Loss: 1.08081800, Validation Accuracy: 0.4706\n",
      "Epoch [3330/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3330/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3331/10000], Training Loss: 0.62291207, Training Accuracy: 0.9286\n",
      "Epoch [3331/10000], Validation Loss: 1.08085650, Validation Accuracy: 0.4706\n",
      "Epoch [3332/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3332/10000], Validation Loss: 1.08085638, Validation Accuracy: 0.4706\n",
      "Epoch [3333/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3333/10000], Validation Loss: 1.08085626, Validation Accuracy: 0.4706\n",
      "Epoch [3334/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3334/10000], Validation Loss: 1.08085620, Validation Accuracy: 0.4706\n",
      "Epoch [3335/10000], Training Loss: 0.63547941, Training Accuracy: 0.9160\n",
      "Epoch [3335/10000], Validation Loss: 1.08085543, Validation Accuracy: 0.4706\n",
      "Epoch [3336/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [3336/10000], Validation Loss: 1.08085352, Validation Accuracy: 0.4706\n",
      "Epoch [3337/10000], Training Loss: 0.63127794, Training Accuracy: 0.9202\n",
      "Epoch [3337/10000], Validation Loss: 1.08085436, Validation Accuracy: 0.4706\n",
      "Epoch [3338/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [3338/10000], Validation Loss: 1.08085483, Validation Accuracy: 0.4706\n",
      "Epoch [3339/10000], Training Loss: 0.62343167, Training Accuracy: 0.9286\n",
      "Epoch [3339/10000], Validation Loss: 1.06615007, Validation Accuracy: 0.4853\n",
      "Epoch [3340/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3340/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3341/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3341/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3342/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3342/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3343/10000], Training Loss: 0.63127672, Training Accuracy: 0.9202\n",
      "Epoch [3343/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3344/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3344/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3345/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3345/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3346/10000], Training Loss: 0.63099940, Training Accuracy: 0.9202\n",
      "Epoch [3346/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3347/10000], Training Loss: 0.61772658, Training Accuracy: 0.9328\n",
      "Epoch [3347/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3348/10000], Training Loss: 0.61026843, Training Accuracy: 0.9412\n",
      "Epoch [3348/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3349/10000], Training Loss: 0.63109049, Training Accuracy: 0.9202\n",
      "Epoch [3349/10000], Validation Loss: 1.03633291, Validation Accuracy: 0.5147\n",
      "Epoch [3350/10000], Training Loss: 0.63549819, Training Accuracy: 0.9160\n",
      "Epoch [3350/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3351/10000], Training Loss: 0.62707208, Training Accuracy: 0.9244\n",
      "Epoch [3351/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3352/10000], Training Loss: 0.64677658, Training Accuracy: 0.9034\n",
      "Epoch [3352/10000], Validation Loss: 1.00732976, Validation Accuracy: 0.5441\n",
      "Epoch [3353/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3353/10000], Validation Loss: 0.99262145, Validation Accuracy: 0.5588\n",
      "Epoch [3354/10000], Training Loss: 0.66489067, Training Accuracy: 0.8866\n",
      "Epoch [3354/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3355/10000], Training Loss: 0.66190569, Training Accuracy: 0.8908\n",
      "Epoch [3355/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3356/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3356/10000], Validation Loss: 1.00732735, Validation Accuracy: 0.5441\n",
      "Epoch [3357/10000], Training Loss: 0.63127719, Training Accuracy: 0.9202\n",
      "Epoch [3357/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3358/10000], Training Loss: 0.66068838, Training Accuracy: 0.8908\n",
      "Epoch [3358/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3359/10000], Training Loss: 0.66065193, Training Accuracy: 0.8908\n",
      "Epoch [3359/10000], Validation Loss: 1.02203220, Validation Accuracy: 0.5294\n",
      "Epoch [3360/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3360/10000], Validation Loss: 1.00732747, Validation Accuracy: 0.5441\n",
      "Epoch [3361/10000], Training Loss: 0.63956523, Training Accuracy: 0.9118\n",
      "Epoch [3361/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3362/10000], Training Loss: 0.63547853, Training Accuracy: 0.9160\n",
      "Epoch [3362/10000], Validation Loss: 1.00732699, Validation Accuracy: 0.5441\n",
      "Epoch [3363/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3363/10000], Validation Loss: 1.00732544, Validation Accuracy: 0.5441\n",
      "Epoch [3364/10000], Training Loss: 0.64387860, Training Accuracy: 0.9076\n",
      "Epoch [3364/10000], Validation Loss: 1.00731930, Validation Accuracy: 0.5441\n",
      "Epoch [3365/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [3365/10000], Validation Loss: 0.99259281, Validation Accuracy: 0.5588\n",
      "Epoch [3366/10000], Training Loss: 0.62287347, Training Accuracy: 0.9286\n",
      "Epoch [3366/10000], Validation Loss: 0.99256796, Validation Accuracy: 0.5588\n",
      "Epoch [3367/10000], Training Loss: 0.64807882, Training Accuracy: 0.9034\n",
      "Epoch [3367/10000], Validation Loss: 0.99254686, Validation Accuracy: 0.5588\n",
      "Epoch [3368/10000], Training Loss: 0.62983519, Training Accuracy: 0.9202\n",
      "Epoch [3368/10000], Validation Loss: 1.05143529, Validation Accuracy: 0.5000\n",
      "Epoch [3369/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3369/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3370/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3370/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3371/10000], Training Loss: 0.62729097, Training Accuracy: 0.9244\n",
      "Epoch [3371/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3372/10000], Training Loss: 0.64808623, Training Accuracy: 0.9034\n",
      "Epoch [3372/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3373/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3373/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3374/10000], Training Loss: 0.64388168, Training Accuracy: 0.9076\n",
      "Epoch [3374/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3375/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3375/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3376/10000], Training Loss: 0.65738148, Training Accuracy: 0.8950\n",
      "Epoch [3376/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3377/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3377/10000], Validation Loss: 1.03674138, Validation Accuracy: 0.5147\n",
      "Epoch [3378/10000], Training Loss: 0.65214855, Training Accuracy: 0.8992\n",
      "Epoch [3378/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3379/10000], Training Loss: 0.64388161, Training Accuracy: 0.9076\n",
      "Epoch [3379/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3380/10000], Training Loss: 0.64392435, Training Accuracy: 0.9076\n",
      "Epoch [3380/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3381/10000], Training Loss: 0.63548113, Training Accuracy: 0.9160\n",
      "Epoch [3381/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3382/10000], Training Loss: 0.61026834, Training Accuracy: 0.9412\n",
      "Epoch [3382/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3383/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3383/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3384/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [3384/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3385/10000], Training Loss: 0.63967666, Training Accuracy: 0.9118\n",
      "Epoch [3385/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3386/10000], Training Loss: 0.61889327, Training Accuracy: 0.9328\n",
      "Epoch [3386/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3387/10000], Training Loss: 0.61867188, Training Accuracy: 0.9328\n",
      "Epoch [3387/10000], Validation Loss: 1.02171159, Validation Accuracy: 0.5294\n",
      "Epoch [3388/10000], Training Loss: 0.63127358, Training Accuracy: 0.9202\n",
      "Epoch [3388/10000], Validation Loss: 1.02202660, Validation Accuracy: 0.5294\n",
      "Epoch [3389/10000], Training Loss: 0.63968291, Training Accuracy: 0.9118\n",
      "Epoch [3389/10000], Validation Loss: 1.02203238, Validation Accuracy: 0.5294\n",
      "Epoch [3390/10000], Training Loss: 0.65228526, Training Accuracy: 0.8992\n",
      "Epoch [3390/10000], Validation Loss: 1.02203292, Validation Accuracy: 0.5294\n",
      "Epoch [3391/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3391/10000], Validation Loss: 1.02203298, Validation Accuracy: 0.5294\n",
      "Epoch [3392/10000], Training Loss: 0.62352702, Training Accuracy: 0.9286\n",
      "Epoch [3392/10000], Validation Loss: 1.05082446, Validation Accuracy: 0.5000\n",
      "Epoch [3393/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [3393/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3394/10000], Training Loss: 0.63544494, Training Accuracy: 0.9160\n",
      "Epoch [3394/10000], Validation Loss: 1.07986730, Validation Accuracy: 0.4706\n",
      "Epoch [3395/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3395/10000], Validation Loss: 1.08085650, Validation Accuracy: 0.4706\n",
      "Epoch [3396/10000], Training Loss: 0.63127695, Training Accuracy: 0.9202\n",
      "Epoch [3396/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3397/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3397/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3398/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3398/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3399/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3399/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3400/10000], Training Loss: 0.64742061, Training Accuracy: 0.9034\n",
      "Epoch [3400/10000], Validation Loss: 1.07996196, Validation Accuracy: 0.4706\n",
      "Epoch [3401/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3401/10000], Validation Loss: 1.02820915, Validation Accuracy: 0.5147\n",
      "Epoch [3402/10000], Training Loss: 0.67329108, Training Accuracy: 0.8782\n",
      "Epoch [3402/10000], Validation Loss: 1.00732741, Validation Accuracy: 0.5441\n",
      "Epoch [3403/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3403/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [3404/10000], Training Loss: 0.69850365, Training Accuracy: 0.8529\n",
      "Epoch [3404/10000], Validation Loss: 1.02203298, Validation Accuracy: 0.5294\n",
      "Epoch [3405/10000], Training Loss: 0.68589873, Training Accuracy: 0.8655\n",
      "Epoch [3405/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3406/10000], Training Loss: 0.69430208, Training Accuracy: 0.8571\n",
      "Epoch [3406/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3407/10000], Training Loss: 0.68460218, Training Accuracy: 0.8655\n",
      "Epoch [3407/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3408/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [3408/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3409/10000], Training Loss: 0.67749537, Training Accuracy: 0.8739\n",
      "Epoch [3409/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3410/10000], Training Loss: 0.70690798, Training Accuracy: 0.8445\n",
      "Epoch [3410/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3411/10000], Training Loss: 0.68959982, Training Accuracy: 0.8613\n",
      "Epoch [3411/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3412/10000], Training Loss: 0.67329357, Training Accuracy: 0.8782\n",
      "Epoch [3412/10000], Validation Loss: 0.99261045, Validation Accuracy: 0.5588\n",
      "Epoch [3413/10000], Training Loss: 0.68146993, Training Accuracy: 0.8697\n",
      "Epoch [3413/10000], Validation Loss: 0.97794256, Validation Accuracy: 0.5735\n",
      "Epoch [3414/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [3414/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3415/10000], Training Loss: 0.68563416, Training Accuracy: 0.8655\n",
      "Epoch [3415/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3416/10000], Training Loss: 0.68589872, Training Accuracy: 0.8655\n",
      "Epoch [3416/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3417/10000], Training Loss: 0.68589863, Training Accuracy: 0.8655\n",
      "Epoch [3417/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3418/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3418/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3419/10000], Training Loss: 0.69009932, Training Accuracy: 0.8613\n",
      "Epoch [3419/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3420/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [3420/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3421/10000], Training Loss: 0.68587971, Training Accuracy: 0.8655\n",
      "Epoch [3421/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3422/10000], Training Loss: 0.68589874, Training Accuracy: 0.8655\n",
      "Epoch [3422/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3423/10000], Training Loss: 0.69008504, Training Accuracy: 0.8613\n",
      "Epoch [3423/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3424/10000], Training Loss: 0.70270494, Training Accuracy: 0.8487\n",
      "Epoch [3424/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3425/10000], Training Loss: 0.67748314, Training Accuracy: 0.8739\n",
      "Epoch [3425/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3426/10000], Training Loss: 0.65847731, Training Accuracy: 0.8908\n",
      "Epoch [3426/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [3427/10000], Training Loss: 0.66486440, Training Accuracy: 0.8866\n",
      "Epoch [3427/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3428/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3428/10000], Validation Loss: 1.02211094, Validation Accuracy: 0.5294\n",
      "Epoch [3429/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [3429/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3430/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [3430/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3431/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3431/10000], Validation Loss: 1.05144185, Validation Accuracy: 0.5000\n",
      "Epoch [3432/10000], Training Loss: 0.62707491, Training Accuracy: 0.9244\n",
      "Epoch [3432/10000], Validation Loss: 1.03887042, Validation Accuracy: 0.5147\n",
      "Epoch [3433/10000], Training Loss: 0.64385744, Training Accuracy: 0.9076\n",
      "Epoch [3433/10000], Validation Loss: 1.03675738, Validation Accuracy: 0.5147\n",
      "Epoch [3434/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3434/10000], Validation Loss: 1.03675467, Validation Accuracy: 0.5147\n",
      "Epoch [3435/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3435/10000], Validation Loss: 1.03675357, Validation Accuracy: 0.5147\n",
      "Epoch [3436/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3436/10000], Validation Loss: 1.03675300, Validation Accuracy: 0.5147\n",
      "Epoch [3437/10000], Training Loss: 0.61445993, Training Accuracy: 0.9370\n",
      "Epoch [3437/10000], Validation Loss: 1.03702754, Validation Accuracy: 0.5147\n",
      "Epoch [3438/10000], Training Loss: 0.63547817, Training Accuracy: 0.9160\n",
      "Epoch [3438/10000], Validation Loss: 1.03909808, Validation Accuracy: 0.5147\n",
      "Epoch [3439/10000], Training Loss: 0.65228598, Training Accuracy: 0.8992\n",
      "Epoch [3439/10000], Validation Loss: 1.04161483, Validation Accuracy: 0.5147\n",
      "Epoch [3440/10000], Training Loss: 0.64300460, Training Accuracy: 0.9076\n",
      "Epoch [3440/10000], Validation Loss: 1.05144012, Validation Accuracy: 0.5000\n",
      "Epoch [3441/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3441/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3442/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3442/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3443/10000], Training Loss: 0.62707517, Training Accuracy: 0.9244\n",
      "Epoch [3443/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3444/10000], Training Loss: 0.65655555, Training Accuracy: 0.8950\n",
      "Epoch [3444/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3445/10000], Training Loss: 0.65227801, Training Accuracy: 0.8992\n",
      "Epoch [3445/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [3446/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [3446/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [3447/10000], Training Loss: 0.66064740, Training Accuracy: 0.8908\n",
      "Epoch [3447/10000], Validation Loss: 0.99209040, Validation Accuracy: 0.5588\n",
      "Epoch [3448/10000], Training Loss: 0.65228438, Training Accuracy: 0.8992\n",
      "Epoch [3448/10000], Validation Loss: 0.97955227, Validation Accuracy: 0.5735\n",
      "Epoch [3449/10000], Training Loss: 0.64133113, Training Accuracy: 0.9118\n",
      "Epoch [3449/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [3450/10000], Training Loss: 0.63127868, Training Accuracy: 0.9202\n",
      "Epoch [3450/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3451/10000], Training Loss: 0.64394928, Training Accuracy: 0.9076\n",
      "Epoch [3451/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3452/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3452/10000], Validation Loss: 0.97791460, Validation Accuracy: 0.5735\n",
      "Epoch [3453/10000], Training Loss: 0.63969703, Training Accuracy: 0.9118\n",
      "Epoch [3453/10000], Validation Loss: 0.96321046, Validation Accuracy: 0.5882\n",
      "Epoch [3454/10000], Training Loss: 0.62208259, Training Accuracy: 0.9286\n",
      "Epoch [3454/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3455/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [3455/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3456/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3456/10000], Validation Loss: 0.99262133, Validation Accuracy: 0.5588\n",
      "Epoch [3457/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3457/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3458/10000], Training Loss: 0.63796000, Training Accuracy: 0.9118\n",
      "Epoch [3458/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3459/10000], Training Loss: 0.65228535, Training Accuracy: 0.8992\n",
      "Epoch [3459/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3460/10000], Training Loss: 0.65228468, Training Accuracy: 0.8992\n",
      "Epoch [3460/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3461/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3461/10000], Validation Loss: 1.00732681, Validation Accuracy: 0.5441\n",
      "Epoch [3462/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3462/10000], Validation Loss: 0.99264541, Validation Accuracy: 0.5588\n",
      "Epoch [3463/10000], Training Loss: 0.63656741, Training Accuracy: 0.9160\n",
      "Epoch [3463/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3464/10000], Training Loss: 0.63612310, Training Accuracy: 0.9160\n",
      "Epoch [3464/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3465/10000], Training Loss: 0.64388566, Training Accuracy: 0.9076\n",
      "Epoch [3465/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3466/10000], Training Loss: 0.65977465, Training Accuracy: 0.8908\n",
      "Epoch [3466/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3467/10000], Training Loss: 0.65648709, Training Accuracy: 0.8950\n",
      "Epoch [3467/10000], Validation Loss: 0.97746435, Validation Accuracy: 0.5735\n",
      "Epoch [3468/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3468/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3469/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3469/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3470/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3470/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3471/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3471/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3472/10000], Training Loss: 0.65640867, Training Accuracy: 0.8950\n",
      "Epoch [3472/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3473/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3473/10000], Validation Loss: 0.97791502, Validation Accuracy: 0.5735\n",
      "Epoch [3474/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3474/10000], Validation Loss: 0.97790423, Validation Accuracy: 0.5735\n",
      "Epoch [3475/10000], Training Loss: 0.63971203, Training Accuracy: 0.9118\n",
      "Epoch [3475/10000], Validation Loss: 0.97788706, Validation Accuracy: 0.5735\n",
      "Epoch [3476/10000], Training Loss: 0.64807561, Training Accuracy: 0.9034\n",
      "Epoch [3476/10000], Validation Loss: 0.97790846, Validation Accuracy: 0.5735\n",
      "Epoch [3477/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [3477/10000], Validation Loss: 0.97791180, Validation Accuracy: 0.5735\n",
      "Epoch [3478/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3478/10000], Validation Loss: 0.97791281, Validation Accuracy: 0.5735\n",
      "Epoch [3479/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [3479/10000], Validation Loss: 0.97791317, Validation Accuracy: 0.5735\n",
      "Epoch [3480/10000], Training Loss: 0.63129353, Training Accuracy: 0.9202\n",
      "Epoch [3480/10000], Validation Loss: 0.97791150, Validation Accuracy: 0.5735\n",
      "Epoch [3481/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [3481/10000], Validation Loss: 1.00731209, Validation Accuracy: 0.5441\n",
      "Epoch [3482/10000], Training Loss: 0.63091673, Training Accuracy: 0.9202\n",
      "Epoch [3482/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3483/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3483/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3484/10000], Training Loss: 0.62707525, Training Accuracy: 0.9244\n",
      "Epoch [3484/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3485/10000], Training Loss: 0.66068864, Training Accuracy: 0.8908\n",
      "Epoch [3485/10000], Validation Loss: 1.00599575, Validation Accuracy: 0.5441\n",
      "Epoch [3486/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3486/10000], Validation Loss: 1.00732130, Validation Accuracy: 0.5441\n",
      "Epoch [3487/10000], Training Loss: 0.64827400, Training Accuracy: 0.9034\n",
      "Epoch [3487/10000], Validation Loss: 1.00729871, Validation Accuracy: 0.5441\n",
      "Epoch [3488/10000], Training Loss: 0.65228587, Training Accuracy: 0.8992\n",
      "Epoch [3488/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3489/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3489/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3490/10000], Training Loss: 0.64384719, Training Accuracy: 0.9076\n",
      "Epoch [3490/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3491/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3491/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3492/10000], Training Loss: 0.63547859, Training Accuracy: 0.9160\n",
      "Epoch [3492/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3493/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3493/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3494/10000], Training Loss: 0.64381418, Training Accuracy: 0.9076\n",
      "Epoch [3494/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3495/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [3495/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3496/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3496/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3497/10000], Training Loss: 0.66509434, Training Accuracy: 0.8866\n",
      "Epoch [3497/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3498/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3498/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3499/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3499/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3500/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3500/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3501/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3501/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3502/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3502/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3503/10000], Training Loss: 0.63968532, Training Accuracy: 0.9118\n",
      "Epoch [3503/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3504/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3504/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3505/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3505/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3506/10000], Training Loss: 0.65229762, Training Accuracy: 0.8992\n",
      "Epoch [3506/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3507/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3507/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3508/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3508/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3509/10000], Training Loss: 0.63968027, Training Accuracy: 0.9118\n",
      "Epoch [3509/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3510/10000], Training Loss: 0.62707572, Training Accuracy: 0.9244\n",
      "Epoch [3510/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3511/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3511/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3512/10000], Training Loss: 0.62548513, Training Accuracy: 0.9244\n",
      "Epoch [3512/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3513/10000], Training Loss: 0.61863976, Training Accuracy: 0.9328\n",
      "Epoch [3513/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3514/10000], Training Loss: 0.64387430, Training Accuracy: 0.9076\n",
      "Epoch [3514/10000], Validation Loss: 0.99261919, Validation Accuracy: 0.5588\n",
      "Epoch [3515/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3515/10000], Validation Loss: 0.97781870, Validation Accuracy: 0.5735\n",
      "Epoch [3516/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3516/10000], Validation Loss: 0.97740838, Validation Accuracy: 0.5735\n",
      "Epoch [3517/10000], Training Loss: 0.63367730, Training Accuracy: 0.9160\n",
      "Epoch [3517/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3518/10000], Training Loss: 0.64388191, Training Accuracy: 0.9076\n",
      "Epoch [3518/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3519/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3519/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3520/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [3520/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3521/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3521/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3522/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3522/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3523/10000], Training Loss: 0.63127677, Training Accuracy: 0.9202\n",
      "Epoch [3523/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3524/10000], Training Loss: 0.64823963, Training Accuracy: 0.9034\n",
      "Epoch [3524/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3525/10000], Training Loss: 0.62287383, Training Accuracy: 0.9286\n",
      "Epoch [3525/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3526/10000], Training Loss: 0.63547859, Training Accuracy: 0.9160\n",
      "Epoch [3526/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3527/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3527/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [3528/10000], Training Loss: 0.65032669, Training Accuracy: 0.8992\n",
      "Epoch [3528/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [3529/10000], Training Loss: 0.63965712, Training Accuracy: 0.9118\n",
      "Epoch [3529/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3530/10000], Training Loss: 0.66906972, Training Accuracy: 0.8824\n",
      "Epoch [3530/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3531/10000], Training Loss: 0.63690530, Training Accuracy: 0.9160\n",
      "Epoch [3531/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3532/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3532/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3533/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3533/10000], Validation Loss: 0.99374786, Validation Accuracy: 0.5588\n",
      "Epoch [3534/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3534/10000], Validation Loss: 0.99261203, Validation Accuracy: 0.5588\n",
      "Epoch [3535/10000], Training Loss: 0.65648646, Training Accuracy: 0.8950\n",
      "Epoch [3535/10000], Validation Loss: 0.99262115, Validation Accuracy: 0.5588\n",
      "Epoch [3536/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3536/10000], Validation Loss: 0.99262133, Validation Accuracy: 0.5588\n",
      "Epoch [3537/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3537/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [3538/10000], Training Loss: 0.64715655, Training Accuracy: 0.9034\n",
      "Epoch [3538/10000], Validation Loss: 1.02203304, Validation Accuracy: 0.5294\n",
      "Epoch [3539/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3539/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3540/10000], Training Loss: 0.63547851, Training Accuracy: 0.9160\n",
      "Epoch [3540/10000], Validation Loss: 1.02203259, Validation Accuracy: 0.5294\n",
      "Epoch [3541/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3541/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3542/10000], Training Loss: 0.64802091, Training Accuracy: 0.9034\n",
      "Epoch [3542/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3543/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3543/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3544/10000], Training Loss: 0.63127691, Training Accuracy: 0.9202\n",
      "Epoch [3544/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3545/10000], Training Loss: 0.64808381, Training Accuracy: 0.9034\n",
      "Epoch [3545/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3546/10000], Training Loss: 0.63572429, Training Accuracy: 0.9160\n",
      "Epoch [3546/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3547/10000], Training Loss: 0.62983858, Training Accuracy: 0.9202\n",
      "Epoch [3547/10000], Validation Loss: 1.02202475, Validation Accuracy: 0.5294\n",
      "Epoch [3548/10000], Training Loss: 0.61447773, Training Accuracy: 0.9370\n",
      "Epoch [3548/10000], Validation Loss: 1.03673893, Validation Accuracy: 0.5147\n",
      "Epoch [3549/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3549/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3550/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3550/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3551/10000], Training Loss: 0.64808608, Training Accuracy: 0.9034\n",
      "Epoch [3551/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3552/10000], Training Loss: 0.63127699, Training Accuracy: 0.9202\n",
      "Epoch [3552/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3553/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3553/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3554/10000], Training Loss: 0.63988932, Training Accuracy: 0.9118\n",
      "Epoch [3554/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3555/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3555/10000], Validation Loss: 1.03673875, Validation Accuracy: 0.5147\n",
      "Epoch [3556/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3556/10000], Validation Loss: 1.03658408, Validation Accuracy: 0.5147\n",
      "Epoch [3557/10000], Training Loss: 0.62708729, Training Accuracy: 0.9244\n",
      "Epoch [3557/10000], Validation Loss: 1.03672969, Validation Accuracy: 0.5147\n",
      "Epoch [3558/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3558/10000], Validation Loss: 1.03670377, Validation Accuracy: 0.5147\n",
      "Epoch [3559/10000], Training Loss: 0.63548036, Training Accuracy: 0.9160\n",
      "Epoch [3559/10000], Validation Loss: 1.03615385, Validation Accuracy: 0.5147\n",
      "Epoch [3560/10000], Training Loss: 0.64388184, Training Accuracy: 0.9076\n",
      "Epoch [3560/10000], Validation Loss: 1.03538281, Validation Accuracy: 0.5147\n",
      "Epoch [3561/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3561/10000], Validation Loss: 1.03548723, Validation Accuracy: 0.5147\n",
      "Epoch [3562/10000], Training Loss: 0.61867180, Training Accuracy: 0.9328\n",
      "Epoch [3562/10000], Validation Loss: 1.03566593, Validation Accuracy: 0.5147\n",
      "Epoch [3563/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3563/10000], Validation Loss: 1.03576487, Validation Accuracy: 0.5147\n",
      "Epoch [3564/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [3564/10000], Validation Loss: 1.03581327, Validation Accuracy: 0.5147\n",
      "Epoch [3565/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3565/10000], Validation Loss: 1.03583658, Validation Accuracy: 0.5147\n",
      "Epoch [3566/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3566/10000], Validation Loss: 1.03584766, Validation Accuracy: 0.5147\n",
      "Epoch [3567/10000], Training Loss: 0.62754764, Training Accuracy: 0.9244\n",
      "Epoch [3567/10000], Validation Loss: 1.03671616, Validation Accuracy: 0.5147\n",
      "Epoch [3568/10000], Training Loss: 0.63127720, Training Accuracy: 0.9202\n",
      "Epoch [3568/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3569/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3569/10000], Validation Loss: 1.01601335, Validation Accuracy: 0.5294\n",
      "Epoch [3570/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3570/10000], Validation Loss: 1.00732803, Validation Accuracy: 0.5441\n",
      "Epoch [3571/10000], Training Loss: 0.62707523, Training Accuracy: 0.9244\n",
      "Epoch [3571/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [3572/10000], Training Loss: 0.63293278, Training Accuracy: 0.9202\n",
      "Epoch [3572/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [3573/10000], Training Loss: 0.62287350, Training Accuracy: 0.9286\n",
      "Epoch [3573/10000], Validation Loss: 1.12347168, Validation Accuracy: 0.4265\n",
      "Epoch [3574/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3574/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3575/10000], Training Loss: 0.63547512, Training Accuracy: 0.9160\n",
      "Epoch [3575/10000], Validation Loss: 1.10912228, Validation Accuracy: 0.4412\n",
      "Epoch [3576/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3576/10000], Validation Loss: 1.13967931, Validation Accuracy: 0.4118\n",
      "Epoch [3577/10000], Training Loss: 0.63525151, Training Accuracy: 0.9160\n",
      "Epoch [3577/10000], Validation Loss: 1.13967985, Validation Accuracy: 0.4118\n",
      "Epoch [3578/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3578/10000], Validation Loss: 1.13902533, Validation Accuracy: 0.4118\n",
      "Epoch [3579/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3579/10000], Validation Loss: 1.13967675, Validation Accuracy: 0.4118\n",
      "Epoch [3580/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3580/10000], Validation Loss: 1.13967997, Validation Accuracy: 0.4118\n",
      "Epoch [3581/10000], Training Loss: 0.62707298, Training Accuracy: 0.9244\n",
      "Epoch [3581/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [3582/10000], Training Loss: 0.62287355, Training Accuracy: 0.9286\n",
      "Epoch [3582/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3583/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3583/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3584/10000], Training Loss: 0.62643445, Training Accuracy: 0.9244\n",
      "Epoch [3584/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [3585/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3585/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3586/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3586/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3587/10000], Training Loss: 0.63127431, Training Accuracy: 0.9202\n",
      "Epoch [3587/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3588/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3588/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3589/10000], Training Loss: 0.61446955, Training Accuracy: 0.9370\n",
      "Epoch [3589/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3590/10000], Training Loss: 0.62287344, Training Accuracy: 0.9286\n",
      "Epoch [3590/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3591/10000], Training Loss: 0.63537272, Training Accuracy: 0.9160\n",
      "Epoch [3591/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3592/10000], Training Loss: 0.63127728, Training Accuracy: 0.9202\n",
      "Epoch [3592/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3593/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3593/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3594/10000], Training Loss: 0.63127605, Training Accuracy: 0.9202\n",
      "Epoch [3594/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3595/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3595/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3596/10000], Training Loss: 0.62798386, Training Accuracy: 0.9244\n",
      "Epoch [3596/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3597/10000], Training Loss: 0.63127706, Training Accuracy: 0.9202\n",
      "Epoch [3597/10000], Validation Loss: 1.11026877, Validation Accuracy: 0.4412\n",
      "Epoch [3598/10000], Training Loss: 0.61447069, Training Accuracy: 0.9370\n",
      "Epoch [3598/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3599/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3599/10000], Validation Loss: 1.05141091, Validation Accuracy: 0.5000\n",
      "Epoch [3600/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3600/10000], Validation Loss: 1.06561893, Validation Accuracy: 0.4853\n",
      "Epoch [3601/10000], Training Loss: 0.63966462, Training Accuracy: 0.9118\n",
      "Epoch [3601/10000], Validation Loss: 1.06614393, Validation Accuracy: 0.4853\n",
      "Epoch [3602/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3602/10000], Validation Loss: 1.06592387, Validation Accuracy: 0.4853\n",
      "Epoch [3603/10000], Training Loss: 0.63050690, Training Accuracy: 0.9202\n",
      "Epoch [3603/10000], Validation Loss: 1.06575096, Validation Accuracy: 0.4853\n",
      "Epoch [3604/10000], Training Loss: 0.61446870, Training Accuracy: 0.9370\n",
      "Epoch [3604/10000], Validation Loss: 1.05144560, Validation Accuracy: 0.5000\n",
      "Epoch [3605/10000], Training Loss: 0.62287427, Training Accuracy: 0.9286\n",
      "Epoch [3605/10000], Validation Loss: 1.05144554, Validation Accuracy: 0.5000\n",
      "Epoch [3606/10000], Training Loss: 0.62707690, Training Accuracy: 0.9244\n",
      "Epoch [3606/10000], Validation Loss: 1.05506003, Validation Accuracy: 0.5000\n",
      "Epoch [3607/10000], Training Loss: 0.60988649, Training Accuracy: 0.9412\n",
      "Epoch [3607/10000], Validation Loss: 1.07938856, Validation Accuracy: 0.4706\n",
      "Epoch [3608/10000], Training Loss: 0.63958979, Training Accuracy: 0.9118\n",
      "Epoch [3608/10000], Validation Loss: 1.11025178, Validation Accuracy: 0.4412\n",
      "Epoch [3609/10000], Training Loss: 0.61447492, Training Accuracy: 0.9370\n",
      "Epoch [3609/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3610/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [3610/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3611/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3611/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3612/10000], Training Loss: 0.62290777, Training Accuracy: 0.9286\n",
      "Epoch [3612/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [3613/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3613/10000], Validation Loss: 1.09084648, Validation Accuracy: 0.4559\n",
      "Epoch [3614/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [3614/10000], Validation Loss: 1.08091491, Validation Accuracy: 0.4706\n",
      "Epoch [3615/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3615/10000], Validation Loss: 1.08085859, Validation Accuracy: 0.4706\n",
      "Epoch [3616/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [3616/10000], Validation Loss: 1.08085555, Validation Accuracy: 0.4706\n",
      "Epoch [3617/10000], Training Loss: 0.62528907, Training Accuracy: 0.9244\n",
      "Epoch [3617/10000], Validation Loss: 1.08081388, Validation Accuracy: 0.4706\n",
      "Epoch [3618/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3618/10000], Validation Loss: 1.05148238, Validation Accuracy: 0.5000\n",
      "Epoch [3619/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3619/10000], Validation Loss: 1.03673920, Validation Accuracy: 0.5147\n",
      "Epoch [3620/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3620/10000], Validation Loss: 1.03673908, Validation Accuracy: 0.5147\n",
      "Epoch [3621/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3621/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [3622/10000], Training Loss: 0.62287332, Training Accuracy: 0.9286\n",
      "Epoch [3622/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3623/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3623/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3624/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3624/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3625/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3625/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3626/10000], Training Loss: 0.62672142, Training Accuracy: 0.9244\n",
      "Epoch [3626/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3627/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3627/10000], Validation Loss: 1.07152796, Validation Accuracy: 0.4853\n",
      "Epoch [3628/10000], Training Loss: 0.62287455, Training Accuracy: 0.9286\n",
      "Epoch [3628/10000], Validation Loss: 1.09535599, Validation Accuracy: 0.4559\n",
      "Epoch [3629/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3629/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [3630/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [3630/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [3631/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [3631/10000], Validation Loss: 1.09556246, Validation Accuracy: 0.4559\n",
      "Epoch [3632/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3632/10000], Validation Loss: 1.09556246, Validation Accuracy: 0.4559\n",
      "Epoch [3633/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3633/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3634/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3634/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3635/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [3635/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3636/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [3636/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3637/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3637/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3638/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [3638/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3639/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [3639/10000], Validation Loss: 1.09556240, Validation Accuracy: 0.4559\n",
      "Epoch [3640/10000], Training Loss: 0.61034836, Training Accuracy: 0.9412\n",
      "Epoch [3640/10000], Validation Loss: 1.09556198, Validation Accuracy: 0.4559\n",
      "Epoch [3641/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3641/10000], Validation Loss: 1.09555686, Validation Accuracy: 0.4559\n",
      "Epoch [3642/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3642/10000], Validation Loss: 1.09555376, Validation Accuracy: 0.4559\n",
      "Epoch [3643/10000], Training Loss: 0.61867095, Training Accuracy: 0.9328\n",
      "Epoch [3643/10000], Validation Loss: 1.09558398, Validation Accuracy: 0.4559\n",
      "Epoch [3644/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [3644/10000], Validation Loss: 1.09563160, Validation Accuracy: 0.4559\n",
      "Epoch [3645/10000], Training Loss: 0.62729047, Training Accuracy: 0.9244\n",
      "Epoch [3645/10000], Validation Loss: 1.08335209, Validation Accuracy: 0.4706\n",
      "Epoch [3646/10000], Training Loss: 0.61569694, Training Accuracy: 0.9370\n",
      "Epoch [3646/10000], Validation Loss: 1.06615901, Validation Accuracy: 0.4853\n",
      "Epoch [3647/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3647/10000], Validation Loss: 1.07998806, Validation Accuracy: 0.4706\n",
      "Epoch [3648/10000], Training Loss: 0.64796477, Training Accuracy: 0.9034\n",
      "Epoch [3648/10000], Validation Loss: 1.06614685, Validation Accuracy: 0.4853\n",
      "Epoch [3649/10000], Training Loss: 0.65648704, Training Accuracy: 0.8950\n",
      "Epoch [3649/10000], Validation Loss: 1.02869225, Validation Accuracy: 0.5147\n",
      "Epoch [3650/10000], Training Loss: 0.65648617, Training Accuracy: 0.8950\n",
      "Epoch [3650/10000], Validation Loss: 1.03223395, Validation Accuracy: 0.5147\n",
      "Epoch [3651/10000], Training Loss: 0.67372136, Training Accuracy: 0.8782\n",
      "Epoch [3651/10000], Validation Loss: 1.02170438, Validation Accuracy: 0.5294\n",
      "Epoch [3652/10000], Training Loss: 0.68582426, Training Accuracy: 0.8655\n",
      "Epoch [3652/10000], Validation Loss: 1.04978734, Validation Accuracy: 0.5000\n",
      "Epoch [3653/10000], Training Loss: 0.64859405, Training Accuracy: 0.9034\n",
      "Epoch [3653/10000], Validation Loss: 1.03673527, Validation Accuracy: 0.5147\n",
      "Epoch [3654/10000], Training Loss: 0.65228643, Training Accuracy: 0.8992\n",
      "Epoch [3654/10000], Validation Loss: 1.03643617, Validation Accuracy: 0.5147\n",
      "Epoch [3655/10000], Training Loss: 0.68169257, Training Accuracy: 0.8697\n",
      "Epoch [3655/10000], Validation Loss: 1.03444973, Validation Accuracy: 0.5147\n",
      "Epoch [3656/10000], Training Loss: 0.67273263, Training Accuracy: 0.8782\n",
      "Epoch [3656/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3657/10000], Training Loss: 0.69820163, Training Accuracy: 0.8529\n",
      "Epoch [3657/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3658/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3658/10000], Validation Loss: 1.00495768, Validation Accuracy: 0.5441\n",
      "Epoch [3659/10000], Training Loss: 0.66095746, Training Accuracy: 0.8908\n",
      "Epoch [3659/10000], Validation Loss: 0.99263543, Validation Accuracy: 0.5588\n",
      "Epoch [3660/10000], Training Loss: 0.65225382, Training Accuracy: 0.8992\n",
      "Epoch [3660/10000], Validation Loss: 0.99980456, Validation Accuracy: 0.5441\n",
      "Epoch [3661/10000], Training Loss: 0.65639821, Training Accuracy: 0.8950\n",
      "Epoch [3661/10000], Validation Loss: 0.99265200, Validation Accuracy: 0.5588\n",
      "Epoch [3662/10000], Training Loss: 0.67749537, Training Accuracy: 0.8739\n",
      "Epoch [3662/10000], Validation Loss: 0.99262208, Validation Accuracy: 0.5588\n",
      "Epoch [3663/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3663/10000], Validation Loss: 0.99262148, Validation Accuracy: 0.5588\n",
      "Epoch [3664/10000], Training Loss: 0.67324798, Training Accuracy: 0.8782\n",
      "Epoch [3664/10000], Validation Loss: 0.99262160, Validation Accuracy: 0.5588\n",
      "Epoch [3665/10000], Training Loss: 0.64718848, Training Accuracy: 0.9034\n",
      "Epoch [3665/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3666/10000], Training Loss: 0.65687181, Training Accuracy: 0.8950\n",
      "Epoch [3666/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3667/10000], Training Loss: 0.66068872, Training Accuracy: 0.8908\n",
      "Epoch [3667/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3668/10000], Training Loss: 0.65648051, Training Accuracy: 0.8950\n",
      "Epoch [3668/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3669/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3669/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [3670/10000], Training Loss: 0.65935064, Training Accuracy: 0.8908\n",
      "Epoch [3670/10000], Validation Loss: 1.05144650, Validation Accuracy: 0.5000\n",
      "Epoch [3671/10000], Training Loss: 0.66488877, Training Accuracy: 0.8866\n",
      "Epoch [3671/10000], Validation Loss: 1.03676313, Validation Accuracy: 0.5147\n",
      "Epoch [3672/10000], Training Loss: 0.69260951, Training Accuracy: 0.8571\n",
      "Epoch [3672/10000], Validation Loss: 1.05144542, Validation Accuracy: 0.5000\n",
      "Epoch [3673/10000], Training Loss: 0.68589802, Training Accuracy: 0.8655\n",
      "Epoch [3673/10000], Validation Loss: 1.07371765, Validation Accuracy: 0.4706\n",
      "Epoch [3674/10000], Training Loss: 0.66045024, Training Accuracy: 0.8908\n",
      "Epoch [3674/10000], Validation Loss: 1.08085471, Validation Accuracy: 0.4706\n",
      "Epoch [3675/10000], Training Loss: 0.66366293, Training Accuracy: 0.8866\n",
      "Epoch [3675/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [3676/10000], Training Loss: 0.65653614, Training Accuracy: 0.8950\n",
      "Epoch [3676/10000], Validation Loss: 1.06858838, Validation Accuracy: 0.4853\n",
      "Epoch [3677/10000], Training Loss: 0.66489026, Training Accuracy: 0.8866\n",
      "Epoch [3677/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3678/10000], Training Loss: 0.64802814, Training Accuracy: 0.9034\n",
      "Epoch [3678/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3679/10000], Training Loss: 0.66450888, Training Accuracy: 0.8866\n",
      "Epoch [3679/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3680/10000], Training Loss: 0.67835189, Training Accuracy: 0.8739\n",
      "Epoch [3680/10000], Validation Loss: 1.05144545, Validation Accuracy: 0.5000\n",
      "Epoch [3681/10000], Training Loss: 0.66031060, Training Accuracy: 0.8908\n",
      "Epoch [3681/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3682/10000], Training Loss: 0.65228552, Training Accuracy: 0.8992\n",
      "Epoch [3682/10000], Validation Loss: 1.02203229, Validation Accuracy: 0.5294\n",
      "Epoch [3683/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3683/10000], Validation Loss: 1.02207446, Validation Accuracy: 0.5294\n",
      "Epoch [3684/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [3684/10000], Validation Loss: 1.02203321, Validation Accuracy: 0.5294\n",
      "Epoch [3685/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [3685/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3686/10000], Training Loss: 0.66493979, Training Accuracy: 0.8866\n",
      "Epoch [3686/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3687/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [3687/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3688/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3688/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3689/10000], Training Loss: 0.66566065, Training Accuracy: 0.8866\n",
      "Epoch [3689/10000], Validation Loss: 1.02203453, Validation Accuracy: 0.5294\n",
      "Epoch [3690/10000], Training Loss: 0.67749537, Training Accuracy: 0.8739\n",
      "Epoch [3690/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3691/10000], Training Loss: 0.67749384, Training Accuracy: 0.8739\n",
      "Epoch [3691/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3692/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3692/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3693/10000], Training Loss: 0.64808513, Training Accuracy: 0.9034\n",
      "Epoch [3693/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [3694/10000], Training Loss: 0.65227612, Training Accuracy: 0.8992\n",
      "Epoch [3694/10000], Validation Loss: 1.02203107, Validation Accuracy: 0.5294\n",
      "Epoch [3695/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3695/10000], Validation Loss: 1.01373601, Validation Accuracy: 0.5294\n",
      "Epoch [3696/10000], Training Loss: 0.64388327, Training Accuracy: 0.9076\n",
      "Epoch [3696/10000], Validation Loss: 1.00752461, Validation Accuracy: 0.5441\n",
      "Epoch [3697/10000], Training Loss: 0.69841562, Training Accuracy: 0.8529\n",
      "Epoch [3697/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [3698/10000], Training Loss: 0.65205094, Training Accuracy: 0.8992\n",
      "Epoch [3698/10000], Validation Loss: 1.02151680, Validation Accuracy: 0.5294\n",
      "Epoch [3699/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3699/10000], Validation Loss: 1.02274975, Validation Accuracy: 0.5294\n",
      "Epoch [3700/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [3700/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3701/10000], Training Loss: 0.65228429, Training Accuracy: 0.8992\n",
      "Epoch [3701/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3702/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3702/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3703/10000], Training Loss: 0.66881210, Training Accuracy: 0.8824\n",
      "Epoch [3703/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3704/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3704/10000], Validation Loss: 1.05115277, Validation Accuracy: 0.5000\n",
      "Epoch [3705/10000], Training Loss: 0.67071063, Training Accuracy: 0.8824\n",
      "Epoch [3705/10000], Validation Loss: 1.02024606, Validation Accuracy: 0.5294\n",
      "Epoch [3706/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [3706/10000], Validation Loss: 1.05181998, Validation Accuracy: 0.5000\n",
      "Epoch [3707/10000], Training Loss: 0.66067175, Training Accuracy: 0.8908\n",
      "Epoch [3707/10000], Validation Loss: 1.08074903, Validation Accuracy: 0.4706\n",
      "Epoch [3708/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3708/10000], Validation Loss: 1.09506005, Validation Accuracy: 0.4559\n",
      "Epoch [3709/10000], Training Loss: 0.66068694, Training Accuracy: 0.8908\n",
      "Epoch [3709/10000], Validation Loss: 1.08324575, Validation Accuracy: 0.4706\n",
      "Epoch [3710/10000], Training Loss: 0.65230992, Training Accuracy: 0.8992\n",
      "Epoch [3710/10000], Validation Loss: 1.07425630, Validation Accuracy: 0.4853\n",
      "Epoch [3711/10000], Training Loss: 0.66492900, Training Accuracy: 0.8866\n",
      "Epoch [3711/10000], Validation Loss: 1.07986909, Validation Accuracy: 0.4706\n",
      "Epoch [3712/10000], Training Loss: 0.65228524, Training Accuracy: 0.8992\n",
      "Epoch [3712/10000], Validation Loss: 1.09508479, Validation Accuracy: 0.4559\n",
      "Epoch [3713/10000], Training Loss: 0.66909197, Training Accuracy: 0.8824\n",
      "Epoch [3713/10000], Validation Loss: 1.09547257, Validation Accuracy: 0.4559\n",
      "Epoch [3714/10000], Training Loss: 0.66476506, Training Accuracy: 0.8866\n",
      "Epoch [3714/10000], Validation Loss: 1.06290156, Validation Accuracy: 0.4853\n",
      "Epoch [3715/10000], Training Loss: 0.67851551, Training Accuracy: 0.8739\n",
      "Epoch [3715/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3716/10000], Training Loss: 0.64388123, Training Accuracy: 0.9076\n",
      "Epoch [3716/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3717/10000], Training Loss: 0.64387399, Training Accuracy: 0.9076\n",
      "Epoch [3717/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3718/10000], Training Loss: 0.66967102, Training Accuracy: 0.8824\n",
      "Epoch [3718/10000], Validation Loss: 1.02235144, Validation Accuracy: 0.5294\n",
      "Epoch [3719/10000], Training Loss: 0.64388177, Training Accuracy: 0.9076\n",
      "Epoch [3719/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3720/10000], Training Loss: 0.63967925, Training Accuracy: 0.9118\n",
      "Epoch [3720/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3721/10000], Training Loss: 0.65648775, Training Accuracy: 0.8950\n",
      "Epoch [3721/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3722/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3722/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3723/10000], Training Loss: 0.65431932, Training Accuracy: 0.8950\n",
      "Epoch [3723/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3724/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3724/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3725/10000], Training Loss: 0.64808357, Training Accuracy: 0.9034\n",
      "Epoch [3725/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3726/10000], Training Loss: 0.65648535, Training Accuracy: 0.8950\n",
      "Epoch [3726/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3727/10000], Training Loss: 0.66068504, Training Accuracy: 0.8908\n",
      "Epoch [3727/10000], Validation Loss: 1.03485054, Validation Accuracy: 0.5147\n",
      "Epoch [3728/10000], Training Loss: 0.65648561, Training Accuracy: 0.8950\n",
      "Epoch [3728/10000], Validation Loss: 1.02204183, Validation Accuracy: 0.5294\n",
      "Epoch [3729/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3729/10000], Validation Loss: 1.02203330, Validation Accuracy: 0.5294\n",
      "Epoch [3730/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3730/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3731/10000], Training Loss: 0.66068867, Training Accuracy: 0.8908\n",
      "Epoch [3731/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3732/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3732/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3733/10000], Training Loss: 0.67327440, Training Accuracy: 0.8782\n",
      "Epoch [3733/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [3734/10000], Training Loss: 0.64651975, Training Accuracy: 0.9034\n",
      "Epoch [3734/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3735/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3735/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3736/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3736/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3737/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [3737/10000], Validation Loss: 1.05144507, Validation Accuracy: 0.5000\n",
      "Epoch [3738/10000], Training Loss: 0.63547788, Training Accuracy: 0.9160\n",
      "Epoch [3738/10000], Validation Loss: 1.06348497, Validation Accuracy: 0.4853\n",
      "Epoch [3739/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [3739/10000], Validation Loss: 1.06614554, Validation Accuracy: 0.4853\n",
      "Epoch [3740/10000], Training Loss: 0.65501254, Training Accuracy: 0.8950\n",
      "Epoch [3740/10000], Validation Loss: 1.03652382, Validation Accuracy: 0.5147\n",
      "Epoch [3741/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [3741/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3742/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3742/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3743/10000], Training Loss: 0.66069143, Training Accuracy: 0.8908\n",
      "Epoch [3743/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3744/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [3744/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3745/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3745/10000], Validation Loss: 1.05144477, Validation Accuracy: 0.5000\n",
      "Epoch [3746/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3746/10000], Validation Loss: 1.05144471, Validation Accuracy: 0.5000\n",
      "Epoch [3747/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3747/10000], Validation Loss: 1.05144459, Validation Accuracy: 0.5000\n",
      "Epoch [3748/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3748/10000], Validation Loss: 1.05144453, Validation Accuracy: 0.5000\n",
      "Epoch [3749/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3749/10000], Validation Loss: 1.05144447, Validation Accuracy: 0.5000\n",
      "Epoch [3750/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [3750/10000], Validation Loss: 1.05144447, Validation Accuracy: 0.5000\n",
      "Epoch [3751/10000], Training Loss: 0.66113854, Training Accuracy: 0.8908\n",
      "Epoch [3751/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3752/10000], Training Loss: 0.63333469, Training Accuracy: 0.9160\n",
      "Epoch [3752/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3753/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3753/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3754/10000], Training Loss: 0.63128246, Training Accuracy: 0.9202\n",
      "Epoch [3754/10000], Validation Loss: 0.99258634, Validation Accuracy: 0.5588\n",
      "Epoch [3755/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3755/10000], Validation Loss: 0.96320966, Validation Accuracy: 0.5882\n",
      "Epoch [3756/10000], Training Loss: 0.63138665, Training Accuracy: 0.9202\n",
      "Epoch [3756/10000], Validation Loss: 0.96320984, Validation Accuracy: 0.5882\n",
      "Epoch [3757/10000], Training Loss: 0.65648899, Training Accuracy: 0.8950\n",
      "Epoch [3757/10000], Validation Loss: 0.96322584, Validation Accuracy: 0.5882\n",
      "Epoch [3758/10000], Training Loss: 0.63547512, Training Accuracy: 0.9160\n",
      "Epoch [3758/10000], Validation Loss: 0.96347618, Validation Accuracy: 0.5882\n",
      "Epoch [3759/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [3759/10000], Validation Loss: 0.96420217, Validation Accuracy: 0.5882\n",
      "Epoch [3760/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3760/10000], Validation Loss: 0.96501419, Validation Accuracy: 0.5882\n",
      "Epoch [3761/10000], Training Loss: 0.64388054, Training Accuracy: 0.9076\n",
      "Epoch [3761/10000], Validation Loss: 0.96565515, Validation Accuracy: 0.5882\n",
      "Epoch [3762/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3762/10000], Validation Loss: 0.96617493, Validation Accuracy: 0.5882\n",
      "Epoch [3763/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [3763/10000], Validation Loss: 0.96645790, Validation Accuracy: 0.5882\n",
      "Epoch [3764/10000], Training Loss: 0.61867419, Training Accuracy: 0.9328\n",
      "Epoch [3764/10000], Validation Loss: 0.96700355, Validation Accuracy: 0.5882\n",
      "Epoch [3765/10000], Training Loss: 0.63548046, Training Accuracy: 0.9160\n",
      "Epoch [3765/10000], Validation Loss: 0.96835110, Validation Accuracy: 0.5882\n",
      "Epoch [3766/10000], Training Loss: 0.63547830, Training Accuracy: 0.9160\n",
      "Epoch [3766/10000], Validation Loss: 0.97005513, Validation Accuracy: 0.5735\n",
      "Epoch [3767/10000], Training Loss: 0.64808358, Training Accuracy: 0.9034\n",
      "Epoch [3767/10000], Validation Loss: 0.97074917, Validation Accuracy: 0.5735\n",
      "Epoch [3768/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3768/10000], Validation Loss: 0.97107899, Validation Accuracy: 0.5735\n",
      "Epoch [3769/10000], Training Loss: 0.63968036, Training Accuracy: 0.9118\n",
      "Epoch [3769/10000], Validation Loss: 0.97124583, Validation Accuracy: 0.5735\n",
      "Epoch [3770/10000], Training Loss: 0.63548294, Training Accuracy: 0.9160\n",
      "Epoch [3770/10000], Validation Loss: 0.97207627, Validation Accuracy: 0.5735\n",
      "Epoch [3771/10000], Training Loss: 0.65217785, Training Accuracy: 0.8992\n",
      "Epoch [3771/10000], Validation Loss: 0.99076644, Validation Accuracy: 0.5588\n",
      "Epoch [3772/10000], Training Loss: 0.64387671, Training Accuracy: 0.9076\n",
      "Epoch [3772/10000], Validation Loss: 0.99254480, Validation Accuracy: 0.5588\n",
      "Epoch [3773/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3773/10000], Validation Loss: 0.99259803, Validation Accuracy: 0.5588\n",
      "Epoch [3774/10000], Training Loss: 0.63968078, Training Accuracy: 0.9118\n",
      "Epoch [3774/10000], Validation Loss: 0.99260324, Validation Accuracy: 0.5588\n",
      "Epoch [3775/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [3775/10000], Validation Loss: 0.99260533, Validation Accuracy: 0.5588\n",
      "Epoch [3776/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3776/10000], Validation Loss: 0.99260622, Validation Accuracy: 0.5588\n",
      "Epoch [3777/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3777/10000], Validation Loss: 0.99260661, Validation Accuracy: 0.5588\n",
      "Epoch [3778/10000], Training Loss: 0.63548017, Training Accuracy: 0.9160\n",
      "Epoch [3778/10000], Validation Loss: 0.99260208, Validation Accuracy: 0.5588\n",
      "Epoch [3779/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3779/10000], Validation Loss: 0.99259764, Validation Accuracy: 0.5588\n",
      "Epoch [3780/10000], Training Loss: 0.64808359, Training Accuracy: 0.9034\n",
      "Epoch [3780/10000], Validation Loss: 0.99259511, Validation Accuracy: 0.5588\n",
      "Epoch [3781/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3781/10000], Validation Loss: 0.99259382, Validation Accuracy: 0.5588\n",
      "Epoch [3782/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [3782/10000], Validation Loss: 0.99259320, Validation Accuracy: 0.5588\n",
      "Epoch [3783/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [3783/10000], Validation Loss: 0.99259287, Validation Accuracy: 0.5588\n",
      "Epoch [3784/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3784/10000], Validation Loss: 0.99259275, Validation Accuracy: 0.5588\n",
      "Epoch [3785/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3785/10000], Validation Loss: 0.99259269, Validation Accuracy: 0.5588\n",
      "Epoch [3786/10000], Training Loss: 0.64810113, Training Accuracy: 0.9034\n",
      "Epoch [3786/10000], Validation Loss: 0.99259803, Validation Accuracy: 0.5588\n",
      "Epoch [3787/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3787/10000], Validation Loss: 0.99261233, Validation Accuracy: 0.5588\n",
      "Epoch [3788/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3788/10000], Validation Loss: 0.99261558, Validation Accuracy: 0.5588\n",
      "Epoch [3789/10000], Training Loss: 0.63546328, Training Accuracy: 0.9160\n",
      "Epoch [3789/10000], Validation Loss: 0.99261576, Validation Accuracy: 0.5588\n",
      "Epoch [3790/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3790/10000], Validation Loss: 0.99261361, Validation Accuracy: 0.5588\n",
      "Epoch [3791/10000], Training Loss: 0.63960324, Training Accuracy: 0.9118\n",
      "Epoch [3791/10000], Validation Loss: 0.99262092, Validation Accuracy: 0.5588\n",
      "Epoch [3792/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3792/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3793/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3793/10000], Validation Loss: 0.99263191, Validation Accuracy: 0.5588\n",
      "Epoch [3794/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3794/10000], Validation Loss: 0.99460602, Validation Accuracy: 0.5588\n",
      "Epoch [3795/10000], Training Loss: 0.63127658, Training Accuracy: 0.9202\n",
      "Epoch [3795/10000], Validation Loss: 1.00272033, Validation Accuracy: 0.5441\n",
      "Epoch [3796/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3796/10000], Validation Loss: 1.00562504, Validation Accuracy: 0.5441\n",
      "Epoch [3797/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3797/10000], Validation Loss: 1.00633487, Validation Accuracy: 0.5441\n",
      "Epoch [3798/10000], Training Loss: 0.64387953, Training Accuracy: 0.9076\n",
      "Epoch [3798/10000], Validation Loss: 1.00641230, Validation Accuracy: 0.5441\n",
      "Epoch [3799/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3799/10000], Validation Loss: 1.00543961, Validation Accuracy: 0.5441\n",
      "Epoch [3800/10000], Training Loss: 0.65653453, Training Accuracy: 0.8950\n",
      "Epoch [3800/10000], Validation Loss: 1.00634584, Validation Accuracy: 0.5441\n",
      "Epoch [3801/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [3801/10000], Validation Loss: 1.00661901, Validation Accuracy: 0.5441\n",
      "Epoch [3802/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3802/10000], Validation Loss: 1.00672272, Validation Accuracy: 0.5441\n",
      "Epoch [3803/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [3803/10000], Validation Loss: 1.00676718, Validation Accuracy: 0.5441\n",
      "Epoch [3804/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [3804/10000], Validation Loss: 1.00678733, Validation Accuracy: 0.5441\n",
      "Epoch [3805/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [3805/10000], Validation Loss: 1.00679681, Validation Accuracy: 0.5441\n",
      "Epoch [3806/10000], Training Loss: 0.65228528, Training Accuracy: 0.8992\n",
      "Epoch [3806/10000], Validation Loss: 1.00680116, Validation Accuracy: 0.5441\n",
      "Epoch [3807/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [3807/10000], Validation Loss: 1.00680324, Validation Accuracy: 0.5441\n",
      "Epoch [3808/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [3808/10000], Validation Loss: 1.00680420, Validation Accuracy: 0.5441\n",
      "Epoch [3809/10000], Training Loss: 0.63144223, Training Accuracy: 0.9202\n",
      "Epoch [3809/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3810/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3810/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [3811/10000], Training Loss: 0.65336078, Training Accuracy: 0.8992\n",
      "Epoch [3811/10000], Validation Loss: 1.03673893, Validation Accuracy: 0.5147\n",
      "Epoch [3812/10000], Training Loss: 0.64352156, Training Accuracy: 0.9076\n",
      "Epoch [3812/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3813/10000], Training Loss: 0.63565822, Training Accuracy: 0.9160\n",
      "Epoch [3813/10000], Validation Loss: 1.02578652, Validation Accuracy: 0.5294\n",
      "Epoch [3814/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3814/10000], Validation Loss: 1.01279283, Validation Accuracy: 0.5441\n",
      "Epoch [3815/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3815/10000], Validation Loss: 1.02203381, Validation Accuracy: 0.5294\n",
      "Epoch [3816/10000], Training Loss: 0.62287115, Training Accuracy: 0.9286\n",
      "Epoch [3816/10000], Validation Loss: 1.03126276, Validation Accuracy: 0.5147\n",
      "Epoch [3817/10000], Training Loss: 0.65226164, Training Accuracy: 0.8992\n",
      "Epoch [3817/10000], Validation Loss: 1.03974396, Validation Accuracy: 0.5147\n",
      "Epoch [3818/10000], Training Loss: 0.62241593, Training Accuracy: 0.9286\n",
      "Epoch [3818/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [3819/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [3819/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3820/10000], Training Loss: 0.62708833, Training Accuracy: 0.9244\n",
      "Epoch [3820/10000], Validation Loss: 1.02203298, Validation Accuracy: 0.5294\n",
      "Epoch [3821/10000], Training Loss: 0.63400812, Training Accuracy: 0.9160\n",
      "Epoch [3821/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3822/10000], Training Loss: 0.63120189, Training Accuracy: 0.9202\n",
      "Epoch [3822/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3823/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3823/10000], Validation Loss: 1.02199131, Validation Accuracy: 0.5294\n",
      "Epoch [3824/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [3824/10000], Validation Loss: 1.00757059, Validation Accuracy: 0.5441\n",
      "Epoch [3825/10000], Training Loss: 0.62708678, Training Accuracy: 0.9244\n",
      "Epoch [3825/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [3826/10000], Training Loss: 0.63944701, Training Accuracy: 0.9118\n",
      "Epoch [3826/10000], Validation Loss: 0.99313596, Validation Accuracy: 0.5588\n",
      "Epoch [3827/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [3827/10000], Validation Loss: 1.00620654, Validation Accuracy: 0.5441\n",
      "Epoch [3828/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3828/10000], Validation Loss: 1.00724450, Validation Accuracy: 0.5441\n",
      "Epoch [3829/10000], Training Loss: 0.63102812, Training Accuracy: 0.9202\n",
      "Epoch [3829/10000], Validation Loss: 1.02203292, Validation Accuracy: 0.5294\n",
      "Epoch [3830/10000], Training Loss: 0.63548300, Training Accuracy: 0.9160\n",
      "Epoch [3830/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3831/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [3831/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3832/10000], Training Loss: 0.64150202, Training Accuracy: 0.9076\n",
      "Epoch [3832/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3833/10000], Training Loss: 0.65655587, Training Accuracy: 0.8950\n",
      "Epoch [3833/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [3834/10000], Training Loss: 0.65228523, Training Accuracy: 0.8992\n",
      "Epoch [3834/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3835/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3835/10000], Validation Loss: 1.03674030, Validation Accuracy: 0.5147\n",
      "Epoch [3836/10000], Training Loss: 0.65229159, Training Accuracy: 0.8992\n",
      "Epoch [3836/10000], Validation Loss: 1.03852534, Validation Accuracy: 0.5147\n",
      "Epoch [3837/10000], Training Loss: 0.65235847, Training Accuracy: 0.8992\n",
      "Epoch [3837/10000], Validation Loss: 1.04044956, Validation Accuracy: 0.5147\n",
      "Epoch [3838/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [3838/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [3839/10000], Training Loss: 0.64931279, Training Accuracy: 0.9034\n",
      "Epoch [3839/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3840/10000], Training Loss: 0.64808277, Training Accuracy: 0.9034\n",
      "Epoch [3840/10000], Validation Loss: 0.97792464, Validation Accuracy: 0.5735\n",
      "Epoch [3841/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [3841/10000], Validation Loss: 0.98746622, Validation Accuracy: 0.5588\n",
      "Epoch [3842/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [3842/10000], Validation Loss: 0.99242872, Validation Accuracy: 0.5588\n",
      "Epoch [3843/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [3843/10000], Validation Loss: 0.99258685, Validation Accuracy: 0.5588\n",
      "Epoch [3844/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [3844/10000], Validation Loss: 0.99260616, Validation Accuracy: 0.5588\n",
      "Epoch [3845/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [3845/10000], Validation Loss: 0.99261111, Validation Accuracy: 0.5588\n",
      "Epoch [3846/10000], Training Loss: 0.64388218, Training Accuracy: 0.9076\n",
      "Epoch [3846/10000], Validation Loss: 0.99261296, Validation Accuracy: 0.5588\n",
      "Epoch [3847/10000], Training Loss: 0.63398540, Training Accuracy: 0.9160\n",
      "Epoch [3847/10000], Validation Loss: 1.00589666, Validation Accuracy: 0.5441\n",
      "Epoch [3848/10000], Training Loss: 0.66067857, Training Accuracy: 0.8908\n",
      "Epoch [3848/10000], Validation Loss: 0.99326083, Validation Accuracy: 0.5588\n",
      "Epoch [3849/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [3849/10000], Validation Loss: 0.99269402, Validation Accuracy: 0.5588\n",
      "Epoch [3850/10000], Training Loss: 0.65683250, Training Accuracy: 0.8950\n",
      "Epoch [3850/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [3851/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [3851/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [3852/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [3852/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [3853/10000], Training Loss: 0.66068867, Training Accuracy: 0.8908\n",
      "Epoch [3853/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [3854/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [3854/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3855/10000], Training Loss: 0.67195146, Training Accuracy: 0.8782\n",
      "Epoch [3855/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [3856/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3856/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3857/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3857/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3858/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3858/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3859/10000], Training Loss: 0.67749539, Training Accuracy: 0.8739\n",
      "Epoch [3859/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3860/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [3860/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3861/10000], Training Loss: 0.66908905, Training Accuracy: 0.8824\n",
      "Epoch [3861/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3862/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3862/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3863/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [3863/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3864/10000], Training Loss: 0.69430210, Training Accuracy: 0.8571\n",
      "Epoch [3864/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3865/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [3865/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3866/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [3866/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3867/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3867/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3868/10000], Training Loss: 0.67328938, Training Accuracy: 0.8782\n",
      "Epoch [3868/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3869/10000], Training Loss: 0.69431154, Training Accuracy: 0.8571\n",
      "Epoch [3869/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3870/10000], Training Loss: 0.68169995, Training Accuracy: 0.8697\n",
      "Epoch [3870/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3871/10000], Training Loss: 0.65648658, Training Accuracy: 0.8950\n",
      "Epoch [3871/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3872/10000], Training Loss: 0.68589873, Training Accuracy: 0.8655\n",
      "Epoch [3872/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3873/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3873/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3874/10000], Training Loss: 0.67329370, Training Accuracy: 0.8782\n",
      "Epoch [3874/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3875/10000], Training Loss: 0.67329092, Training Accuracy: 0.8782\n",
      "Epoch [3875/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3876/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [3876/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3877/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [3877/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3878/10000], Training Loss: 0.65648726, Training Accuracy: 0.8950\n",
      "Epoch [3878/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3879/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3879/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3880/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [3880/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3881/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3881/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3882/10000], Training Loss: 0.66844282, Training Accuracy: 0.8824\n",
      "Epoch [3882/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3883/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [3883/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3884/10000], Training Loss: 0.65228537, Training Accuracy: 0.8992\n",
      "Epoch [3884/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3885/10000], Training Loss: 0.68589874, Training Accuracy: 0.8655\n",
      "Epoch [3885/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3886/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [3886/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3887/10000], Training Loss: 0.66326863, Training Accuracy: 0.8908\n",
      "Epoch [3887/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3888/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [3888/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [3889/10000], Training Loss: 0.66909200, Training Accuracy: 0.8824\n",
      "Epoch [3889/10000], Validation Loss: 1.12497944, Validation Accuracy: 0.4265\n",
      "Epoch [3890/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3890/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3891/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3891/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3892/10000], Training Loss: 0.68169706, Training Accuracy: 0.8697\n",
      "Epoch [3892/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3893/10000], Training Loss: 0.64808364, Training Accuracy: 0.9034\n",
      "Epoch [3893/10000], Validation Loss: 1.12497526, Validation Accuracy: 0.4265\n",
      "Epoch [3894/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3894/10000], Validation Loss: 1.12469012, Validation Accuracy: 0.4265\n",
      "Epoch [3895/10000], Training Loss: 0.67749430, Training Accuracy: 0.8739\n",
      "Epoch [3895/10000], Validation Loss: 1.12468916, Validation Accuracy: 0.4265\n",
      "Epoch [3896/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [3896/10000], Validation Loss: 1.12495416, Validation Accuracy: 0.4265\n",
      "Epoch [3897/10000], Training Loss: 0.69430153, Training Accuracy: 0.8571\n",
      "Epoch [3897/10000], Validation Loss: 1.12514472, Validation Accuracy: 0.4265\n",
      "Epoch [3898/10000], Training Loss: 0.69850377, Training Accuracy: 0.8529\n",
      "Epoch [3898/10000], Validation Loss: 1.12525588, Validation Accuracy: 0.4265\n",
      "Epoch [3899/10000], Training Loss: 0.66484126, Training Accuracy: 0.8866\n",
      "Epoch [3899/10000], Validation Loss: 1.12473768, Validation Accuracy: 0.4265\n",
      "Epoch [3900/10000], Training Loss: 0.66909194, Training Accuracy: 0.8824\n",
      "Epoch [3900/10000], Validation Loss: 1.11026508, Validation Accuracy: 0.4412\n",
      "Epoch [3901/10000], Training Loss: 0.68081038, Training Accuracy: 0.8697\n",
      "Epoch [3901/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [3902/10000], Training Loss: 0.69430210, Training Accuracy: 0.8571\n",
      "Epoch [3902/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3903/10000], Training Loss: 0.66908745, Training Accuracy: 0.8824\n",
      "Epoch [3903/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [3904/10000], Training Loss: 0.69010042, Training Accuracy: 0.8613\n",
      "Epoch [3904/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3905/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3905/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3906/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [3906/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3907/10000], Training Loss: 0.69850378, Training Accuracy: 0.8529\n",
      "Epoch [3907/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3908/10000], Training Loss: 0.67749161, Training Accuracy: 0.8739\n",
      "Epoch [3908/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3909/10000], Training Loss: 0.69430210, Training Accuracy: 0.8571\n",
      "Epoch [3909/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3910/10000], Training Loss: 0.68276555, Training Accuracy: 0.8697\n",
      "Epoch [3910/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [3911/10000], Training Loss: 0.70242057, Training Accuracy: 0.8487\n",
      "Epoch [3911/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [3912/10000], Training Loss: 0.70270580, Training Accuracy: 0.8487\n",
      "Epoch [3912/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3913/10000], Training Loss: 0.67749539, Training Accuracy: 0.8739\n",
      "Epoch [3913/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3914/10000], Training Loss: 0.69010042, Training Accuracy: 0.8613\n",
      "Epoch [3914/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3915/10000], Training Loss: 0.68169705, Training Accuracy: 0.8697\n",
      "Epoch [3915/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3916/10000], Training Loss: 0.67329368, Training Accuracy: 0.8782\n",
      "Epoch [3916/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3917/10000], Training Loss: 0.68169701, Training Accuracy: 0.8697\n",
      "Epoch [3917/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3918/10000], Training Loss: 0.69010023, Training Accuracy: 0.8613\n",
      "Epoch [3918/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3919/10000], Training Loss: 0.67749537, Training Accuracy: 0.8739\n",
      "Epoch [3919/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3920/10000], Training Loss: 0.69010042, Training Accuracy: 0.8613\n",
      "Epoch [3920/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3921/10000], Training Loss: 0.67751407, Training Accuracy: 0.8739\n",
      "Epoch [3921/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3922/10000], Training Loss: 0.69403700, Training Accuracy: 0.8571\n",
      "Epoch [3922/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3923/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3923/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3924/10000], Training Loss: 0.69573843, Training Accuracy: 0.8571\n",
      "Epoch [3924/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3925/10000], Training Loss: 0.68589874, Training Accuracy: 0.8655\n",
      "Epoch [3925/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3926/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3926/10000], Validation Loss: 1.15434521, Validation Accuracy: 0.3971\n",
      "Epoch [3927/10000], Training Loss: 0.67244726, Training Accuracy: 0.8782\n",
      "Epoch [3927/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [3928/10000], Training Loss: 0.67773541, Training Accuracy: 0.8739\n",
      "Epoch [3928/10000], Validation Loss: 1.12491512, Validation Accuracy: 0.4265\n",
      "Epoch [3929/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3929/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3930/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3930/10000], Validation Loss: 1.09556270, Validation Accuracy: 0.4559\n",
      "Epoch [3931/10000], Training Loss: 0.66909203, Training Accuracy: 0.8824\n",
      "Epoch [3931/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [3932/10000], Training Loss: 0.66905455, Training Accuracy: 0.8824\n",
      "Epoch [3932/10000], Validation Loss: 1.09556437, Validation Accuracy: 0.4559\n",
      "Epoch [3933/10000], Training Loss: 0.65217524, Training Accuracy: 0.8992\n",
      "Epoch [3933/10000], Validation Loss: 1.11484033, Validation Accuracy: 0.4412\n",
      "Epoch [3934/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3934/10000], Validation Loss: 1.12480927, Validation Accuracy: 0.4265\n",
      "Epoch [3935/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [3935/10000], Validation Loss: 1.12496156, Validation Accuracy: 0.4265\n",
      "Epoch [3936/10000], Training Loss: 0.66892198, Training Accuracy: 0.8824\n",
      "Epoch [3936/10000], Validation Loss: 1.11028451, Validation Accuracy: 0.4412\n",
      "Epoch [3937/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3937/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3938/10000], Training Loss: 0.68166581, Training Accuracy: 0.8697\n",
      "Epoch [3938/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3939/10000], Training Loss: 0.66488363, Training Accuracy: 0.8866\n",
      "Epoch [3939/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3940/10000], Training Loss: 0.68169670, Training Accuracy: 0.8697\n",
      "Epoch [3940/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3941/10000], Training Loss: 0.66909203, Training Accuracy: 0.8824\n",
      "Epoch [3941/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3942/10000], Training Loss: 0.67326993, Training Accuracy: 0.8782\n",
      "Epoch [3942/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3943/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3943/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3944/10000], Training Loss: 0.66909317, Training Accuracy: 0.8824\n",
      "Epoch [3944/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3945/10000], Training Loss: 0.68169706, Training Accuracy: 0.8697\n",
      "Epoch [3945/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3946/10000], Training Loss: 0.68170812, Training Accuracy: 0.8697\n",
      "Epoch [3946/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3947/10000], Training Loss: 0.67749293, Training Accuracy: 0.8739\n",
      "Epoch [3947/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3948/10000], Training Loss: 0.68999036, Training Accuracy: 0.8613\n",
      "Epoch [3948/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3949/10000], Training Loss: 0.65228524, Training Accuracy: 0.8992\n",
      "Epoch [3949/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3950/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [3950/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3951/10000], Training Loss: 0.68160750, Training Accuracy: 0.8697\n",
      "Epoch [3951/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3952/10000], Training Loss: 0.68589875, Training Accuracy: 0.8655\n",
      "Epoch [3952/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3953/10000], Training Loss: 0.67749585, Training Accuracy: 0.8739\n",
      "Epoch [3953/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3954/10000], Training Loss: 0.69010042, Training Accuracy: 0.8613\n",
      "Epoch [3954/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3955/10000], Training Loss: 0.66909262, Training Accuracy: 0.8824\n",
      "Epoch [3955/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3956/10000], Training Loss: 0.65646910, Training Accuracy: 0.8950\n",
      "Epoch [3956/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3957/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [3957/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3958/10000], Training Loss: 0.68589370, Training Accuracy: 0.8655\n",
      "Epoch [3958/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3959/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [3959/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3960/10000], Training Loss: 0.66114044, Training Accuracy: 0.8908\n",
      "Epoch [3960/10000], Validation Loss: 1.12173510, Validation Accuracy: 0.4265\n",
      "Epoch [3961/10000], Training Loss: 0.67329849, Training Accuracy: 0.8782\n",
      "Epoch [3961/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [3962/10000], Training Loss: 0.67749526, Training Accuracy: 0.8739\n",
      "Epoch [3962/10000], Validation Loss: 1.11199719, Validation Accuracy: 0.4412\n",
      "Epoch [3963/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [3963/10000], Validation Loss: 1.11026901, Validation Accuracy: 0.4412\n",
      "Epoch [3964/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [3964/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3965/10000], Training Loss: 0.68169706, Training Accuracy: 0.8697\n",
      "Epoch [3965/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3966/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [3966/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3967/10000], Training Loss: 0.68171038, Training Accuracy: 0.8697\n",
      "Epoch [3967/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3968/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3968/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3969/10000], Training Loss: 0.67749539, Training Accuracy: 0.8739\n",
      "Epoch [3969/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [3970/10000], Training Loss: 0.67329370, Training Accuracy: 0.8782\n",
      "Epoch [3970/10000], Validation Loss: 1.11026853, Validation Accuracy: 0.4412\n",
      "Epoch [3971/10000], Training Loss: 0.66963794, Training Accuracy: 0.8824\n",
      "Epoch [3971/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3972/10000], Training Loss: 0.67329353, Training Accuracy: 0.8782\n",
      "Epoch [3972/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [3973/10000], Training Loss: 0.65775746, Training Accuracy: 0.8950\n",
      "Epoch [3973/10000], Validation Loss: 1.11023653, Validation Accuracy: 0.4412\n",
      "Epoch [3974/10000], Training Loss: 0.66898269, Training Accuracy: 0.8824\n",
      "Epoch [3974/10000], Validation Loss: 1.08105230, Validation Accuracy: 0.4706\n",
      "Epoch [3975/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [3975/10000], Validation Loss: 1.09446377, Validation Accuracy: 0.4559\n",
      "Epoch [3976/10000], Training Loss: 0.65643987, Training Accuracy: 0.8950\n",
      "Epoch [3976/10000], Validation Loss: 1.09546763, Validation Accuracy: 0.4559\n",
      "Epoch [3977/10000], Training Loss: 0.68584027, Training Accuracy: 0.8655\n",
      "Epoch [3977/10000], Validation Loss: 1.09546554, Validation Accuracy: 0.4559\n",
      "Epoch [3978/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3978/10000], Validation Loss: 1.09546435, Validation Accuracy: 0.4559\n",
      "Epoch [3979/10000], Training Loss: 0.65649022, Training Accuracy: 0.8950\n",
      "Epoch [3979/10000], Validation Loss: 1.09541416, Validation Accuracy: 0.4559\n",
      "Epoch [3980/10000], Training Loss: 0.67731246, Training Accuracy: 0.8739\n",
      "Epoch [3980/10000], Validation Loss: 1.09538388, Validation Accuracy: 0.4559\n",
      "Epoch [3981/10000], Training Loss: 0.65658402, Training Accuracy: 0.8950\n",
      "Epoch [3981/10000], Validation Loss: 1.09555739, Validation Accuracy: 0.4559\n",
      "Epoch [3982/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [3982/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [3983/10000], Training Loss: 0.69850376, Training Accuracy: 0.8529\n",
      "Epoch [3983/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [3984/10000], Training Loss: 0.67009784, Training Accuracy: 0.8824\n",
      "Epoch [3984/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [3985/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [3985/10000], Validation Loss: 1.11026824, Validation Accuracy: 0.4412\n",
      "Epoch [3986/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [3986/10000], Validation Loss: 1.09556246, Validation Accuracy: 0.4559\n",
      "Epoch [3987/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [3987/10000], Validation Loss: 1.08095080, Validation Accuracy: 0.4706\n",
      "Epoch [3988/10000], Training Loss: 0.67740248, Training Accuracy: 0.8739\n",
      "Epoch [3988/10000], Validation Loss: 1.08085674, Validation Accuracy: 0.4706\n",
      "Epoch [3989/10000], Training Loss: 0.66488915, Training Accuracy: 0.8866\n",
      "Epoch [3989/10000], Validation Loss: 1.08085674, Validation Accuracy: 0.4706\n",
      "Epoch [3990/10000], Training Loss: 0.68989907, Training Accuracy: 0.8613\n",
      "Epoch [3990/10000], Validation Loss: 1.08085501, Validation Accuracy: 0.4706\n",
      "Epoch [3991/10000], Training Loss: 0.68191159, Training Accuracy: 0.8697\n",
      "Epoch [3991/10000], Validation Loss: 1.07286945, Validation Accuracy: 0.4706\n",
      "Epoch [3992/10000], Training Loss: 0.66759019, Training Accuracy: 0.8824\n",
      "Epoch [3992/10000], Validation Loss: 1.05144677, Validation Accuracy: 0.5000\n",
      "Epoch [3993/10000], Training Loss: 0.67617889, Training Accuracy: 0.8739\n",
      "Epoch [3993/10000], Validation Loss: 1.06615144, Validation Accuracy: 0.4853\n",
      "Epoch [3994/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [3994/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [3995/10000], Training Loss: 0.67329371, Training Accuracy: 0.8782\n",
      "Epoch [3995/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [3996/10000], Training Loss: 0.69850670, Training Accuracy: 0.8529\n",
      "Epoch [3996/10000], Validation Loss: 1.07509619, Validation Accuracy: 0.4706\n",
      "Epoch [3997/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [3997/10000], Validation Loss: 1.08088523, Validation Accuracy: 0.4706\n",
      "Epoch [3998/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [3998/10000], Validation Loss: 1.10956579, Validation Accuracy: 0.4412\n",
      "Epoch [3999/10000], Training Loss: 0.66069852, Training Accuracy: 0.8908\n",
      "Epoch [3999/10000], Validation Loss: 1.11026824, Validation Accuracy: 0.4412\n",
      "Epoch [4000/10000], Training Loss: 0.67329393, Training Accuracy: 0.8782\n",
      "Epoch [4000/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4001/10000], Training Loss: 0.68589874, Training Accuracy: 0.8655\n",
      "Epoch [4001/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4002/10000], Training Loss: 0.65239636, Training Accuracy: 0.8992\n",
      "Epoch [4002/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4003/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [4003/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4004/10000], Training Loss: 0.66909318, Training Accuracy: 0.8824\n",
      "Epoch [4004/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4005/10000], Training Loss: 0.64808395, Training Accuracy: 0.9034\n",
      "Epoch [4005/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4006/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [4006/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4007/10000], Training Loss: 0.66054292, Training Accuracy: 0.8908\n",
      "Epoch [4007/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4008/10000], Training Loss: 0.63555179, Training Accuracy: 0.9160\n",
      "Epoch [4008/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4009/10000], Training Loss: 0.66909159, Training Accuracy: 0.8824\n",
      "Epoch [4009/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4010/10000], Training Loss: 0.65648036, Training Accuracy: 0.8950\n",
      "Epoch [4010/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4011/10000], Training Loss: 0.66467644, Training Accuracy: 0.8866\n",
      "Epoch [4011/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4012/10000], Training Loss: 0.66909203, Training Accuracy: 0.8824\n",
      "Epoch [4012/10000], Validation Loss: 1.09604877, Validation Accuracy: 0.4559\n",
      "Epoch [4013/10000], Training Loss: 0.64808170, Training Accuracy: 0.9034\n",
      "Epoch [4013/10000], Validation Loss: 1.10987329, Validation Accuracy: 0.4412\n",
      "Epoch [4014/10000], Training Loss: 0.65648699, Training Accuracy: 0.8950\n",
      "Epoch [4014/10000], Validation Loss: 1.09148717, Validation Accuracy: 0.4559\n",
      "Epoch [4015/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4015/10000], Validation Loss: 1.08083981, Validation Accuracy: 0.4706\n",
      "Epoch [4016/10000], Training Loss: 0.67543903, Training Accuracy: 0.8739\n",
      "Epoch [4016/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4017/10000], Training Loss: 0.67648592, Training Accuracy: 0.8739\n",
      "Epoch [4017/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [4018/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4018/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [4019/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4019/10000], Validation Loss: 1.13968217, Validation Accuracy: 0.4118\n",
      "Epoch [4020/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4020/10000], Validation Loss: 1.16909158, Validation Accuracy: 0.3824\n",
      "Epoch [4021/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4021/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [4022/10000], Training Loss: 0.66271131, Training Accuracy: 0.8866\n",
      "Epoch [4022/10000], Validation Loss: 1.13949329, Validation Accuracy: 0.4118\n",
      "Epoch [4023/10000], Training Loss: 0.63917966, Training Accuracy: 0.9118\n",
      "Epoch [4023/10000], Validation Loss: 1.12255722, Validation Accuracy: 0.4265\n",
      "Epoch [4024/10000], Training Loss: 0.64839641, Training Accuracy: 0.9034\n",
      "Epoch [4024/10000], Validation Loss: 1.09608495, Validation Accuracy: 0.4559\n",
      "Epoch [4025/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4025/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4026/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4026/10000], Validation Loss: 1.11024463, Validation Accuracy: 0.4412\n",
      "Epoch [4027/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4027/10000], Validation Loss: 1.08241546, Validation Accuracy: 0.4706\n",
      "Epoch [4028/10000], Training Loss: 0.66909383, Training Accuracy: 0.8824\n",
      "Epoch [4028/10000], Validation Loss: 1.08088762, Validation Accuracy: 0.4706\n",
      "Epoch [4029/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4029/10000], Validation Loss: 1.08086133, Validation Accuracy: 0.4706\n",
      "Epoch [4030/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4030/10000], Validation Loss: 1.08085841, Validation Accuracy: 0.4706\n",
      "Epoch [4031/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4031/10000], Validation Loss: 1.08085734, Validation Accuracy: 0.4706\n",
      "Epoch [4032/10000], Training Loss: 0.66049017, Training Accuracy: 0.8908\n",
      "Epoch [4032/10000], Validation Loss: 1.08088982, Validation Accuracy: 0.4706\n",
      "Epoch [4033/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4033/10000], Validation Loss: 1.08192766, Validation Accuracy: 0.4706\n",
      "Epoch [4034/10000], Training Loss: 0.66068854, Training Accuracy: 0.8908\n",
      "Epoch [4034/10000], Validation Loss: 1.08546120, Validation Accuracy: 0.4706\n",
      "Epoch [4035/10000], Training Loss: 0.64794053, Training Accuracy: 0.9034\n",
      "Epoch [4035/10000], Validation Loss: 1.09457046, Validation Accuracy: 0.4559\n",
      "Epoch [4036/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4036/10000], Validation Loss: 1.09545451, Validation Accuracy: 0.4559\n",
      "Epoch [4037/10000], Training Loss: 0.66068869, Training Accuracy: 0.8908\n",
      "Epoch [4037/10000], Validation Loss: 1.09552628, Validation Accuracy: 0.4559\n",
      "Epoch [4038/10000], Training Loss: 0.65253890, Training Accuracy: 0.8992\n",
      "Epoch [4038/10000], Validation Loss: 1.09540218, Validation Accuracy: 0.4559\n",
      "Epoch [4039/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4039/10000], Validation Loss: 1.09468138, Validation Accuracy: 0.4559\n",
      "Epoch [4040/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4040/10000], Validation Loss: 1.09366769, Validation Accuracy: 0.4559\n",
      "Epoch [4041/10000], Training Loss: 0.64388459, Training Accuracy: 0.9076\n",
      "Epoch [4041/10000], Validation Loss: 1.09292001, Validation Accuracy: 0.4559\n",
      "Epoch [4042/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4042/10000], Validation Loss: 1.09260947, Validation Accuracy: 0.4559\n",
      "Epoch [4043/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [4043/10000], Validation Loss: 1.09244889, Validation Accuracy: 0.4559\n",
      "Epoch [4044/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4044/10000], Validation Loss: 1.09236938, Validation Accuracy: 0.4559\n",
      "Epoch [4045/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4045/10000], Validation Loss: 1.09233069, Validation Accuracy: 0.4559\n",
      "Epoch [4046/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4046/10000], Validation Loss: 1.09231180, Validation Accuracy: 0.4559\n",
      "Epoch [4047/10000], Training Loss: 0.66070576, Training Accuracy: 0.8908\n",
      "Epoch [4047/10000], Validation Loss: 1.09250706, Validation Accuracy: 0.4559\n",
      "Epoch [4048/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4048/10000], Validation Loss: 1.09277278, Validation Accuracy: 0.4559\n",
      "Epoch [4049/10000], Training Loss: 0.69010040, Training Accuracy: 0.8613\n",
      "Epoch [4049/10000], Validation Loss: 1.09289378, Validation Accuracy: 0.4559\n",
      "Epoch [4050/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4050/10000], Validation Loss: 1.09295100, Validation Accuracy: 0.4559\n",
      "Epoch [4051/10000], Training Loss: 0.63529664, Training Accuracy: 0.9160\n",
      "Epoch [4051/10000], Validation Loss: 1.08826149, Validation Accuracy: 0.4559\n",
      "Epoch [4052/10000], Training Loss: 0.65503235, Training Accuracy: 0.8950\n",
      "Epoch [4052/10000], Validation Loss: 1.06615227, Validation Accuracy: 0.4853\n",
      "Epoch [4053/10000], Training Loss: 0.65189654, Training Accuracy: 0.8992\n",
      "Epoch [4053/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4054/10000], Training Loss: 0.66489031, Training Accuracy: 0.8866\n",
      "Epoch [4054/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4055/10000], Training Loss: 0.65228546, Training Accuracy: 0.8992\n",
      "Epoch [4055/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4056/10000], Training Loss: 0.66053288, Training Accuracy: 0.8908\n",
      "Epoch [4056/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4057/10000], Training Loss: 0.66496508, Training Accuracy: 0.8866\n",
      "Epoch [4057/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4058/10000], Training Loss: 0.65648704, Training Accuracy: 0.8950\n",
      "Epoch [4058/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4059/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4059/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4060/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4060/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4061/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4061/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4062/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4062/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4063/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [4063/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4064/10000], Training Loss: 0.67668150, Training Accuracy: 0.8739\n",
      "Epoch [4064/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4065/10000], Training Loss: 0.64769121, Training Accuracy: 0.9034\n",
      "Epoch [4065/10000], Validation Loss: 1.07906824, Validation Accuracy: 0.4706\n",
      "Epoch [4066/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4066/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4067/10000], Training Loss: 0.64806144, Training Accuracy: 0.9034\n",
      "Epoch [4067/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4068/10000], Training Loss: 0.67309120, Training Accuracy: 0.8782\n",
      "Epoch [4068/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4069/10000], Training Loss: 0.68938004, Training Accuracy: 0.8613\n",
      "Epoch [4069/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4070/10000], Training Loss: 0.66068873, Training Accuracy: 0.8908\n",
      "Epoch [4070/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4071/10000], Training Loss: 0.66068939, Training Accuracy: 0.8908\n",
      "Epoch [4071/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4072/10000], Training Loss: 0.68574664, Training Accuracy: 0.8655\n",
      "Epoch [4072/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4073/10000], Training Loss: 0.69010059, Training Accuracy: 0.8613\n",
      "Epoch [4073/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4074/10000], Training Loss: 0.67291442, Training Accuracy: 0.8782\n",
      "Epoch [4074/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4075/10000], Training Loss: 0.68589866, Training Accuracy: 0.8655\n",
      "Epoch [4075/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4076/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [4076/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4077/10000], Training Loss: 0.67328389, Training Accuracy: 0.8782\n",
      "Epoch [4077/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4078/10000], Training Loss: 0.66488958, Training Accuracy: 0.8866\n",
      "Epoch [4078/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4079/10000], Training Loss: 0.65978365, Training Accuracy: 0.8908\n",
      "Epoch [4079/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4080/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4080/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4081/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4081/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4082/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4082/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4083/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [4083/10000], Validation Loss: 1.09556729, Validation Accuracy: 0.4559\n",
      "Epoch [4084/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4084/10000], Validation Loss: 1.09588963, Validation Accuracy: 0.4559\n",
      "Epoch [4085/10000], Training Loss: 0.67290718, Training Accuracy: 0.8782\n",
      "Epoch [4085/10000], Validation Loss: 1.11024153, Validation Accuracy: 0.4412\n",
      "Epoch [4086/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4086/10000], Validation Loss: 1.09748882, Validation Accuracy: 0.4559\n",
      "Epoch [4087/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [4087/10000], Validation Loss: 1.09556401, Validation Accuracy: 0.4559\n",
      "Epoch [4088/10000], Training Loss: 0.65208243, Training Accuracy: 0.8992\n",
      "Epoch [4088/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4089/10000], Training Loss: 0.65908582, Training Accuracy: 0.8908\n",
      "Epoch [4089/10000], Validation Loss: 1.11026829, Validation Accuracy: 0.4412\n",
      "Epoch [4090/10000], Training Loss: 0.66064962, Training Accuracy: 0.8908\n",
      "Epoch [4090/10000], Validation Loss: 1.09555626, Validation Accuracy: 0.4559\n",
      "Epoch [4091/10000], Training Loss: 0.65915342, Training Accuracy: 0.8908\n",
      "Epoch [4091/10000], Validation Loss: 1.09111875, Validation Accuracy: 0.4559\n",
      "Epoch [4092/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4092/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4093/10000], Training Loss: 0.64808387, Training Accuracy: 0.9034\n",
      "Epoch [4093/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4094/10000], Training Loss: 0.66032556, Training Accuracy: 0.8908\n",
      "Epoch [4094/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4095/10000], Training Loss: 0.67720957, Training Accuracy: 0.8739\n",
      "Epoch [4095/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4096/10000], Training Loss: 0.65215902, Training Accuracy: 0.8992\n",
      "Epoch [4096/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4097/10000], Training Loss: 0.67329087, Training Accuracy: 0.8782\n",
      "Epoch [4097/10000], Validation Loss: 1.03634760, Validation Accuracy: 0.5147\n",
      "Epoch [4098/10000], Training Loss: 0.65648746, Training Accuracy: 0.8950\n",
      "Epoch [4098/10000], Validation Loss: 1.00802985, Validation Accuracy: 0.5441\n",
      "Epoch [4099/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [4099/10000], Validation Loss: 1.00732896, Validation Accuracy: 0.5441\n",
      "Epoch [4100/10000], Training Loss: 0.68912149, Training Accuracy: 0.8613\n",
      "Epoch [4100/10000], Validation Loss: 1.02325848, Validation Accuracy: 0.5294\n",
      "Epoch [4101/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4101/10000], Validation Loss: 1.03673699, Validation Accuracy: 0.5147\n",
      "Epoch [4102/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [4102/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4103/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4103/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4104/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [4104/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4105/10000], Training Loss: 0.64388191, Training Accuracy: 0.9076\n",
      "Epoch [4105/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4106/10000], Training Loss: 0.65648586, Training Accuracy: 0.8950\n",
      "Epoch [4106/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4107/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4107/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4108/10000], Training Loss: 0.66686325, Training Accuracy: 0.8824\n",
      "Epoch [4108/10000], Validation Loss: 1.02204028, Validation Accuracy: 0.5294\n",
      "Epoch [4109/10000], Training Loss: 0.66469999, Training Accuracy: 0.8866\n",
      "Epoch [4109/10000], Validation Loss: 1.02203354, Validation Accuracy: 0.5294\n",
      "Epoch [4110/10000], Training Loss: 0.66682862, Training Accuracy: 0.8824\n",
      "Epoch [4110/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4111/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4111/10000], Validation Loss: 1.03673959, Validation Accuracy: 0.5147\n",
      "Epoch [4112/10000], Training Loss: 0.65228526, Training Accuracy: 0.8992\n",
      "Epoch [4112/10000], Validation Loss: 1.03673926, Validation Accuracy: 0.5147\n",
      "Epoch [4113/10000], Training Loss: 0.65228478, Training Accuracy: 0.8992\n",
      "Epoch [4113/10000], Validation Loss: 1.05144170, Validation Accuracy: 0.5000\n",
      "Epoch [4114/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4114/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4115/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [4115/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4116/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4116/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4117/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [4117/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4118/10000], Training Loss: 0.65648584, Training Accuracy: 0.8950\n",
      "Epoch [4118/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4119/10000], Training Loss: 0.67329370, Training Accuracy: 0.8782\n",
      "Epoch [4119/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4120/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [4120/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4121/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4121/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4122/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [4122/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4123/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [4123/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4124/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4124/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4125/10000], Training Loss: 0.66067553, Training Accuracy: 0.8908\n",
      "Epoch [4125/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4126/10000], Training Loss: 0.67296949, Training Accuracy: 0.8782\n",
      "Epoch [4126/10000], Validation Loss: 1.06613624, Validation Accuracy: 0.4853\n",
      "Epoch [4127/10000], Training Loss: 0.66068864, Training Accuracy: 0.8908\n",
      "Epoch [4127/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4128/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4128/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4129/10000], Training Loss: 0.63967532, Training Accuracy: 0.9118\n",
      "Epoch [4129/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4130/10000], Training Loss: 0.64388368, Training Accuracy: 0.9076\n",
      "Epoch [4130/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4131/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4131/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4132/10000], Training Loss: 0.65650698, Training Accuracy: 0.8950\n",
      "Epoch [4132/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4133/10000], Training Loss: 0.66068856, Training Accuracy: 0.8908\n",
      "Epoch [4133/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4134/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4134/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4135/10000], Training Loss: 0.64388201, Training Accuracy: 0.9076\n",
      "Epoch [4135/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4136/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4136/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4137/10000], Training Loss: 0.64202976, Training Accuracy: 0.9076\n",
      "Epoch [4137/10000], Validation Loss: 1.05143878, Validation Accuracy: 0.5000\n",
      "Epoch [4138/10000], Training Loss: 0.67329370, Training Accuracy: 0.8782\n",
      "Epoch [4138/10000], Validation Loss: 1.02875626, Validation Accuracy: 0.5147\n",
      "Epoch [4139/10000], Training Loss: 0.65664634, Training Accuracy: 0.8950\n",
      "Epoch [4139/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4140/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4140/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4141/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [4141/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4142/10000], Training Loss: 0.65715375, Training Accuracy: 0.8950\n",
      "Epoch [4142/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4143/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [4143/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4144/10000], Training Loss: 0.64385893, Training Accuracy: 0.9076\n",
      "Epoch [4144/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4145/10000], Training Loss: 0.67323755, Training Accuracy: 0.8782\n",
      "Epoch [4145/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4146/10000], Training Loss: 0.69007112, Training Accuracy: 0.8613\n",
      "Epoch [4146/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4147/10000], Training Loss: 0.66484745, Training Accuracy: 0.8866\n",
      "Epoch [4147/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4148/10000], Training Loss: 0.67329431, Training Accuracy: 0.8782\n",
      "Epoch [4148/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4149/10000], Training Loss: 0.67726657, Training Accuracy: 0.8739\n",
      "Epoch [4149/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4150/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4150/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4151/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [4151/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4152/10000], Training Loss: 0.65647703, Training Accuracy: 0.8950\n",
      "Epoch [4152/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4153/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [4153/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4154/10000], Training Loss: 0.67749144, Training Accuracy: 0.8739\n",
      "Epoch [4154/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4155/10000], Training Loss: 0.66068803, Training Accuracy: 0.8908\n",
      "Epoch [4155/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4156/10000], Training Loss: 0.67749560, Training Accuracy: 0.8739\n",
      "Epoch [4156/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4157/10000], Training Loss: 0.63968011, Training Accuracy: 0.9118\n",
      "Epoch [4157/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4158/10000], Training Loss: 0.66909188, Training Accuracy: 0.8824\n",
      "Epoch [4158/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4159/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4159/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4160/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4160/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4161/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4161/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4162/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4162/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4163/10000], Training Loss: 0.64449504, Training Accuracy: 0.9076\n",
      "Epoch [4163/10000], Validation Loss: 1.05144453, Validation Accuracy: 0.5000\n",
      "Epoch [4164/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [4164/10000], Validation Loss: 1.06562549, Validation Accuracy: 0.4853\n",
      "Epoch [4165/10000], Training Loss: 0.66970912, Training Accuracy: 0.8824\n",
      "Epoch [4165/10000], Validation Loss: 1.06602877, Validation Accuracy: 0.4853\n",
      "Epoch [4166/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4166/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4167/10000], Training Loss: 0.66062892, Training Accuracy: 0.8908\n",
      "Epoch [4167/10000], Validation Loss: 1.03646156, Validation Accuracy: 0.5147\n",
      "Epoch [4168/10000], Training Loss: 0.64388425, Training Accuracy: 0.9076\n",
      "Epoch [4168/10000], Validation Loss: 1.02203348, Validation Accuracy: 0.5294\n",
      "Epoch [4169/10000], Training Loss: 0.66029747, Training Accuracy: 0.8908\n",
      "Epoch [4169/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [4170/10000], Training Loss: 0.64756279, Training Accuracy: 0.9034\n",
      "Epoch [4170/10000], Validation Loss: 1.03673822, Validation Accuracy: 0.5147\n",
      "Epoch [4171/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [4171/10000], Validation Loss: 1.13968426, Validation Accuracy: 0.4118\n",
      "Epoch [4172/10000], Training Loss: 0.66488984, Training Accuracy: 0.8866\n",
      "Epoch [4172/10000], Validation Loss: 1.15850675, Validation Accuracy: 0.3971\n",
      "Epoch [4173/10000], Training Loss: 0.65648740, Training Accuracy: 0.8950\n",
      "Epoch [4173/10000], Validation Loss: 1.16802973, Validation Accuracy: 0.3824\n",
      "Epoch [4174/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [4174/10000], Validation Loss: 1.16887134, Validation Accuracy: 0.3824\n",
      "Epoch [4175/10000], Training Loss: 0.68589874, Training Accuracy: 0.8655\n",
      "Epoch [4175/10000], Validation Loss: 1.15428460, Validation Accuracy: 0.3971\n",
      "Epoch [4176/10000], Training Loss: 0.66489037, Training Accuracy: 0.8866\n",
      "Epoch [4176/10000], Validation Loss: 1.15431637, Validation Accuracy: 0.3971\n",
      "Epoch [4177/10000], Training Loss: 0.64473158, Training Accuracy: 0.9076\n",
      "Epoch [4177/10000], Validation Loss: 1.15965474, Validation Accuracy: 0.3971\n",
      "Epoch [4178/10000], Training Loss: 0.67329372, Training Accuracy: 0.8782\n",
      "Epoch [4178/10000], Validation Loss: 1.13976479, Validation Accuracy: 0.4118\n",
      "Epoch [4179/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4179/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4180/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4180/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4181/10000], Training Loss: 0.66488850, Training Accuracy: 0.8866\n",
      "Epoch [4181/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4182/10000], Training Loss: 0.65647936, Training Accuracy: 0.8950\n",
      "Epoch [4182/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4183/10000], Training Loss: 0.65337078, Training Accuracy: 0.8992\n",
      "Epoch [4183/10000], Validation Loss: 1.11016619, Validation Accuracy: 0.4412\n",
      "Epoch [4184/10000], Training Loss: 0.67911904, Training Accuracy: 0.8739\n",
      "Epoch [4184/10000], Validation Loss: 1.06616849, Validation Accuracy: 0.4853\n",
      "Epoch [4185/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4185/10000], Validation Loss: 1.05126697, Validation Accuracy: 0.5000\n",
      "Epoch [4186/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4186/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4187/10000], Training Loss: 0.66491804, Training Accuracy: 0.8866\n",
      "Epoch [4187/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4188/10000], Training Loss: 0.66068824, Training Accuracy: 0.8908\n",
      "Epoch [4188/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4189/10000], Training Loss: 0.67743767, Training Accuracy: 0.8739\n",
      "Epoch [4189/10000], Validation Loss: 1.06615055, Validation Accuracy: 0.4853\n",
      "Epoch [4190/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4190/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4191/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4191/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4192/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4192/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4193/10000], Training Loss: 0.65648614, Training Accuracy: 0.8950\n",
      "Epoch [4193/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4194/10000], Training Loss: 0.67321345, Training Accuracy: 0.8782\n",
      "Epoch [4194/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4195/10000], Training Loss: 0.64845823, Training Accuracy: 0.9034\n",
      "Epoch [4195/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4196/10000], Training Loss: 0.65648729, Training Accuracy: 0.8950\n",
      "Epoch [4196/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4197/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4197/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4198/10000], Training Loss: 0.69455270, Training Accuracy: 0.8571\n",
      "Epoch [4198/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4199/10000], Training Loss: 0.67749567, Training Accuracy: 0.8739\n",
      "Epoch [4199/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4200/10000], Training Loss: 0.67749535, Training Accuracy: 0.8739\n",
      "Epoch [4200/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4201/10000], Training Loss: 0.66488846, Training Accuracy: 0.8866\n",
      "Epoch [4201/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4202/10000], Training Loss: 0.65918954, Training Accuracy: 0.8908\n",
      "Epoch [4202/10000], Validation Loss: 1.07991350, Validation Accuracy: 0.4706\n",
      "Epoch [4203/10000], Training Loss: 0.65272778, Training Accuracy: 0.8992\n",
      "Epoch [4203/10000], Validation Loss: 1.03645220, Validation Accuracy: 0.5147\n",
      "Epoch [4204/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [4204/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [4205/10000], Training Loss: 0.67047502, Training Accuracy: 0.8824\n",
      "Epoch [4205/10000], Validation Loss: 1.00748363, Validation Accuracy: 0.5441\n",
      "Epoch [4206/10000], Training Loss: 0.67288679, Training Accuracy: 0.8782\n",
      "Epoch [4206/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [4207/10000], Training Loss: 0.67329365, Training Accuracy: 0.8782\n",
      "Epoch [4207/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [4208/10000], Training Loss: 0.65704185, Training Accuracy: 0.8950\n",
      "Epoch [4208/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4209/10000], Training Loss: 0.66039465, Training Accuracy: 0.8908\n",
      "Epoch [4209/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [4210/10000], Training Loss: 0.64388232, Training Accuracy: 0.9076\n",
      "Epoch [4210/10000], Validation Loss: 1.03651401, Validation Accuracy: 0.5147\n",
      "Epoch [4211/10000], Training Loss: 0.65639351, Training Accuracy: 0.8950\n",
      "Epoch [4211/10000], Validation Loss: 1.02203426, Validation Accuracy: 0.5294\n",
      "Epoch [4212/10000], Training Loss: 0.64041415, Training Accuracy: 0.9118\n",
      "Epoch [4212/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [4213/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4213/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [4214/10000], Training Loss: 0.67749539, Training Accuracy: 0.8739\n",
      "Epoch [4214/10000], Validation Loss: 0.99267676, Validation Accuracy: 0.5588\n",
      "Epoch [4215/10000], Training Loss: 0.66870802, Training Accuracy: 0.8824\n",
      "Epoch [4215/10000], Validation Loss: 0.99876359, Validation Accuracy: 0.5441\n",
      "Epoch [4216/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4216/10000], Validation Loss: 1.00340176, Validation Accuracy: 0.5441\n",
      "Epoch [4217/10000], Training Loss: 0.67329367, Training Accuracy: 0.8782\n",
      "Epoch [4217/10000], Validation Loss: 1.00498354, Validation Accuracy: 0.5441\n",
      "Epoch [4218/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4218/10000], Validation Loss: 1.00600165, Validation Accuracy: 0.5441\n",
      "Epoch [4219/10000], Training Loss: 0.65228526, Training Accuracy: 0.8992\n",
      "Epoch [4219/10000], Validation Loss: 1.00715280, Validation Accuracy: 0.5441\n",
      "Epoch [4220/10000], Training Loss: 0.65172610, Training Accuracy: 0.8992\n",
      "Epoch [4220/10000], Validation Loss: 1.00880611, Validation Accuracy: 0.5441\n",
      "Epoch [4221/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4221/10000], Validation Loss: 1.01030481, Validation Accuracy: 0.5441\n",
      "Epoch [4222/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [4222/10000], Validation Loss: 1.02575395, Validation Accuracy: 0.5294\n",
      "Epoch [4223/10000], Training Loss: 0.66489077, Training Accuracy: 0.8866\n",
      "Epoch [4223/10000], Validation Loss: 1.02630472, Validation Accuracy: 0.5294\n",
      "Epoch [4224/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4224/10000], Validation Loss: 1.02692112, Validation Accuracy: 0.5294\n",
      "Epoch [4225/10000], Training Loss: 0.64394842, Training Accuracy: 0.9076\n",
      "Epoch [4225/10000], Validation Loss: 1.02213758, Validation Accuracy: 0.5294\n",
      "Epoch [4226/10000], Training Loss: 0.66909196, Training Accuracy: 0.8824\n",
      "Epoch [4226/10000], Validation Loss: 1.02203381, Validation Accuracy: 0.5294\n",
      "Epoch [4227/10000], Training Loss: 0.64524506, Training Accuracy: 0.9076\n",
      "Epoch [4227/10000], Validation Loss: 1.02203238, Validation Accuracy: 0.5294\n",
      "Epoch [4228/10000], Training Loss: 0.64416700, Training Accuracy: 0.9076\n",
      "Epoch [4228/10000], Validation Loss: 1.03672612, Validation Accuracy: 0.5147\n",
      "Epoch [4229/10000], Training Loss: 0.63968027, Training Accuracy: 0.9118\n",
      "Epoch [4229/10000], Validation Loss: 1.03325367, Validation Accuracy: 0.5147\n",
      "Epoch [4230/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4230/10000], Validation Loss: 1.02626979, Validation Accuracy: 0.5294\n",
      "Epoch [4231/10000], Training Loss: 0.65228297, Training Accuracy: 0.8992\n",
      "Epoch [4231/10000], Validation Loss: 1.02729708, Validation Accuracy: 0.5294\n",
      "Epoch [4232/10000], Training Loss: 0.65192458, Training Accuracy: 0.8992\n",
      "Epoch [4232/10000], Validation Loss: 1.03219581, Validation Accuracy: 0.5147\n",
      "Epoch [4233/10000], Training Loss: 0.64808307, Training Accuracy: 0.9034\n",
      "Epoch [4233/10000], Validation Loss: 1.06132361, Validation Accuracy: 0.4853\n",
      "Epoch [4234/10000], Training Loss: 0.66489044, Training Accuracy: 0.8866\n",
      "Epoch [4234/10000], Validation Loss: 1.06141445, Validation Accuracy: 0.4853\n",
      "Epoch [4235/10000], Training Loss: 0.67749520, Training Accuracy: 0.8739\n",
      "Epoch [4235/10000], Validation Loss: 1.06147650, Validation Accuracy: 0.4853\n",
      "Epoch [4236/10000], Training Loss: 0.66909199, Training Accuracy: 0.8824\n",
      "Epoch [4236/10000], Validation Loss: 1.04686835, Validation Accuracy: 0.5000\n",
      "Epoch [4237/10000], Training Loss: 0.67328273, Training Accuracy: 0.8782\n",
      "Epoch [4237/10000], Validation Loss: 1.04686883, Validation Accuracy: 0.5000\n",
      "Epoch [4238/10000], Training Loss: 0.66490462, Training Accuracy: 0.8866\n",
      "Epoch [4238/10000], Validation Loss: 1.04986003, Validation Accuracy: 0.5000\n",
      "Epoch [4239/10000], Training Loss: 0.66068923, Training Accuracy: 0.8908\n",
      "Epoch [4239/10000], Validation Loss: 1.05056283, Validation Accuracy: 0.5000\n",
      "Epoch [4240/10000], Training Loss: 0.67329368, Training Accuracy: 0.8782\n",
      "Epoch [4240/10000], Validation Loss: 1.05078492, Validation Accuracy: 0.5000\n",
      "Epoch [4241/10000], Training Loss: 0.67749538, Training Accuracy: 0.8739\n",
      "Epoch [4241/10000], Validation Loss: 1.05087158, Validation Accuracy: 0.5000\n",
      "Epoch [4242/10000], Training Loss: 0.69430209, Training Accuracy: 0.8571\n",
      "Epoch [4242/10000], Validation Loss: 1.05090907, Validation Accuracy: 0.5000\n",
      "Epoch [4243/10000], Training Loss: 0.67749537, Training Accuracy: 0.8739\n",
      "Epoch [4243/10000], Validation Loss: 1.05092695, Validation Accuracy: 0.5000\n",
      "Epoch [4244/10000], Training Loss: 0.68169974, Training Accuracy: 0.8697\n",
      "Epoch [4244/10000], Validation Loss: 1.05092308, Validation Accuracy: 0.5000\n",
      "Epoch [4245/10000], Training Loss: 0.67793621, Training Accuracy: 0.8739\n",
      "Epoch [4245/10000], Validation Loss: 1.05115488, Validation Accuracy: 0.5000\n",
      "Epoch [4246/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4246/10000], Validation Loss: 1.05048689, Validation Accuracy: 0.5000\n",
      "Epoch [4247/10000], Training Loss: 0.66489104, Training Accuracy: 0.8866\n",
      "Epoch [4247/10000], Validation Loss: 1.05144057, Validation Accuracy: 0.5000\n",
      "Epoch [4248/10000], Training Loss: 0.66217683, Training Accuracy: 0.8908\n",
      "Epoch [4248/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4249/10000], Training Loss: 0.65633069, Training Accuracy: 0.8950\n",
      "Epoch [4249/10000], Validation Loss: 1.07949638, Validation Accuracy: 0.4706\n",
      "Epoch [4250/10000], Training Loss: 0.66848396, Training Accuracy: 0.8824\n",
      "Epoch [4250/10000], Validation Loss: 1.10986161, Validation Accuracy: 0.4412\n",
      "Epoch [4251/10000], Training Loss: 0.68885715, Training Accuracy: 0.8613\n",
      "Epoch [4251/10000], Validation Loss: 1.09617585, Validation Accuracy: 0.4559\n",
      "Epoch [4252/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4252/10000], Validation Loss: 1.12625599, Validation Accuracy: 0.4265\n",
      "Epoch [4253/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4253/10000], Validation Loss: 1.12497437, Validation Accuracy: 0.4265\n",
      "Epoch [4254/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4254/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4255/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4255/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4256/10000], Training Loss: 0.68583196, Training Accuracy: 0.8655\n",
      "Epoch [4256/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4257/10000], Training Loss: 0.65228523, Training Accuracy: 0.8992\n",
      "Epoch [4257/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4258/10000], Training Loss: 0.67754721, Training Accuracy: 0.8739\n",
      "Epoch [4258/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4259/10000], Training Loss: 0.65647835, Training Accuracy: 0.8950\n",
      "Epoch [4259/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4260/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4260/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4261/10000], Training Loss: 0.65228536, Training Accuracy: 0.8992\n",
      "Epoch [4261/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4262/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4262/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4263/10000], Training Loss: 0.66178123, Training Accuracy: 0.8908\n",
      "Epoch [4263/10000], Validation Loss: 1.13967985, Validation Accuracy: 0.4118\n",
      "Epoch [4264/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4264/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4265/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [4265/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4266/10000], Training Loss: 0.65354934, Training Accuracy: 0.8992\n",
      "Epoch [4266/10000], Validation Loss: 1.09529597, Validation Accuracy: 0.4559\n",
      "Epoch [4267/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4267/10000], Validation Loss: 1.08085644, Validation Accuracy: 0.4706\n",
      "Epoch [4268/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [4268/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4269/10000], Training Loss: 0.66488326, Training Accuracy: 0.8866\n",
      "Epoch [4269/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4270/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4270/10000], Validation Loss: 1.04113811, Validation Accuracy: 0.5147\n",
      "Epoch [4271/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4271/10000], Validation Loss: 1.03673911, Validation Accuracy: 0.5147\n",
      "Epoch [4272/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4272/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4273/10000], Training Loss: 0.67329375, Training Accuracy: 0.8782\n",
      "Epoch [4273/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4274/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4274/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4275/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4275/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4276/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4276/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4277/10000], Training Loss: 0.64388195, Training Accuracy: 0.9076\n",
      "Epoch [4277/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4278/10000], Training Loss: 0.65229001, Training Accuracy: 0.8992\n",
      "Epoch [4278/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4279/10000], Training Loss: 0.64548954, Training Accuracy: 0.9076\n",
      "Epoch [4279/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4280/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4280/10000], Validation Loss: 1.05145389, Validation Accuracy: 0.5000\n",
      "Epoch [4281/10000], Training Loss: 0.65228500, Training Accuracy: 0.8992\n",
      "Epoch [4281/10000], Validation Loss: 1.06626022, Validation Accuracy: 0.4853\n",
      "Epoch [4282/10000], Training Loss: 0.67329258, Training Accuracy: 0.8782\n",
      "Epoch [4282/10000], Validation Loss: 1.06651384, Validation Accuracy: 0.4853\n",
      "Epoch [4283/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4283/10000], Validation Loss: 1.06678677, Validation Accuracy: 0.4853\n",
      "Epoch [4284/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4284/10000], Validation Loss: 1.06697989, Validation Accuracy: 0.4853\n",
      "Epoch [4285/10000], Training Loss: 0.67344637, Training Accuracy: 0.8782\n",
      "Epoch [4285/10000], Validation Loss: 1.06615096, Validation Accuracy: 0.4853\n",
      "Epoch [4286/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4286/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4287/10000], Training Loss: 0.66068760, Training Accuracy: 0.8908\n",
      "Epoch [4287/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4288/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4288/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4289/10000], Training Loss: 0.67329370, Training Accuracy: 0.8782\n",
      "Epoch [4289/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4290/10000], Training Loss: 0.65645663, Training Accuracy: 0.8950\n",
      "Epoch [4290/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4291/10000], Training Loss: 0.66069069, Training Accuracy: 0.8908\n",
      "Epoch [4291/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4292/10000], Training Loss: 0.68169705, Training Accuracy: 0.8697\n",
      "Epoch [4292/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4293/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4293/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4294/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4294/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4295/10000], Training Loss: 0.64138047, Training Accuracy: 0.9118\n",
      "Epoch [4295/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4296/10000], Training Loss: 0.69430198, Training Accuracy: 0.8571\n",
      "Epoch [4296/10000], Validation Loss: 1.11026776, Validation Accuracy: 0.4412\n",
      "Epoch [4297/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4297/10000], Validation Loss: 1.09594512, Validation Accuracy: 0.4559\n",
      "Epoch [4298/10000], Training Loss: 0.64760539, Training Accuracy: 0.9034\n",
      "Epoch [4298/10000], Validation Loss: 1.09557766, Validation Accuracy: 0.4559\n",
      "Epoch [4299/10000], Training Loss: 0.65228544, Training Accuracy: 0.8992\n",
      "Epoch [4299/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4300/10000], Training Loss: 0.69850376, Training Accuracy: 0.8529\n",
      "Epoch [4300/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4301/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4301/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4302/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4302/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4303/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4303/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4304/10000], Training Loss: 0.67195397, Training Accuracy: 0.8782\n",
      "Epoch [4304/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4305/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4305/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4306/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [4306/10000], Validation Loss: 1.08080751, Validation Accuracy: 0.4706\n",
      "Epoch [4307/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4307/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4308/10000], Training Loss: 0.65648303, Training Accuracy: 0.8950\n",
      "Epoch [4308/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4309/10000], Training Loss: 0.64808519, Training Accuracy: 0.9034\n",
      "Epoch [4309/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4310/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4310/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4311/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4311/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4312/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4312/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4313/10000], Training Loss: 0.64808368, Training Accuracy: 0.9034\n",
      "Epoch [4313/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4314/10000], Training Loss: 0.64580156, Training Accuracy: 0.9034\n",
      "Epoch [4314/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4315/10000], Training Loss: 0.66489037, Training Accuracy: 0.8866\n",
      "Epoch [4315/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4316/10000], Training Loss: 0.65225512, Training Accuracy: 0.8992\n",
      "Epoch [4316/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4317/10000], Training Loss: 0.67749537, Training Accuracy: 0.8739\n",
      "Epoch [4317/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4318/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4318/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4319/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4319/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4320/10000], Training Loss: 0.64882353, Training Accuracy: 0.9034\n",
      "Epoch [4320/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4321/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4321/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4322/10000], Training Loss: 0.64037240, Training Accuracy: 0.9118\n",
      "Epoch [4322/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4323/10000], Training Loss: 0.65229189, Training Accuracy: 0.8992\n",
      "Epoch [4323/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4324/10000], Training Loss: 0.63967608, Training Accuracy: 0.9118\n",
      "Epoch [4324/10000], Validation Loss: 1.09556001, Validation Accuracy: 0.4559\n",
      "Epoch [4325/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [4325/10000], Validation Loss: 1.06615061, Validation Accuracy: 0.4853\n",
      "Epoch [4326/10000], Training Loss: 0.64710248, Training Accuracy: 0.9034\n",
      "Epoch [4326/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [4327/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4327/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4328/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [4328/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4329/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4329/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4330/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [4330/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4331/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4331/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4332/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [4332/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4333/10000], Training Loss: 0.66162113, Training Accuracy: 0.8908\n",
      "Epoch [4333/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4334/10000], Training Loss: 0.66068786, Training Accuracy: 0.8908\n",
      "Epoch [4334/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [4335/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4335/10000], Validation Loss: 1.06600764, Validation Accuracy: 0.4853\n",
      "Epoch [4336/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4336/10000], Validation Loss: 1.05310807, Validation Accuracy: 0.5000\n",
      "Epoch [4337/10000], Training Loss: 0.65100699, Training Accuracy: 0.8992\n",
      "Epoch [4337/10000], Validation Loss: 1.05144498, Validation Accuracy: 0.5000\n",
      "Epoch [4338/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4338/10000], Validation Loss: 1.06520304, Validation Accuracy: 0.4853\n",
      "Epoch [4339/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4339/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [4340/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4340/10000], Validation Loss: 1.05144218, Validation Accuracy: 0.5000\n",
      "Epoch [4341/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4341/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [4342/10000], Training Loss: 0.65222221, Training Accuracy: 0.8992\n",
      "Epoch [4342/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [4343/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [4343/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [4344/10000], Training Loss: 0.65228564, Training Accuracy: 0.8992\n",
      "Epoch [4344/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [4345/10000], Training Loss: 0.66040541, Training Accuracy: 0.8908\n",
      "Epoch [4345/10000], Validation Loss: 1.02202290, Validation Accuracy: 0.5294\n",
      "Epoch [4346/10000], Training Loss: 0.64841739, Training Accuracy: 0.9034\n",
      "Epoch [4346/10000], Validation Loss: 1.03671494, Validation Accuracy: 0.5147\n",
      "Epoch [4347/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4347/10000], Validation Loss: 1.03673992, Validation Accuracy: 0.5147\n",
      "Epoch [4348/10000], Training Loss: 0.66489110, Training Accuracy: 0.8866\n",
      "Epoch [4348/10000], Validation Loss: 1.03721783, Validation Accuracy: 0.5147\n",
      "Epoch [4349/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4349/10000], Validation Loss: 1.04226184, Validation Accuracy: 0.5147\n",
      "Epoch [4350/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4350/10000], Validation Loss: 1.04718393, Validation Accuracy: 0.5000\n",
      "Epoch [4351/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4351/10000], Validation Loss: 1.04890776, Validation Accuracy: 0.5000\n",
      "Epoch [4352/10000], Training Loss: 0.64771090, Training Accuracy: 0.9034\n",
      "Epoch [4352/10000], Validation Loss: 1.05125010, Validation Accuracy: 0.5000\n",
      "Epoch [4353/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [4353/10000], Validation Loss: 1.05143833, Validation Accuracy: 0.5000\n",
      "Epoch [4354/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4354/10000], Validation Loss: 1.03673828, Validation Accuracy: 0.5147\n",
      "Epoch [4355/10000], Training Loss: 0.67749535, Training Accuracy: 0.8739\n",
      "Epoch [4355/10000], Validation Loss: 1.03673679, Validation Accuracy: 0.5147\n",
      "Epoch [4356/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [4356/10000], Validation Loss: 1.03673267, Validation Accuracy: 0.5147\n",
      "Epoch [4357/10000], Training Loss: 0.66068871, Training Accuracy: 0.8908\n",
      "Epoch [4357/10000], Validation Loss: 1.03672791, Validation Accuracy: 0.5147\n",
      "Epoch [4358/10000], Training Loss: 0.64808337, Training Accuracy: 0.9034\n",
      "Epoch [4358/10000], Validation Loss: 1.03672421, Validation Accuracy: 0.5147\n",
      "Epoch [4359/10000], Training Loss: 0.68589872, Training Accuracy: 0.8655\n",
      "Epoch [4359/10000], Validation Loss: 1.03672189, Validation Accuracy: 0.5147\n",
      "Epoch [4360/10000], Training Loss: 0.66186224, Training Accuracy: 0.8908\n",
      "Epoch [4360/10000], Validation Loss: 1.02249897, Validation Accuracy: 0.5294\n",
      "Epoch [4361/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4361/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4362/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4362/10000], Validation Loss: 1.06594324, Validation Accuracy: 0.4853\n",
      "Epoch [4363/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4363/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4364/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4364/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4365/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4365/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4366/10000], Training Loss: 0.63968003, Training Accuracy: 0.9118\n",
      "Epoch [4366/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4367/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4367/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4368/10000], Training Loss: 0.66068757, Training Accuracy: 0.8908\n",
      "Epoch [4368/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4369/10000], Training Loss: 0.66470117, Training Accuracy: 0.8866\n",
      "Epoch [4369/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4370/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4370/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4371/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [4371/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4372/10000], Training Loss: 0.64345929, Training Accuracy: 0.9076\n",
      "Epoch [4372/10000], Validation Loss: 1.06735849, Validation Accuracy: 0.4853\n",
      "Epoch [4373/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4373/10000], Validation Loss: 1.07163376, Validation Accuracy: 0.4853\n",
      "Epoch [4374/10000], Training Loss: 0.65228598, Training Accuracy: 0.8992\n",
      "Epoch [4374/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4375/10000], Training Loss: 0.65206284, Training Accuracy: 0.8992\n",
      "Epoch [4375/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4376/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4376/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4377/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4377/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4378/10000], Training Loss: 0.63958302, Training Accuracy: 0.9118\n",
      "Epoch [4378/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4379/10000], Training Loss: 0.65228598, Training Accuracy: 0.8992\n",
      "Epoch [4379/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4380/10000], Training Loss: 0.66909208, Training Accuracy: 0.8824\n",
      "Epoch [4380/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4381/10000], Training Loss: 0.65229470, Training Accuracy: 0.8992\n",
      "Epoch [4381/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4382/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4382/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4383/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4383/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4384/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4384/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4385/10000], Training Loss: 0.66784436, Training Accuracy: 0.8824\n",
      "Epoch [4385/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4386/10000], Training Loss: 0.62287279, Training Accuracy: 0.9286\n",
      "Epoch [4386/10000], Validation Loss: 1.06615084, Validation Accuracy: 0.4853\n",
      "Epoch [4387/10000], Training Loss: 0.65648695, Training Accuracy: 0.8950\n",
      "Epoch [4387/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4388/10000], Training Loss: 0.63141749, Training Accuracy: 0.9202\n",
      "Epoch [4388/10000], Validation Loss: 1.06614918, Validation Accuracy: 0.4853\n",
      "Epoch [4389/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4389/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4390/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4390/10000], Validation Loss: 1.06640667, Validation Accuracy: 0.4853\n",
      "Epoch [4391/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4391/10000], Validation Loss: 1.05173182, Validation Accuracy: 0.5000\n",
      "Epoch [4392/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4392/10000], Validation Loss: 1.05174792, Validation Accuracy: 0.5000\n",
      "Epoch [4393/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4393/10000], Validation Loss: 1.05175591, Validation Accuracy: 0.5000\n",
      "Epoch [4394/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4394/10000], Validation Loss: 1.05175984, Validation Accuracy: 0.5000\n",
      "Epoch [4395/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4395/10000], Validation Loss: 1.05176175, Validation Accuracy: 0.5000\n",
      "Epoch [4396/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4396/10000], Validation Loss: 1.05176264, Validation Accuracy: 0.5000\n",
      "Epoch [4397/10000], Training Loss: 0.62286819, Training Accuracy: 0.9286\n",
      "Epoch [4397/10000], Validation Loss: 1.05174577, Validation Accuracy: 0.5000\n",
      "Epoch [4398/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4398/10000], Validation Loss: 1.05172932, Validation Accuracy: 0.5000\n",
      "Epoch [4399/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4399/10000], Validation Loss: 1.05172229, Validation Accuracy: 0.5000\n",
      "Epoch [4400/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4400/10000], Validation Loss: 1.05171883, Validation Accuracy: 0.5000\n",
      "Epoch [4401/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4401/10000], Validation Loss: 1.05171722, Validation Accuracy: 0.5000\n",
      "Epoch [4402/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4402/10000], Validation Loss: 1.05171645, Validation Accuracy: 0.5000\n",
      "Epoch [4403/10000], Training Loss: 0.62287210, Training Accuracy: 0.9286\n",
      "Epoch [4403/10000], Validation Loss: 1.05171019, Validation Accuracy: 0.5000\n",
      "Epoch [4404/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4404/10000], Validation Loss: 1.05170572, Validation Accuracy: 0.5000\n",
      "Epoch [4405/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4405/10000], Validation Loss: 1.05170357, Validation Accuracy: 0.5000\n",
      "Epoch [4406/10000], Training Loss: 0.63127685, Training Accuracy: 0.9202\n",
      "Epoch [4406/10000], Validation Loss: 1.05170387, Validation Accuracy: 0.5000\n",
      "Epoch [4407/10000], Training Loss: 0.62708101, Training Accuracy: 0.9244\n",
      "Epoch [4407/10000], Validation Loss: 1.05169863, Validation Accuracy: 0.5000\n",
      "Epoch [4408/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4408/10000], Validation Loss: 1.05169100, Validation Accuracy: 0.5000\n",
      "Epoch [4409/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4409/10000], Validation Loss: 1.05168742, Validation Accuracy: 0.5000\n",
      "Epoch [4410/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4410/10000], Validation Loss: 1.05168569, Validation Accuracy: 0.5000\n",
      "Epoch [4411/10000], Training Loss: 0.61858228, Training Accuracy: 0.9328\n",
      "Epoch [4411/10000], Validation Loss: 1.05228281, Validation Accuracy: 0.5000\n",
      "Epoch [4412/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4412/10000], Validation Loss: 1.06558990, Validation Accuracy: 0.4853\n",
      "Epoch [4413/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4413/10000], Validation Loss: 1.06601578, Validation Accuracy: 0.4853\n",
      "Epoch [4414/10000], Training Loss: 0.64388159, Training Accuracy: 0.9076\n",
      "Epoch [4414/10000], Validation Loss: 1.06406564, Validation Accuracy: 0.4853\n",
      "Epoch [4415/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4415/10000], Validation Loss: 1.05972254, Validation Accuracy: 0.4853\n",
      "Epoch [4416/10000], Training Loss: 0.63547808, Training Accuracy: 0.9160\n",
      "Epoch [4416/10000], Validation Loss: 1.05700499, Validation Accuracy: 0.5000\n",
      "Epoch [4417/10000], Training Loss: 0.63968051, Training Accuracy: 0.9118\n",
      "Epoch [4417/10000], Validation Loss: 1.05589646, Validation Accuracy: 0.5000\n",
      "Epoch [4418/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [4418/10000], Validation Loss: 1.05547601, Validation Accuracy: 0.5000\n",
      "Epoch [4419/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4419/10000], Validation Loss: 1.05528408, Validation Accuracy: 0.5000\n",
      "Epoch [4420/10000], Training Loss: 0.64386785, Training Accuracy: 0.9076\n",
      "Epoch [4420/10000], Validation Loss: 1.05593842, Validation Accuracy: 0.5000\n",
      "Epoch [4421/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4421/10000], Validation Loss: 1.06007624, Validation Accuracy: 0.4853\n",
      "Epoch [4422/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4422/10000], Validation Loss: 1.06193405, Validation Accuracy: 0.4853\n",
      "Epoch [4423/10000], Training Loss: 0.65655889, Training Accuracy: 0.8950\n",
      "Epoch [4423/10000], Validation Loss: 1.06470370, Validation Accuracy: 0.4853\n",
      "Epoch [4424/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [4424/10000], Validation Loss: 1.06547064, Validation Accuracy: 0.4853\n",
      "Epoch [4425/10000], Training Loss: 0.61447945, Training Accuracy: 0.9370\n",
      "Epoch [4425/10000], Validation Loss: 1.06569809, Validation Accuracy: 0.4853\n",
      "Epoch [4426/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4426/10000], Validation Loss: 1.06526363, Validation Accuracy: 0.4853\n",
      "Epoch [4427/10000], Training Loss: 0.63968023, Training Accuracy: 0.9118\n",
      "Epoch [4427/10000], Validation Loss: 1.06469494, Validation Accuracy: 0.4853\n",
      "Epoch [4428/10000], Training Loss: 0.64800080, Training Accuracy: 0.9034\n",
      "Epoch [4428/10000], Validation Loss: 1.06566632, Validation Accuracy: 0.4853\n",
      "Epoch [4429/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [4429/10000], Validation Loss: 1.05611008, Validation Accuracy: 0.4853\n",
      "Epoch [4430/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4430/10000], Validation Loss: 1.03948647, Validation Accuracy: 0.5147\n",
      "Epoch [4431/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4431/10000], Validation Loss: 1.03780550, Validation Accuracy: 0.5147\n",
      "Epoch [4432/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4432/10000], Validation Loss: 1.03742641, Validation Accuracy: 0.5147\n",
      "Epoch [4433/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4433/10000], Validation Loss: 1.03729659, Validation Accuracy: 0.5147\n",
      "Epoch [4434/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4434/10000], Validation Loss: 1.03724349, Validation Accuracy: 0.5147\n",
      "Epoch [4435/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4435/10000], Validation Loss: 1.03721976, Validation Accuracy: 0.5147\n",
      "Epoch [4436/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4436/10000], Validation Loss: 1.03720880, Validation Accuracy: 0.5147\n",
      "Epoch [4437/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4437/10000], Validation Loss: 1.03720355, Validation Accuracy: 0.5147\n",
      "Epoch [4438/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4438/10000], Validation Loss: 1.03720111, Validation Accuracy: 0.5147\n",
      "Epoch [4439/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4439/10000], Validation Loss: 1.03719997, Validation Accuracy: 0.5147\n",
      "Epoch [4440/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4440/10000], Validation Loss: 1.03719938, Validation Accuracy: 0.5147\n",
      "Epoch [4441/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4441/10000], Validation Loss: 1.03719914, Validation Accuracy: 0.5147\n",
      "Epoch [4442/10000], Training Loss: 0.60606694, Training Accuracy: 0.9454\n",
      "Epoch [4442/10000], Validation Loss: 1.03720272, Validation Accuracy: 0.5147\n",
      "Epoch [4443/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4443/10000], Validation Loss: 1.03721082, Validation Accuracy: 0.5147\n",
      "Epoch [4444/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4444/10000], Validation Loss: 1.03721482, Validation Accuracy: 0.5147\n",
      "Epoch [4445/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4445/10000], Validation Loss: 1.03721666, Validation Accuracy: 0.5147\n",
      "Epoch [4446/10000], Training Loss: 0.62707295, Training Accuracy: 0.9244\n",
      "Epoch [4446/10000], Validation Loss: 1.03715354, Validation Accuracy: 0.5147\n",
      "Epoch [4447/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4447/10000], Validation Loss: 1.03709936, Validation Accuracy: 0.5147\n",
      "Epoch [4448/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [4448/10000], Validation Loss: 1.03707594, Validation Accuracy: 0.5147\n",
      "Epoch [4449/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4449/10000], Validation Loss: 1.03706515, Validation Accuracy: 0.5147\n",
      "Epoch [4450/10000], Training Loss: 0.62700459, Training Accuracy: 0.9244\n",
      "Epoch [4450/10000], Validation Loss: 1.06564772, Validation Accuracy: 0.4853\n",
      "Epoch [4451/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4451/10000], Validation Loss: 1.05752659, Validation Accuracy: 0.4853\n",
      "Epoch [4452/10000], Training Loss: 0.62713556, Training Accuracy: 0.9244\n",
      "Epoch [4452/10000], Validation Loss: 1.05144531, Validation Accuracy: 0.5000\n",
      "Epoch [4453/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4453/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4454/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4454/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4455/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4455/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4456/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4456/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4457/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [4457/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4458/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4458/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4459/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4459/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4460/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4460/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4461/10000], Training Loss: 0.64917014, Training Accuracy: 0.9034\n",
      "Epoch [4461/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4462/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4462/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [4463/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4463/10000], Validation Loss: 1.04667568, Validation Accuracy: 0.5000\n",
      "Epoch [4464/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4464/10000], Validation Loss: 1.05143344, Validation Accuracy: 0.5000\n",
      "Epoch [4465/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4465/10000], Validation Loss: 1.05144435, Validation Accuracy: 0.5000\n",
      "Epoch [4466/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4466/10000], Validation Loss: 1.05144477, Validation Accuracy: 0.5000\n",
      "Epoch [4467/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4467/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4468/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4468/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4469/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [4469/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4470/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4470/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4471/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [4471/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4472/10000], Training Loss: 0.63127709, Training Accuracy: 0.9202\n",
      "Epoch [4472/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4473/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4473/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4474/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4474/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4475/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4475/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4476/10000], Training Loss: 0.63127714, Training Accuracy: 0.9202\n",
      "Epoch [4476/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4477/10000], Training Loss: 0.64388147, Training Accuracy: 0.9076\n",
      "Epoch [4477/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4478/10000], Training Loss: 0.62287350, Training Accuracy: 0.9286\n",
      "Epoch [4478/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4479/10000], Training Loss: 0.64388198, Training Accuracy: 0.9076\n",
      "Epoch [4479/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4480/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4480/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4481/10000], Training Loss: 0.62707580, Training Accuracy: 0.9244\n",
      "Epoch [4481/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [4482/10000], Training Loss: 0.63019577, Training Accuracy: 0.9202\n",
      "Epoch [4482/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4483/10000], Training Loss: 0.65310683, Training Accuracy: 0.8992\n",
      "Epoch [4483/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [4484/10000], Training Loss: 0.63128128, Training Accuracy: 0.9202\n",
      "Epoch [4484/10000], Validation Loss: 1.05151331, Validation Accuracy: 0.5000\n",
      "Epoch [4485/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4485/10000], Validation Loss: 1.06614923, Validation Accuracy: 0.4853\n",
      "Epoch [4486/10000], Training Loss: 0.63547985, Training Accuracy: 0.9160\n",
      "Epoch [4486/10000], Validation Loss: 1.06614715, Validation Accuracy: 0.4853\n",
      "Epoch [4487/10000], Training Loss: 0.63126574, Training Accuracy: 0.9202\n",
      "Epoch [4487/10000], Validation Loss: 1.06613600, Validation Accuracy: 0.4853\n",
      "Epoch [4488/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4488/10000], Validation Loss: 1.08082873, Validation Accuracy: 0.4706\n",
      "Epoch [4489/10000], Training Loss: 0.64214761, Training Accuracy: 0.9076\n",
      "Epoch [4489/10000], Validation Loss: 1.08084583, Validation Accuracy: 0.4706\n",
      "Epoch [4490/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4490/10000], Validation Loss: 1.06355447, Validation Accuracy: 0.4853\n",
      "Epoch [4491/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4491/10000], Validation Loss: 1.03675967, Validation Accuracy: 0.5147\n",
      "Epoch [4492/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4492/10000], Validation Loss: 1.03665888, Validation Accuracy: 0.5147\n",
      "Epoch [4493/10000], Training Loss: 0.63127580, Training Accuracy: 0.9202\n",
      "Epoch [4493/10000], Validation Loss: 1.03485858, Validation Accuracy: 0.5147\n",
      "Epoch [4494/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4494/10000], Validation Loss: 1.04525197, Validation Accuracy: 0.5000\n",
      "Epoch [4495/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4495/10000], Validation Loss: 1.04243714, Validation Accuracy: 0.5147\n",
      "Epoch [4496/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4496/10000], Validation Loss: 1.04120374, Validation Accuracy: 0.5147\n",
      "Epoch [4497/10000], Training Loss: 0.64382357, Training Accuracy: 0.9076\n",
      "Epoch [4497/10000], Validation Loss: 1.03817612, Validation Accuracy: 0.5147\n",
      "Epoch [4498/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4498/10000], Validation Loss: 1.05192375, Validation Accuracy: 0.5000\n",
      "Epoch [4499/10000], Training Loss: 0.63570595, Training Accuracy: 0.9160\n",
      "Epoch [4499/10000], Validation Loss: 1.05608338, Validation Accuracy: 0.5000\n",
      "Epoch [4500/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4500/10000], Validation Loss: 1.06570280, Validation Accuracy: 0.4853\n",
      "Epoch [4501/10000], Training Loss: 0.63967942, Training Accuracy: 0.9118\n",
      "Epoch [4501/10000], Validation Loss: 1.06609672, Validation Accuracy: 0.4853\n",
      "Epoch [4502/10000], Training Loss: 0.63967933, Training Accuracy: 0.9118\n",
      "Epoch [4502/10000], Validation Loss: 1.06613660, Validation Accuracy: 0.4853\n",
      "Epoch [4503/10000], Training Loss: 0.63127699, Training Accuracy: 0.9202\n",
      "Epoch [4503/10000], Validation Loss: 1.06614596, Validation Accuracy: 0.4853\n",
      "Epoch [4504/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4504/10000], Validation Loss: 1.06614918, Validation Accuracy: 0.4853\n",
      "Epoch [4505/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4505/10000], Validation Loss: 1.06615043, Validation Accuracy: 0.4853\n",
      "Epoch [4506/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4506/10000], Validation Loss: 1.06615108, Validation Accuracy: 0.4853\n",
      "Epoch [4507/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4507/10000], Validation Loss: 1.06615126, Validation Accuracy: 0.4853\n",
      "Epoch [4508/10000], Training Loss: 0.64388234, Training Accuracy: 0.9076\n",
      "Epoch [4508/10000], Validation Loss: 1.06615132, Validation Accuracy: 0.4853\n",
      "Epoch [4509/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4509/10000], Validation Loss: 1.06615138, Validation Accuracy: 0.4853\n",
      "Epoch [4510/10000], Training Loss: 0.65226471, Training Accuracy: 0.8992\n",
      "Epoch [4510/10000], Validation Loss: 1.06614953, Validation Accuracy: 0.4853\n",
      "Epoch [4511/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4511/10000], Validation Loss: 1.06614888, Validation Accuracy: 0.4853\n",
      "Epoch [4512/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [4512/10000], Validation Loss: 1.05157644, Validation Accuracy: 0.5000\n",
      "Epoch [4513/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4513/10000], Validation Loss: 1.05144477, Validation Accuracy: 0.5000\n",
      "Epoch [4514/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4514/10000], Validation Loss: 1.05144459, Validation Accuracy: 0.5000\n",
      "Epoch [4515/10000], Training Loss: 0.63546810, Training Accuracy: 0.9160\n",
      "Epoch [4515/10000], Validation Loss: 1.05144465, Validation Accuracy: 0.5000\n",
      "Epoch [4516/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4516/10000], Validation Loss: 1.05144465, Validation Accuracy: 0.5000\n",
      "Epoch [4517/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4517/10000], Validation Loss: 1.05144465, Validation Accuracy: 0.5000\n",
      "Epoch [4518/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4518/10000], Validation Loss: 1.05144465, Validation Accuracy: 0.5000\n",
      "Epoch [4519/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4519/10000], Validation Loss: 1.05144465, Validation Accuracy: 0.5000\n",
      "Epoch [4520/10000], Training Loss: 0.63434792, Training Accuracy: 0.9160\n",
      "Epoch [4520/10000], Validation Loss: 1.05450159, Validation Accuracy: 0.5000\n",
      "Epoch [4521/10000], Training Loss: 0.63963701, Training Accuracy: 0.9118\n",
      "Epoch [4521/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4522/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4522/10000], Validation Loss: 1.07899714, Validation Accuracy: 0.4706\n",
      "Epoch [4523/10000], Training Loss: 0.62707533, Training Accuracy: 0.9244\n",
      "Epoch [4523/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4524/10000], Training Loss: 0.64805866, Training Accuracy: 0.9034\n",
      "Epoch [4524/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4525/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [4525/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4526/10000], Training Loss: 0.63127698, Training Accuracy: 0.9202\n",
      "Epoch [4526/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4527/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [4527/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4528/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4528/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4529/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4529/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4530/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4530/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4531/10000], Training Loss: 0.63547851, Training Accuracy: 0.9160\n",
      "Epoch [4531/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4532/10000], Training Loss: 0.65648577, Training Accuracy: 0.8950\n",
      "Epoch [4532/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4533/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4533/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4534/10000], Training Loss: 0.63968159, Training Accuracy: 0.9118\n",
      "Epoch [4534/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4535/10000], Training Loss: 0.64403452, Training Accuracy: 0.9076\n",
      "Epoch [4535/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4536/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4536/10000], Validation Loss: 1.08074039, Validation Accuracy: 0.4706\n",
      "Epoch [4537/10000], Training Loss: 0.63966509, Training Accuracy: 0.9118\n",
      "Epoch [4537/10000], Validation Loss: 1.06609887, Validation Accuracy: 0.4853\n",
      "Epoch [4538/10000], Training Loss: 0.63547887, Training Accuracy: 0.9160\n",
      "Epoch [4538/10000], Validation Loss: 1.05251080, Validation Accuracy: 0.5000\n",
      "Epoch [4539/10000], Training Loss: 0.62712207, Training Accuracy: 0.9244\n",
      "Epoch [4539/10000], Validation Loss: 1.05146891, Validation Accuracy: 0.5000\n",
      "Epoch [4540/10000], Training Loss: 0.65624854, Training Accuracy: 0.8950\n",
      "Epoch [4540/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4541/10000], Training Loss: 0.64227310, Training Accuracy: 0.9076\n",
      "Epoch [4541/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4542/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4542/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4543/10000], Training Loss: 0.64387994, Training Accuracy: 0.9076\n",
      "Epoch [4543/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4544/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4544/10000], Validation Loss: 1.11026782, Validation Accuracy: 0.4412\n",
      "Epoch [4545/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4545/10000], Validation Loss: 1.11183989, Validation Accuracy: 0.4412\n",
      "Epoch [4546/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4546/10000], Validation Loss: 1.12452328, Validation Accuracy: 0.4265\n",
      "Epoch [4547/10000], Training Loss: 0.65648701, Training Accuracy: 0.8950\n",
      "Epoch [4547/10000], Validation Loss: 1.12494254, Validation Accuracy: 0.4265\n",
      "Epoch [4548/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4548/10000], Validation Loss: 1.12496567, Validation Accuracy: 0.4265\n",
      "Epoch [4549/10000], Training Loss: 0.66068858, Training Accuracy: 0.8908\n",
      "Epoch [4549/10000], Validation Loss: 1.12496984, Validation Accuracy: 0.4265\n",
      "Epoch [4550/10000], Training Loss: 0.63083644, Training Accuracy: 0.9202\n",
      "Epoch [4550/10000], Validation Loss: 1.12307900, Validation Accuracy: 0.4265\n",
      "Epoch [4551/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4551/10000], Validation Loss: 1.11026800, Validation Accuracy: 0.4412\n",
      "Epoch [4552/10000], Training Loss: 0.65646487, Training Accuracy: 0.8950\n",
      "Epoch [4552/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4553/10000], Training Loss: 0.64805904, Training Accuracy: 0.9034\n",
      "Epoch [4553/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4554/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4554/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4555/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4555/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4556/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4556/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4557/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [4557/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4558/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4558/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4559/10000], Training Loss: 0.64808806, Training Accuracy: 0.9034\n",
      "Epoch [4559/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4560/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [4560/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4561/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4561/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4562/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4562/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4563/10000], Training Loss: 0.64806273, Training Accuracy: 0.9034\n",
      "Epoch [4563/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4564/10000], Training Loss: 0.66068870, Training Accuracy: 0.8908\n",
      "Epoch [4564/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4565/10000], Training Loss: 0.65528913, Training Accuracy: 0.8950\n",
      "Epoch [4565/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4566/10000], Training Loss: 0.62707178, Training Accuracy: 0.9244\n",
      "Epoch [4566/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4567/10000], Training Loss: 0.61870154, Training Accuracy: 0.9328\n",
      "Epoch [4567/10000], Validation Loss: 1.11013573, Validation Accuracy: 0.4412\n",
      "Epoch [4568/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4568/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4569/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4569/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4570/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4570/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4571/10000], Training Loss: 0.65126622, Training Accuracy: 0.8992\n",
      "Epoch [4571/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4572/10000], Training Loss: 0.64387482, Training Accuracy: 0.9076\n",
      "Epoch [4572/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [4573/10000], Training Loss: 0.62707868, Training Accuracy: 0.9244\n",
      "Epoch [4573/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [4574/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4574/10000], Validation Loss: 1.16909200, Validation Accuracy: 0.3824\n",
      "Epoch [4575/10000], Training Loss: 0.65646165, Training Accuracy: 0.8950\n",
      "Epoch [4575/10000], Validation Loss: 1.16909200, Validation Accuracy: 0.3824\n",
      "Epoch [4576/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4576/10000], Validation Loss: 1.16909200, Validation Accuracy: 0.3824\n",
      "Epoch [4577/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4577/10000], Validation Loss: 1.16909200, Validation Accuracy: 0.3824\n",
      "Epoch [4578/10000], Training Loss: 0.64393009, Training Accuracy: 0.9076\n",
      "Epoch [4578/10000], Validation Loss: 1.16909200, Validation Accuracy: 0.3824\n",
      "Epoch [4579/10000], Training Loss: 0.62287375, Training Accuracy: 0.9286\n",
      "Epoch [4579/10000], Validation Loss: 1.16909200, Validation Accuracy: 0.3824\n",
      "Epoch [4580/10000], Training Loss: 0.63549360, Training Accuracy: 0.9160\n",
      "Epoch [4580/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [4581/10000], Training Loss: 0.63127662, Training Accuracy: 0.9202\n",
      "Epoch [4581/10000], Validation Loss: 1.16909122, Validation Accuracy: 0.3824\n",
      "Epoch [4582/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4582/10000], Validation Loss: 1.16908967, Validation Accuracy: 0.3824\n",
      "Epoch [4583/10000], Training Loss: 0.61812340, Training Accuracy: 0.9328\n",
      "Epoch [4583/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4584/10000], Training Loss: 0.62710441, Training Accuracy: 0.9244\n",
      "Epoch [4584/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4585/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4585/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4586/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4586/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4587/10000], Training Loss: 0.62707973, Training Accuracy: 0.9244\n",
      "Epoch [4587/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4588/10000], Training Loss: 0.65228317, Training Accuracy: 0.8992\n",
      "Epoch [4588/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4589/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4589/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4590/10000], Training Loss: 0.62707276, Training Accuracy: 0.9244\n",
      "Epoch [4590/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4591/10000], Training Loss: 0.62712331, Training Accuracy: 0.9244\n",
      "Epoch [4591/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4592/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4592/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4593/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4593/10000], Validation Loss: 1.19850367, Validation Accuracy: 0.3529\n",
      "Epoch [4594/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4594/10000], Validation Loss: 1.19850355, Validation Accuracy: 0.3529\n",
      "Epoch [4595/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4595/10000], Validation Loss: 1.19850302, Validation Accuracy: 0.3529\n",
      "Epoch [4596/10000], Training Loss: 0.61092027, Training Accuracy: 0.9412\n",
      "Epoch [4596/10000], Validation Loss: 1.18973142, Validation Accuracy: 0.3676\n",
      "Epoch [4597/10000], Training Loss: 0.61904573, Training Accuracy: 0.9328\n",
      "Epoch [4597/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [4598/10000], Training Loss: 0.64354755, Training Accuracy: 0.9076\n",
      "Epoch [4598/10000], Validation Loss: 1.11027902, Validation Accuracy: 0.4412\n",
      "Epoch [4599/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4599/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4600/10000], Training Loss: 0.61446937, Training Accuracy: 0.9370\n",
      "Epoch [4600/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4601/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4601/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4602/10000], Training Loss: 0.62707513, Training Accuracy: 0.9244\n",
      "Epoch [4602/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4603/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4603/10000], Validation Loss: 1.06615090, Validation Accuracy: 0.4853\n",
      "Epoch [4604/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4604/10000], Validation Loss: 1.06615108, Validation Accuracy: 0.4853\n",
      "Epoch [4605/10000], Training Loss: 0.63127659, Training Accuracy: 0.9202\n",
      "Epoch [4605/10000], Validation Loss: 1.06615138, Validation Accuracy: 0.4853\n",
      "Epoch [4606/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4606/10000], Validation Loss: 1.06615162, Validation Accuracy: 0.4853\n",
      "Epoch [4607/10000], Training Loss: 0.63118938, Training Accuracy: 0.9202\n",
      "Epoch [4607/10000], Validation Loss: 1.06615430, Validation Accuracy: 0.4853\n",
      "Epoch [4608/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4608/10000], Validation Loss: 1.08122122, Validation Accuracy: 0.4706\n",
      "Epoch [4609/10000], Training Loss: 0.63967328, Training Accuracy: 0.9118\n",
      "Epoch [4609/10000], Validation Loss: 1.08376265, Validation Accuracy: 0.4706\n",
      "Epoch [4610/10000], Training Loss: 0.65228316, Training Accuracy: 0.8992\n",
      "Epoch [4610/10000], Validation Loss: 1.08874673, Validation Accuracy: 0.4559\n",
      "Epoch [4611/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4611/10000], Validation Loss: 1.09148800, Validation Accuracy: 0.4559\n",
      "Epoch [4612/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4612/10000], Validation Loss: 1.09252185, Validation Accuracy: 0.4559\n",
      "Epoch [4613/10000], Training Loss: 0.61027781, Training Accuracy: 0.9412\n",
      "Epoch [4613/10000], Validation Loss: 1.09291506, Validation Accuracy: 0.4559\n",
      "Epoch [4614/10000], Training Loss: 0.64793798, Training Accuracy: 0.9034\n",
      "Epoch [4614/10000], Validation Loss: 1.09242302, Validation Accuracy: 0.4559\n",
      "Epoch [4615/10000], Training Loss: 0.61447022, Training Accuracy: 0.9370\n",
      "Epoch [4615/10000], Validation Loss: 1.09183556, Validation Accuracy: 0.4559\n",
      "Epoch [4616/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4616/10000], Validation Loss: 1.09150440, Validation Accuracy: 0.4559\n",
      "Epoch [4617/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4617/10000], Validation Loss: 1.09133893, Validation Accuracy: 0.4559\n",
      "Epoch [4618/10000], Training Loss: 0.61869098, Training Accuracy: 0.9328\n",
      "Epoch [4618/10000], Validation Loss: 1.09131992, Validation Accuracy: 0.4559\n",
      "Epoch [4619/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4619/10000], Validation Loss: 1.07660323, Validation Accuracy: 0.4706\n",
      "Epoch [4620/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4620/10000], Validation Loss: 1.07659692, Validation Accuracy: 0.4706\n",
      "Epoch [4621/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4621/10000], Validation Loss: 1.07659417, Validation Accuracy: 0.4706\n",
      "Epoch [4622/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4622/10000], Validation Loss: 1.07659280, Validation Accuracy: 0.4706\n",
      "Epoch [4623/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4623/10000], Validation Loss: 1.07659215, Validation Accuracy: 0.4706\n",
      "Epoch [4624/10000], Training Loss: 0.62510802, Training Accuracy: 0.9244\n",
      "Epoch [4624/10000], Validation Loss: 1.08085674, Validation Accuracy: 0.4706\n",
      "Epoch [4625/10000], Training Loss: 0.62707518, Training Accuracy: 0.9244\n",
      "Epoch [4625/10000], Validation Loss: 1.08103234, Validation Accuracy: 0.4706\n",
      "Epoch [4626/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4626/10000], Validation Loss: 1.07071269, Validation Accuracy: 0.4853\n",
      "Epoch [4627/10000], Training Loss: 0.61491920, Training Accuracy: 0.9370\n",
      "Epoch [4627/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4628/10000], Training Loss: 0.61026935, Training Accuracy: 0.9412\n",
      "Epoch [4628/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4629/10000], Training Loss: 0.63124692, Training Accuracy: 0.9202\n",
      "Epoch [4629/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4630/10000], Training Loss: 0.63985346, Training Accuracy: 0.9118\n",
      "Epoch [4630/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4631/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4631/10000], Validation Loss: 1.08244145, Validation Accuracy: 0.4706\n",
      "Epoch [4632/10000], Training Loss: 0.64808462, Training Accuracy: 0.9034\n",
      "Epoch [4632/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4633/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4633/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4634/10000], Training Loss: 0.63142163, Training Accuracy: 0.9202\n",
      "Epoch [4634/10000], Validation Loss: 1.08085823, Validation Accuracy: 0.4706\n",
      "Epoch [4635/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4635/10000], Validation Loss: 1.11026782, Validation Accuracy: 0.4412\n",
      "Epoch [4636/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4636/10000], Validation Loss: 1.08103073, Validation Accuracy: 0.4706\n",
      "Epoch [4637/10000], Training Loss: 0.63127697, Training Accuracy: 0.9202\n",
      "Epoch [4637/10000], Validation Loss: 1.08085698, Validation Accuracy: 0.4706\n",
      "Epoch [4638/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4638/10000], Validation Loss: 1.08085638, Validation Accuracy: 0.4706\n",
      "Epoch [4639/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4639/10000], Validation Loss: 1.08085459, Validation Accuracy: 0.4706\n",
      "Epoch [4640/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4640/10000], Validation Loss: 1.08085108, Validation Accuracy: 0.4706\n",
      "Epoch [4641/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4641/10000], Validation Loss: 1.08084756, Validation Accuracy: 0.4706\n",
      "Epoch [4642/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4642/10000], Validation Loss: 1.08084530, Validation Accuracy: 0.4706\n",
      "Epoch [4643/10000], Training Loss: 0.63102717, Training Accuracy: 0.9202\n",
      "Epoch [4643/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4644/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4644/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4645/10000], Training Loss: 0.63127687, Training Accuracy: 0.9202\n",
      "Epoch [4645/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4646/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4646/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4647/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4647/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4648/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4648/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4649/10000], Training Loss: 0.62287380, Training Accuracy: 0.9286\n",
      "Epoch [4649/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4650/10000], Training Loss: 0.65228450, Training Accuracy: 0.8992\n",
      "Epoch [4650/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4651/10000], Training Loss: 0.65228708, Training Accuracy: 0.8992\n",
      "Epoch [4651/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4652/10000], Training Loss: 0.62287364, Training Accuracy: 0.9286\n",
      "Epoch [4652/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4653/10000], Training Loss: 0.64224559, Training Accuracy: 0.9076\n",
      "Epoch [4653/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4654/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4654/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [4655/10000], Training Loss: 0.62288554, Training Accuracy: 0.9286\n",
      "Epoch [4655/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [4656/10000], Training Loss: 0.62709132, Training Accuracy: 0.9244\n",
      "Epoch [4656/10000], Validation Loss: 1.09547329, Validation Accuracy: 0.4559\n",
      "Epoch [4657/10000], Training Loss: 0.62707439, Training Accuracy: 0.9244\n",
      "Epoch [4657/10000], Validation Loss: 1.08457172, Validation Accuracy: 0.4706\n",
      "Epoch [4658/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4658/10000], Validation Loss: 1.08108735, Validation Accuracy: 0.4706\n",
      "Epoch [4659/10000], Training Loss: 0.61027919, Training Accuracy: 0.9412\n",
      "Epoch [4659/10000], Validation Loss: 1.08090246, Validation Accuracy: 0.4706\n",
      "Epoch [4660/10000], Training Loss: 0.62310902, Training Accuracy: 0.9286\n",
      "Epoch [4660/10000], Validation Loss: 1.09556437, Validation Accuracy: 0.4559\n",
      "Epoch [4661/10000], Training Loss: 0.62287864, Training Accuracy: 0.9286\n",
      "Epoch [4661/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4662/10000], Training Loss: 0.63542859, Training Accuracy: 0.9160\n",
      "Epoch [4662/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4663/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [4663/10000], Validation Loss: 1.11026824, Validation Accuracy: 0.4412\n",
      "Epoch [4664/10000], Training Loss: 0.65226915, Training Accuracy: 0.8992\n",
      "Epoch [4664/10000], Validation Loss: 1.10912794, Validation Accuracy: 0.4412\n",
      "Epoch [4665/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4665/10000], Validation Loss: 1.10276419, Validation Accuracy: 0.4412\n",
      "Epoch [4666/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4666/10000], Validation Loss: 1.09877622, Validation Accuracy: 0.4559\n",
      "Epoch [4667/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4667/10000], Validation Loss: 1.09753782, Validation Accuracy: 0.4559\n",
      "Epoch [4668/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4668/10000], Validation Loss: 1.09710407, Validation Accuracy: 0.4559\n",
      "Epoch [4669/10000], Training Loss: 0.62703230, Training Accuracy: 0.9244\n",
      "Epoch [4669/10000], Validation Loss: 1.09611422, Validation Accuracy: 0.4559\n",
      "Epoch [4670/10000], Training Loss: 0.62286769, Training Accuracy: 0.9286\n",
      "Epoch [4670/10000], Validation Loss: 1.09581804, Validation Accuracy: 0.4559\n",
      "Epoch [4671/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4671/10000], Validation Loss: 1.09569699, Validation Accuracy: 0.4559\n",
      "Epoch [4672/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [4672/10000], Validation Loss: 1.09566116, Validation Accuracy: 0.4559\n",
      "Epoch [4673/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4673/10000], Validation Loss: 1.09564751, Validation Accuracy: 0.4559\n",
      "Epoch [4674/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4674/10000], Validation Loss: 1.09564167, Validation Accuracy: 0.4559\n",
      "Epoch [4675/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [4675/10000], Validation Loss: 1.09563893, Validation Accuracy: 0.4559\n",
      "Epoch [4676/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4676/10000], Validation Loss: 1.09563774, Validation Accuracy: 0.4559\n",
      "Epoch [4677/10000], Training Loss: 0.65229550, Training Accuracy: 0.8992\n",
      "Epoch [4677/10000], Validation Loss: 1.09563935, Validation Accuracy: 0.4559\n",
      "Epoch [4678/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [4678/10000], Validation Loss: 1.09564072, Validation Accuracy: 0.4559\n",
      "Epoch [4679/10000], Training Loss: 0.64809403, Training Accuracy: 0.9034\n",
      "Epoch [4679/10000], Validation Loss: 1.09559149, Validation Accuracy: 0.4559\n",
      "Epoch [4680/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4680/10000], Validation Loss: 1.09556973, Validation Accuracy: 0.4559\n",
      "Epoch [4681/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4681/10000], Validation Loss: 1.09556621, Validation Accuracy: 0.4559\n",
      "Epoch [4682/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4682/10000], Validation Loss: 1.09556520, Validation Accuracy: 0.4559\n",
      "Epoch [4683/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4683/10000], Validation Loss: 1.09556484, Validation Accuracy: 0.4559\n",
      "Epoch [4684/10000], Training Loss: 0.62715985, Training Accuracy: 0.9244\n",
      "Epoch [4684/10000], Validation Loss: 1.10975140, Validation Accuracy: 0.4412\n",
      "Epoch [4685/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4685/10000], Validation Loss: 1.11026806, Validation Accuracy: 0.4412\n",
      "Epoch [4686/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4686/10000], Validation Loss: 1.11009729, Validation Accuracy: 0.4412\n",
      "Epoch [4687/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4687/10000], Validation Loss: 1.10751975, Validation Accuracy: 0.4412\n",
      "Epoch [4688/10000], Training Loss: 0.62846670, Training Accuracy: 0.9244\n",
      "Epoch [4688/10000], Validation Loss: 1.08086383, Validation Accuracy: 0.4706\n",
      "Epoch [4689/10000], Training Loss: 0.63967443, Training Accuracy: 0.9118\n",
      "Epoch [4689/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4690/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4690/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4691/10000], Training Loss: 0.62725769, Training Accuracy: 0.9244\n",
      "Epoch [4691/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4692/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [4692/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4693/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4693/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4694/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4694/10000], Validation Loss: 1.09556264, Validation Accuracy: 0.4559\n",
      "Epoch [4695/10000], Training Loss: 0.63589552, Training Accuracy: 0.9160\n",
      "Epoch [4695/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4696/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4696/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4697/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4697/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4698/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4698/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4699/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4699/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4700/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4700/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4701/10000], Training Loss: 0.62052366, Training Accuracy: 0.9286\n",
      "Epoch [4701/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4702/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4702/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [4703/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4703/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [4704/10000], Training Loss: 0.65648695, Training Accuracy: 0.8950\n",
      "Epoch [4704/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [4705/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4705/10000], Validation Loss: 1.13968027, Validation Accuracy: 0.4118\n",
      "Epoch [4706/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4706/10000], Validation Loss: 1.13968045, Validation Accuracy: 0.4118\n",
      "Epoch [4707/10000], Training Loss: 0.66963702, Training Accuracy: 0.8824\n",
      "Epoch [4707/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [4708/10000], Training Loss: 0.63567349, Training Accuracy: 0.9160\n",
      "Epoch [4708/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [4709/10000], Training Loss: 0.64074908, Training Accuracy: 0.9118\n",
      "Epoch [4709/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4710/10000], Training Loss: 0.63127693, Training Accuracy: 0.9202\n",
      "Epoch [4710/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4711/10000], Training Loss: 0.62287366, Training Accuracy: 0.9286\n",
      "Epoch [4711/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4712/10000], Training Loss: 0.65610736, Training Accuracy: 0.8950\n",
      "Epoch [4712/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4713/10000], Training Loss: 0.61856961, Training Accuracy: 0.9328\n",
      "Epoch [4713/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4714/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4714/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4715/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4715/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4716/10000], Training Loss: 0.64366182, Training Accuracy: 0.9076\n",
      "Epoch [4716/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4717/10000], Training Loss: 0.61447011, Training Accuracy: 0.9370\n",
      "Epoch [4717/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4718/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [4718/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4719/10000], Training Loss: 0.61448982, Training Accuracy: 0.9370\n",
      "Epoch [4719/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4720/10000], Training Loss: 0.63127562, Training Accuracy: 0.9202\n",
      "Epoch [4720/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4721/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4721/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4722/10000], Training Loss: 0.65114058, Training Accuracy: 0.8992\n",
      "Epoch [4722/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4723/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4723/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4724/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4724/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4725/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4725/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4726/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4726/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4727/10000], Training Loss: 0.61866795, Training Accuracy: 0.9328\n",
      "Epoch [4727/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4728/10000], Training Loss: 0.61442182, Training Accuracy: 0.9370\n",
      "Epoch [4728/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4729/10000], Training Loss: 0.63967981, Training Accuracy: 0.9118\n",
      "Epoch [4729/10000], Validation Loss: 1.09556329, Validation Accuracy: 0.4559\n",
      "Epoch [4730/10000], Training Loss: 0.63929996, Training Accuracy: 0.9118\n",
      "Epoch [4730/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4731/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4731/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4732/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4732/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4733/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4733/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4734/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4734/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4735/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4735/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4736/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4736/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4737/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4737/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4738/10000], Training Loss: 0.61446947, Training Accuracy: 0.9370\n",
      "Epoch [4738/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4739/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [4739/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4740/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [4740/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4741/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4741/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4742/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4742/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4743/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4743/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4744/10000], Training Loss: 0.61447038, Training Accuracy: 0.9370\n",
      "Epoch [4744/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4745/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4745/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4746/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4746/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4747/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4747/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4748/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4748/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4749/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4749/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4750/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [4750/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4751/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4751/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4752/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4752/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4753/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4753/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4754/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4754/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4755/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4755/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4756/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4756/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4757/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [4757/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4758/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4758/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4759/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [4759/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4760/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4760/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4761/10000], Training Loss: 0.62707224, Training Accuracy: 0.9244\n",
      "Epoch [4761/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4762/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [4762/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4763/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4763/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4764/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4764/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4765/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [4765/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4766/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4766/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4767/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4767/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4768/10000], Training Loss: 0.62304966, Training Accuracy: 0.9286\n",
      "Epoch [4768/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4769/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4769/10000], Validation Loss: 1.11026818, Validation Accuracy: 0.4412\n",
      "Epoch [4770/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4770/10000], Validation Loss: 1.10884482, Validation Accuracy: 0.4412\n",
      "Epoch [4771/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4771/10000], Validation Loss: 1.09721458, Validation Accuracy: 0.4559\n",
      "Epoch [4772/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4772/10000], Validation Loss: 1.09580094, Validation Accuracy: 0.4559\n",
      "Epoch [4773/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4773/10000], Validation Loss: 1.09565359, Validation Accuracy: 0.4559\n",
      "Epoch [4774/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [4774/10000], Validation Loss: 1.09561980, Validation Accuracy: 0.4559\n",
      "Epoch [4775/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4775/10000], Validation Loss: 1.09560835, Validation Accuracy: 0.4559\n",
      "Epoch [4776/10000], Training Loss: 0.62707523, Training Accuracy: 0.9244\n",
      "Epoch [4776/10000], Validation Loss: 1.09560364, Validation Accuracy: 0.4559\n",
      "Epoch [4777/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4777/10000], Validation Loss: 1.09560162, Validation Accuracy: 0.4559\n",
      "Epoch [4778/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4778/10000], Validation Loss: 1.09560072, Validation Accuracy: 0.4559\n",
      "Epoch [4779/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4779/10000], Validation Loss: 1.09560025, Validation Accuracy: 0.4559\n",
      "Epoch [4780/10000], Training Loss: 0.62682753, Training Accuracy: 0.9244\n",
      "Epoch [4780/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [4781/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4781/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4782/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4782/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4783/10000], Training Loss: 0.63115360, Training Accuracy: 0.9202\n",
      "Epoch [4783/10000], Validation Loss: 1.13784373, Validation Accuracy: 0.4118\n",
      "Epoch [4784/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4784/10000], Validation Loss: 1.11026335, Validation Accuracy: 0.4412\n",
      "Epoch [4785/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4785/10000], Validation Loss: 1.08178926, Validation Accuracy: 0.4706\n",
      "Epoch [4786/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4786/10000], Validation Loss: 1.08086252, Validation Accuracy: 0.4706\n",
      "Epoch [4787/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4787/10000], Validation Loss: 1.08085716, Validation Accuracy: 0.4706\n",
      "Epoch [4788/10000], Training Loss: 0.63707736, Training Accuracy: 0.9160\n",
      "Epoch [4788/10000], Validation Loss: 1.08091486, Validation Accuracy: 0.4706\n",
      "Epoch [4789/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4789/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [4790/10000], Training Loss: 0.61400562, Training Accuracy: 0.9370\n",
      "Epoch [4790/10000], Validation Loss: 1.08084774, Validation Accuracy: 0.4706\n",
      "Epoch [4791/10000], Training Loss: 0.62707516, Training Accuracy: 0.9244\n",
      "Epoch [4791/10000], Validation Loss: 1.03580898, Validation Accuracy: 0.5147\n",
      "Epoch [4792/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [4792/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [4793/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4793/10000], Validation Loss: 1.03672764, Validation Accuracy: 0.5147\n",
      "Epoch [4794/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4794/10000], Validation Loss: 1.03485474, Validation Accuracy: 0.5147\n",
      "Epoch [4795/10000], Training Loss: 0.61448275, Training Accuracy: 0.9370\n",
      "Epoch [4795/10000], Validation Loss: 1.02563760, Validation Accuracy: 0.5294\n",
      "Epoch [4796/10000], Training Loss: 0.60637558, Training Accuracy: 0.9454\n",
      "Epoch [4796/10000], Validation Loss: 1.02204442, Validation Accuracy: 0.5294\n",
      "Epoch [4797/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4797/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [4798/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4798/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4799/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [4799/10000], Validation Loss: 1.03673959, Validation Accuracy: 0.5147\n",
      "Epoch [4800/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4800/10000], Validation Loss: 1.03676260, Validation Accuracy: 0.5147\n",
      "Epoch [4801/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4801/10000], Validation Loss: 1.03688669, Validation Accuracy: 0.5147\n",
      "Epoch [4802/10000], Training Loss: 0.62718661, Training Accuracy: 0.9244\n",
      "Epoch [4802/10000], Validation Loss: 1.03809583, Validation Accuracy: 0.5147\n",
      "Epoch [4803/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4803/10000], Validation Loss: 1.04365045, Validation Accuracy: 0.5000\n",
      "Epoch [4804/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4804/10000], Validation Loss: 1.03381592, Validation Accuracy: 0.5147\n",
      "Epoch [4805/10000], Training Loss: 0.61867013, Training Accuracy: 0.9328\n",
      "Epoch [4805/10000], Validation Loss: 1.03492832, Validation Accuracy: 0.5147\n",
      "Epoch [4806/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4806/10000], Validation Loss: 1.03531873, Validation Accuracy: 0.5147\n",
      "Epoch [4807/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [4807/10000], Validation Loss: 1.03548801, Validation Accuracy: 0.5147\n",
      "Epoch [4808/10000], Training Loss: 0.62704706, Training Accuracy: 0.9244\n",
      "Epoch [4808/10000], Validation Loss: 1.03643858, Validation Accuracy: 0.5147\n",
      "Epoch [4809/10000], Training Loss: 0.60606660, Training Accuracy: 0.9454\n",
      "Epoch [4809/10000], Validation Loss: 1.03666812, Validation Accuracy: 0.5147\n",
      "Epoch [4810/10000], Training Loss: 0.61448056, Training Accuracy: 0.9370\n",
      "Epoch [4810/10000], Validation Loss: 1.03656727, Validation Accuracy: 0.5147\n",
      "Epoch [4811/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4811/10000], Validation Loss: 1.03647739, Validation Accuracy: 0.5147\n",
      "Epoch [4812/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4812/10000], Validation Loss: 1.03641927, Validation Accuracy: 0.5147\n",
      "Epoch [4813/10000], Training Loss: 0.61026934, Training Accuracy: 0.9412\n",
      "Epoch [4813/10000], Validation Loss: 1.03641719, Validation Accuracy: 0.5147\n",
      "Epoch [4814/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4814/10000], Validation Loss: 1.03641611, Validation Accuracy: 0.5147\n",
      "Epoch [4815/10000], Training Loss: 0.63127433, Training Accuracy: 0.9202\n",
      "Epoch [4815/10000], Validation Loss: 1.03631896, Validation Accuracy: 0.5147\n",
      "Epoch [4816/10000], Training Loss: 0.61867103, Training Accuracy: 0.9328\n",
      "Epoch [4816/10000], Validation Loss: 1.03627604, Validation Accuracy: 0.5147\n",
      "Epoch [4817/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [4817/10000], Validation Loss: 1.03625405, Validation Accuracy: 0.5147\n",
      "Epoch [4818/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [4818/10000], Validation Loss: 1.03624320, Validation Accuracy: 0.5147\n",
      "Epoch [4819/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [4819/10000], Validation Loss: 1.03623790, Validation Accuracy: 0.5147\n",
      "Epoch [4820/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [4820/10000], Validation Loss: 1.03623533, Validation Accuracy: 0.5147\n",
      "Epoch [4821/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4821/10000], Validation Loss: 1.03623420, Validation Accuracy: 0.5147\n",
      "Epoch [4822/10000], Training Loss: 0.60143764, Training Accuracy: 0.9496\n",
      "Epoch [4822/10000], Validation Loss: 1.03891188, Validation Accuracy: 0.5147\n",
      "Epoch [4823/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [4823/10000], Validation Loss: 1.04429042, Validation Accuracy: 0.5000\n",
      "Epoch [4824/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [4824/10000], Validation Loss: 1.04247040, Validation Accuracy: 0.5147\n",
      "Epoch [4825/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4825/10000], Validation Loss: 1.04165775, Validation Accuracy: 0.5147\n",
      "Epoch [4826/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4826/10000], Validation Loss: 1.04128975, Validation Accuracy: 0.5147\n",
      "Epoch [4827/10000], Training Loss: 0.61028820, Training Accuracy: 0.9412\n",
      "Epoch [4827/10000], Validation Loss: 1.04132712, Validation Accuracy: 0.5147\n",
      "Epoch [4828/10000], Training Loss: 0.61871382, Training Accuracy: 0.9328\n",
      "Epoch [4828/10000], Validation Loss: 1.05144441, Validation Accuracy: 0.5000\n",
      "Epoch [4829/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4829/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4830/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [4830/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4831/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4831/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4832/10000], Training Loss: 0.63547759, Training Accuracy: 0.9160\n",
      "Epoch [4832/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4833/10000], Training Loss: 0.61867190, Training Accuracy: 0.9328\n",
      "Epoch [4833/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4834/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4834/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4835/10000], Training Loss: 0.60286005, Training Accuracy: 0.9496\n",
      "Epoch [4835/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4836/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4836/10000], Validation Loss: 1.02134818, Validation Accuracy: 0.5294\n",
      "Epoch [4837/10000], Training Loss: 0.63127951, Training Accuracy: 0.9202\n",
      "Epoch [4837/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4838/10000], Training Loss: 0.64369872, Training Accuracy: 0.9076\n",
      "Epoch [4838/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4839/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [4839/10000], Validation Loss: 1.03673524, Validation Accuracy: 0.5147\n",
      "Epoch [4840/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [4840/10000], Validation Loss: 1.03669828, Validation Accuracy: 0.5147\n",
      "Epoch [4841/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4841/10000], Validation Loss: 1.03661120, Validation Accuracy: 0.5147\n",
      "Epoch [4842/10000], Training Loss: 0.63186114, Training Accuracy: 0.9202\n",
      "Epoch [4842/10000], Validation Loss: 1.00761643, Validation Accuracy: 0.5441\n",
      "Epoch [4843/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4843/10000], Validation Loss: 0.97802651, Validation Accuracy: 0.5735\n",
      "Epoch [4844/10000], Training Loss: 0.65682322, Training Accuracy: 0.8950\n",
      "Epoch [4844/10000], Validation Loss: 0.99261671, Validation Accuracy: 0.5588\n",
      "Epoch [4845/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [4845/10000], Validation Loss: 0.99256808, Validation Accuracy: 0.5588\n",
      "Epoch [4846/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [4846/10000], Validation Loss: 0.97925001, Validation Accuracy: 0.5735\n",
      "Epoch [4847/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [4847/10000], Validation Loss: 0.97795644, Validation Accuracy: 0.5735\n",
      "Epoch [4848/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4848/10000], Validation Loss: 0.99262914, Validation Accuracy: 0.5588\n",
      "Epoch [4849/10000], Training Loss: 0.65648605, Training Accuracy: 0.8950\n",
      "Epoch [4849/10000], Validation Loss: 0.99262470, Validation Accuracy: 0.5588\n",
      "Epoch [4850/10000], Training Loss: 0.64809169, Training Accuracy: 0.9034\n",
      "Epoch [4850/10000], Validation Loss: 1.00732899, Validation Accuracy: 0.5441\n",
      "Epoch [4851/10000], Training Loss: 0.63127691, Training Accuracy: 0.9202\n",
      "Epoch [4851/10000], Validation Loss: 1.00732803, Validation Accuracy: 0.5441\n",
      "Epoch [4852/10000], Training Loss: 0.64806432, Training Accuracy: 0.9034\n",
      "Epoch [4852/10000], Validation Loss: 1.00732854, Validation Accuracy: 0.5441\n",
      "Epoch [4853/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4853/10000], Validation Loss: 1.00733083, Validation Accuracy: 0.5441\n",
      "Epoch [4854/10000], Training Loss: 0.63963577, Training Accuracy: 0.9118\n",
      "Epoch [4854/10000], Validation Loss: 1.00739828, Validation Accuracy: 0.5441\n",
      "Epoch [4855/10000], Training Loss: 0.63127691, Training Accuracy: 0.9202\n",
      "Epoch [4855/10000], Validation Loss: 1.01726398, Validation Accuracy: 0.5294\n",
      "Epoch [4856/10000], Training Loss: 0.64620346, Training Accuracy: 0.9034\n",
      "Epoch [4856/10000], Validation Loss: 1.01975408, Validation Accuracy: 0.5294\n",
      "Epoch [4857/10000], Training Loss: 0.63969472, Training Accuracy: 0.9118\n",
      "Epoch [4857/10000], Validation Loss: 1.00732765, Validation Accuracy: 0.5441\n",
      "Epoch [4858/10000], Training Loss: 0.64371479, Training Accuracy: 0.9076\n",
      "Epoch [4858/10000], Validation Loss: 1.02204776, Validation Accuracy: 0.5294\n",
      "Epoch [4859/10000], Training Loss: 0.62707524, Training Accuracy: 0.9244\n",
      "Epoch [4859/10000], Validation Loss: 1.02210420, Validation Accuracy: 0.5294\n",
      "Epoch [4860/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4860/10000], Validation Loss: 1.02218419, Validation Accuracy: 0.5294\n",
      "Epoch [4861/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4861/10000], Validation Loss: 1.02224940, Validation Accuracy: 0.5294\n",
      "Epoch [4862/10000], Training Loss: 0.63935444, Training Accuracy: 0.9118\n",
      "Epoch [4862/10000], Validation Loss: 1.02203912, Validation Accuracy: 0.5294\n",
      "Epoch [4863/10000], Training Loss: 0.62287334, Training Accuracy: 0.9286\n",
      "Epoch [4863/10000], Validation Loss: 1.02203608, Validation Accuracy: 0.5294\n",
      "Epoch [4864/10000], Training Loss: 0.63127374, Training Accuracy: 0.9202\n",
      "Epoch [4864/10000], Validation Loss: 1.02203560, Validation Accuracy: 0.5294\n",
      "Epoch [4865/10000], Training Loss: 0.63968022, Training Accuracy: 0.9118\n",
      "Epoch [4865/10000], Validation Loss: 1.02203554, Validation Accuracy: 0.5294\n",
      "Epoch [4866/10000], Training Loss: 0.62270672, Training Accuracy: 0.9286\n",
      "Epoch [4866/10000], Validation Loss: 1.02203417, Validation Accuracy: 0.5294\n",
      "Epoch [4867/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [4867/10000], Validation Loss: 1.02203345, Validation Accuracy: 0.5294\n",
      "Epoch [4868/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4868/10000], Validation Loss: 1.02203333, Validation Accuracy: 0.5294\n",
      "Epoch [4869/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4869/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [4870/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4870/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [4871/10000], Training Loss: 0.64808612, Training Accuracy: 0.9034\n",
      "Epoch [4871/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [4872/10000], Training Loss: 0.64808057, Training Accuracy: 0.9034\n",
      "Epoch [4872/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [4873/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4873/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [4874/10000], Training Loss: 0.62287240, Training Accuracy: 0.9286\n",
      "Epoch [4874/10000], Validation Loss: 1.02203327, Validation Accuracy: 0.5294\n",
      "Epoch [4875/10000], Training Loss: 0.62738274, Training Accuracy: 0.9244\n",
      "Epoch [4875/10000], Validation Loss: 1.03673846, Validation Accuracy: 0.5147\n",
      "Epoch [4876/10000], Training Loss: 0.64807790, Training Accuracy: 0.9034\n",
      "Epoch [4876/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4877/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [4877/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4878/10000], Training Loss: 0.61867176, Training Accuracy: 0.9328\n",
      "Epoch [4878/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4879/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4879/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4880/10000], Training Loss: 0.62287337, Training Accuracy: 0.9286\n",
      "Epoch [4880/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4881/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4881/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4882/10000], Training Loss: 0.63957112, Training Accuracy: 0.9118\n",
      "Epoch [4882/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4883/10000], Training Loss: 0.63547806, Training Accuracy: 0.9160\n",
      "Epoch [4883/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4884/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4884/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4885/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4885/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4886/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4886/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4887/10000], Training Loss: 0.62707147, Training Accuracy: 0.9244\n",
      "Epoch [4887/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4888/10000], Training Loss: 0.61866798, Training Accuracy: 0.9328\n",
      "Epoch [4888/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4889/10000], Training Loss: 0.62707604, Training Accuracy: 0.9244\n",
      "Epoch [4889/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4890/10000], Training Loss: 0.62704815, Training Accuracy: 0.9244\n",
      "Epoch [4890/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4891/10000], Training Loss: 0.63158514, Training Accuracy: 0.9202\n",
      "Epoch [4891/10000], Validation Loss: 1.00736555, Validation Accuracy: 0.5441\n",
      "Epoch [4892/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [4892/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4893/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4893/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4894/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4894/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4895/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4895/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4896/10000], Training Loss: 0.63547835, Training Accuracy: 0.9160\n",
      "Epoch [4896/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [4897/10000], Training Loss: 0.64388189, Training Accuracy: 0.9076\n",
      "Epoch [4897/10000], Validation Loss: 1.00729457, Validation Accuracy: 0.5441\n",
      "Epoch [4898/10000], Training Loss: 0.62704709, Training Accuracy: 0.9244\n",
      "Epoch [4898/10000], Validation Loss: 1.00689718, Validation Accuracy: 0.5441\n",
      "Epoch [4899/10000], Training Loss: 0.64808464, Training Accuracy: 0.9034\n",
      "Epoch [4899/10000], Validation Loss: 1.00532815, Validation Accuracy: 0.5441\n",
      "Epoch [4900/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4900/10000], Validation Loss: 1.00325468, Validation Accuracy: 0.5441\n",
      "Epoch [4901/10000], Training Loss: 0.62289231, Training Accuracy: 0.9286\n",
      "Epoch [4901/10000], Validation Loss: 1.00538686, Validation Accuracy: 0.5441\n",
      "Epoch [4902/10000], Training Loss: 0.61867023, Training Accuracy: 0.9328\n",
      "Epoch [4902/10000], Validation Loss: 1.00711223, Validation Accuracy: 0.5441\n",
      "Epoch [4903/10000], Training Loss: 0.62298172, Training Accuracy: 0.9286\n",
      "Epoch [4903/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4904/10000], Training Loss: 0.62286964, Training Accuracy: 0.9286\n",
      "Epoch [4904/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [4905/10000], Training Loss: 0.64388020, Training Accuracy: 0.9076\n",
      "Epoch [4905/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4906/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4906/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4907/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4907/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4908/10000], Training Loss: 0.62293175, Training Accuracy: 0.9286\n",
      "Epoch [4908/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4909/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4909/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4910/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4910/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4911/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4911/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4912/10000], Training Loss: 0.63141548, Training Accuracy: 0.9202\n",
      "Epoch [4912/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4913/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4913/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4914/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4914/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4915/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4915/10000], Validation Loss: 1.00733542, Validation Accuracy: 0.5441\n",
      "Epoch [4916/10000], Training Loss: 0.63127671, Training Accuracy: 0.9202\n",
      "Epoch [4916/10000], Validation Loss: 1.00767139, Validation Accuracy: 0.5441\n",
      "Epoch [4917/10000], Training Loss: 0.61867181, Training Accuracy: 0.9328\n",
      "Epoch [4917/10000], Validation Loss: 1.00932345, Validation Accuracy: 0.5441\n",
      "Epoch [4918/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4918/10000], Validation Loss: 1.01152563, Validation Accuracy: 0.5441\n",
      "Epoch [4919/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4919/10000], Validation Loss: 1.01301324, Validation Accuracy: 0.5441\n",
      "Epoch [4920/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4920/10000], Validation Loss: 1.01379430, Validation Accuracy: 0.5294\n",
      "Epoch [4921/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [4921/10000], Validation Loss: 1.01417798, Validation Accuracy: 0.5294\n",
      "Epoch [4922/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4922/10000], Validation Loss: 1.01436263, Validation Accuracy: 0.5294\n",
      "Epoch [4923/10000], Training Loss: 0.64911666, Training Accuracy: 0.9034\n",
      "Epoch [4923/10000], Validation Loss: 1.02172035, Validation Accuracy: 0.5294\n",
      "Epoch [4924/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4924/10000], Validation Loss: 1.03017896, Validation Accuracy: 0.5147\n",
      "Epoch [4925/10000], Training Loss: 0.62707316, Training Accuracy: 0.9244\n",
      "Epoch [4925/10000], Validation Loss: 1.02483881, Validation Accuracy: 0.5294\n",
      "Epoch [4926/10000], Training Loss: 0.62115764, Training Accuracy: 0.9286\n",
      "Epoch [4926/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [4927/10000], Training Loss: 0.62694409, Training Accuracy: 0.9244\n",
      "Epoch [4927/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4928/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4928/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [4929/10000], Training Loss: 0.63131380, Training Accuracy: 0.9202\n",
      "Epoch [4929/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4930/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4930/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4931/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4931/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4932/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4932/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4933/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4933/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4934/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [4934/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4935/10000], Training Loss: 0.61859466, Training Accuracy: 0.9328\n",
      "Epoch [4935/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4936/10000], Training Loss: 0.61026801, Training Accuracy: 0.9412\n",
      "Epoch [4936/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4937/10000], Training Loss: 0.61867276, Training Accuracy: 0.9328\n",
      "Epoch [4937/10000], Validation Loss: 1.05144513, Validation Accuracy: 0.5000\n",
      "Epoch [4938/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [4938/10000], Validation Loss: 1.05144680, Validation Accuracy: 0.5000\n",
      "Epoch [4939/10000], Training Loss: 0.61867177, Training Accuracy: 0.9328\n",
      "Epoch [4939/10000], Validation Loss: 1.05145055, Validation Accuracy: 0.5000\n",
      "Epoch [4940/10000], Training Loss: 0.61867195, Training Accuracy: 0.9328\n",
      "Epoch [4940/10000], Validation Loss: 1.05145448, Validation Accuracy: 0.5000\n",
      "Epoch [4941/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4941/10000], Validation Loss: 1.05145711, Validation Accuracy: 0.5000\n",
      "Epoch [4942/10000], Training Loss: 0.61444598, Training Accuracy: 0.9370\n",
      "Epoch [4942/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4943/10000], Training Loss: 0.61851327, Training Accuracy: 0.9328\n",
      "Epoch [4943/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4944/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4944/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4945/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4945/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4946/10000], Training Loss: 0.61398674, Training Accuracy: 0.9370\n",
      "Epoch [4946/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4947/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [4947/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4948/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4948/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4949/10000], Training Loss: 0.61867165, Training Accuracy: 0.9328\n",
      "Epoch [4949/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4950/10000], Training Loss: 0.61445668, Training Accuracy: 0.9370\n",
      "Epoch [4950/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4951/10000], Training Loss: 0.61026788, Training Accuracy: 0.9412\n",
      "Epoch [4951/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4952/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4952/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4953/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4953/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4954/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [4954/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4955/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [4955/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [4956/10000], Training Loss: 0.61787673, Training Accuracy: 0.9328\n",
      "Epoch [4956/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4957/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [4957/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [4958/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4958/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [4959/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [4959/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4960/10000], Training Loss: 0.60593199, Training Accuracy: 0.9454\n",
      "Epoch [4960/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [4961/10000], Training Loss: 0.61867248, Training Accuracy: 0.9328\n",
      "Epoch [4961/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [4962/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [4962/10000], Validation Loss: 1.00735256, Validation Accuracy: 0.5441\n",
      "Epoch [4963/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4963/10000], Validation Loss: 1.00786486, Validation Accuracy: 0.5441\n",
      "Epoch [4964/10000], Training Loss: 0.61014170, Training Accuracy: 0.9412\n",
      "Epoch [4964/10000], Validation Loss: 1.00749615, Validation Accuracy: 0.5441\n",
      "Epoch [4965/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [4965/10000], Validation Loss: 1.00733605, Validation Accuracy: 0.5441\n",
      "Epoch [4966/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [4966/10000], Validation Loss: 1.00732943, Validation Accuracy: 0.5441\n",
      "Epoch [4967/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [4967/10000], Validation Loss: 1.00732836, Validation Accuracy: 0.5441\n",
      "Epoch [4968/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [4968/10000], Validation Loss: 1.00732806, Validation Accuracy: 0.5441\n",
      "Epoch [4969/10000], Training Loss: 0.59350100, Training Accuracy: 0.9580\n",
      "Epoch [4969/10000], Validation Loss: 1.00735226, Validation Accuracy: 0.5441\n",
      "Epoch [4970/10000], Training Loss: 0.61425866, Training Accuracy: 0.9370\n",
      "Epoch [4970/10000], Validation Loss: 0.99263769, Validation Accuracy: 0.5588\n",
      "Epoch [4971/10000], Training Loss: 0.62287208, Training Accuracy: 0.9286\n",
      "Epoch [4971/10000], Validation Loss: 0.99262270, Validation Accuracy: 0.5588\n",
      "Epoch [4972/10000], Training Loss: 0.60800567, Training Accuracy: 0.9412\n",
      "Epoch [4972/10000], Validation Loss: 1.03673911, Validation Accuracy: 0.5147\n",
      "Epoch [4973/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4973/10000], Validation Loss: 1.06613249, Validation Accuracy: 0.4853\n",
      "Epoch [4974/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4974/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4975/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [4975/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [4976/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [4976/10000], Validation Loss: 1.06711465, Validation Accuracy: 0.4853\n",
      "Epoch [4977/10000], Training Loss: 0.62396870, Training Accuracy: 0.9244\n",
      "Epoch [4977/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4978/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4978/10000], Validation Loss: 1.09556335, Validation Accuracy: 0.4559\n",
      "Epoch [4979/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4979/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [4980/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4980/10000], Validation Loss: 1.12335390, Validation Accuracy: 0.4265\n",
      "Epoch [4981/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4981/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4982/10000], Training Loss: 0.62286880, Training Accuracy: 0.9286\n",
      "Epoch [4982/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4983/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4983/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [4984/10000], Training Loss: 0.61384596, Training Accuracy: 0.9370\n",
      "Epoch [4984/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4985/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [4985/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [4986/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4986/10000], Validation Loss: 1.08086711, Validation Accuracy: 0.4706\n",
      "Epoch [4987/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [4987/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [4988/10000], Training Loss: 0.61884343, Training Accuracy: 0.9328\n",
      "Epoch [4988/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4989/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4989/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [4990/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [4990/10000], Validation Loss: 1.03674966, Validation Accuracy: 0.5147\n",
      "Epoch [4991/10000], Training Loss: 0.61012180, Training Accuracy: 0.9412\n",
      "Epoch [4991/10000], Validation Loss: 1.05144602, Validation Accuracy: 0.5000\n",
      "Epoch [4992/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [4992/10000], Validation Loss: 1.05147886, Validation Accuracy: 0.5000\n",
      "Epoch [4993/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [4993/10000], Validation Loss: 1.05162764, Validation Accuracy: 0.5000\n",
      "Epoch [4994/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [4994/10000], Validation Loss: 1.05185479, Validation Accuracy: 0.5000\n",
      "Epoch [4995/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [4995/10000], Validation Loss: 1.05204737, Validation Accuracy: 0.5000\n",
      "Epoch [4996/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [4996/10000], Validation Loss: 1.05216879, Validation Accuracy: 0.5000\n",
      "Epoch [4997/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [4997/10000], Validation Loss: 1.05223525, Validation Accuracy: 0.5000\n",
      "Epoch [4998/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [4998/10000], Validation Loss: 1.05226916, Validation Accuracy: 0.5000\n",
      "Epoch [4999/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [4999/10000], Validation Loss: 1.05228609, Validation Accuracy: 0.5000\n",
      "Epoch [5000/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5000/10000], Validation Loss: 1.05229425, Validation Accuracy: 0.5000\n",
      "Epoch [5001/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [5001/10000], Validation Loss: 1.05229861, Validation Accuracy: 0.5000\n",
      "Epoch [5002/10000], Training Loss: 0.61446949, Training Accuracy: 0.9370\n",
      "Epoch [5002/10000], Validation Loss: 1.05156839, Validation Accuracy: 0.5000\n",
      "Epoch [5003/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5003/10000], Validation Loss: 1.05146301, Validation Accuracy: 0.5000\n",
      "Epoch [5004/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5004/10000], Validation Loss: 1.03674632, Validation Accuracy: 0.5147\n",
      "Epoch [5005/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5005/10000], Validation Loss: 1.03674376, Validation Accuracy: 0.5147\n",
      "Epoch [5006/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5006/10000], Validation Loss: 1.03674287, Validation Accuracy: 0.5147\n",
      "Epoch [5007/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [5007/10000], Validation Loss: 1.03674251, Validation Accuracy: 0.5147\n",
      "Epoch [5008/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5008/10000], Validation Loss: 1.03674239, Validation Accuracy: 0.5147\n",
      "Epoch [5009/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5009/10000], Validation Loss: 1.03674227, Validation Accuracy: 0.5147\n",
      "Epoch [5010/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5010/10000], Validation Loss: 1.03674227, Validation Accuracy: 0.5147\n",
      "Epoch [5011/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5011/10000], Validation Loss: 1.03674221, Validation Accuracy: 0.5147\n",
      "Epoch [5012/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5012/10000], Validation Loss: 1.03674221, Validation Accuracy: 0.5147\n",
      "Epoch [5013/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5013/10000], Validation Loss: 1.03674221, Validation Accuracy: 0.5147\n",
      "Epoch [5014/10000], Training Loss: 0.59772733, Training Accuracy: 0.9538\n",
      "Epoch [5014/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5015/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5015/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [5016/10000], Training Loss: 0.61548753, Training Accuracy: 0.9370\n",
      "Epoch [5016/10000], Validation Loss: 1.05133164, Validation Accuracy: 0.5000\n",
      "Epoch [5017/10000], Training Loss: 0.63126015, Training Accuracy: 0.9202\n",
      "Epoch [5017/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [5018/10000], Training Loss: 0.59346185, Training Accuracy: 0.9580\n",
      "Epoch [5018/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5019/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5019/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5020/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5020/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5021/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5021/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5022/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5022/10000], Validation Loss: 1.02202243, Validation Accuracy: 0.5294\n",
      "Epoch [5023/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5023/10000], Validation Loss: 1.02189922, Validation Accuracy: 0.5294\n",
      "Epoch [5024/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [5024/10000], Validation Loss: 1.02159566, Validation Accuracy: 0.5294\n",
      "Epoch [5025/10000], Training Loss: 0.60186179, Training Accuracy: 0.9496\n",
      "Epoch [5025/10000], Validation Loss: 1.02061695, Validation Accuracy: 0.5294\n",
      "Epoch [5026/10000], Training Loss: 0.61446844, Training Accuracy: 0.9370\n",
      "Epoch [5026/10000], Validation Loss: 1.02157611, Validation Accuracy: 0.5294\n",
      "Epoch [5027/10000], Training Loss: 0.62711446, Training Accuracy: 0.9244\n",
      "Epoch [5027/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5028/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5028/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5029/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5029/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5030/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5030/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5031/10000], Training Loss: 0.61150301, Training Accuracy: 0.9412\n",
      "Epoch [5031/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [5032/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5032/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [5033/10000], Training Loss: 0.62287466, Training Accuracy: 0.9286\n",
      "Epoch [5033/10000], Validation Loss: 1.08085698, Validation Accuracy: 0.4706\n",
      "Epoch [5034/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5034/10000], Validation Loss: 1.11023241, Validation Accuracy: 0.4412\n",
      "Epoch [5035/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5035/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [5036/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5036/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5037/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5037/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5038/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5038/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5039/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5039/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5040/10000], Training Loss: 0.59769957, Training Accuracy: 0.9538\n",
      "Epoch [5040/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5041/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5041/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5042/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5042/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5043/10000], Training Loss: 0.61447021, Training Accuracy: 0.9370\n",
      "Epoch [5043/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5044/10000], Training Loss: 0.60165868, Training Accuracy: 0.9496\n",
      "Epoch [5044/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5045/10000], Training Loss: 0.61445383, Training Accuracy: 0.9370\n",
      "Epoch [5045/10000], Validation Loss: 1.11026818, Validation Accuracy: 0.4412\n",
      "Epoch [5046/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5046/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5047/10000], Training Loss: 0.61027667, Training Accuracy: 0.9412\n",
      "Epoch [5047/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5048/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5048/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5049/10000], Training Loss: 0.61026478, Training Accuracy: 0.9412\n",
      "Epoch [5049/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5050/10000], Training Loss: 0.60631759, Training Accuracy: 0.9454\n",
      "Epoch [5050/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5051/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5051/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5052/10000], Training Loss: 0.64808353, Training Accuracy: 0.9034\n",
      "Epoch [5052/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5053/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5053/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5054/10000], Training Loss: 0.61446917, Training Accuracy: 0.9370\n",
      "Epoch [5054/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5055/10000], Training Loss: 0.63968331, Training Accuracy: 0.9118\n",
      "Epoch [5055/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5056/10000], Training Loss: 0.61867188, Training Accuracy: 0.9328\n",
      "Epoch [5056/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5057/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5057/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5058/10000], Training Loss: 0.61212693, Training Accuracy: 0.9412\n",
      "Epoch [5058/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5059/10000], Training Loss: 0.61880397, Training Accuracy: 0.9328\n",
      "Epoch [5059/10000], Validation Loss: 1.11612767, Validation Accuracy: 0.4412\n",
      "Epoch [5060/10000], Training Loss: 0.60645135, Training Accuracy: 0.9454\n",
      "Epoch [5060/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5061/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5061/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5062/10000], Training Loss: 0.63131335, Training Accuracy: 0.9202\n",
      "Epoch [5062/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5063/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5063/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5064/10000], Training Loss: 0.61537094, Training Accuracy: 0.9370\n",
      "Epoch [5064/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [5065/10000], Training Loss: 0.62300561, Training Accuracy: 0.9286\n",
      "Epoch [5065/10000], Validation Loss: 1.09556234, Validation Accuracy: 0.4559\n",
      "Epoch [5066/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5066/10000], Validation Loss: 1.09374744, Validation Accuracy: 0.4559\n",
      "Epoch [5067/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5067/10000], Validation Loss: 1.09620672, Validation Accuracy: 0.4559\n",
      "Epoch [5068/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5068/10000], Validation Loss: 1.08135474, Validation Accuracy: 0.4706\n",
      "Epoch [5069/10000], Training Loss: 0.59828786, Training Accuracy: 0.9496\n",
      "Epoch [5069/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5070/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5070/10000], Validation Loss: 1.05153000, Validation Accuracy: 0.5000\n",
      "Epoch [5071/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5071/10000], Validation Loss: 1.04463890, Validation Accuracy: 0.5000\n",
      "Epoch [5072/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5072/10000], Validation Loss: 1.03582084, Validation Accuracy: 0.5147\n",
      "Epoch [5073/10000], Training Loss: 0.58925487, Training Accuracy: 0.9622\n",
      "Epoch [5073/10000], Validation Loss: 1.03655195, Validation Accuracy: 0.5147\n",
      "Epoch [5074/10000], Training Loss: 0.60572064, Training Accuracy: 0.9454\n",
      "Epoch [5074/10000], Validation Loss: 1.03653944, Validation Accuracy: 0.5147\n",
      "Epoch [5075/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5075/10000], Validation Loss: 1.03653330, Validation Accuracy: 0.5147\n",
      "Epoch [5076/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [5076/10000], Validation Loss: 1.03653073, Validation Accuracy: 0.5147\n",
      "Epoch [5077/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5077/10000], Validation Loss: 1.03653002, Validation Accuracy: 0.5147\n",
      "Epoch [5078/10000], Training Loss: 0.59766308, Training Accuracy: 0.9538\n",
      "Epoch [5078/10000], Validation Loss: 1.03653044, Validation Accuracy: 0.5147\n",
      "Epoch [5079/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5079/10000], Validation Loss: 1.03653085, Validation Accuracy: 0.5147\n",
      "Epoch [5080/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5080/10000], Validation Loss: 1.03653103, Validation Accuracy: 0.5147\n",
      "Epoch [5081/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5081/10000], Validation Loss: 1.03653109, Validation Accuracy: 0.5147\n",
      "Epoch [5082/10000], Training Loss: 0.60968554, Training Accuracy: 0.9412\n",
      "Epoch [5082/10000], Validation Loss: 1.03665340, Validation Accuracy: 0.5147\n",
      "Epoch [5083/10000], Training Loss: 0.61026638, Training Accuracy: 0.9412\n",
      "Epoch [5083/10000], Validation Loss: 1.05148935, Validation Accuracy: 0.5000\n",
      "Epoch [5084/10000], Training Loss: 0.61021493, Training Accuracy: 0.9412\n",
      "Epoch [5084/10000], Validation Loss: 1.08001286, Validation Accuracy: 0.4706\n",
      "Epoch [5085/10000], Training Loss: 0.60521531, Training Accuracy: 0.9454\n",
      "Epoch [5085/10000], Validation Loss: 1.05275717, Validation Accuracy: 0.5000\n",
      "Epoch [5086/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5086/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5087/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5087/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5088/10000], Training Loss: 0.60594211, Training Accuracy: 0.9454\n",
      "Epoch [5088/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5089/10000], Training Loss: 0.60327243, Training Accuracy: 0.9496\n",
      "Epoch [5089/10000], Validation Loss: 1.04493970, Validation Accuracy: 0.5000\n",
      "Epoch [5090/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5090/10000], Validation Loss: 1.02204865, Validation Accuracy: 0.5294\n",
      "Epoch [5091/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5091/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5092/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5092/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5093/10000], Training Loss: 0.61030913, Training Accuracy: 0.9412\n",
      "Epoch [5093/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5094/10000], Training Loss: 0.62707881, Training Accuracy: 0.9244\n",
      "Epoch [5094/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5095/10000], Training Loss: 0.62287177, Training Accuracy: 0.9286\n",
      "Epoch [5095/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5096/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5096/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5097/10000], Training Loss: 0.60604238, Training Accuracy: 0.9454\n",
      "Epoch [5097/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5098/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5098/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5099/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5099/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5100/10000], Training Loss: 0.61637572, Training Accuracy: 0.9328\n",
      "Epoch [5100/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5101/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5101/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5102/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5102/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5103/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5103/10000], Validation Loss: 1.06615096, Validation Accuracy: 0.4853\n",
      "Epoch [5104/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5104/10000], Validation Loss: 1.06616163, Validation Accuracy: 0.4853\n",
      "Epoch [5105/10000], Training Loss: 0.61867269, Training Accuracy: 0.9328\n",
      "Epoch [5105/10000], Validation Loss: 1.06639117, Validation Accuracy: 0.4853\n",
      "Epoch [5106/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5106/10000], Validation Loss: 1.06717819, Validation Accuracy: 0.4853\n",
      "Epoch [5107/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5107/10000], Validation Loss: 1.06814682, Validation Accuracy: 0.4853\n",
      "Epoch [5108/10000], Training Loss: 0.59766349, Training Accuracy: 0.9538\n",
      "Epoch [5108/10000], Validation Loss: 1.06885761, Validation Accuracy: 0.4853\n",
      "Epoch [5109/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5109/10000], Validation Loss: 1.06927502, Validation Accuracy: 0.4853\n",
      "Epoch [5110/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5110/10000], Validation Loss: 1.06949204, Validation Accuracy: 0.4853\n",
      "Epoch [5111/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5111/10000], Validation Loss: 1.06959969, Validation Accuracy: 0.4853\n",
      "Epoch [5112/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5112/10000], Validation Loss: 1.06965178, Validation Accuracy: 0.4853\n",
      "Epoch [5113/10000], Training Loss: 0.60646918, Training Accuracy: 0.9454\n",
      "Epoch [5113/10000], Validation Loss: 1.09556270, Validation Accuracy: 0.4559\n",
      "Epoch [5114/10000], Training Loss: 0.60186342, Training Accuracy: 0.9496\n",
      "Epoch [5114/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5115/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5115/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5116/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5116/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5117/10000], Training Loss: 0.62717785, Training Accuracy: 0.9244\n",
      "Epoch [5117/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5118/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5118/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5119/10000], Training Loss: 0.63548529, Training Accuracy: 0.9160\n",
      "Epoch [5119/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5120/10000], Training Loss: 0.62707514, Training Accuracy: 0.9244\n",
      "Epoch [5120/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5121/10000], Training Loss: 0.60606690, Training Accuracy: 0.9454\n",
      "Epoch [5121/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5122/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5122/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5123/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5123/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5124/10000], Training Loss: 0.61014178, Training Accuracy: 0.9412\n",
      "Epoch [5124/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5125/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5125/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5126/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5126/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5127/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [5127/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5128/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5128/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5129/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5129/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5130/10000], Training Loss: 0.60606731, Training Accuracy: 0.9454\n",
      "Epoch [5130/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5131/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [5131/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5132/10000], Training Loss: 0.59780103, Training Accuracy: 0.9538\n",
      "Epoch [5132/10000], Validation Loss: 1.11009729, Validation Accuracy: 0.4412\n",
      "Epoch [5133/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5133/10000], Validation Loss: 1.09851485, Validation Accuracy: 0.4559\n",
      "Epoch [5134/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5134/10000], Validation Loss: 1.09580040, Validation Accuracy: 0.4559\n",
      "Epoch [5135/10000], Training Loss: 0.62708722, Training Accuracy: 0.9244\n",
      "Epoch [5135/10000], Validation Loss: 1.09557140, Validation Accuracy: 0.4559\n",
      "Epoch [5136/10000], Training Loss: 0.61866946, Training Accuracy: 0.9328\n",
      "Epoch [5136/10000], Validation Loss: 1.09556323, Validation Accuracy: 0.4559\n",
      "Epoch [5137/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5137/10000], Validation Loss: 1.09556270, Validation Accuracy: 0.4559\n",
      "Epoch [5138/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5138/10000], Validation Loss: 1.09556264, Validation Accuracy: 0.4559\n",
      "Epoch [5139/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5139/10000], Validation Loss: 1.09556264, Validation Accuracy: 0.4559\n",
      "Epoch [5140/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5140/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5141/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [5141/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5142/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [5142/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5143/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5143/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5144/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5144/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5145/10000], Training Loss: 0.61265297, Training Accuracy: 0.9370\n",
      "Epoch [5145/10000], Validation Loss: 1.10992026, Validation Accuracy: 0.4412\n",
      "Epoch [5146/10000], Training Loss: 0.60319796, Training Accuracy: 0.9496\n",
      "Epoch [5146/10000], Validation Loss: 1.10986632, Validation Accuracy: 0.4412\n",
      "Epoch [5147/10000], Training Loss: 0.63127675, Training Accuracy: 0.9202\n",
      "Epoch [5147/10000], Validation Loss: 1.12482470, Validation Accuracy: 0.4265\n",
      "Epoch [5148/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5148/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5149/10000], Training Loss: 0.61182332, Training Accuracy: 0.9412\n",
      "Epoch [5149/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [5150/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [5150/10000], Validation Loss: 1.15438569, Validation Accuracy: 0.3971\n",
      "Epoch [5151/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5151/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5152/10000], Training Loss: 0.63524337, Training Accuracy: 0.9160\n",
      "Epoch [5152/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5153/10000], Training Loss: 0.60672704, Training Accuracy: 0.9454\n",
      "Epoch [5153/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5154/10000], Training Loss: 0.61444882, Training Accuracy: 0.9370\n",
      "Epoch [5154/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5155/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5155/10000], Validation Loss: 1.13967586, Validation Accuracy: 0.4118\n",
      "Epoch [5156/10000], Training Loss: 0.59346692, Training Accuracy: 0.9580\n",
      "Epoch [5156/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5157/10000], Training Loss: 0.61447014, Training Accuracy: 0.9370\n",
      "Epoch [5157/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5158/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5158/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5159/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5159/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5160/10000], Training Loss: 0.61867554, Training Accuracy: 0.9328\n",
      "Epoch [5160/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5161/10000], Training Loss: 0.60187007, Training Accuracy: 0.9496\n",
      "Epoch [5161/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5162/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5162/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5163/10000], Training Loss: 0.60601766, Training Accuracy: 0.9454\n",
      "Epoch [5163/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5164/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5164/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5165/10000], Training Loss: 0.60209738, Training Accuracy: 0.9496\n",
      "Epoch [5165/10000], Validation Loss: 1.13967633, Validation Accuracy: 0.4118\n",
      "Epoch [5166/10000], Training Loss: 0.60558625, Training Accuracy: 0.9454\n",
      "Epoch [5166/10000], Validation Loss: 1.11177307, Validation Accuracy: 0.4412\n",
      "Epoch [5167/10000], Training Loss: 0.60186517, Training Accuracy: 0.9496\n",
      "Epoch [5167/10000], Validation Loss: 1.09480500, Validation Accuracy: 0.4559\n",
      "Epoch [5168/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5168/10000], Validation Loss: 1.09556246, Validation Accuracy: 0.4559\n",
      "Epoch [5169/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5169/10000], Validation Loss: 1.06727773, Validation Accuracy: 0.4853\n",
      "Epoch [5170/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5170/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5171/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5171/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5172/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5172/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5173/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5173/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5174/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5174/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5175/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5175/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5176/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5176/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5177/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5177/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5178/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5178/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5179/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5179/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5180/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5180/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [5181/10000], Training Loss: 0.60129546, Training Accuracy: 0.9496\n",
      "Epoch [5181/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5182/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5182/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5183/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5183/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5184/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5184/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5185/10000], Training Loss: 0.60605876, Training Accuracy: 0.9454\n",
      "Epoch [5185/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5186/10000], Training Loss: 0.58906106, Training Accuracy: 0.9622\n",
      "Epoch [5186/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5187/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5187/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5188/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5188/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5189/10000], Training Loss: 0.60618324, Training Accuracy: 0.9454\n",
      "Epoch [5189/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5190/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5190/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5191/10000], Training Loss: 0.59370593, Training Accuracy: 0.9580\n",
      "Epoch [5191/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5192/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5192/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5193/10000], Training Loss: 0.59352307, Training Accuracy: 0.9580\n",
      "Epoch [5193/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5194/10000], Training Loss: 0.61446566, Training Accuracy: 0.9370\n",
      "Epoch [5194/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5195/10000], Training Loss: 0.60186504, Training Accuracy: 0.9496\n",
      "Epoch [5195/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5196/10000], Training Loss: 0.59766319, Training Accuracy: 0.9538\n",
      "Epoch [5196/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5197/10000], Training Loss: 0.59766358, Training Accuracy: 0.9538\n",
      "Epoch [5197/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5198/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5198/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5199/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [5199/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5200/10000], Training Loss: 0.59351391, Training Accuracy: 0.9580\n",
      "Epoch [5200/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5201/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5201/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5202/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5202/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5203/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5203/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5204/10000], Training Loss: 0.60943751, Training Accuracy: 0.9412\n",
      "Epoch [5204/10000], Validation Loss: 1.09498966, Validation Accuracy: 0.4559\n",
      "Epoch [5205/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5205/10000], Validation Loss: 1.05144507, Validation Accuracy: 0.5000\n",
      "Epoch [5206/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5206/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5207/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5207/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5208/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5208/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5209/10000], Training Loss: 0.58085683, Training Accuracy: 0.9706\n",
      "Epoch [5209/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5210/10000], Training Loss: 0.63127494, Training Accuracy: 0.9202\n",
      "Epoch [5210/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5211/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5211/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5212/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5212/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5213/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5213/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5214/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [5214/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5215/10000], Training Loss: 0.60603296, Training Accuracy: 0.9454\n",
      "Epoch [5215/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5216/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5216/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5217/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5217/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5218/10000], Training Loss: 0.61027305, Training Accuracy: 0.9412\n",
      "Epoch [5218/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5219/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5219/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5220/10000], Training Loss: 0.59764784, Training Accuracy: 0.9538\n",
      "Epoch [5220/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5221/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5221/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5222/10000], Training Loss: 0.60555173, Training Accuracy: 0.9454\n",
      "Epoch [5222/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5223/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5223/10000], Validation Loss: 1.08085781, Validation Accuracy: 0.4706\n",
      "Epoch [5224/10000], Training Loss: 0.58925997, Training Accuracy: 0.9622\n",
      "Epoch [5224/10000], Validation Loss: 1.08089370, Validation Accuracy: 0.4706\n",
      "Epoch [5225/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5225/10000], Validation Loss: 1.08103746, Validation Accuracy: 0.4706\n",
      "Epoch [5226/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5226/10000], Validation Loss: 1.08123660, Validation Accuracy: 0.4706\n",
      "Epoch [5227/10000], Training Loss: 0.58925997, Training Accuracy: 0.9622\n",
      "Epoch [5227/10000], Validation Loss: 1.08137506, Validation Accuracy: 0.4706\n",
      "Epoch [5228/10000], Training Loss: 0.61327239, Training Accuracy: 0.9370\n",
      "Epoch [5228/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5229/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5229/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5230/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5230/10000], Validation Loss: 1.15252900, Validation Accuracy: 0.3971\n",
      "Epoch [5231/10000], Training Loss: 0.59345891, Training Accuracy: 0.9580\n",
      "Epoch [5231/10000], Validation Loss: 1.12496901, Validation Accuracy: 0.4265\n",
      "Epoch [5232/10000], Training Loss: 0.61026021, Training Accuracy: 0.9412\n",
      "Epoch [5232/10000], Validation Loss: 1.11050588, Validation Accuracy: 0.4412\n",
      "Epoch [5233/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5233/10000], Validation Loss: 1.11026949, Validation Accuracy: 0.4412\n",
      "Epoch [5234/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5234/10000], Validation Loss: 1.11026853, Validation Accuracy: 0.4412\n",
      "Epoch [5235/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5235/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [5236/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5236/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [5237/10000], Training Loss: 0.61866266, Training Accuracy: 0.9328\n",
      "Epoch [5237/10000], Validation Loss: 1.11029589, Validation Accuracy: 0.4412\n",
      "Epoch [5238/10000], Training Loss: 0.59346213, Training Accuracy: 0.9580\n",
      "Epoch [5238/10000], Validation Loss: 1.11354917, Validation Accuracy: 0.4412\n",
      "Epoch [5239/10000], Training Loss: 0.58945837, Training Accuracy: 0.9622\n",
      "Epoch [5239/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5240/10000], Training Loss: 0.60186498, Training Accuracy: 0.9496\n",
      "Epoch [5240/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5241/10000], Training Loss: 0.59594109, Training Accuracy: 0.9538\n",
      "Epoch [5241/10000], Validation Loss: 1.11026847, Validation Accuracy: 0.4412\n",
      "Epoch [5242/10000], Training Loss: 0.60186359, Training Accuracy: 0.9496\n",
      "Epoch [5242/10000], Validation Loss: 1.07135069, Validation Accuracy: 0.4853\n",
      "Epoch [5243/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5243/10000], Validation Loss: 1.03667942, Validation Accuracy: 0.5147\n",
      "Epoch [5244/10000], Training Loss: 0.60059477, Training Accuracy: 0.9496\n",
      "Epoch [5244/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5245/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5245/10000], Validation Loss: 1.04943639, Validation Accuracy: 0.5000\n",
      "Epoch [5246/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5246/10000], Validation Loss: 1.06595027, Validation Accuracy: 0.4853\n",
      "Epoch [5247/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5247/10000], Validation Loss: 1.06614727, Validation Accuracy: 0.4853\n",
      "Epoch [5248/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5248/10000], Validation Loss: 1.06615025, Validation Accuracy: 0.4853\n",
      "Epoch [5249/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5249/10000], Validation Loss: 1.06615067, Validation Accuracy: 0.4853\n",
      "Epoch [5250/10000], Training Loss: 0.61343686, Training Accuracy: 0.9370\n",
      "Epoch [5250/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [5251/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [5251/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5252/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5252/10000], Validation Loss: 1.12561727, Validation Accuracy: 0.4265\n",
      "Epoch [5253/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5253/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5254/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5254/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5255/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5255/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5256/10000], Training Loss: 0.59483988, Training Accuracy: 0.9580\n",
      "Epoch [5256/10000], Validation Loss: 1.11026865, Validation Accuracy: 0.4412\n",
      "Epoch [5257/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5257/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5258/10000], Training Loss: 0.59763510, Training Accuracy: 0.9538\n",
      "Epoch [5258/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5259/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5259/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5260/10000], Training Loss: 0.60186504, Training Accuracy: 0.9496\n",
      "Epoch [5260/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5261/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5261/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5262/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5262/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5263/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5263/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5264/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5264/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5265/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5265/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5266/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5266/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5267/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5267/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5268/10000], Training Loss: 0.59767132, Training Accuracy: 0.9538\n",
      "Epoch [5268/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5269/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5269/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5270/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5270/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5271/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5271/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5272/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5272/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [5273/10000], Training Loss: 0.61589818, Training Accuracy: 0.9370\n",
      "Epoch [5273/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5274/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5274/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5275/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5275/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5276/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5276/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5277/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5277/10000], Validation Loss: 1.15439999, Validation Accuracy: 0.3971\n",
      "Epoch [5278/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5278/10000], Validation Loss: 1.16772550, Validation Accuracy: 0.3824\n",
      "Epoch [5279/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5279/10000], Validation Loss: 1.16907340, Validation Accuracy: 0.3824\n",
      "Epoch [5280/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5280/10000], Validation Loss: 1.16908967, Validation Accuracy: 0.3824\n",
      "Epoch [5281/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5281/10000], Validation Loss: 1.16909111, Validation Accuracy: 0.3824\n",
      "Epoch [5282/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5282/10000], Validation Loss: 1.16909146, Validation Accuracy: 0.3824\n",
      "Epoch [5283/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5283/10000], Validation Loss: 1.16909158, Validation Accuracy: 0.3824\n",
      "Epoch [5284/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5284/10000], Validation Loss: 1.16909158, Validation Accuracy: 0.3824\n",
      "Epoch [5285/10000], Training Loss: 0.60666123, Training Accuracy: 0.9454\n",
      "Epoch [5285/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5286/10000], Training Loss: 0.59685586, Training Accuracy: 0.9538\n",
      "Epoch [5286/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5287/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5287/10000], Validation Loss: 1.19868761, Validation Accuracy: 0.3529\n",
      "Epoch [5288/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5288/10000], Validation Loss: 1.19848752, Validation Accuracy: 0.3529\n",
      "Epoch [5289/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5289/10000], Validation Loss: 1.16910607, Validation Accuracy: 0.3824\n",
      "Epoch [5290/10000], Training Loss: 0.59750098, Training Accuracy: 0.9538\n",
      "Epoch [5290/10000], Validation Loss: 1.17852640, Validation Accuracy: 0.3676\n",
      "Epoch [5291/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5291/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5292/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5292/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5293/10000], Training Loss: 0.60572247, Training Accuracy: 0.9454\n",
      "Epoch [5293/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5294/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5294/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5295/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5295/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5296/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5296/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5297/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5297/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5298/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5298/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5299/10000], Training Loss: 0.61026921, Training Accuracy: 0.9412\n",
      "Epoch [5299/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5300/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5300/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5301/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5301/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5302/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5302/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5303/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5303/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5304/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5304/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5305/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5305/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5306/10000], Training Loss: 0.60179163, Training Accuracy: 0.9496\n",
      "Epoch [5306/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5307/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5307/10000], Validation Loss: 1.15635860, Validation Accuracy: 0.3971\n",
      "Epoch [5308/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5308/10000], Validation Loss: 1.15438908, Validation Accuracy: 0.3971\n",
      "Epoch [5309/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5309/10000], Validation Loss: 1.15438622, Validation Accuracy: 0.3971\n",
      "Epoch [5310/10000], Training Loss: 0.59346169, Training Accuracy: 0.9580\n",
      "Epoch [5310/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5311/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5311/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5312/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5312/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5313/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5313/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5314/10000], Training Loss: 0.58925975, Training Accuracy: 0.9622\n",
      "Epoch [5314/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5315/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5315/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5316/10000], Training Loss: 0.58926000, Training Accuracy: 0.9622\n",
      "Epoch [5316/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5317/10000], Training Loss: 0.61026854, Training Accuracy: 0.9412\n",
      "Epoch [5317/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5318/10000], Training Loss: 0.61445915, Training Accuracy: 0.9370\n",
      "Epoch [5318/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5319/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5319/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5320/10000], Training Loss: 0.58908598, Training Accuracy: 0.9622\n",
      "Epoch [5320/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5321/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5321/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5322/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5322/10000], Validation Loss: 1.15438628, Validation Accuracy: 0.3971\n",
      "Epoch [5323/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5323/10000], Validation Loss: 1.15439379, Validation Accuracy: 0.3971\n",
      "Epoch [5324/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5324/10000], Validation Loss: 1.15443218, Validation Accuracy: 0.3971\n",
      "Epoch [5325/10000], Training Loss: 0.59766354, Training Accuracy: 0.9538\n",
      "Epoch [5325/10000], Validation Loss: 1.15449345, Validation Accuracy: 0.3971\n",
      "Epoch [5326/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5326/10000], Validation Loss: 1.15454483, Validation Accuracy: 0.3971\n",
      "Epoch [5327/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5327/10000], Validation Loss: 1.15457749, Validation Accuracy: 0.3971\n",
      "Epoch [5328/10000], Training Loss: 0.60186693, Training Accuracy: 0.9496\n",
      "Epoch [5328/10000], Validation Loss: 1.15459198, Validation Accuracy: 0.3971\n",
      "Epoch [5329/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5329/10000], Validation Loss: 1.15459895, Validation Accuracy: 0.3971\n",
      "Epoch [5330/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5330/10000], Validation Loss: 1.15460235, Validation Accuracy: 0.3971\n",
      "Epoch [5331/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5331/10000], Validation Loss: 1.15460402, Validation Accuracy: 0.3971\n",
      "Epoch [5332/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5332/10000], Validation Loss: 1.15460479, Validation Accuracy: 0.3971\n",
      "Epoch [5333/10000], Training Loss: 0.59766255, Training Accuracy: 0.9538\n",
      "Epoch [5333/10000], Validation Loss: 1.15475404, Validation Accuracy: 0.3971\n",
      "Epoch [5334/10000], Training Loss: 0.59766243, Training Accuracy: 0.9538\n",
      "Epoch [5334/10000], Validation Loss: 1.15505850, Validation Accuracy: 0.3971\n",
      "Epoch [5335/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5335/10000], Validation Loss: 1.15528893, Validation Accuracy: 0.3971\n",
      "Epoch [5336/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5336/10000], Validation Loss: 1.15542412, Validation Accuracy: 0.3971\n",
      "Epoch [5337/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5337/10000], Validation Loss: 1.15549582, Validation Accuracy: 0.3971\n",
      "Epoch [5338/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5338/10000], Validation Loss: 1.15553159, Validation Accuracy: 0.3971\n",
      "Epoch [5339/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5339/10000], Validation Loss: 1.15554929, Validation Accuracy: 0.3971\n",
      "Epoch [5340/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5340/10000], Validation Loss: 1.15555769, Validation Accuracy: 0.3971\n",
      "Epoch [5341/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5341/10000], Validation Loss: 1.15556133, Validation Accuracy: 0.3971\n",
      "Epoch [5342/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5342/10000], Validation Loss: 1.15556300, Validation Accuracy: 0.3971\n",
      "Epoch [5343/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5343/10000], Validation Loss: 1.15556365, Validation Accuracy: 0.3971\n",
      "Epoch [5344/10000], Training Loss: 0.59337728, Training Accuracy: 0.9580\n",
      "Epoch [5344/10000], Validation Loss: 1.15453172, Validation Accuracy: 0.3971\n",
      "Epoch [5345/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5345/10000], Validation Loss: 1.15439308, Validation Accuracy: 0.3971\n",
      "Epoch [5346/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5346/10000], Validation Loss: 1.15438771, Validation Accuracy: 0.3971\n",
      "Epoch [5347/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5347/10000], Validation Loss: 1.15438682, Validation Accuracy: 0.3971\n",
      "Epoch [5348/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5348/10000], Validation Loss: 1.15438646, Validation Accuracy: 0.3971\n",
      "Epoch [5349/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5349/10000], Validation Loss: 1.15438628, Validation Accuracy: 0.3971\n",
      "Epoch [5350/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5350/10000], Validation Loss: 1.15438616, Validation Accuracy: 0.3971\n",
      "Epoch [5351/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5351/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5352/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5352/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5353/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5353/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5354/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5354/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5355/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5355/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5356/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5356/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5357/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5357/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5358/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5358/10000], Validation Loss: 1.15438604, Validation Accuracy: 0.3971\n",
      "Epoch [5359/10000], Training Loss: 0.60889240, Training Accuracy: 0.9412\n",
      "Epoch [5359/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5360/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5360/10000], Validation Loss: 1.14596784, Validation Accuracy: 0.3971\n",
      "Epoch [5361/10000], Training Loss: 0.59768480, Training Accuracy: 0.9538\n",
      "Epoch [5361/10000], Validation Loss: 1.09698331, Validation Accuracy: 0.4559\n",
      "Epoch [5362/10000], Training Loss: 0.60516749, Training Accuracy: 0.9454\n",
      "Epoch [5362/10000], Validation Loss: 1.12542349, Validation Accuracy: 0.4265\n",
      "Epoch [5363/10000], Training Loss: 0.59766257, Training Accuracy: 0.9538\n",
      "Epoch [5363/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5364/10000], Training Loss: 0.61453646, Training Accuracy: 0.9370\n",
      "Epoch [5364/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5365/10000], Training Loss: 0.59758229, Training Accuracy: 0.9538\n",
      "Epoch [5365/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5366/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5366/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5367/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5367/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5368/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5368/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5369/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5369/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5370/10000], Training Loss: 0.59766319, Training Accuracy: 0.9538\n",
      "Epoch [5370/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5371/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5371/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5372/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5372/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5373/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [5373/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5374/10000], Training Loss: 0.62285831, Training Accuracy: 0.9286\n",
      "Epoch [5374/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5375/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5375/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5376/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5376/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5377/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [5377/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5378/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5378/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5379/10000], Training Loss: 0.59768069, Training Accuracy: 0.9538\n",
      "Epoch [5379/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5380/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5380/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5381/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5381/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5382/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5382/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5383/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5383/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5384/10000], Training Loss: 0.57665503, Training Accuracy: 0.9748\n",
      "Epoch [5384/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5385/10000], Training Loss: 0.59766339, Training Accuracy: 0.9538\n",
      "Epoch [5385/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5386/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5386/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5387/10000], Training Loss: 0.58926233, Training Accuracy: 0.9622\n",
      "Epoch [5387/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5388/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5388/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5389/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5389/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5390/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5390/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5391/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5391/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5392/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5392/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5393/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5393/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5394/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5394/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5395/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5395/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5396/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5396/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5397/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [5397/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5398/10000], Training Loss: 0.58482468, Training Accuracy: 0.9664\n",
      "Epoch [5398/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5399/10000], Training Loss: 0.59769381, Training Accuracy: 0.9538\n",
      "Epoch [5399/10000], Validation Loss: 1.16909194, Validation Accuracy: 0.3824\n",
      "Epoch [5400/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5400/10000], Validation Loss: 1.16906369, Validation Accuracy: 0.3824\n",
      "Epoch [5401/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5401/10000], Validation Loss: 1.14014012, Validation Accuracy: 0.4118\n",
      "Epoch [5402/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5402/10000], Validation Loss: 1.13968408, Validation Accuracy: 0.4118\n",
      "Epoch [5403/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5403/10000], Validation Loss: 1.13968056, Validation Accuracy: 0.4118\n",
      "Epoch [5404/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5404/10000], Validation Loss: 1.13968033, Validation Accuracy: 0.4118\n",
      "Epoch [5405/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5405/10000], Validation Loss: 1.13968027, Validation Accuracy: 0.4118\n",
      "Epoch [5406/10000], Training Loss: 0.59766364, Training Accuracy: 0.9538\n",
      "Epoch [5406/10000], Validation Loss: 1.13968027, Validation Accuracy: 0.4118\n",
      "Epoch [5407/10000], Training Loss: 0.59346188, Training Accuracy: 0.9580\n",
      "Epoch [5407/10000], Validation Loss: 1.13968027, Validation Accuracy: 0.4118\n",
      "Epoch [5408/10000], Training Loss: 0.58505462, Training Accuracy: 0.9664\n",
      "Epoch [5408/10000], Validation Loss: 1.13968027, Validation Accuracy: 0.4118\n",
      "Epoch [5409/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5409/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5410/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5410/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5411/10000], Training Loss: 0.60651001, Training Accuracy: 0.9454\n",
      "Epoch [5411/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5412/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5412/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5413/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5413/10000], Validation Loss: 1.08087170, Validation Accuracy: 0.4706\n",
      "Epoch [5414/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5414/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5415/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5415/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5416/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5416/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5417/10000], Training Loss: 0.60605311, Training Accuracy: 0.9454\n",
      "Epoch [5417/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5418/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5418/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5419/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5419/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5420/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5420/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5421/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5421/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5422/10000], Training Loss: 0.63127828, Training Accuracy: 0.9202\n",
      "Epoch [5422/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5423/10000], Training Loss: 0.60914447, Training Accuracy: 0.9412\n",
      "Epoch [5423/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5424/10000], Training Loss: 0.61027002, Training Accuracy: 0.9412\n",
      "Epoch [5424/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5425/10000], Training Loss: 0.59764787, Training Accuracy: 0.9538\n",
      "Epoch [5425/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5426/10000], Training Loss: 0.60603281, Training Accuracy: 0.9454\n",
      "Epoch [5426/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5427/10000], Training Loss: 0.60606452, Training Accuracy: 0.9454\n",
      "Epoch [5427/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5428/10000], Training Loss: 0.59777753, Training Accuracy: 0.9538\n",
      "Epoch [5428/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5429/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5429/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5430/10000], Training Loss: 0.60186504, Training Accuracy: 0.9496\n",
      "Epoch [5430/10000], Validation Loss: 1.13891518, Validation Accuracy: 0.4118\n",
      "Epoch [5431/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5431/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5432/10000], Training Loss: 0.60607094, Training Accuracy: 0.9454\n",
      "Epoch [5432/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5433/10000], Training Loss: 0.60606616, Training Accuracy: 0.9454\n",
      "Epoch [5433/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5434/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5434/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5435/10000], Training Loss: 0.61447045, Training Accuracy: 0.9370\n",
      "Epoch [5435/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5436/10000], Training Loss: 0.58926001, Training Accuracy: 0.9622\n",
      "Epoch [5436/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5437/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [5437/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5438/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [5438/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5439/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5439/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5440/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5440/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5441/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [5441/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5442/10000], Training Loss: 0.61026726, Training Accuracy: 0.9412\n",
      "Epoch [5442/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5443/10000], Training Loss: 0.59244970, Training Accuracy: 0.9580\n",
      "Epoch [5443/10000], Validation Loss: 1.13970655, Validation Accuracy: 0.4118\n",
      "Epoch [5444/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [5444/10000], Validation Loss: 1.14562613, Validation Accuracy: 0.4118\n",
      "Epoch [5445/10000], Training Loss: 0.59788861, Training Accuracy: 0.9538\n",
      "Epoch [5445/10000], Validation Loss: 1.15438557, Validation Accuracy: 0.3971\n",
      "Epoch [5446/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5446/10000], Validation Loss: 1.15274358, Validation Accuracy: 0.3971\n",
      "Epoch [5447/10000], Training Loss: 0.59343043, Training Accuracy: 0.9580\n",
      "Epoch [5447/10000], Validation Loss: 1.13962662, Validation Accuracy: 0.4118\n",
      "Epoch [5448/10000], Training Loss: 0.59308981, Training Accuracy: 0.9580\n",
      "Epoch [5448/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5449/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5449/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5450/10000], Training Loss: 0.59347392, Training Accuracy: 0.9580\n",
      "Epoch [5450/10000], Validation Loss: 1.13967967, Validation Accuracy: 0.4118\n",
      "Epoch [5451/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5451/10000], Validation Loss: 1.13959783, Validation Accuracy: 0.4118\n",
      "Epoch [5452/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5452/10000], Validation Loss: 1.13968003, Validation Accuracy: 0.4118\n",
      "Epoch [5453/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5453/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5454/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5454/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5455/10000], Training Loss: 0.60632625, Training Accuracy: 0.9454\n",
      "Epoch [5455/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5456/10000], Training Loss: 0.59346090, Training Accuracy: 0.9580\n",
      "Epoch [5456/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5457/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [5457/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5458/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5458/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5459/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [5459/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5460/10000], Training Loss: 0.58505854, Training Accuracy: 0.9664\n",
      "Epoch [5460/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5461/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5461/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5462/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5462/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5463/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5463/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5464/10000], Training Loss: 0.59765650, Training Accuracy: 0.9538\n",
      "Epoch [5464/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5465/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5465/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5466/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5466/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5467/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [5467/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5468/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [5468/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5469/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5469/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5470/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5470/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5471/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5471/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5472/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5472/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5473/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5473/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5474/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5474/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5475/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5475/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5476/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5476/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5477/10000], Training Loss: 0.60685717, Training Accuracy: 0.9454\n",
      "Epoch [5477/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5478/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5478/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5479/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5479/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5480/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5480/10000], Validation Loss: 1.11036360, Validation Accuracy: 0.4412\n",
      "Epoch [5481/10000], Training Loss: 0.59345894, Training Accuracy: 0.9580\n",
      "Epoch [5481/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5482/10000], Training Loss: 0.58506053, Training Accuracy: 0.9664\n",
      "Epoch [5482/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5483/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5483/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5484/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [5484/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5485/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5485/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [5486/10000], Training Loss: 0.59761330, Training Accuracy: 0.9538\n",
      "Epoch [5486/10000], Validation Loss: 1.10961270, Validation Accuracy: 0.4412\n",
      "Epoch [5487/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5487/10000], Validation Loss: 1.11022466, Validation Accuracy: 0.4412\n",
      "Epoch [5488/10000], Training Loss: 0.62246102, Training Accuracy: 0.9286\n",
      "Epoch [5488/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5489/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [5489/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5490/10000], Training Loss: 0.61407805, Training Accuracy: 0.9370\n",
      "Epoch [5490/10000], Validation Loss: 1.11035788, Validation Accuracy: 0.4412\n",
      "Epoch [5491/10000], Training Loss: 0.58926120, Training Accuracy: 0.9622\n",
      "Epoch [5491/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5492/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5492/10000], Validation Loss: 1.12499005, Validation Accuracy: 0.4265\n",
      "Epoch [5493/10000], Training Loss: 0.59766334, Training Accuracy: 0.9538\n",
      "Epoch [5493/10000], Validation Loss: 1.13895196, Validation Accuracy: 0.4118\n",
      "Epoch [5494/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5494/10000], Validation Loss: 1.13967311, Validation Accuracy: 0.4118\n",
      "Epoch [5495/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5495/10000], Validation Loss: 1.13967949, Validation Accuracy: 0.4118\n",
      "Epoch [5496/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5496/10000], Validation Loss: 1.13967997, Validation Accuracy: 0.4118\n",
      "Epoch [5497/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [5497/10000], Validation Loss: 1.13968009, Validation Accuracy: 0.4118\n",
      "Epoch [5498/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5498/10000], Validation Loss: 1.13968009, Validation Accuracy: 0.4118\n",
      "Epoch [5499/10000], Training Loss: 0.58925984, Training Accuracy: 0.9622\n",
      "Epoch [5499/10000], Validation Loss: 1.13968009, Validation Accuracy: 0.4118\n",
      "Epoch [5500/10000], Training Loss: 0.59766333, Training Accuracy: 0.9538\n",
      "Epoch [5500/10000], Validation Loss: 1.13968015, Validation Accuracy: 0.4118\n",
      "Epoch [5501/10000], Training Loss: 0.58936462, Training Accuracy: 0.9622\n",
      "Epoch [5501/10000], Validation Loss: 1.13957810, Validation Accuracy: 0.4118\n",
      "Epoch [5502/10000], Training Loss: 0.59346346, Training Accuracy: 0.9580\n",
      "Epoch [5502/10000], Validation Loss: 1.13271195, Validation Accuracy: 0.4118\n",
      "Epoch [5503/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5503/10000], Validation Loss: 1.12646544, Validation Accuracy: 0.4265\n",
      "Epoch [5504/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5504/10000], Validation Loss: 1.12552160, Validation Accuracy: 0.4265\n",
      "Epoch [5505/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5505/10000], Validation Loss: 1.12530828, Validation Accuracy: 0.4265\n",
      "Epoch [5506/10000], Training Loss: 0.60570338, Training Accuracy: 0.9454\n",
      "Epoch [5506/10000], Validation Loss: 1.13966757, Validation Accuracy: 0.4118\n",
      "Epoch [5507/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5507/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5508/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5508/10000], Validation Loss: 1.13967288, Validation Accuracy: 0.4118\n",
      "Epoch [5509/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5509/10000], Validation Loss: 1.12728673, Validation Accuracy: 0.4265\n",
      "Epoch [5510/10000], Training Loss: 0.61025730, Training Accuracy: 0.9412\n",
      "Epoch [5510/10000], Validation Loss: 1.12502480, Validation Accuracy: 0.4265\n",
      "Epoch [5511/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5511/10000], Validation Loss: 1.12498629, Validation Accuracy: 0.4265\n",
      "Epoch [5512/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [5512/10000], Validation Loss: 1.12498033, Validation Accuracy: 0.4265\n",
      "Epoch [5513/10000], Training Loss: 0.58730896, Training Accuracy: 0.9622\n",
      "Epoch [5513/10000], Validation Loss: 1.12497890, Validation Accuracy: 0.4265\n",
      "Epoch [5514/10000], Training Loss: 0.59763671, Training Accuracy: 0.9538\n",
      "Epoch [5514/10000], Validation Loss: 1.12499511, Validation Accuracy: 0.4265\n",
      "Epoch [5515/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5515/10000], Validation Loss: 1.12501818, Validation Accuracy: 0.4265\n",
      "Epoch [5516/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5516/10000], Validation Loss: 1.12478131, Validation Accuracy: 0.4265\n",
      "Epoch [5517/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5517/10000], Validation Loss: 1.12504935, Validation Accuracy: 0.4265\n",
      "Epoch [5518/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5518/10000], Validation Loss: 1.12505609, Validation Accuracy: 0.4265\n",
      "Epoch [5519/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5519/10000], Validation Loss: 1.12505955, Validation Accuracy: 0.4265\n",
      "Epoch [5520/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5520/10000], Validation Loss: 1.12506121, Validation Accuracy: 0.4265\n",
      "Epoch [5521/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5521/10000], Validation Loss: 1.12506199, Validation Accuracy: 0.4265\n",
      "Epoch [5522/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5522/10000], Validation Loss: 1.12506241, Validation Accuracy: 0.4265\n",
      "Epoch [5523/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5523/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5524/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5524/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5525/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5525/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5526/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5526/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5527/10000], Training Loss: 0.59346131, Training Accuracy: 0.9580\n",
      "Epoch [5527/10000], Validation Loss: 1.12506270, Validation Accuracy: 0.4265\n",
      "Epoch [5528/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [5528/10000], Validation Loss: 1.12506264, Validation Accuracy: 0.4265\n",
      "Epoch [5529/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [5529/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5530/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5530/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5531/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5531/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5532/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5532/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5533/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5533/10000], Validation Loss: 1.12506258, Validation Accuracy: 0.4265\n",
      "Epoch [5534/10000], Training Loss: 0.60171329, Training Accuracy: 0.9496\n",
      "Epoch [5534/10000], Validation Loss: 1.12501293, Validation Accuracy: 0.4265\n",
      "Epoch [5535/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5535/10000], Validation Loss: 1.12500048, Validation Accuracy: 0.4265\n",
      "Epoch [5536/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5536/10000], Validation Loss: 1.12499601, Validation Accuracy: 0.4265\n",
      "Epoch [5537/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [5537/10000], Validation Loss: 1.12499422, Validation Accuracy: 0.4265\n",
      "Epoch [5538/10000], Training Loss: 0.61577249, Training Accuracy: 0.9370\n",
      "Epoch [5538/10000], Validation Loss: 1.15438503, Validation Accuracy: 0.3971\n",
      "Epoch [5539/10000], Training Loss: 0.62285033, Training Accuracy: 0.9286\n",
      "Epoch [5539/10000], Validation Loss: 1.13967943, Validation Accuracy: 0.4118\n",
      "Epoch [5540/10000], Training Loss: 0.64389734, Training Accuracy: 0.9076\n",
      "Epoch [5540/10000], Validation Loss: 1.13996673, Validation Accuracy: 0.4118\n",
      "Epoch [5541/10000], Training Loss: 0.65640882, Training Accuracy: 0.8950\n",
      "Epoch [5541/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5542/10000], Training Loss: 0.66487796, Training Accuracy: 0.8866\n",
      "Epoch [5542/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5543/10000], Training Loss: 0.66392831, Training Accuracy: 0.8866\n",
      "Epoch [5543/10000], Validation Loss: 1.15438610, Validation Accuracy: 0.3971\n",
      "Epoch [5544/10000], Training Loss: 0.66909604, Training Accuracy: 0.8824\n",
      "Epoch [5544/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5545/10000], Training Loss: 0.63523738, Training Accuracy: 0.9160\n",
      "Epoch [5545/10000], Validation Loss: 1.13968021, Validation Accuracy: 0.4118\n",
      "Epoch [5546/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5546/10000], Validation Loss: 1.15425086, Validation Accuracy: 0.3971\n",
      "Epoch [5547/10000], Training Loss: 0.61026851, Training Accuracy: 0.9412\n",
      "Epoch [5547/10000], Validation Loss: 1.12864685, Validation Accuracy: 0.4265\n",
      "Epoch [5548/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5548/10000], Validation Loss: 1.11055136, Validation Accuracy: 0.4412\n",
      "Epoch [5549/10000], Training Loss: 0.61027463, Training Accuracy: 0.9412\n",
      "Epoch [5549/10000], Validation Loss: 1.11034250, Validation Accuracy: 0.4412\n",
      "Epoch [5550/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5550/10000], Validation Loss: 1.11019230, Validation Accuracy: 0.4412\n",
      "Epoch [5551/10000], Training Loss: 0.61447049, Training Accuracy: 0.9370\n",
      "Epoch [5551/10000], Validation Loss: 1.10975796, Validation Accuracy: 0.4412\n",
      "Epoch [5552/10000], Training Loss: 0.61025166, Training Accuracy: 0.9412\n",
      "Epoch [5552/10000], Validation Loss: 1.10957819, Validation Accuracy: 0.4412\n",
      "Epoch [5553/10000], Training Loss: 0.61026911, Training Accuracy: 0.9412\n",
      "Epoch [5553/10000], Validation Loss: 1.11011285, Validation Accuracy: 0.4412\n",
      "Epoch [5554/10000], Training Loss: 0.60170797, Training Accuracy: 0.9496\n",
      "Epoch [5554/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5555/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5555/10000], Validation Loss: 1.12497431, Validation Accuracy: 0.4265\n",
      "Epoch [5556/10000], Training Loss: 0.60605425, Training Accuracy: 0.9454\n",
      "Epoch [5556/10000], Validation Loss: 1.10745770, Validation Accuracy: 0.4412\n",
      "Epoch [5557/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5557/10000], Validation Loss: 1.13967985, Validation Accuracy: 0.4118\n",
      "Epoch [5558/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5558/10000], Validation Loss: 1.07830131, Validation Accuracy: 0.4706\n",
      "Epoch [5559/10000], Training Loss: 0.61871466, Training Accuracy: 0.9328\n",
      "Epoch [5559/10000], Validation Loss: 1.05350813, Validation Accuracy: 0.5000\n",
      "Epoch [5560/10000], Training Loss: 0.61027741, Training Accuracy: 0.9412\n",
      "Epoch [5560/10000], Validation Loss: 1.03874692, Validation Accuracy: 0.5147\n",
      "Epoch [5561/10000], Training Loss: 0.59313689, Training Accuracy: 0.9580\n",
      "Epoch [5561/10000], Validation Loss: 1.02203390, Validation Accuracy: 0.5294\n",
      "Epoch [5562/10000], Training Loss: 0.63967793, Training Accuracy: 0.9118\n",
      "Epoch [5562/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5563/10000], Training Loss: 0.62262975, Training Accuracy: 0.9286\n",
      "Epoch [5563/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5564/10000], Training Loss: 0.60650590, Training Accuracy: 0.9454\n",
      "Epoch [5564/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5565/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5565/10000], Validation Loss: 1.00750765, Validation Accuracy: 0.5441\n",
      "Epoch [5566/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5566/10000], Validation Loss: 1.02255183, Validation Accuracy: 0.5294\n",
      "Epoch [5567/10000], Training Loss: 0.60138051, Training Accuracy: 0.9496\n",
      "Epoch [5567/10000], Validation Loss: 1.02202994, Validation Accuracy: 0.5294\n",
      "Epoch [5568/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5568/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5569/10000], Training Loss: 0.58924395, Training Accuracy: 0.9622\n",
      "Epoch [5569/10000], Validation Loss: 1.06615058, Validation Accuracy: 0.4853\n",
      "Epoch [5570/10000], Training Loss: 0.58085694, Training Accuracy: 0.9706\n",
      "Epoch [5570/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [5571/10000], Training Loss: 0.59585969, Training Accuracy: 0.9538\n",
      "Epoch [5571/10000], Validation Loss: 1.05144477, Validation Accuracy: 0.5000\n",
      "Epoch [5572/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5572/10000], Validation Loss: 1.02203292, Validation Accuracy: 0.5294\n",
      "Epoch [5573/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5573/10000], Validation Loss: 0.99264610, Validation Accuracy: 0.5588\n",
      "Epoch [5574/10000], Training Loss: 0.62287336, Training Accuracy: 0.9286\n",
      "Epoch [5574/10000], Validation Loss: 0.97950312, Validation Accuracy: 0.5735\n",
      "Epoch [5575/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [5575/10000], Validation Loss: 0.96322376, Validation Accuracy: 0.5882\n",
      "Epoch [5576/10000], Training Loss: 0.60193331, Training Accuracy: 0.9496\n",
      "Epoch [5576/10000], Validation Loss: 0.96479180, Validation Accuracy: 0.5882\n",
      "Epoch [5577/10000], Training Loss: 0.60606922, Training Accuracy: 0.9454\n",
      "Epoch [5577/10000], Validation Loss: 0.97875658, Validation Accuracy: 0.5735\n",
      "Epoch [5578/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5578/10000], Validation Loss: 0.99261725, Validation Accuracy: 0.5588\n",
      "Epoch [5579/10000], Training Loss: 0.61867208, Training Accuracy: 0.9328\n",
      "Epoch [5579/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5580/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5580/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [5581/10000], Training Loss: 0.60605389, Training Accuracy: 0.9454\n",
      "Epoch [5581/10000], Validation Loss: 0.99262154, Validation Accuracy: 0.5588\n",
      "Epoch [5582/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5582/10000], Validation Loss: 0.99262181, Validation Accuracy: 0.5588\n",
      "Epoch [5583/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5583/10000], Validation Loss: 0.99262211, Validation Accuracy: 0.5588\n",
      "Epoch [5584/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5584/10000], Validation Loss: 0.99262220, Validation Accuracy: 0.5588\n",
      "Epoch [5585/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5585/10000], Validation Loss: 0.99262232, Validation Accuracy: 0.5588\n",
      "Epoch [5586/10000], Training Loss: 0.60597469, Training Accuracy: 0.9454\n",
      "Epoch [5586/10000], Validation Loss: 0.99354240, Validation Accuracy: 0.5588\n",
      "Epoch [5587/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5587/10000], Validation Loss: 1.02197024, Validation Accuracy: 0.5294\n",
      "Epoch [5588/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [5588/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5589/10000], Training Loss: 0.61259192, Training Accuracy: 0.9370\n",
      "Epoch [5589/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5590/10000], Training Loss: 0.58085670, Training Accuracy: 0.9706\n",
      "Epoch [5590/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5591/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5591/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [5592/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5592/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [5593/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5593/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [5594/10000], Training Loss: 0.62138946, Training Accuracy: 0.9286\n",
      "Epoch [5594/10000], Validation Loss: 1.02203494, Validation Accuracy: 0.5294\n",
      "Epoch [5595/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5595/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5596/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5596/10000], Validation Loss: 1.00729975, Validation Accuracy: 0.5441\n",
      "Epoch [5597/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5597/10000], Validation Loss: 1.00730422, Validation Accuracy: 0.5441\n",
      "Epoch [5598/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5598/10000], Validation Loss: 1.00732711, Validation Accuracy: 0.5441\n",
      "Epoch [5599/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [5599/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5600/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5600/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5601/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5601/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5602/10000], Training Loss: 0.61020706, Training Accuracy: 0.9412\n",
      "Epoch [5602/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5603/10000], Training Loss: 0.62287297, Training Accuracy: 0.9286\n",
      "Epoch [5603/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5604/10000], Training Loss: 0.60792334, Training Accuracy: 0.9412\n",
      "Epoch [5604/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5605/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5605/10000], Validation Loss: 1.02203420, Validation Accuracy: 0.5294\n",
      "Epoch [5606/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5606/10000], Validation Loss: 1.02269760, Validation Accuracy: 0.5294\n",
      "Epoch [5607/10000], Training Loss: 0.61438556, Training Accuracy: 0.9370\n",
      "Epoch [5607/10000], Validation Loss: 1.03673014, Validation Accuracy: 0.5147\n",
      "Epoch [5608/10000], Training Loss: 0.61867035, Training Accuracy: 0.9328\n",
      "Epoch [5608/10000], Validation Loss: 1.03673884, Validation Accuracy: 0.5147\n",
      "Epoch [5609/10000], Training Loss: 0.61026963, Training Accuracy: 0.9412\n",
      "Epoch [5609/10000], Validation Loss: 1.03673896, Validation Accuracy: 0.5147\n",
      "Epoch [5610/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5610/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5611/10000], Training Loss: 0.62709671, Training Accuracy: 0.9244\n",
      "Epoch [5611/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5612/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5612/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5613/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [5613/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5614/10000], Training Loss: 0.61450086, Training Accuracy: 0.9370\n",
      "Epoch [5614/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5615/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5615/10000], Validation Loss: 1.02203229, Validation Accuracy: 0.5294\n",
      "Epoch [5616/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5616/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5617/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5617/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5618/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5618/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5619/10000], Training Loss: 0.60606733, Training Accuracy: 0.9454\n",
      "Epoch [5619/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5620/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5620/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5621/10000], Training Loss: 0.60186349, Training Accuracy: 0.9496\n",
      "Epoch [5621/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5622/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5622/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5623/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5623/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5624/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5624/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5625/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5625/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5626/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5626/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5627/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5627/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5628/10000], Training Loss: 0.61866871, Training Accuracy: 0.9328\n",
      "Epoch [5628/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5629/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [5629/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5630/10000], Training Loss: 0.60606061, Training Accuracy: 0.9454\n",
      "Epoch [5630/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5631/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5631/10000], Validation Loss: 1.02203307, Validation Accuracy: 0.5294\n",
      "Epoch [5632/10000], Training Loss: 0.60606686, Training Accuracy: 0.9454\n",
      "Epoch [5632/10000], Validation Loss: 1.02203301, Validation Accuracy: 0.5294\n",
      "Epoch [5633/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5633/10000], Validation Loss: 1.02203295, Validation Accuracy: 0.5294\n",
      "Epoch [5634/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5634/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5635/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5635/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5636/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5636/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5637/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5637/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5638/10000], Training Loss: 0.60606673, Training Accuracy: 0.9454\n",
      "Epoch [5638/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5639/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5639/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5640/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5640/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5641/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5641/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5642/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5642/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5643/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [5643/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5644/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5644/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5645/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5645/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5646/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [5646/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5647/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5647/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5648/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5648/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5649/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5649/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5650/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5650/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5651/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5651/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5652/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5652/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5653/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5653/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5654/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5654/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5655/10000], Training Loss: 0.60186521, Training Accuracy: 0.9496\n",
      "Epoch [5655/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [5656/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5656/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5657/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5657/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [5658/10000], Training Loss: 0.60169382, Training Accuracy: 0.9496\n",
      "Epoch [5658/10000], Validation Loss: 1.00733861, Validation Accuracy: 0.5441\n",
      "Epoch [5659/10000], Training Loss: 0.61447322, Training Accuracy: 0.9370\n",
      "Epoch [5659/10000], Validation Loss: 1.03321773, Validation Accuracy: 0.5147\n",
      "Epoch [5660/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5660/10000], Validation Loss: 1.03661782, Validation Accuracy: 0.5147\n",
      "Epoch [5661/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5661/10000], Validation Loss: 1.02279890, Validation Accuracy: 0.5294\n",
      "Epoch [5662/10000], Training Loss: 0.62143203, Training Accuracy: 0.9286\n",
      "Epoch [5662/10000], Validation Loss: 1.03659406, Validation Accuracy: 0.5147\n",
      "Epoch [5663/10000], Training Loss: 0.61867178, Training Accuracy: 0.9328\n",
      "Epoch [5663/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [5664/10000], Training Loss: 0.63547853, Training Accuracy: 0.9160\n",
      "Epoch [5664/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5665/10000], Training Loss: 0.63965090, Training Accuracy: 0.9118\n",
      "Epoch [5665/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5666/10000], Training Loss: 0.63127679, Training Accuracy: 0.9202\n",
      "Epoch [5666/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5667/10000], Training Loss: 0.64003776, Training Accuracy: 0.9118\n",
      "Epoch [5667/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5668/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5668/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5669/10000], Training Loss: 0.63127620, Training Accuracy: 0.9202\n",
      "Epoch [5669/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5670/10000], Training Loss: 0.62851569, Training Accuracy: 0.9244\n",
      "Epoch [5670/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [5671/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5671/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [5672/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [5672/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [5673/10000], Training Loss: 0.62271049, Training Accuracy: 0.9286\n",
      "Epoch [5673/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [5674/10000], Training Loss: 0.60530335, Training Accuracy: 0.9454\n",
      "Epoch [5674/10000], Validation Loss: 0.99268821, Validation Accuracy: 0.5588\n",
      "Epoch [5675/10000], Training Loss: 0.61584574, Training Accuracy: 0.9370\n",
      "Epoch [5675/10000], Validation Loss: 0.97781277, Validation Accuracy: 0.5735\n",
      "Epoch [5676/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5676/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5677/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5677/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5678/10000], Training Loss: 0.61446986, Training Accuracy: 0.9370\n",
      "Epoch [5678/10000], Validation Loss: 0.99264356, Validation Accuracy: 0.5588\n",
      "Epoch [5679/10000], Training Loss: 0.60881057, Training Accuracy: 0.9412\n",
      "Epoch [5679/10000], Validation Loss: 1.00718421, Validation Accuracy: 0.5441\n",
      "Epoch [5680/10000], Training Loss: 0.61842339, Training Accuracy: 0.9328\n",
      "Epoch [5680/10000], Validation Loss: 1.03665617, Validation Accuracy: 0.5147\n",
      "Epoch [5681/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5681/10000], Validation Loss: 1.05144191, Validation Accuracy: 0.5000\n",
      "Epoch [5682/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5682/10000], Validation Loss: 1.05144429, Validation Accuracy: 0.5000\n",
      "Epoch [5683/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5683/10000], Validation Loss: 1.05144459, Validation Accuracy: 0.5000\n",
      "Epoch [5684/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [5684/10000], Validation Loss: 1.05144471, Validation Accuracy: 0.5000\n",
      "Epoch [5685/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5685/10000], Validation Loss: 1.05144471, Validation Accuracy: 0.5000\n",
      "Epoch [5686/10000], Training Loss: 0.62703624, Training Accuracy: 0.9244\n",
      "Epoch [5686/10000], Validation Loss: 1.05144471, Validation Accuracy: 0.5000\n",
      "Epoch [5687/10000], Training Loss: 0.61447087, Training Accuracy: 0.9370\n",
      "Epoch [5687/10000], Validation Loss: 1.05144453, Validation Accuracy: 0.5000\n",
      "Epoch [5688/10000], Training Loss: 0.61026921, Training Accuracy: 0.9412\n",
      "Epoch [5688/10000], Validation Loss: 1.06615031, Validation Accuracy: 0.4853\n",
      "Epoch [5689/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5689/10000], Validation Loss: 1.06615019, Validation Accuracy: 0.4853\n",
      "Epoch [5690/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5690/10000], Validation Loss: 1.06615013, Validation Accuracy: 0.4853\n",
      "Epoch [5691/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5691/10000], Validation Loss: 1.06615013, Validation Accuracy: 0.4853\n",
      "Epoch [5692/10000], Training Loss: 0.62287355, Training Accuracy: 0.9286\n",
      "Epoch [5692/10000], Validation Loss: 1.06615013, Validation Accuracy: 0.4853\n",
      "Epoch [5693/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5693/10000], Validation Loss: 1.06615013, Validation Accuracy: 0.4853\n",
      "Epoch [5694/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5694/10000], Validation Loss: 1.06615013, Validation Accuracy: 0.4853\n",
      "Epoch [5695/10000], Training Loss: 0.60605648, Training Accuracy: 0.9454\n",
      "Epoch [5695/10000], Validation Loss: 1.06614572, Validation Accuracy: 0.4853\n",
      "Epoch [5696/10000], Training Loss: 0.61372737, Training Accuracy: 0.9370\n",
      "Epoch [5696/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [5697/10000], Training Loss: 0.61026846, Training Accuracy: 0.9412\n",
      "Epoch [5697/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [5698/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5698/10000], Validation Loss: 1.03672218, Validation Accuracy: 0.5147\n",
      "Epoch [5699/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5699/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [5700/10000], Training Loss: 0.59993300, Training Accuracy: 0.9496\n",
      "Epoch [5700/10000], Validation Loss: 1.03396595, Validation Accuracy: 0.5147\n",
      "Epoch [5701/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5701/10000], Validation Loss: 1.03453174, Validation Accuracy: 0.5147\n",
      "Epoch [5702/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5702/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5703/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5703/10000], Validation Loss: 1.03673872, Validation Accuracy: 0.5147\n",
      "Epoch [5704/10000], Training Loss: 0.62008633, Training Accuracy: 0.9328\n",
      "Epoch [5704/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [5705/10000], Training Loss: 0.60176098, Training Accuracy: 0.9496\n",
      "Epoch [5705/10000], Validation Loss: 1.03673813, Validation Accuracy: 0.5147\n",
      "Epoch [5706/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5706/10000], Validation Loss: 1.02203366, Validation Accuracy: 0.5294\n",
      "Epoch [5707/10000], Training Loss: 0.60605701, Training Accuracy: 0.9454\n",
      "Epoch [5707/10000], Validation Loss: 1.02203855, Validation Accuracy: 0.5294\n",
      "Epoch [5708/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [5708/10000], Validation Loss: 1.02204856, Validation Accuracy: 0.5294\n",
      "Epoch [5709/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5709/10000], Validation Loss: 1.02205852, Validation Accuracy: 0.5294\n",
      "Epoch [5710/10000], Training Loss: 0.61026845, Training Accuracy: 0.9412\n",
      "Epoch [5710/10000], Validation Loss: 1.02206543, Validation Accuracy: 0.5294\n",
      "Epoch [5711/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5711/10000], Validation Loss: 1.02206931, Validation Accuracy: 0.5294\n",
      "Epoch [5712/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5712/10000], Validation Loss: 1.02207139, Validation Accuracy: 0.5294\n",
      "Epoch [5713/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5713/10000], Validation Loss: 1.02207240, Validation Accuracy: 0.5294\n",
      "Epoch [5714/10000], Training Loss: 0.63125695, Training Accuracy: 0.9202\n",
      "Epoch [5714/10000], Validation Loss: 1.02205864, Validation Accuracy: 0.5294\n",
      "Epoch [5715/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5715/10000], Validation Loss: 1.02203628, Validation Accuracy: 0.5294\n",
      "Epoch [5716/10000], Training Loss: 0.60565816, Training Accuracy: 0.9454\n",
      "Epoch [5716/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [5717/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5717/10000], Validation Loss: 1.03673935, Validation Accuracy: 0.5147\n",
      "Epoch [5718/10000], Training Loss: 0.60562773, Training Accuracy: 0.9454\n",
      "Epoch [5718/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5719/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5719/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5720/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5720/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5721/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5721/10000], Validation Loss: 1.06615084, Validation Accuracy: 0.4853\n",
      "Epoch [5722/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5722/10000], Validation Loss: 1.06615269, Validation Accuracy: 0.4853\n",
      "Epoch [5723/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5723/10000], Validation Loss: 1.06616420, Validation Accuracy: 0.4853\n",
      "Epoch [5724/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [5724/10000], Validation Loss: 1.08089131, Validation Accuracy: 0.4706\n",
      "Epoch [5725/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5725/10000], Validation Loss: 1.08091170, Validation Accuracy: 0.4706\n",
      "Epoch [5726/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5726/10000], Validation Loss: 1.08092552, Validation Accuracy: 0.4706\n",
      "Epoch [5727/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5727/10000], Validation Loss: 1.08093333, Validation Accuracy: 0.4706\n",
      "Epoch [5728/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5728/10000], Validation Loss: 1.08093739, Validation Accuracy: 0.4706\n",
      "Epoch [5729/10000], Training Loss: 0.61449400, Training Accuracy: 0.9370\n",
      "Epoch [5729/10000], Validation Loss: 1.08174258, Validation Accuracy: 0.4706\n",
      "Epoch [5730/10000], Training Loss: 0.61413580, Training Accuracy: 0.9370\n",
      "Epoch [5730/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5731/10000], Training Loss: 0.59454983, Training Accuracy: 0.9580\n",
      "Epoch [5731/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5732/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5732/10000], Validation Loss: 1.01375639, Validation Accuracy: 0.5294\n",
      "Epoch [5733/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [5733/10000], Validation Loss: 1.02939898, Validation Accuracy: 0.5147\n",
      "Epoch [5734/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5734/10000], Validation Loss: 1.05134675, Validation Accuracy: 0.5000\n",
      "Epoch [5735/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5735/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [5736/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5736/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [5737/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [5737/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [5738/10000], Training Loss: 0.59766598, Training Accuracy: 0.9538\n",
      "Epoch [5738/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [5739/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [5739/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [5740/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [5740/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [5741/10000], Training Loss: 0.59541621, Training Accuracy: 0.9538\n",
      "Epoch [5741/10000], Validation Loss: 1.02203321, Validation Accuracy: 0.5294\n",
      "Epoch [5742/10000], Training Loss: 0.60189357, Training Accuracy: 0.9496\n",
      "Epoch [5742/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5743/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5743/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [5744/10000], Training Loss: 0.61023194, Training Accuracy: 0.9412\n",
      "Epoch [5744/10000], Validation Loss: 1.08085603, Validation Accuracy: 0.4706\n",
      "Epoch [5745/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5745/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5746/10000], Training Loss: 0.59766377, Training Accuracy: 0.9538\n",
      "Epoch [5746/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5747/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5747/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5748/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [5748/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [5749/10000], Training Loss: 0.61755998, Training Accuracy: 0.9328\n",
      "Epoch [5749/10000], Validation Loss: 1.05110353, Validation Accuracy: 0.5000\n",
      "Epoch [5750/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [5750/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [5751/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5751/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [5752/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [5752/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [5753/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5753/10000], Validation Loss: 1.06892067, Validation Accuracy: 0.4853\n",
      "Epoch [5754/10000], Training Loss: 0.58926021, Training Accuracy: 0.9622\n",
      "Epoch [5754/10000], Validation Loss: 1.08084440, Validation Accuracy: 0.4706\n",
      "Epoch [5755/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5755/10000], Validation Loss: 1.08085644, Validation Accuracy: 0.4706\n",
      "Epoch [5756/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5756/10000], Validation Loss: 1.08085662, Validation Accuracy: 0.4706\n",
      "Epoch [5757/10000], Training Loss: 0.59871777, Training Accuracy: 0.9538\n",
      "Epoch [5757/10000], Validation Loss: 1.06613123, Validation Accuracy: 0.4853\n",
      "Epoch [5758/10000], Training Loss: 0.59766343, Training Accuracy: 0.9538\n",
      "Epoch [5758/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [5759/10000], Training Loss: 0.60936880, Training Accuracy: 0.9412\n",
      "Epoch [5759/10000], Validation Loss: 1.12497371, Validation Accuracy: 0.4265\n",
      "Epoch [5760/10000], Training Loss: 0.61867890, Training Accuracy: 0.9328\n",
      "Epoch [5760/10000], Validation Loss: 1.12341678, Validation Accuracy: 0.4265\n",
      "Epoch [5761/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [5761/10000], Validation Loss: 1.09687316, Validation Accuracy: 0.4559\n",
      "Epoch [5762/10000], Training Loss: 0.61450511, Training Accuracy: 0.9370\n",
      "Epoch [5762/10000], Validation Loss: 1.09587097, Validation Accuracy: 0.4559\n",
      "Epoch [5763/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5763/10000], Validation Loss: 1.09576523, Validation Accuracy: 0.4559\n",
      "Epoch [5764/10000], Training Loss: 0.63115009, Training Accuracy: 0.9202\n",
      "Epoch [5764/10000], Validation Loss: 1.10800666, Validation Accuracy: 0.4412\n",
      "Epoch [5765/10000], Training Loss: 0.62278717, Training Accuracy: 0.9286\n",
      "Epoch [5765/10000], Validation Loss: 1.09774333, Validation Accuracy: 0.4559\n",
      "Epoch [5766/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5766/10000], Validation Loss: 1.09608203, Validation Accuracy: 0.4559\n",
      "Epoch [5767/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5767/10000], Validation Loss: 1.09614533, Validation Accuracy: 0.4559\n",
      "Epoch [5768/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5768/10000], Validation Loss: 1.09693635, Validation Accuracy: 0.4559\n",
      "Epoch [5769/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5769/10000], Validation Loss: 1.09782147, Validation Accuracy: 0.4559\n",
      "Epoch [5770/10000], Training Loss: 0.61446909, Training Accuracy: 0.9370\n",
      "Epoch [5770/10000], Validation Loss: 1.03732640, Validation Accuracy: 0.5147\n",
      "Epoch [5771/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [5771/10000], Validation Loss: 1.03754091, Validation Accuracy: 0.5147\n",
      "Epoch [5772/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5772/10000], Validation Loss: 1.03783643, Validation Accuracy: 0.5147\n",
      "Epoch [5773/10000], Training Loss: 0.61440336, Training Accuracy: 0.9370\n",
      "Epoch [5773/10000], Validation Loss: 1.00732785, Validation Accuracy: 0.5441\n",
      "Epoch [5774/10000], Training Loss: 0.61017880, Training Accuracy: 0.9412\n",
      "Epoch [5774/10000], Validation Loss: 0.99264407, Validation Accuracy: 0.5588\n",
      "Epoch [5775/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [5775/10000], Validation Loss: 0.99245358, Validation Accuracy: 0.5588\n",
      "Epoch [5776/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5776/10000], Validation Loss: 0.99261993, Validation Accuracy: 0.5588\n",
      "Epoch [5777/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [5777/10000], Validation Loss: 0.99262121, Validation Accuracy: 0.5588\n",
      "Epoch [5778/10000], Training Loss: 0.63126607, Training Accuracy: 0.9202\n",
      "Epoch [5778/10000], Validation Loss: 0.99262127, Validation Accuracy: 0.5588\n",
      "Epoch [5779/10000], Training Loss: 0.64388196, Training Accuracy: 0.9076\n",
      "Epoch [5779/10000], Validation Loss: 1.00732696, Validation Accuracy: 0.5441\n",
      "Epoch [5780/10000], Training Loss: 0.62273078, Training Accuracy: 0.9286\n",
      "Epoch [5780/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [5781/10000], Training Loss: 0.62687565, Training Accuracy: 0.9244\n",
      "Epoch [5781/10000], Validation Loss: 1.00038505, Validation Accuracy: 0.5441\n",
      "Epoch [5782/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5782/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5783/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [5783/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5784/10000], Training Loss: 0.64388786, Training Accuracy: 0.9076\n",
      "Epoch [5784/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5785/10000], Training Loss: 0.63980498, Training Accuracy: 0.9118\n",
      "Epoch [5785/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5786/10000], Training Loss: 0.64387711, Training Accuracy: 0.9076\n",
      "Epoch [5786/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5787/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [5787/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5788/10000], Training Loss: 0.62624099, Training Accuracy: 0.9244\n",
      "Epoch [5788/10000], Validation Loss: 0.99262628, Validation Accuracy: 0.5588\n",
      "Epoch [5789/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [5789/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5790/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5790/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5791/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [5791/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5792/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [5792/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5793/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [5793/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5794/10000], Training Loss: 0.61682928, Training Accuracy: 0.9328\n",
      "Epoch [5794/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5795/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5795/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5796/10000], Training Loss: 0.66106501, Training Accuracy: 0.8908\n",
      "Epoch [5796/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5797/10000], Training Loss: 0.64584013, Training Accuracy: 0.9034\n",
      "Epoch [5797/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [5798/10000], Training Loss: 0.61871226, Training Accuracy: 0.9328\n",
      "Epoch [5798/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [5799/10000], Training Loss: 0.61407988, Training Accuracy: 0.9370\n",
      "Epoch [5799/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [5800/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [5800/10000], Validation Loss: 1.03673431, Validation Accuracy: 0.5147\n",
      "Epoch [5801/10000], Training Loss: 0.61027949, Training Accuracy: 0.9412\n",
      "Epoch [5801/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [5802/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5802/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [5803/10000], Training Loss: 0.63222807, Training Accuracy: 0.9202\n",
      "Epoch [5803/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5804/10000], Training Loss: 0.61845240, Training Accuracy: 0.9328\n",
      "Epoch [5804/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5805/10000], Training Loss: 0.63513688, Training Accuracy: 0.9160\n",
      "Epoch [5805/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [5806/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5806/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [5807/10000], Training Loss: 0.62422321, Training Accuracy: 0.9286\n",
      "Epoch [5807/10000], Validation Loss: 1.02197969, Validation Accuracy: 0.5294\n",
      "Epoch [5808/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5808/10000], Validation Loss: 1.00736961, Validation Accuracy: 0.5441\n",
      "Epoch [5809/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [5809/10000], Validation Loss: 1.02163792, Validation Accuracy: 0.5294\n",
      "Epoch [5810/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5810/10000], Validation Loss: 1.01048958, Validation Accuracy: 0.5441\n",
      "Epoch [5811/10000], Training Loss: 0.60186476, Training Accuracy: 0.9496\n",
      "Epoch [5811/10000], Validation Loss: 1.00732630, Validation Accuracy: 0.5441\n",
      "Epoch [5812/10000], Training Loss: 0.60835726, Training Accuracy: 0.9412\n",
      "Epoch [5812/10000], Validation Loss: 0.99282247, Validation Accuracy: 0.5588\n",
      "Epoch [5813/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5813/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [5814/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5814/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [5815/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [5815/10000], Validation Loss: 1.03673369, Validation Accuracy: 0.5147\n",
      "Epoch [5816/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5816/10000], Validation Loss: 1.03618795, Validation Accuracy: 0.5147\n",
      "Epoch [5817/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5817/10000], Validation Loss: 1.03254282, Validation Accuracy: 0.5147\n",
      "Epoch [5818/10000], Training Loss: 0.63121079, Training Accuracy: 0.9202\n",
      "Epoch [5818/10000], Validation Loss: 1.03874242, Validation Accuracy: 0.5147\n",
      "Epoch [5819/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5819/10000], Validation Loss: 1.03700531, Validation Accuracy: 0.5147\n",
      "Epoch [5820/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5820/10000], Validation Loss: 1.03683531, Validation Accuracy: 0.5147\n",
      "Epoch [5821/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5821/10000], Validation Loss: 1.03679794, Validation Accuracy: 0.5147\n",
      "Epoch [5822/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5822/10000], Validation Loss: 1.03678548, Validation Accuracy: 0.5147\n",
      "Epoch [5823/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [5823/10000], Validation Loss: 1.03678048, Validation Accuracy: 0.5147\n",
      "Epoch [5824/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [5824/10000], Validation Loss: 1.03677827, Validation Accuracy: 0.5147\n",
      "Epoch [5825/10000], Training Loss: 0.61447582, Training Accuracy: 0.9370\n",
      "Epoch [5825/10000], Validation Loss: 1.03676295, Validation Accuracy: 0.5147\n",
      "Epoch [5826/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5826/10000], Validation Loss: 1.03675789, Validation Accuracy: 0.5147\n",
      "Epoch [5827/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [5827/10000], Validation Loss: 1.03675592, Validation Accuracy: 0.5147\n",
      "Epoch [5828/10000], Training Loss: 0.62707130, Training Accuracy: 0.9244\n",
      "Epoch [5828/10000], Validation Loss: 1.03675681, Validation Accuracy: 0.5147\n",
      "Epoch [5829/10000], Training Loss: 0.61867939, Training Accuracy: 0.9328\n",
      "Epoch [5829/10000], Validation Loss: 1.03675276, Validation Accuracy: 0.5147\n",
      "Epoch [5830/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5830/10000], Validation Loss: 1.03674632, Validation Accuracy: 0.5147\n",
      "Epoch [5831/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5831/10000], Validation Loss: 1.03674442, Validation Accuracy: 0.5147\n",
      "Epoch [5832/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5832/10000], Validation Loss: 1.03674364, Validation Accuracy: 0.5147\n",
      "Epoch [5833/10000], Training Loss: 0.61446921, Training Accuracy: 0.9370\n",
      "Epoch [5833/10000], Validation Loss: 1.03674382, Validation Accuracy: 0.5147\n",
      "Epoch [5834/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5834/10000], Validation Loss: 1.03674394, Validation Accuracy: 0.5147\n",
      "Epoch [5835/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [5835/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5836/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5836/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5837/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5837/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5838/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5838/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5839/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [5839/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5840/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5840/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5841/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5841/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5842/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5842/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5843/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [5843/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5844/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [5844/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5845/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5845/10000], Validation Loss: 1.03674400, Validation Accuracy: 0.5147\n",
      "Epoch [5846/10000], Training Loss: 0.62249163, Training Accuracy: 0.9286\n",
      "Epoch [5846/10000], Validation Loss: 1.02106917, Validation Accuracy: 0.5294\n",
      "Epoch [5847/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [5847/10000], Validation Loss: 1.00732419, Validation Accuracy: 0.5441\n",
      "Epoch [5848/10000], Training Loss: 0.61026852, Training Accuracy: 0.9412\n",
      "Epoch [5848/10000], Validation Loss: 1.00732705, Validation Accuracy: 0.5441\n",
      "Epoch [5849/10000], Training Loss: 0.62288925, Training Accuracy: 0.9286\n",
      "Epoch [5849/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5850/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [5850/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5851/10000], Training Loss: 0.63120420, Training Accuracy: 0.9202\n",
      "Epoch [5851/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [5852/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [5852/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [5853/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [5853/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [5854/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [5854/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [5855/10000], Training Loss: 0.62291460, Training Accuracy: 0.9286\n",
      "Epoch [5855/10000], Validation Loss: 0.97786316, Validation Accuracy: 0.5735\n",
      "Epoch [5856/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [5856/10000], Validation Loss: 0.94854927, Validation Accuracy: 0.6029\n",
      "Epoch [5857/10000], Training Loss: 0.63127686, Training Accuracy: 0.9202\n",
      "Epoch [5857/10000], Validation Loss: 0.94850397, Validation Accuracy: 0.6029\n",
      "Epoch [5858/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [5858/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [5859/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [5859/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [5860/10000], Training Loss: 0.62287356, Training Accuracy: 0.9286\n",
      "Epoch [5860/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [5861/10000], Training Loss: 0.61290677, Training Accuracy: 0.9370\n",
      "Epoch [5861/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [5862/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5862/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5863/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5863/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5864/10000], Training Loss: 0.62292255, Training Accuracy: 0.9286\n",
      "Epoch [5864/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5865/10000], Training Loss: 0.61355215, Training Accuracy: 0.9370\n",
      "Epoch [5865/10000], Validation Loss: 0.92310575, Validation Accuracy: 0.6324\n",
      "Epoch [5866/10000], Training Loss: 0.59337519, Training Accuracy: 0.9580\n",
      "Epoch [5866/10000], Validation Loss: 0.93379754, Validation Accuracy: 0.6176\n",
      "Epoch [5867/10000], Training Loss: 0.60605939, Training Accuracy: 0.9454\n",
      "Epoch [5867/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [5868/10000], Training Loss: 0.60600504, Training Accuracy: 0.9454\n",
      "Epoch [5868/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [5869/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5869/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [5870/10000], Training Loss: 0.60442466, Training Accuracy: 0.9454\n",
      "Epoch [5870/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [5871/10000], Training Loss: 0.60186510, Training Accuracy: 0.9496\n",
      "Epoch [5871/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [5872/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5872/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5873/10000], Training Loss: 0.60606644, Training Accuracy: 0.9454\n",
      "Epoch [5873/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5874/10000], Training Loss: 0.59441245, Training Accuracy: 0.9580\n",
      "Epoch [5874/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5875/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5875/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [5876/10000], Training Loss: 0.62287351, Training Accuracy: 0.9286\n",
      "Epoch [5876/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [5877/10000], Training Loss: 0.61026783, Training Accuracy: 0.9412\n",
      "Epoch [5877/10000], Validation Loss: 0.93379876, Validation Accuracy: 0.6176\n",
      "Epoch [5878/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5878/10000], Validation Loss: 0.93379828, Validation Accuracy: 0.6176\n",
      "Epoch [5879/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5879/10000], Validation Loss: 0.93379819, Validation Accuracy: 0.6176\n",
      "Epoch [5880/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [5880/10000], Validation Loss: 0.91909227, Validation Accuracy: 0.6324\n",
      "Epoch [5881/10000], Training Loss: 0.63127365, Training Accuracy: 0.9202\n",
      "Epoch [5881/10000], Validation Loss: 0.91909227, Validation Accuracy: 0.6324\n",
      "Epoch [5882/10000], Training Loss: 0.63105749, Training Accuracy: 0.9202\n",
      "Epoch [5882/10000], Validation Loss: 0.91909406, Validation Accuracy: 0.6324\n",
      "Epoch [5883/10000], Training Loss: 0.60160113, Training Accuracy: 0.9496\n",
      "Epoch [5883/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5884/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [5884/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5885/10000], Training Loss: 0.61446990, Training Accuracy: 0.9370\n",
      "Epoch [5885/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5886/10000], Training Loss: 0.61447276, Training Accuracy: 0.9370\n",
      "Epoch [5886/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5887/10000], Training Loss: 0.59766349, Training Accuracy: 0.9538\n",
      "Epoch [5887/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5888/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5888/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5889/10000], Training Loss: 0.60168317, Training Accuracy: 0.9496\n",
      "Epoch [5889/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5890/10000], Training Loss: 0.60188786, Training Accuracy: 0.9496\n",
      "Epoch [5890/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5891/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [5891/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5892/10000], Training Loss: 0.61904790, Training Accuracy: 0.9328\n",
      "Epoch [5892/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5893/10000], Training Loss: 0.60409388, Training Accuracy: 0.9454\n",
      "Epoch [5893/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [5894/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [5894/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [5895/10000], Training Loss: 0.62197053, Training Accuracy: 0.9286\n",
      "Epoch [5895/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5896/10000], Training Loss: 0.59766184, Training Accuracy: 0.9538\n",
      "Epoch [5896/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5897/10000], Training Loss: 0.61446974, Training Accuracy: 0.9370\n",
      "Epoch [5897/10000], Validation Loss: 0.93379778, Validation Accuracy: 0.6176\n",
      "Epoch [5898/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5898/10000], Validation Loss: 0.93328255, Validation Accuracy: 0.6176\n",
      "Epoch [5899/10000], Training Loss: 0.61868187, Training Accuracy: 0.9328\n",
      "Epoch [5899/10000], Validation Loss: 0.93379655, Validation Accuracy: 0.6176\n",
      "Epoch [5900/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5900/10000], Validation Loss: 0.91909206, Validation Accuracy: 0.6324\n",
      "Epoch [5901/10000], Training Loss: 0.61475814, Training Accuracy: 0.9370\n",
      "Epoch [5901/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5902/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5902/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5903/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [5903/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5904/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5904/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5905/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [5905/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5906/10000], Training Loss: 0.59766338, Training Accuracy: 0.9538\n",
      "Epoch [5906/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5907/10000], Training Loss: 0.61028997, Training Accuracy: 0.9412\n",
      "Epoch [5907/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5908/10000], Training Loss: 0.60198162, Training Accuracy: 0.9496\n",
      "Epoch [5908/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5909/10000], Training Loss: 0.61867741, Training Accuracy: 0.9328\n",
      "Epoch [5909/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5910/10000], Training Loss: 0.59764369, Training Accuracy: 0.9538\n",
      "Epoch [5910/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5911/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5911/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5912/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5912/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5913/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5913/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [5914/10000], Training Loss: 0.62264971, Training Accuracy: 0.9286\n",
      "Epoch [5914/10000], Validation Loss: 0.96409214, Validation Accuracy: 0.5882\n",
      "Epoch [5915/10000], Training Loss: 0.60883644, Training Accuracy: 0.9412\n",
      "Epoch [5915/10000], Validation Loss: 0.97791547, Validation Accuracy: 0.5735\n",
      "Epoch [5916/10000], Training Loss: 0.59698065, Training Accuracy: 0.9538\n",
      "Epoch [5916/10000], Validation Loss: 0.96352074, Validation Accuracy: 0.5882\n",
      "Epoch [5917/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5917/10000], Validation Loss: 0.93461525, Validation Accuracy: 0.6176\n",
      "Epoch [5918/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5918/10000], Validation Loss: 0.93380004, Validation Accuracy: 0.6176\n",
      "Epoch [5919/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5919/10000], Validation Loss: 0.93379796, Validation Accuracy: 0.6176\n",
      "Epoch [5920/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5920/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [5921/10000], Training Loss: 0.61445527, Training Accuracy: 0.9370\n",
      "Epoch [5921/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [5922/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [5922/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [5923/10000], Training Loss: 0.59363508, Training Accuracy: 0.9580\n",
      "Epoch [5923/10000], Validation Loss: 0.96320894, Validation Accuracy: 0.5882\n",
      "Epoch [5924/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5924/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5925/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [5925/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5926/10000], Training Loss: 0.59798342, Training Accuracy: 0.9538\n",
      "Epoch [5926/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5927/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5927/10000], Validation Loss: 0.96285772, Validation Accuracy: 0.5882\n",
      "Epoch [5928/10000], Training Loss: 0.60606925, Training Accuracy: 0.9454\n",
      "Epoch [5928/10000], Validation Loss: 0.96320957, Validation Accuracy: 0.5882\n",
      "Epoch [5929/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5929/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5930/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5930/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5931/10000], Training Loss: 0.58925836, Training Accuracy: 0.9622\n",
      "Epoch [5931/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5932/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5932/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5933/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5933/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5934/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5934/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5935/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5935/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [5936/10000], Training Loss: 0.59645029, Training Accuracy: 0.9538\n",
      "Epoch [5936/10000], Validation Loss: 0.96319914, Validation Accuracy: 0.5882\n",
      "Epoch [5937/10000], Training Loss: 0.61447040, Training Accuracy: 0.9370\n",
      "Epoch [5937/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [5938/10000], Training Loss: 0.62163832, Training Accuracy: 0.9286\n",
      "Epoch [5938/10000], Validation Loss: 0.97658345, Validation Accuracy: 0.5735\n",
      "Epoch [5939/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [5939/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5940/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5940/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5941/10000], Training Loss: 0.62287342, Training Accuracy: 0.9286\n",
      "Epoch [5941/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5942/10000], Training Loss: 0.61026858, Training Accuracy: 0.9412\n",
      "Epoch [5942/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5943/10000], Training Loss: 0.61030687, Training Accuracy: 0.9412\n",
      "Epoch [5943/10000], Validation Loss: 0.96316895, Validation Accuracy: 0.5882\n",
      "Epoch [5944/10000], Training Loss: 0.60606693, Training Accuracy: 0.9454\n",
      "Epoch [5944/10000], Validation Loss: 0.94860539, Validation Accuracy: 0.6029\n",
      "Epoch [5945/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5945/10000], Validation Loss: 0.94849896, Validation Accuracy: 0.6029\n",
      "Epoch [5946/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5946/10000], Validation Loss: 0.94849613, Validation Accuracy: 0.6029\n",
      "Epoch [5947/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5947/10000], Validation Loss: 0.94849461, Validation Accuracy: 0.6029\n",
      "Epoch [5948/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5948/10000], Validation Loss: 0.94849384, Validation Accuracy: 0.6029\n",
      "Epoch [5949/10000], Training Loss: 0.60827417, Training Accuracy: 0.9412\n",
      "Epoch [5949/10000], Validation Loss: 0.96320930, Validation Accuracy: 0.5882\n",
      "Epoch [5950/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5950/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5951/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5951/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5952/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [5952/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5953/10000], Training Loss: 0.59346184, Training Accuracy: 0.9580\n",
      "Epoch [5953/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5954/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [5954/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5955/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5955/10000], Validation Loss: 0.96320972, Validation Accuracy: 0.5882\n",
      "Epoch [5956/10000], Training Loss: 0.59346291, Training Accuracy: 0.9580\n",
      "Epoch [5956/10000], Validation Loss: 0.96320972, Validation Accuracy: 0.5882\n",
      "Epoch [5957/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5957/10000], Validation Loss: 0.96320966, Validation Accuracy: 0.5882\n",
      "Epoch [5958/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [5958/10000], Validation Loss: 0.96320966, Validation Accuracy: 0.5882\n",
      "Epoch [5959/10000], Training Loss: 0.61446012, Training Accuracy: 0.9370\n",
      "Epoch [5959/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5960/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [5960/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5961/10000], Training Loss: 0.60186833, Training Accuracy: 0.9496\n",
      "Epoch [5961/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5962/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [5962/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5963/10000], Training Loss: 0.61026803, Training Accuracy: 0.9412\n",
      "Epoch [5963/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5964/10000], Training Loss: 0.60606308, Training Accuracy: 0.9454\n",
      "Epoch [5964/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [5965/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5965/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5966/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [5966/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5967/10000], Training Loss: 0.60186590, Training Accuracy: 0.9496\n",
      "Epoch [5967/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5968/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5968/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5969/10000], Training Loss: 0.59766834, Training Accuracy: 0.9538\n",
      "Epoch [5969/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [5970/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [5970/10000], Validation Loss: 0.96320948, Validation Accuracy: 0.5882\n",
      "Epoch [5971/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5971/10000], Validation Loss: 0.96320942, Validation Accuracy: 0.5882\n",
      "Epoch [5972/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [5972/10000], Validation Loss: 0.96320942, Validation Accuracy: 0.5882\n",
      "Epoch [5973/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5973/10000], Validation Loss: 0.96320942, Validation Accuracy: 0.5882\n",
      "Epoch [5974/10000], Training Loss: 0.59766453, Training Accuracy: 0.9538\n",
      "Epoch [5974/10000], Validation Loss: 0.96320936, Validation Accuracy: 0.5882\n",
      "Epoch [5975/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [5975/10000], Validation Loss: 0.96320930, Validation Accuracy: 0.5882\n",
      "Epoch [5976/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5976/10000], Validation Loss: 0.96320930, Validation Accuracy: 0.5882\n",
      "Epoch [5977/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [5977/10000], Validation Loss: 0.96320930, Validation Accuracy: 0.5882\n",
      "Epoch [5978/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5978/10000], Validation Loss: 0.96320930, Validation Accuracy: 0.5882\n",
      "Epoch [5979/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5979/10000], Validation Loss: 0.96320930, Validation Accuracy: 0.5882\n",
      "Epoch [5980/10000], Training Loss: 0.60115073, Training Accuracy: 0.9496\n",
      "Epoch [5980/10000], Validation Loss: 0.97791606, Validation Accuracy: 0.5735\n",
      "Epoch [5981/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5981/10000], Validation Loss: 0.97823840, Validation Accuracy: 0.5735\n",
      "Epoch [5982/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5982/10000], Validation Loss: 0.98231912, Validation Accuracy: 0.5735\n",
      "Epoch [5983/10000], Training Loss: 0.62287363, Training Accuracy: 0.9286\n",
      "Epoch [5983/10000], Validation Loss: 0.98716620, Validation Accuracy: 0.5588\n",
      "Epoch [5984/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [5984/10000], Validation Loss: 0.98913997, Validation Accuracy: 0.5588\n",
      "Epoch [5985/10000], Training Loss: 0.60186485, Training Accuracy: 0.9496\n",
      "Epoch [5985/10000], Validation Loss: 0.98978689, Validation Accuracy: 0.5588\n",
      "Epoch [5986/10000], Training Loss: 0.61026422, Training Accuracy: 0.9412\n",
      "Epoch [5986/10000], Validation Loss: 0.98834026, Validation Accuracy: 0.5588\n",
      "Epoch [5987/10000], Training Loss: 0.59766356, Training Accuracy: 0.9538\n",
      "Epoch [5987/10000], Validation Loss: 0.98723191, Validation Accuracy: 0.5588\n",
      "Epoch [5988/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [5988/10000], Validation Loss: 0.98665354, Validation Accuracy: 0.5588\n",
      "Epoch [5989/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5989/10000], Validation Loss: 0.98636824, Validation Accuracy: 0.5588\n",
      "Epoch [5990/10000], Training Loss: 0.61562796, Training Accuracy: 0.9370\n",
      "Epoch [5990/10000], Validation Loss: 0.99241242, Validation Accuracy: 0.5588\n",
      "Epoch [5991/10000], Training Loss: 0.60606686, Training Accuracy: 0.9454\n",
      "Epoch [5991/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [5992/10000], Training Loss: 0.61026837, Training Accuracy: 0.9412\n",
      "Epoch [5992/10000], Validation Loss: 0.99265060, Validation Accuracy: 0.5588\n",
      "Epoch [5993/10000], Training Loss: 0.60607523, Training Accuracy: 0.9454\n",
      "Epoch [5993/10000], Validation Loss: 1.00712195, Validation Accuracy: 0.5441\n",
      "Epoch [5994/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [5994/10000], Validation Loss: 1.00732496, Validation Accuracy: 0.5441\n",
      "Epoch [5995/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [5995/10000], Validation Loss: 1.00732699, Validation Accuracy: 0.5441\n",
      "Epoch [5996/10000], Training Loss: 0.61036950, Training Accuracy: 0.9412\n",
      "Epoch [5996/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [5997/10000], Training Loss: 0.59371125, Training Accuracy: 0.9580\n",
      "Epoch [5997/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [5998/10000], Training Loss: 0.59766308, Training Accuracy: 0.9538\n",
      "Epoch [5998/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [5999/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [5999/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6000/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6000/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6001/10000], Training Loss: 0.62288987, Training Accuracy: 0.9286\n",
      "Epoch [6001/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6002/10000], Training Loss: 0.61707545, Training Accuracy: 0.9328\n",
      "Epoch [6002/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6003/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6003/10000], Validation Loss: 1.00303143, Validation Accuracy: 0.5441\n",
      "Epoch [6004/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6004/10000], Validation Loss: 0.98136833, Validation Accuracy: 0.5735\n",
      "Epoch [6005/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6005/10000], Validation Loss: 0.99262628, Validation Accuracy: 0.5588\n",
      "Epoch [6006/10000], Training Loss: 0.61025966, Training Accuracy: 0.9412\n",
      "Epoch [6006/10000], Validation Loss: 0.97791570, Validation Accuracy: 0.5735\n",
      "Epoch [6007/10000], Training Loss: 0.63125013, Training Accuracy: 0.9202\n",
      "Epoch [6007/10000], Validation Loss: 0.97791553, Validation Accuracy: 0.5735\n",
      "Epoch [6008/10000], Training Loss: 0.62274038, Training Accuracy: 0.9286\n",
      "Epoch [6008/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6009/10000], Training Loss: 0.62287492, Training Accuracy: 0.9286\n",
      "Epoch [6009/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6010/10000], Training Loss: 0.61867262, Training Accuracy: 0.9328\n",
      "Epoch [6010/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6011/10000], Training Loss: 0.61449687, Training Accuracy: 0.9370\n",
      "Epoch [6011/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6012/10000], Training Loss: 0.61447001, Training Accuracy: 0.9370\n",
      "Epoch [6012/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6013/10000], Training Loss: 0.59580421, Training Accuracy: 0.9538\n",
      "Epoch [6013/10000], Validation Loss: 0.96337211, Validation Accuracy: 0.5882\n",
      "Epoch [6014/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [6014/10000], Validation Loss: 0.99134365, Validation Accuracy: 0.5588\n",
      "Epoch [6015/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6015/10000], Validation Loss: 0.97786644, Validation Accuracy: 0.5735\n",
      "Epoch [6016/10000], Training Loss: 0.61446481, Training Accuracy: 0.9370\n",
      "Epoch [6016/10000], Validation Loss: 0.97790563, Validation Accuracy: 0.5735\n",
      "Epoch [6017/10000], Training Loss: 0.60996046, Training Accuracy: 0.9412\n",
      "Epoch [6017/10000], Validation Loss: 0.97786903, Validation Accuracy: 0.5735\n",
      "Epoch [6018/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6018/10000], Validation Loss: 0.97297487, Validation Accuracy: 0.5735\n",
      "Epoch [6019/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6019/10000], Validation Loss: 0.96515191, Validation Accuracy: 0.5882\n",
      "Epoch [6020/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [6020/10000], Validation Loss: 0.96383908, Validation Accuracy: 0.5882\n",
      "Epoch [6021/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [6021/10000], Validation Loss: 0.96356654, Validation Accuracy: 0.5882\n",
      "Epoch [6022/10000], Training Loss: 0.62287570, Training Accuracy: 0.9286\n",
      "Epoch [6022/10000], Validation Loss: 0.96330512, Validation Accuracy: 0.5882\n",
      "Epoch [6023/10000], Training Loss: 0.60606969, Training Accuracy: 0.9454\n",
      "Epoch [6023/10000], Validation Loss: 0.96322525, Validation Accuracy: 0.5882\n",
      "Epoch [6024/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6024/10000], Validation Loss: 0.96321309, Validation Accuracy: 0.5882\n",
      "Epoch [6025/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6025/10000], Validation Loss: 0.96320903, Validation Accuracy: 0.5882\n",
      "Epoch [6026/10000], Training Loss: 0.59992882, Training Accuracy: 0.9496\n",
      "Epoch [6026/10000], Validation Loss: 0.96321914, Validation Accuracy: 0.5882\n",
      "Epoch [6027/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6027/10000], Validation Loss: 0.97794068, Validation Accuracy: 0.5735\n",
      "Epoch [6028/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6028/10000], Validation Loss: 0.97795576, Validation Accuracy: 0.5735\n",
      "Epoch [6029/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6029/10000], Validation Loss: 0.97796601, Validation Accuracy: 0.5735\n",
      "Epoch [6030/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6030/10000], Validation Loss: 0.97797185, Validation Accuracy: 0.5735\n",
      "Epoch [6031/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6031/10000], Validation Loss: 0.97797489, Validation Accuracy: 0.5735\n",
      "Epoch [6032/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6032/10000], Validation Loss: 0.97797644, Validation Accuracy: 0.5735\n",
      "Epoch [6033/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6033/10000], Validation Loss: 0.97797719, Validation Accuracy: 0.5735\n",
      "Epoch [6034/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6034/10000], Validation Loss: 0.97797754, Validation Accuracy: 0.5735\n",
      "Epoch [6035/10000], Training Loss: 0.61026876, Training Accuracy: 0.9412\n",
      "Epoch [6035/10000], Validation Loss: 0.97796959, Validation Accuracy: 0.5735\n",
      "Epoch [6036/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6036/10000], Validation Loss: 0.97796527, Validation Accuracy: 0.5735\n",
      "Epoch [6037/10000], Training Loss: 0.58926012, Training Accuracy: 0.9622\n",
      "Epoch [6037/10000], Validation Loss: 0.97796318, Validation Accuracy: 0.5735\n",
      "Epoch [6038/10000], Training Loss: 0.61871059, Training Accuracy: 0.9328\n",
      "Epoch [6038/10000], Validation Loss: 0.97836915, Validation Accuracy: 0.5735\n",
      "Epoch [6039/10000], Training Loss: 0.60606611, Training Accuracy: 0.9454\n",
      "Epoch [6039/10000], Validation Loss: 0.98454890, Validation Accuracy: 0.5588\n",
      "Epoch [6040/10000], Training Loss: 0.60606776, Training Accuracy: 0.9454\n",
      "Epoch [6040/10000], Validation Loss: 0.98966095, Validation Accuracy: 0.5588\n",
      "Epoch [6041/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6041/10000], Validation Loss: 0.99110788, Validation Accuracy: 0.5588\n",
      "Epoch [6042/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6042/10000], Validation Loss: 0.99154612, Validation Accuracy: 0.5588\n",
      "Epoch [6043/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6043/10000], Validation Loss: 0.99171150, Validation Accuracy: 0.5588\n",
      "Epoch [6044/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6044/10000], Validation Loss: 0.99178123, Validation Accuracy: 0.5588\n",
      "Epoch [6045/10000], Training Loss: 0.60186516, Training Accuracy: 0.9496\n",
      "Epoch [6045/10000], Validation Loss: 0.99181265, Validation Accuracy: 0.5588\n",
      "Epoch [6046/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6046/10000], Validation Loss: 0.99182725, Validation Accuracy: 0.5588\n",
      "Epoch [6047/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6047/10000], Validation Loss: 0.99183419, Validation Accuracy: 0.5588\n",
      "Epoch [6048/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6048/10000], Validation Loss: 0.99183741, Validation Accuracy: 0.5588\n",
      "Epoch [6049/10000], Training Loss: 0.61025376, Training Accuracy: 0.9412\n",
      "Epoch [6049/10000], Validation Loss: 0.97797546, Validation Accuracy: 0.5735\n",
      "Epoch [6050/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6050/10000], Validation Loss: 0.97791648, Validation Accuracy: 0.5735\n",
      "Epoch [6051/10000], Training Loss: 0.60171043, Training Accuracy: 0.9496\n",
      "Epoch [6051/10000], Validation Loss: 0.97791576, Validation Accuracy: 0.5735\n",
      "Epoch [6052/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6052/10000], Validation Loss: 0.97791815, Validation Accuracy: 0.5735\n",
      "Epoch [6053/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6053/10000], Validation Loss: 0.97792283, Validation Accuracy: 0.5735\n",
      "Epoch [6054/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6054/10000], Validation Loss: 0.97792354, Validation Accuracy: 0.5735\n",
      "Epoch [6055/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6055/10000], Validation Loss: 0.97791794, Validation Accuracy: 0.5735\n",
      "Epoch [6056/10000], Training Loss: 0.61373964, Training Accuracy: 0.9370\n",
      "Epoch [6056/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6057/10000], Training Loss: 0.60606679, Training Accuracy: 0.9454\n",
      "Epoch [6057/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6058/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6058/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6059/10000], Training Loss: 0.60183491, Training Accuracy: 0.9496\n",
      "Epoch [6059/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6060/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6060/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6061/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6061/10000], Validation Loss: 0.93379781, Validation Accuracy: 0.6176\n",
      "Epoch [6062/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6062/10000], Validation Loss: 0.93379775, Validation Accuracy: 0.6176\n",
      "Epoch [6063/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6063/10000], Validation Loss: 0.93379766, Validation Accuracy: 0.6176\n",
      "Epoch [6064/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6064/10000], Validation Loss: 0.93379760, Validation Accuracy: 0.6176\n",
      "Epoch [6065/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6065/10000], Validation Loss: 0.93379760, Validation Accuracy: 0.6176\n",
      "Epoch [6066/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6066/10000], Validation Loss: 0.93379760, Validation Accuracy: 0.6176\n",
      "Epoch [6067/10000], Training Loss: 0.61027440, Training Accuracy: 0.9412\n",
      "Epoch [6067/10000], Validation Loss: 0.93379760, Validation Accuracy: 0.6176\n",
      "Epoch [6068/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6068/10000], Validation Loss: 0.93379760, Validation Accuracy: 0.6176\n",
      "Epoch [6069/10000], Training Loss: 0.59454079, Training Accuracy: 0.9580\n",
      "Epoch [6069/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6070/10000], Training Loss: 0.58926607, Training Accuracy: 0.9622\n",
      "Epoch [6070/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6071/10000], Training Loss: 0.62707524, Training Accuracy: 0.9244\n",
      "Epoch [6071/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6072/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6072/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6073/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6073/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6074/10000], Training Loss: 0.61480061, Training Accuracy: 0.9370\n",
      "Epoch [6074/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6075/10000], Training Loss: 0.60878918, Training Accuracy: 0.9412\n",
      "Epoch [6075/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6076/10000], Training Loss: 0.60606665, Training Accuracy: 0.9454\n",
      "Epoch [6076/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6077/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6077/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6078/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6078/10000], Validation Loss: 0.94850355, Validation Accuracy: 0.6029\n",
      "Epoch [6079/10000], Training Loss: 0.62705561, Training Accuracy: 0.9244\n",
      "Epoch [6079/10000], Validation Loss: 0.94849655, Validation Accuracy: 0.6029\n",
      "Epoch [6080/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6080/10000], Validation Loss: 0.94842523, Validation Accuracy: 0.6029\n",
      "Epoch [6081/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6081/10000], Validation Loss: 0.94817105, Validation Accuracy: 0.6029\n",
      "Epoch [6082/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [6082/10000], Validation Loss: 0.94784141, Validation Accuracy: 0.6029\n",
      "Epoch [6083/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6083/10000], Validation Loss: 0.94758558, Validation Accuracy: 0.6029\n",
      "Epoch [6084/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6084/10000], Validation Loss: 0.94743145, Validation Accuracy: 0.6029\n",
      "Epoch [6085/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6085/10000], Validation Loss: 0.94734895, Validation Accuracy: 0.6029\n",
      "Epoch [6086/10000], Training Loss: 0.61867903, Training Accuracy: 0.9328\n",
      "Epoch [6086/10000], Validation Loss: 0.94739878, Validation Accuracy: 0.6029\n",
      "Epoch [6087/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6087/10000], Validation Loss: 0.94749719, Validation Accuracy: 0.6029\n",
      "Epoch [6088/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6088/10000], Validation Loss: 0.94753733, Validation Accuracy: 0.6029\n",
      "Epoch [6089/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6089/10000], Validation Loss: 0.94755507, Validation Accuracy: 0.6029\n",
      "Epoch [6090/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6090/10000], Validation Loss: 0.94756323, Validation Accuracy: 0.6029\n",
      "Epoch [6091/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6091/10000], Validation Loss: 0.94756716, Validation Accuracy: 0.6029\n",
      "Epoch [6092/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6092/10000], Validation Loss: 0.94756907, Validation Accuracy: 0.6029\n",
      "Epoch [6093/10000], Training Loss: 0.61443646, Training Accuracy: 0.9370\n",
      "Epoch [6093/10000], Validation Loss: 0.94777194, Validation Accuracy: 0.6029\n",
      "Epoch [6094/10000], Training Loss: 0.62708299, Training Accuracy: 0.9244\n",
      "Epoch [6094/10000], Validation Loss: 0.94782162, Validation Accuracy: 0.6029\n",
      "Epoch [6095/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6095/10000], Validation Loss: 0.94774899, Validation Accuracy: 0.6029\n",
      "Epoch [6096/10000], Training Loss: 0.59769972, Training Accuracy: 0.9538\n",
      "Epoch [6096/10000], Validation Loss: 0.94767427, Validation Accuracy: 0.6029\n",
      "Epoch [6097/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [6097/10000], Validation Loss: 0.94753563, Validation Accuracy: 0.6029\n",
      "Epoch [6098/10000], Training Loss: 0.58983258, Training Accuracy: 0.9622\n",
      "Epoch [6098/10000], Validation Loss: 0.93255538, Validation Accuracy: 0.6176\n",
      "Epoch [6099/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6099/10000], Validation Loss: 0.94790187, Validation Accuracy: 0.6029\n",
      "Epoch [6100/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6100/10000], Validation Loss: 0.94829482, Validation Accuracy: 0.6029\n",
      "Epoch [6101/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6101/10000], Validation Loss: 0.94838497, Validation Accuracy: 0.6029\n",
      "Epoch [6102/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6102/10000], Validation Loss: 0.94841385, Validation Accuracy: 0.6029\n",
      "Epoch [6103/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6103/10000], Validation Loss: 0.94842517, Validation Accuracy: 0.6029\n",
      "Epoch [6104/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6104/10000], Validation Loss: 0.94843012, Validation Accuracy: 0.6029\n",
      "Epoch [6105/10000], Training Loss: 0.60190152, Training Accuracy: 0.9496\n",
      "Epoch [6105/10000], Validation Loss: 0.94845587, Validation Accuracy: 0.6029\n",
      "Epoch [6106/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6106/10000], Validation Loss: 0.94847223, Validation Accuracy: 0.6029\n",
      "Epoch [6107/10000], Training Loss: 0.61030623, Training Accuracy: 0.9412\n",
      "Epoch [6107/10000], Validation Loss: 0.94847697, Validation Accuracy: 0.6029\n",
      "Epoch [6108/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6108/10000], Validation Loss: 0.94847888, Validation Accuracy: 0.6029\n",
      "Epoch [6109/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6109/10000], Validation Loss: 0.94847974, Validation Accuracy: 0.6029\n",
      "Epoch [6110/10000], Training Loss: 0.60607786, Training Accuracy: 0.9454\n",
      "Epoch [6110/10000], Validation Loss: 0.94847989, Validation Accuracy: 0.6029\n",
      "Epoch [6111/10000], Training Loss: 0.61867166, Training Accuracy: 0.9328\n",
      "Epoch [6111/10000], Validation Loss: 0.94848156, Validation Accuracy: 0.6029\n",
      "Epoch [6112/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [6112/10000], Validation Loss: 0.94848225, Validation Accuracy: 0.6029\n",
      "Epoch [6113/10000], Training Loss: 0.60606697, Training Accuracy: 0.9454\n",
      "Epoch [6113/10000], Validation Loss: 0.94848225, Validation Accuracy: 0.6029\n",
      "Epoch [6114/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6114/10000], Validation Loss: 0.94848225, Validation Accuracy: 0.6029\n",
      "Epoch [6115/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6115/10000], Validation Loss: 0.94848222, Validation Accuracy: 0.6029\n",
      "Epoch [6116/10000], Training Loss: 0.61026856, Training Accuracy: 0.9412\n",
      "Epoch [6116/10000], Validation Loss: 0.94848216, Validation Accuracy: 0.6029\n",
      "Epoch [6117/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6117/10000], Validation Loss: 0.94848210, Validation Accuracy: 0.6029\n",
      "Epoch [6118/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6118/10000], Validation Loss: 0.94848210, Validation Accuracy: 0.6029\n",
      "Epoch [6119/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6119/10000], Validation Loss: 0.94848210, Validation Accuracy: 0.6029\n",
      "Epoch [6120/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6120/10000], Validation Loss: 0.94848210, Validation Accuracy: 0.6029\n",
      "Epoch [6121/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6121/10000], Validation Loss: 0.94848207, Validation Accuracy: 0.6029\n",
      "Epoch [6122/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6122/10000], Validation Loss: 0.94848207, Validation Accuracy: 0.6029\n",
      "Epoch [6123/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6123/10000], Validation Loss: 0.94848204, Validation Accuracy: 0.6029\n",
      "Epoch [6124/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6124/10000], Validation Loss: 0.94848204, Validation Accuracy: 0.6029\n",
      "Epoch [6125/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6125/10000], Validation Loss: 0.94848204, Validation Accuracy: 0.6029\n",
      "Epoch [6126/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6126/10000], Validation Loss: 0.94848204, Validation Accuracy: 0.6029\n",
      "Epoch [6127/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6127/10000], Validation Loss: 0.94848204, Validation Accuracy: 0.6029\n",
      "Epoch [6128/10000], Training Loss: 0.60553610, Training Accuracy: 0.9454\n",
      "Epoch [6128/10000], Validation Loss: 0.94809169, Validation Accuracy: 0.6029\n",
      "Epoch [6129/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [6129/10000], Validation Loss: 0.96160993, Validation Accuracy: 0.5882\n",
      "Epoch [6130/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6130/10000], Validation Loss: 0.96208945, Validation Accuracy: 0.5882\n",
      "Epoch [6131/10000], Training Loss: 0.60173193, Training Accuracy: 0.9496\n",
      "Epoch [6131/10000], Validation Loss: 0.94826290, Validation Accuracy: 0.6029\n",
      "Epoch [6132/10000], Training Loss: 0.60191650, Training Accuracy: 0.9496\n",
      "Epoch [6132/10000], Validation Loss: 0.94849867, Validation Accuracy: 0.6029\n",
      "Epoch [6133/10000], Training Loss: 0.59767906, Training Accuracy: 0.9538\n",
      "Epoch [6133/10000], Validation Loss: 0.94850352, Validation Accuracy: 0.6029\n",
      "Epoch [6134/10000], Training Loss: 0.61446937, Training Accuracy: 0.9370\n",
      "Epoch [6134/10000], Validation Loss: 0.94850370, Validation Accuracy: 0.6029\n",
      "Epoch [6135/10000], Training Loss: 0.61454456, Training Accuracy: 0.9370\n",
      "Epoch [6135/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6136/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6136/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6137/10000], Training Loss: 0.60186004, Training Accuracy: 0.9496\n",
      "Epoch [6137/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6138/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6138/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6139/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6139/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6140/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6140/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6141/10000], Training Loss: 0.59766324, Training Accuracy: 0.9538\n",
      "Epoch [6141/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6142/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6142/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6143/10000], Training Loss: 0.62707511, Training Accuracy: 0.9244\n",
      "Epoch [6143/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6144/10000], Training Loss: 0.59825810, Training Accuracy: 0.9538\n",
      "Epoch [6144/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [6145/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6145/10000], Validation Loss: 0.99453950, Validation Accuracy: 0.5588\n",
      "Epoch [6146/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6146/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6147/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6147/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6148/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6148/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6149/10000], Training Loss: 0.63127651, Training Accuracy: 0.9202\n",
      "Epoch [6149/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6150/10000], Training Loss: 0.60584526, Training Accuracy: 0.9454\n",
      "Epoch [6150/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6151/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6151/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6152/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6152/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6153/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6153/10000], Validation Loss: 1.00731912, Validation Accuracy: 0.5441\n",
      "Epoch [6154/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6154/10000], Validation Loss: 1.00682285, Validation Accuracy: 0.5441\n",
      "Epoch [6155/10000], Training Loss: 0.60169028, Training Accuracy: 0.9496\n",
      "Epoch [6155/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6156/10000], Training Loss: 0.60937717, Training Accuracy: 0.9412\n",
      "Epoch [6156/10000], Validation Loss: 0.97791517, Validation Accuracy: 0.5735\n",
      "Epoch [6157/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6157/10000], Validation Loss: 0.96301743, Validation Accuracy: 0.5882\n",
      "Epoch [6158/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6158/10000], Validation Loss: 0.94850367, Validation Accuracy: 0.6029\n",
      "Epoch [6159/10000], Training Loss: 0.61324179, Training Accuracy: 0.9370\n",
      "Epoch [6159/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6160/10000], Training Loss: 0.58521061, Training Accuracy: 0.9664\n",
      "Epoch [6160/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6161/10000], Training Loss: 0.60186510, Training Accuracy: 0.9496\n",
      "Epoch [6161/10000], Validation Loss: 0.97791484, Validation Accuracy: 0.5735\n",
      "Epoch [6162/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6162/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6163/10000], Training Loss: 0.60152175, Training Accuracy: 0.9496\n",
      "Epoch [6163/10000], Validation Loss: 0.96321458, Validation Accuracy: 0.5882\n",
      "Epoch [6164/10000], Training Loss: 0.59756636, Training Accuracy: 0.9538\n",
      "Epoch [6164/10000], Validation Loss: 0.97791615, Validation Accuracy: 0.5735\n",
      "Epoch [6165/10000], Training Loss: 0.59318849, Training Accuracy: 0.9580\n",
      "Epoch [6165/10000], Validation Loss: 0.96320990, Validation Accuracy: 0.5882\n",
      "Epoch [6166/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6166/10000], Validation Loss: 0.96320990, Validation Accuracy: 0.5882\n",
      "Epoch [6167/10000], Training Loss: 0.61026589, Training Accuracy: 0.9412\n",
      "Epoch [6167/10000], Validation Loss: 0.96320996, Validation Accuracy: 0.5882\n",
      "Epoch [6168/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6168/10000], Validation Loss: 0.96320996, Validation Accuracy: 0.5882\n",
      "Epoch [6169/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6169/10000], Validation Loss: 0.96320996, Validation Accuracy: 0.5882\n",
      "Epoch [6170/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [6170/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [6171/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [6171/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [6172/10000], Training Loss: 0.60615161, Training Accuracy: 0.9454\n",
      "Epoch [6172/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [6173/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6173/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [6174/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6174/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [6175/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [6175/10000], Validation Loss: 0.96321002, Validation Accuracy: 0.5882\n",
      "Epoch [6176/10000], Training Loss: 0.62696609, Training Accuracy: 0.9244\n",
      "Epoch [6176/10000], Validation Loss: 0.96321008, Validation Accuracy: 0.5882\n",
      "Epoch [6177/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [6177/10000], Validation Loss: 0.96321020, Validation Accuracy: 0.5882\n",
      "Epoch [6178/10000], Training Loss: 0.61026790, Training Accuracy: 0.9412\n",
      "Epoch [6178/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6179/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6179/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6180/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6180/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6181/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6181/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6182/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [6182/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6183/10000], Training Loss: 0.60186516, Training Accuracy: 0.9496\n",
      "Epoch [6183/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6184/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6184/10000], Validation Loss: 0.96321031, Validation Accuracy: 0.5882\n",
      "Epoch [6185/10000], Training Loss: 0.60240745, Training Accuracy: 0.9496\n",
      "Epoch [6185/10000], Validation Loss: 0.96320957, Validation Accuracy: 0.5882\n",
      "Epoch [6186/10000], Training Loss: 0.61027120, Training Accuracy: 0.9412\n",
      "Epoch [6186/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6187/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6187/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6188/10000], Training Loss: 0.61836158, Training Accuracy: 0.9328\n",
      "Epoch [6188/10000], Validation Loss: 0.98524621, Validation Accuracy: 0.5588\n",
      "Epoch [6189/10000], Training Loss: 0.61906361, Training Accuracy: 0.9328\n",
      "Epoch [6189/10000], Validation Loss: 1.00732771, Validation Accuracy: 0.5441\n",
      "Epoch [6190/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6190/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6191/10000], Training Loss: 0.62292447, Training Accuracy: 0.9286\n",
      "Epoch [6191/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6192/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [6192/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6193/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6193/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6194/10000], Training Loss: 0.61811359, Training Accuracy: 0.9328\n",
      "Epoch [6194/10000], Validation Loss: 1.00732645, Validation Accuracy: 0.5441\n",
      "Epoch [6195/10000], Training Loss: 0.61458841, Training Accuracy: 0.9370\n",
      "Epoch [6195/10000], Validation Loss: 0.99325469, Validation Accuracy: 0.5588\n",
      "Epoch [6196/10000], Training Loss: 0.62312246, Training Accuracy: 0.9286\n",
      "Epoch [6196/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6197/10000], Training Loss: 0.63854596, Training Accuracy: 0.9118\n",
      "Epoch [6197/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6198/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6198/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6199/10000], Training Loss: 0.59766338, Training Accuracy: 0.9538\n",
      "Epoch [6199/10000], Validation Loss: 0.94850367, Validation Accuracy: 0.6029\n",
      "Epoch [6200/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6200/10000], Validation Loss: 0.94845888, Validation Accuracy: 0.6029\n",
      "Epoch [6201/10000], Training Loss: 0.60186417, Training Accuracy: 0.9496\n",
      "Epoch [6201/10000], Validation Loss: 0.94786084, Validation Accuracy: 0.6029\n",
      "Epoch [6202/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6202/10000], Validation Loss: 0.94721434, Validation Accuracy: 0.6029\n",
      "Epoch [6203/10000], Training Loss: 0.59766325, Training Accuracy: 0.9538\n",
      "Epoch [6203/10000], Validation Loss: 0.94712996, Validation Accuracy: 0.6029\n",
      "Epoch [6204/10000], Training Loss: 0.60186504, Training Accuracy: 0.9496\n",
      "Epoch [6204/10000], Validation Loss: 0.94714856, Validation Accuracy: 0.6029\n",
      "Epoch [6205/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6205/10000], Validation Loss: 0.94716883, Validation Accuracy: 0.6029\n",
      "Epoch [6206/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6206/10000], Validation Loss: 0.94718099, Validation Accuracy: 0.6029\n",
      "Epoch [6207/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6207/10000], Validation Loss: 0.94718739, Validation Accuracy: 0.6029\n",
      "Epoch [6208/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6208/10000], Validation Loss: 0.94719055, Validation Accuracy: 0.6029\n",
      "Epoch [6209/10000], Training Loss: 0.61448199, Training Accuracy: 0.9370\n",
      "Epoch [6209/10000], Validation Loss: 0.94751319, Validation Accuracy: 0.6029\n",
      "Epoch [6210/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6210/10000], Validation Loss: 0.94808123, Validation Accuracy: 0.6029\n",
      "Epoch [6211/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6211/10000], Validation Loss: 0.94824973, Validation Accuracy: 0.6029\n",
      "Epoch [6212/10000], Training Loss: 0.62282325, Training Accuracy: 0.9286\n",
      "Epoch [6212/10000], Validation Loss: 0.94833708, Validation Accuracy: 0.6029\n",
      "Epoch [6213/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6213/10000], Validation Loss: 0.94836968, Validation Accuracy: 0.6029\n",
      "Epoch [6214/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6214/10000], Validation Loss: 0.94838309, Validation Accuracy: 0.6029\n",
      "Epoch [6215/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6215/10000], Validation Loss: 0.94838911, Validation Accuracy: 0.6029\n",
      "Epoch [6216/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [6216/10000], Validation Loss: 0.94839191, Validation Accuracy: 0.6029\n",
      "Epoch [6217/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6217/10000], Validation Loss: 0.94839320, Validation Accuracy: 0.6029\n",
      "Epoch [6218/10000], Training Loss: 0.62286492, Training Accuracy: 0.9286\n",
      "Epoch [6218/10000], Validation Loss: 0.94818994, Validation Accuracy: 0.6029\n",
      "Epoch [6219/10000], Training Loss: 0.61834578, Training Accuracy: 0.9328\n",
      "Epoch [6219/10000], Validation Loss: 0.94803986, Validation Accuracy: 0.6029\n",
      "Epoch [6220/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6220/10000], Validation Loss: 0.94850335, Validation Accuracy: 0.6029\n",
      "Epoch [6221/10000], Training Loss: 0.61019152, Training Accuracy: 0.9412\n",
      "Epoch [6221/10000], Validation Loss: 0.94850370, Validation Accuracy: 0.6029\n",
      "Epoch [6222/10000], Training Loss: 0.60606632, Training Accuracy: 0.9454\n",
      "Epoch [6222/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6223/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6223/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6224/10000], Training Loss: 0.59767778, Training Accuracy: 0.9538\n",
      "Epoch [6224/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6225/10000], Training Loss: 0.59766362, Training Accuracy: 0.9538\n",
      "Epoch [6225/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6226/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6226/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6227/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6227/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6228/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6228/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6229/10000], Training Loss: 0.61440298, Training Accuracy: 0.9370\n",
      "Epoch [6229/10000], Validation Loss: 0.94850364, Validation Accuracy: 0.6029\n",
      "Epoch [6230/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6230/10000], Validation Loss: 0.94850317, Validation Accuracy: 0.6029\n",
      "Epoch [6231/10000], Training Loss: 0.62287454, Training Accuracy: 0.9286\n",
      "Epoch [6231/10000], Validation Loss: 0.94850245, Validation Accuracy: 0.6029\n",
      "Epoch [6232/10000], Training Loss: 0.63547783, Training Accuracy: 0.9160\n",
      "Epoch [6232/10000], Validation Loss: 0.94850171, Validation Accuracy: 0.6029\n",
      "Epoch [6233/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6233/10000], Validation Loss: 0.94850120, Validation Accuracy: 0.6029\n",
      "Epoch [6234/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6234/10000], Validation Loss: 0.94850090, Validation Accuracy: 0.6029\n",
      "Epoch [6235/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6235/10000], Validation Loss: 0.94850075, Validation Accuracy: 0.6029\n",
      "Epoch [6236/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6236/10000], Validation Loss: 0.94850066, Validation Accuracy: 0.6029\n",
      "Epoch [6237/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6237/10000], Validation Loss: 0.94850063, Validation Accuracy: 0.6029\n",
      "Epoch [6238/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [6238/10000], Validation Loss: 0.94850060, Validation Accuracy: 0.6029\n",
      "Epoch [6239/10000], Training Loss: 0.61561792, Training Accuracy: 0.9370\n",
      "Epoch [6239/10000], Validation Loss: 0.96271992, Validation Accuracy: 0.5882\n",
      "Epoch [6240/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [6240/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6241/10000], Training Loss: 0.60200391, Training Accuracy: 0.9496\n",
      "Epoch [6241/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6242/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6242/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6243/10000], Training Loss: 0.61867573, Training Accuracy: 0.9328\n",
      "Epoch [6243/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6244/10000], Training Loss: 0.62728732, Training Accuracy: 0.9244\n",
      "Epoch [6244/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6245/10000], Training Loss: 0.61422176, Training Accuracy: 0.9370\n",
      "Epoch [6245/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6246/10000], Training Loss: 0.58505855, Training Accuracy: 0.9664\n",
      "Epoch [6246/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6247/10000], Training Loss: 0.60142878, Training Accuracy: 0.9496\n",
      "Epoch [6247/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6248/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [6248/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6249/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6249/10000], Validation Loss: 0.97791639, Validation Accuracy: 0.5735\n",
      "Epoch [6250/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [6250/10000], Validation Loss: 0.99262166, Validation Accuracy: 0.5588\n",
      "Epoch [6251/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6251/10000], Validation Loss: 0.99272335, Validation Accuracy: 0.5588\n",
      "Epoch [6252/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6252/10000], Validation Loss: 0.99422765, Validation Accuracy: 0.5588\n",
      "Epoch [6253/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6253/10000], Validation Loss: 0.99751055, Validation Accuracy: 0.5588\n",
      "Epoch [6254/10000], Training Loss: 0.60606805, Training Accuracy: 0.9454\n",
      "Epoch [6254/10000], Validation Loss: 0.99995255, Validation Accuracy: 0.5441\n",
      "Epoch [6255/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6255/10000], Validation Loss: 1.00118577, Validation Accuracy: 0.5441\n",
      "Epoch [6256/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6256/10000], Validation Loss: 1.00175589, Validation Accuracy: 0.5441\n",
      "Epoch [6257/10000], Training Loss: 0.59767284, Training Accuracy: 0.9538\n",
      "Epoch [6257/10000], Validation Loss: 0.99777514, Validation Accuracy: 0.5588\n",
      "Epoch [6258/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6258/10000], Validation Loss: 0.99402726, Validation Accuracy: 0.5588\n",
      "Epoch [6259/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6259/10000], Validation Loss: 0.99330598, Validation Accuracy: 0.5588\n",
      "Epoch [6260/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [6260/10000], Validation Loss: 0.99310148, Validation Accuracy: 0.5588\n",
      "Epoch [6261/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [6261/10000], Validation Loss: 0.99302572, Validation Accuracy: 0.5588\n",
      "Epoch [6262/10000], Training Loss: 0.60606652, Training Accuracy: 0.9454\n",
      "Epoch [6262/10000], Validation Loss: 0.99299216, Validation Accuracy: 0.5588\n",
      "Epoch [6263/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6263/10000], Validation Loss: 0.99297625, Validation Accuracy: 0.5588\n",
      "Epoch [6264/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6264/10000], Validation Loss: 0.99296886, Validation Accuracy: 0.5588\n",
      "Epoch [6265/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [6265/10000], Validation Loss: 0.99296540, Validation Accuracy: 0.5588\n",
      "Epoch [6266/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [6266/10000], Validation Loss: 0.99296373, Validation Accuracy: 0.5588\n",
      "Epoch [6267/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6267/10000], Validation Loss: 0.99296302, Validation Accuracy: 0.5588\n",
      "Epoch [6268/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6268/10000], Validation Loss: 0.99296272, Validation Accuracy: 0.5588\n",
      "Epoch [6269/10000], Training Loss: 0.59766354, Training Accuracy: 0.9538\n",
      "Epoch [6269/10000], Validation Loss: 0.99296343, Validation Accuracy: 0.5588\n",
      "Epoch [6270/10000], Training Loss: 0.58520997, Training Accuracy: 0.9664\n",
      "Epoch [6270/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6271/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6271/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6272/10000], Training Loss: 0.60187722, Training Accuracy: 0.9496\n",
      "Epoch [6272/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6273/10000], Training Loss: 0.59600068, Training Accuracy: 0.9538\n",
      "Epoch [6273/10000], Validation Loss: 0.97752145, Validation Accuracy: 0.5735\n",
      "Epoch [6274/10000], Training Loss: 0.60606676, Training Accuracy: 0.9454\n",
      "Epoch [6274/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6275/10000], Training Loss: 0.62287565, Training Accuracy: 0.9286\n",
      "Epoch [6275/10000], Validation Loss: 1.01164734, Validation Accuracy: 0.5441\n",
      "Epoch [6276/10000], Training Loss: 0.62286807, Training Accuracy: 0.9286\n",
      "Epoch [6276/10000], Validation Loss: 1.02202830, Validation Accuracy: 0.5294\n",
      "Epoch [6277/10000], Training Loss: 0.60336672, Training Accuracy: 0.9496\n",
      "Epoch [6277/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6278/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6278/10000], Validation Loss: 0.99262127, Validation Accuracy: 0.5588\n",
      "Epoch [6279/10000], Training Loss: 0.61026871, Training Accuracy: 0.9412\n",
      "Epoch [6279/10000], Validation Loss: 0.97791553, Validation Accuracy: 0.5735\n",
      "Epoch [6280/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6280/10000], Validation Loss: 0.97954103, Validation Accuracy: 0.5735\n",
      "Epoch [6281/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6281/10000], Validation Loss: 0.99201924, Validation Accuracy: 0.5588\n",
      "Epoch [6282/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6282/10000], Validation Loss: 0.99262720, Validation Accuracy: 0.5588\n",
      "Epoch [6283/10000], Training Loss: 0.59848656, Training Accuracy: 0.9538\n",
      "Epoch [6283/10000], Validation Loss: 1.00732702, Validation Accuracy: 0.5441\n",
      "Epoch [6284/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6284/10000], Validation Loss: 0.97793686, Validation Accuracy: 0.5735\n",
      "Epoch [6285/10000], Training Loss: 0.60606689, Training Accuracy: 0.9454\n",
      "Epoch [6285/10000], Validation Loss: 1.00663385, Validation Accuracy: 0.5441\n",
      "Epoch [6286/10000], Training Loss: 0.61867120, Training Accuracy: 0.9328\n",
      "Epoch [6286/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6287/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6287/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6288/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6288/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6289/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6289/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6290/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6290/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6291/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6291/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6292/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6292/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6293/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6293/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6294/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6294/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6295/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6295/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6296/10000], Training Loss: 0.59799648, Training Accuracy: 0.9538\n",
      "Epoch [6296/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6297/10000], Training Loss: 0.61060156, Training Accuracy: 0.9412\n",
      "Epoch [6297/10000], Validation Loss: 1.02119794, Validation Accuracy: 0.5294\n",
      "Epoch [6298/10000], Training Loss: 0.60708583, Training Accuracy: 0.9454\n",
      "Epoch [6298/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6299/10000], Training Loss: 0.61058470, Training Accuracy: 0.9412\n",
      "Epoch [6299/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6300/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6300/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6301/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6301/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [6302/10000], Training Loss: 0.59346184, Training Accuracy: 0.9580\n",
      "Epoch [6302/10000], Validation Loss: 0.93379810, Validation Accuracy: 0.6176\n",
      "Epoch [6303/10000], Training Loss: 0.60650391, Training Accuracy: 0.9454\n",
      "Epoch [6303/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6304/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [6304/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6305/10000], Training Loss: 0.61032343, Training Accuracy: 0.9412\n",
      "Epoch [6305/10000], Validation Loss: 0.94796783, Validation Accuracy: 0.6029\n",
      "Epoch [6306/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6306/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6307/10000], Training Loss: 0.61866873, Training Accuracy: 0.9328\n",
      "Epoch [6307/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6308/10000], Training Loss: 0.61446983, Training Accuracy: 0.9370\n",
      "Epoch [6308/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6309/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6309/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6310/10000], Training Loss: 0.61031171, Training Accuracy: 0.9412\n",
      "Epoch [6310/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6311/10000], Training Loss: 0.59761001, Training Accuracy: 0.9538\n",
      "Epoch [6311/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6312/10000], Training Loss: 0.61474443, Training Accuracy: 0.9370\n",
      "Epoch [6312/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6313/10000], Training Loss: 0.61867175, Training Accuracy: 0.9328\n",
      "Epoch [6313/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6314/10000], Training Loss: 0.58925750, Training Accuracy: 0.9622\n",
      "Epoch [6314/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6315/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6315/10000], Validation Loss: 0.93379781, Validation Accuracy: 0.6176\n",
      "Epoch [6316/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [6316/10000], Validation Loss: 0.93379760, Validation Accuracy: 0.6176\n",
      "Epoch [6317/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6317/10000], Validation Loss: 0.93379724, Validation Accuracy: 0.6176\n",
      "Epoch [6318/10000], Training Loss: 0.61445168, Training Accuracy: 0.9370\n",
      "Epoch [6318/10000], Validation Loss: 0.93379501, Validation Accuracy: 0.6176\n",
      "Epoch [6319/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6319/10000], Validation Loss: 0.93379113, Validation Accuracy: 0.6176\n",
      "Epoch [6320/10000], Training Loss: 0.60371602, Training Accuracy: 0.9454\n",
      "Epoch [6320/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6321/10000], Training Loss: 0.60606698, Training Accuracy: 0.9454\n",
      "Epoch [6321/10000], Validation Loss: 0.96320957, Validation Accuracy: 0.5882\n",
      "Epoch [6322/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6322/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [6323/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6323/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6324/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6324/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6325/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6325/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6326/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6326/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6327/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6327/10000], Validation Loss: 0.94850370, Validation Accuracy: 0.6029\n",
      "Epoch [6328/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6328/10000], Validation Loss: 0.94850370, Validation Accuracy: 0.6029\n",
      "Epoch [6329/10000], Training Loss: 0.63127687, Training Accuracy: 0.9202\n",
      "Epoch [6329/10000], Validation Loss: 0.94850370, Validation Accuracy: 0.6029\n",
      "Epoch [6330/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6330/10000], Validation Loss: 0.94850367, Validation Accuracy: 0.6029\n",
      "Epoch [6331/10000], Training Loss: 0.62723379, Training Accuracy: 0.9244\n",
      "Epoch [6331/10000], Validation Loss: 0.93379778, Validation Accuracy: 0.6176\n",
      "Epoch [6332/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [6332/10000], Validation Loss: 0.93379775, Validation Accuracy: 0.6176\n",
      "Epoch [6333/10000], Training Loss: 0.61963597, Training Accuracy: 0.9328\n",
      "Epoch [6333/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6334/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6334/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6335/10000], Training Loss: 0.61909823, Training Accuracy: 0.9328\n",
      "Epoch [6335/10000], Validation Loss: 0.94841030, Validation Accuracy: 0.6029\n",
      "Epoch [6336/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6336/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6337/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6337/10000], Validation Loss: 0.93693760, Validation Accuracy: 0.6176\n",
      "Epoch [6338/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6338/10000], Validation Loss: 0.94850343, Validation Accuracy: 0.6029\n",
      "Epoch [6339/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6339/10000], Validation Loss: 0.94904321, Validation Accuracy: 0.6029\n",
      "Epoch [6340/10000], Training Loss: 0.59700289, Training Accuracy: 0.9538\n",
      "Epoch [6340/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6341/10000], Training Loss: 0.61434467, Training Accuracy: 0.9370\n",
      "Epoch [6341/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6342/10000], Training Loss: 0.61026866, Training Accuracy: 0.9412\n",
      "Epoch [6342/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [6343/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6343/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6344/10000], Training Loss: 0.61027839, Training Accuracy: 0.9412\n",
      "Epoch [6344/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6345/10000], Training Loss: 0.60189356, Training Accuracy: 0.9496\n",
      "Epoch [6345/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6346/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6346/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6347/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6347/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6348/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6348/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6349/10000], Training Loss: 0.62287342, Training Accuracy: 0.9286\n",
      "Epoch [6349/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6350/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6350/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6351/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6351/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6352/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6352/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6353/10000], Training Loss: 0.58926013, Training Accuracy: 0.9622\n",
      "Epoch [6353/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6354/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6354/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6355/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6355/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6356/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6356/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [6357/10000], Training Loss: 0.60015292, Training Accuracy: 0.9496\n",
      "Epoch [6357/10000], Validation Loss: 0.94850361, Validation Accuracy: 0.6029\n",
      "Epoch [6358/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6358/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [6359/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6359/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6360/10000], Training Loss: 0.59346431, Training Accuracy: 0.9580\n",
      "Epoch [6360/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6361/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [6361/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6362/10000], Training Loss: 0.60606921, Training Accuracy: 0.9454\n",
      "Epoch [6362/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6363/10000], Training Loss: 0.60186486, Training Accuracy: 0.9496\n",
      "Epoch [6363/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6364/10000], Training Loss: 0.59061933, Training Accuracy: 0.9580\n",
      "Epoch [6364/10000], Validation Loss: 0.96320951, Validation Accuracy: 0.5882\n",
      "Epoch [6365/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6365/10000], Validation Loss: 0.93383291, Validation Accuracy: 0.6176\n",
      "Epoch [6366/10000], Training Loss: 0.60186505, Training Accuracy: 0.9496\n",
      "Epoch [6366/10000], Validation Loss: 0.96321467, Validation Accuracy: 0.5882\n",
      "Epoch [6367/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6367/10000], Validation Loss: 0.97387397, Validation Accuracy: 0.5735\n",
      "Epoch [6368/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6368/10000], Validation Loss: 0.97781411, Validation Accuracy: 0.5735\n",
      "Epoch [6369/10000], Training Loss: 0.60508072, Training Accuracy: 0.9454\n",
      "Epoch [6369/10000], Validation Loss: 0.96319366, Validation Accuracy: 0.5882\n",
      "Epoch [6370/10000], Training Loss: 0.59766343, Training Accuracy: 0.9538\n",
      "Epoch [6370/10000], Validation Loss: 0.96331272, Validation Accuracy: 0.5882\n",
      "Epoch [6371/10000], Training Loss: 0.60064135, Training Accuracy: 0.9496\n",
      "Epoch [6371/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6372/10000], Training Loss: 0.59345735, Training Accuracy: 0.9580\n",
      "Epoch [6372/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6373/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [6373/10000], Validation Loss: 1.03673834, Validation Accuracy: 0.5147\n",
      "Epoch [6374/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6374/10000], Validation Loss: 1.03623757, Validation Accuracy: 0.5147\n",
      "Epoch [6375/10000], Training Loss: 0.60186516, Training Accuracy: 0.9496\n",
      "Epoch [6375/10000], Validation Loss: 1.02203551, Validation Accuracy: 0.5294\n",
      "Epoch [6376/10000], Training Loss: 0.59632564, Training Accuracy: 0.9538\n",
      "Epoch [6376/10000], Validation Loss: 1.02131826, Validation Accuracy: 0.5294\n",
      "Epoch [6377/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [6377/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6378/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6378/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6379/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6379/10000], Validation Loss: 0.99261484, Validation Accuracy: 0.5588\n",
      "Epoch [6380/10000], Training Loss: 0.58925694, Training Accuracy: 0.9622\n",
      "Epoch [6380/10000], Validation Loss: 0.99229991, Validation Accuracy: 0.5588\n",
      "Epoch [6381/10000], Training Loss: 0.58092879, Training Accuracy: 0.9706\n",
      "Epoch [6381/10000], Validation Loss: 0.98216924, Validation Accuracy: 0.5735\n",
      "Epoch [6382/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6382/10000], Validation Loss: 0.97824633, Validation Accuracy: 0.5735\n",
      "Epoch [6383/10000], Training Loss: 0.58928921, Training Accuracy: 0.9622\n",
      "Epoch [6383/10000], Validation Loss: 0.97802737, Validation Accuracy: 0.5735\n",
      "Epoch [6384/10000], Training Loss: 0.59514640, Training Accuracy: 0.9580\n",
      "Epoch [6384/10000], Validation Loss: 1.02203265, Validation Accuracy: 0.5294\n",
      "Epoch [6385/10000], Training Loss: 0.59091067, Training Accuracy: 0.9622\n",
      "Epoch [6385/10000], Validation Loss: 1.02194589, Validation Accuracy: 0.5294\n",
      "Epoch [6386/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [6386/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6387/10000], Training Loss: 0.58762356, Training Accuracy: 0.9622\n",
      "Epoch [6387/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6388/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6388/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6389/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6389/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6390/10000], Training Loss: 0.60742537, Training Accuracy: 0.9454\n",
      "Epoch [6390/10000], Validation Loss: 0.94788826, Validation Accuracy: 0.6029\n",
      "Epoch [6391/10000], Training Loss: 0.60187597, Training Accuracy: 0.9496\n",
      "Epoch [6391/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6392/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [6392/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [6393/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6393/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [6394/10000], Training Loss: 0.58968249, Training Accuracy: 0.9622\n",
      "Epoch [6394/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [6395/10000], Training Loss: 0.57707672, Training Accuracy: 0.9748\n",
      "Epoch [6395/10000], Validation Loss: 0.91905123, Validation Accuracy: 0.6324\n",
      "Epoch [6396/10000], Training Loss: 0.59346173, Training Accuracy: 0.9580\n",
      "Epoch [6396/10000], Validation Loss: 0.96229053, Validation Accuracy: 0.5882\n",
      "Epoch [6397/10000], Training Loss: 0.60606269, Training Accuracy: 0.9454\n",
      "Epoch [6397/10000], Validation Loss: 0.94841027, Validation Accuracy: 0.6029\n",
      "Epoch [6398/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6398/10000], Validation Loss: 0.94845477, Validation Accuracy: 0.6029\n",
      "Epoch [6399/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6399/10000], Validation Loss: 0.96559721, Validation Accuracy: 0.5882\n",
      "Epoch [6400/10000], Training Loss: 0.58925953, Training Accuracy: 0.9622\n",
      "Epoch [6400/10000], Validation Loss: 0.97649989, Validation Accuracy: 0.5735\n",
      "Epoch [6401/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6401/10000], Validation Loss: 0.97675976, Validation Accuracy: 0.5735\n",
      "Epoch [6402/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [6402/10000], Validation Loss: 0.97698191, Validation Accuracy: 0.5735\n",
      "Epoch [6403/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6403/10000], Validation Loss: 0.97709090, Validation Accuracy: 0.5735\n",
      "Epoch [6404/10000], Training Loss: 0.60107554, Training Accuracy: 0.9496\n",
      "Epoch [6404/10000], Validation Loss: 0.96320862, Validation Accuracy: 0.5882\n",
      "Epoch [6405/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [6405/10000], Validation Loss: 0.94853348, Validation Accuracy: 0.6029\n",
      "Epoch [6406/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [6406/10000], Validation Loss: 0.94850329, Validation Accuracy: 0.6029\n",
      "Epoch [6407/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [6407/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [6408/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6408/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [6409/10000], Training Loss: 0.59345789, Training Accuracy: 0.9580\n",
      "Epoch [6409/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [6410/10000], Training Loss: 0.60163376, Training Accuracy: 0.9496\n",
      "Epoch [6410/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [6411/10000], Training Loss: 0.59361138, Training Accuracy: 0.9580\n",
      "Epoch [6411/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6412/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6412/10000], Validation Loss: 0.98205683, Validation Accuracy: 0.5735\n",
      "Epoch [6413/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6413/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6414/10000], Training Loss: 0.59768485, Training Accuracy: 0.9538\n",
      "Epoch [6414/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6415/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6415/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6416/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6416/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6417/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [6417/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6418/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6418/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6419/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6419/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6420/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6420/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6421/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6421/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6422/10000], Training Loss: 0.60186510, Training Accuracy: 0.9496\n",
      "Epoch [6422/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6423/10000], Training Loss: 0.60991262, Training Accuracy: 0.9412\n",
      "Epoch [6423/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6424/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6424/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6425/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6425/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6426/10000], Training Loss: 0.59133180, Training Accuracy: 0.9580\n",
      "Epoch [6426/10000], Validation Loss: 1.00732717, Validation Accuracy: 0.5441\n",
      "Epoch [6427/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6427/10000], Validation Loss: 0.99264133, Validation Accuracy: 0.5588\n",
      "Epoch [6428/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6428/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6429/10000], Training Loss: 0.58926050, Training Accuracy: 0.9622\n",
      "Epoch [6429/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6430/10000], Training Loss: 0.60606724, Training Accuracy: 0.9454\n",
      "Epoch [6430/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6431/10000], Training Loss: 0.60609356, Training Accuracy: 0.9454\n",
      "Epoch [6431/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6432/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6432/10000], Validation Loss: 0.99216753, Validation Accuracy: 0.5588\n",
      "Epoch [6433/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6433/10000], Validation Loss: 0.97791854, Validation Accuracy: 0.5735\n",
      "Epoch [6434/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6434/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6435/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6435/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6436/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6436/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6437/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6437/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6438/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6438/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6439/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6439/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6440/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6440/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6441/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6441/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6442/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6442/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6443/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6443/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6444/10000], Training Loss: 0.60186402, Training Accuracy: 0.9496\n",
      "Epoch [6444/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6445/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6445/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6446/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [6446/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6447/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6447/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6448/10000], Training Loss: 0.61446958, Training Accuracy: 0.9370\n",
      "Epoch [6448/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6449/10000], Training Loss: 0.58327988, Training Accuracy: 0.9664\n",
      "Epoch [6449/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6450/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6450/10000], Validation Loss: 0.97792953, Validation Accuracy: 0.5735\n",
      "Epoch [6451/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6451/10000], Validation Loss: 0.97826096, Validation Accuracy: 0.5735\n",
      "Epoch [6452/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6452/10000], Validation Loss: 0.97955287, Validation Accuracy: 0.5735\n",
      "Epoch [6453/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [6453/10000], Validation Loss: 0.98115087, Validation Accuracy: 0.5735\n",
      "Epoch [6454/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6454/10000], Validation Loss: 0.98225334, Validation Accuracy: 0.5735\n",
      "Epoch [6455/10000], Training Loss: 0.60613255, Training Accuracy: 0.9454\n",
      "Epoch [6455/10000], Validation Loss: 0.98385119, Validation Accuracy: 0.5735\n",
      "Epoch [6456/10000], Training Loss: 0.61447010, Training Accuracy: 0.9370\n",
      "Epoch [6456/10000], Validation Loss: 0.98881304, Validation Accuracy: 0.5588\n",
      "Epoch [6457/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6457/10000], Validation Loss: 0.99042177, Validation Accuracy: 0.5588\n",
      "Epoch [6458/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6458/10000], Validation Loss: 0.99096867, Validation Accuracy: 0.5588\n",
      "Epoch [6459/10000], Training Loss: 0.61447023, Training Accuracy: 0.9370\n",
      "Epoch [6459/10000], Validation Loss: 0.99118286, Validation Accuracy: 0.5588\n",
      "Epoch [6460/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6460/10000], Validation Loss: 0.99127358, Validation Accuracy: 0.5588\n",
      "Epoch [6461/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6461/10000], Validation Loss: 0.99131531, Validation Accuracy: 0.5588\n",
      "Epoch [6462/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6462/10000], Validation Loss: 0.99133486, Validation Accuracy: 0.5588\n",
      "Epoch [6463/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6463/10000], Validation Loss: 0.99134427, Validation Accuracy: 0.5588\n",
      "Epoch [6464/10000], Training Loss: 0.58505879, Training Accuracy: 0.9664\n",
      "Epoch [6464/10000], Validation Loss: 0.99132457, Validation Accuracy: 0.5588\n",
      "Epoch [6465/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6465/10000], Validation Loss: 0.99127141, Validation Accuracy: 0.5588\n",
      "Epoch [6466/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6466/10000], Validation Loss: 0.99124521, Validation Accuracy: 0.5588\n",
      "Epoch [6467/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6467/10000], Validation Loss: 0.99123257, Validation Accuracy: 0.5588\n",
      "Epoch [6468/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6468/10000], Validation Loss: 0.99122661, Validation Accuracy: 0.5588\n",
      "Epoch [6469/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6469/10000], Validation Loss: 0.99122411, Validation Accuracy: 0.5588\n",
      "Epoch [6470/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6470/10000], Validation Loss: 0.99122310, Validation Accuracy: 0.5588\n",
      "Epoch [6471/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6471/10000], Validation Loss: 0.99122277, Validation Accuracy: 0.5588\n",
      "Epoch [6472/10000], Training Loss: 0.59346242, Training Accuracy: 0.9580\n",
      "Epoch [6472/10000], Validation Loss: 0.99120149, Validation Accuracy: 0.5588\n",
      "Epoch [6473/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6473/10000], Validation Loss: 0.99115291, Validation Accuracy: 0.5588\n",
      "Epoch [6474/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6474/10000], Validation Loss: 0.99112901, Validation Accuracy: 0.5588\n",
      "Epoch [6475/10000], Training Loss: 0.59771832, Training Accuracy: 0.9538\n",
      "Epoch [6475/10000], Validation Loss: 0.98625898, Validation Accuracy: 0.5588\n",
      "Epoch [6476/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [6476/10000], Validation Loss: 0.98226842, Validation Accuracy: 0.5735\n",
      "Epoch [6477/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6477/10000], Validation Loss: 0.98080724, Validation Accuracy: 0.5735\n",
      "Epoch [6478/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6478/10000], Validation Loss: 0.98025441, Validation Accuracy: 0.5735\n",
      "Epoch [6479/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [6479/10000], Validation Loss: 0.98002240, Validation Accuracy: 0.5735\n",
      "Epoch [6480/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [6480/10000], Validation Loss: 0.97991753, Validation Accuracy: 0.5735\n",
      "Epoch [6481/10000], Training Loss: 0.59809827, Training Accuracy: 0.9538\n",
      "Epoch [6481/10000], Validation Loss: 0.97791597, Validation Accuracy: 0.5735\n",
      "Epoch [6482/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6482/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6483/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6483/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6484/10000], Training Loss: 0.62707499, Training Accuracy: 0.9244\n",
      "Epoch [6484/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6485/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6485/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6486/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6486/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6487/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6487/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6488/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6488/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6489/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6489/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6490/10000], Training Loss: 0.59346344, Training Accuracy: 0.9580\n",
      "Epoch [6490/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6491/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6491/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6492/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [6492/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6493/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6493/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6494/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6494/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6495/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6495/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6496/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6496/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6497/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6497/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6498/10000], Training Loss: 0.59346179, Training Accuracy: 0.9580\n",
      "Epoch [6498/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6499/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6499/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6500/10000], Training Loss: 0.61447637, Training Accuracy: 0.9370\n",
      "Epoch [6500/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6501/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6501/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6502/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6502/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6503/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6503/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [6504/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6504/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [6505/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6505/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [6506/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6506/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [6507/10000], Training Loss: 0.60987474, Training Accuracy: 0.9412\n",
      "Epoch [6507/10000], Validation Loss: 0.94841421, Validation Accuracy: 0.6029\n",
      "Epoch [6508/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6508/10000], Validation Loss: 0.92910871, Validation Accuracy: 0.6176\n",
      "Epoch [6509/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6509/10000], Validation Loss: 0.93357286, Validation Accuracy: 0.6176\n",
      "Epoch [6510/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6510/10000], Validation Loss: 0.93377560, Validation Accuracy: 0.6176\n",
      "Epoch [6511/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6511/10000], Validation Loss: 0.93379083, Validation Accuracy: 0.6176\n",
      "Epoch [6512/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6512/10000], Validation Loss: 0.93379381, Validation Accuracy: 0.6176\n",
      "Epoch [6513/10000], Training Loss: 0.62333629, Training Accuracy: 0.9286\n",
      "Epoch [6513/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6514/10000], Training Loss: 0.60176527, Training Accuracy: 0.9496\n",
      "Epoch [6514/10000], Validation Loss: 0.96320972, Validation Accuracy: 0.5882\n",
      "Epoch [6515/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6515/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6516/10000], Training Loss: 0.60606679, Training Accuracy: 0.9454\n",
      "Epoch [6516/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6517/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6517/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6518/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6518/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [6519/10000], Training Loss: 0.58924087, Training Accuracy: 0.9622\n",
      "Epoch [6519/10000], Validation Loss: 0.96320948, Validation Accuracy: 0.5882\n",
      "Epoch [6520/10000], Training Loss: 0.61838491, Training Accuracy: 0.9328\n",
      "Epoch [6520/10000], Validation Loss: 0.96320948, Validation Accuracy: 0.5882\n",
      "Epoch [6521/10000], Training Loss: 0.60187414, Training Accuracy: 0.9496\n",
      "Epoch [6521/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6522/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6522/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6523/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6523/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6524/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [6524/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6525/10000], Training Loss: 0.61446526, Training Accuracy: 0.9370\n",
      "Epoch [6525/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6526/10000], Training Loss: 0.61026842, Training Accuracy: 0.9412\n",
      "Epoch [6526/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6527/10000], Training Loss: 0.61005822, Training Accuracy: 0.9412\n",
      "Epoch [6527/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6528/10000], Training Loss: 0.59547915, Training Accuracy: 0.9538\n",
      "Epoch [6528/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6529/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6529/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6530/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [6530/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6531/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6531/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6532/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6532/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [6533/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6533/10000], Validation Loss: 0.96320793, Validation Accuracy: 0.5882\n",
      "Epoch [6534/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [6534/10000], Validation Loss: 0.96319526, Validation Accuracy: 0.5882\n",
      "Epoch [6535/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6535/10000], Validation Loss: 0.96317032, Validation Accuracy: 0.5882\n",
      "Epoch [6536/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6536/10000], Validation Loss: 0.96314630, Validation Accuracy: 0.5882\n",
      "Epoch [6537/10000], Training Loss: 0.59346248, Training Accuracy: 0.9580\n",
      "Epoch [6537/10000], Validation Loss: 0.96313101, Validation Accuracy: 0.5882\n",
      "Epoch [6538/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6538/10000], Validation Loss: 0.96312293, Validation Accuracy: 0.5882\n",
      "Epoch [6539/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6539/10000], Validation Loss: 0.96311879, Validation Accuracy: 0.5882\n",
      "Epoch [6540/10000], Training Loss: 0.60607522, Training Accuracy: 0.9454\n",
      "Epoch [6540/10000], Validation Loss: 0.96310717, Validation Accuracy: 0.5882\n",
      "Epoch [6541/10000], Training Loss: 0.60606123, Training Accuracy: 0.9454\n",
      "Epoch [6541/10000], Validation Loss: 0.96313283, Validation Accuracy: 0.5882\n",
      "Epoch [6542/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6542/10000], Validation Loss: 0.96314281, Validation Accuracy: 0.5882\n",
      "Epoch [6543/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6543/10000], Validation Loss: 0.96314713, Validation Accuracy: 0.5882\n",
      "Epoch [6544/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6544/10000], Validation Loss: 0.96314910, Validation Accuracy: 0.5882\n",
      "Epoch [6545/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [6545/10000], Validation Loss: 0.96315002, Validation Accuracy: 0.5882\n",
      "Epoch [6546/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [6546/10000], Validation Loss: 0.96315044, Validation Accuracy: 0.5882\n",
      "Epoch [6547/10000], Training Loss: 0.59345206, Training Accuracy: 0.9580\n",
      "Epoch [6547/10000], Validation Loss: 0.96314698, Validation Accuracy: 0.5882\n",
      "Epoch [6548/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6548/10000], Validation Loss: 0.96312678, Validation Accuracy: 0.5882\n",
      "Epoch [6549/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6549/10000], Validation Loss: 0.96311495, Validation Accuracy: 0.5882\n",
      "Epoch [6550/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [6550/10000], Validation Loss: 0.96310875, Validation Accuracy: 0.5882\n",
      "Epoch [6551/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6551/10000], Validation Loss: 0.96310562, Validation Accuracy: 0.5882\n",
      "Epoch [6552/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [6552/10000], Validation Loss: 0.96310407, Validation Accuracy: 0.5882\n",
      "Epoch [6553/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6553/10000], Validation Loss: 0.96310332, Validation Accuracy: 0.5882\n",
      "Epoch [6554/10000], Training Loss: 0.58926087, Training Accuracy: 0.9622\n",
      "Epoch [6554/10000], Validation Loss: 0.96310282, Validation Accuracy: 0.5882\n",
      "Epoch [6555/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [6555/10000], Validation Loss: 0.96310255, Validation Accuracy: 0.5882\n",
      "Epoch [6556/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [6556/10000], Validation Loss: 0.96310243, Validation Accuracy: 0.5882\n",
      "Epoch [6557/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6557/10000], Validation Loss: 0.96310240, Validation Accuracy: 0.5882\n",
      "Epoch [6558/10000], Training Loss: 0.58505778, Training Accuracy: 0.9664\n",
      "Epoch [6558/10000], Validation Loss: 0.96309766, Validation Accuracy: 0.5882\n",
      "Epoch [6559/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6559/10000], Validation Loss: 0.96309271, Validation Accuracy: 0.5882\n",
      "Epoch [6560/10000], Training Loss: 0.61225572, Training Accuracy: 0.9370\n",
      "Epoch [6560/10000], Validation Loss: 0.93329966, Validation Accuracy: 0.6176\n",
      "Epoch [6561/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6561/10000], Validation Loss: 0.91910473, Validation Accuracy: 0.6324\n",
      "Epoch [6562/10000], Training Loss: 0.60310797, Training Accuracy: 0.9496\n",
      "Epoch [6562/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6563/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [6563/10000], Validation Loss: 1.00719485, Validation Accuracy: 0.5441\n",
      "Epoch [6564/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6564/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6565/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6565/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6566/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6566/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6567/10000], Training Loss: 0.61026836, Training Accuracy: 0.9412\n",
      "Epoch [6567/10000], Validation Loss: 1.00732872, Validation Accuracy: 0.5441\n",
      "Epoch [6568/10000], Training Loss: 0.62690323, Training Accuracy: 0.9244\n",
      "Epoch [6568/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [6569/10000], Training Loss: 0.63967446, Training Accuracy: 0.9118\n",
      "Epoch [6569/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6570/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [6570/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6571/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6571/10000], Validation Loss: 1.02202827, Validation Accuracy: 0.5294\n",
      "Epoch [6572/10000], Training Loss: 0.63127113, Training Accuracy: 0.9202\n",
      "Epoch [6572/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6573/10000], Training Loss: 0.64388197, Training Accuracy: 0.9076\n",
      "Epoch [6573/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6574/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6574/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6575/10000], Training Loss: 0.63542431, Training Accuracy: 0.9160\n",
      "Epoch [6575/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6576/10000], Training Loss: 0.62707704, Training Accuracy: 0.9244\n",
      "Epoch [6576/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6577/10000], Training Loss: 0.63545991, Training Accuracy: 0.9160\n",
      "Epoch [6577/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6578/10000], Training Loss: 0.63968027, Training Accuracy: 0.9118\n",
      "Epoch [6578/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [6579/10000], Training Loss: 0.64386969, Training Accuracy: 0.9076\n",
      "Epoch [6579/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6580/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6580/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6581/10000], Training Loss: 0.63968197, Training Accuracy: 0.9118\n",
      "Epoch [6581/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6582/10000], Training Loss: 0.63968851, Training Accuracy: 0.9118\n",
      "Epoch [6582/10000], Validation Loss: 1.06615070, Validation Accuracy: 0.4853\n",
      "Epoch [6583/10000], Training Loss: 0.63547862, Training Accuracy: 0.9160\n",
      "Epoch [6583/10000], Validation Loss: 1.06614873, Validation Accuracy: 0.4853\n",
      "Epoch [6584/10000], Training Loss: 0.64362235, Training Accuracy: 0.9076\n",
      "Epoch [6584/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6585/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6585/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6586/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6586/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6587/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6587/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6588/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6588/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6589/10000], Training Loss: 0.62287283, Training Accuracy: 0.9286\n",
      "Epoch [6589/10000], Validation Loss: 1.06615075, Validation Accuracy: 0.4853\n",
      "Epoch [6590/10000], Training Loss: 0.64827980, Training Accuracy: 0.9034\n",
      "Epoch [6590/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [6591/10000], Training Loss: 0.63967804, Training Accuracy: 0.9118\n",
      "Epoch [6591/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [6592/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6592/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [6593/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6593/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [6594/10000], Training Loss: 0.62015978, Training Accuracy: 0.9328\n",
      "Epoch [6594/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6595/10000], Training Loss: 0.63538217, Training Accuracy: 0.9160\n",
      "Epoch [6595/10000], Validation Loss: 1.02203211, Validation Accuracy: 0.5294\n",
      "Epoch [6596/10000], Training Loss: 0.63102093, Training Accuracy: 0.9202\n",
      "Epoch [6596/10000], Validation Loss: 0.97974941, Validation Accuracy: 0.5735\n",
      "Epoch [6597/10000], Training Loss: 0.61574758, Training Accuracy: 0.9370\n",
      "Epoch [6597/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [6598/10000], Training Loss: 0.58935997, Training Accuracy: 0.9622\n",
      "Epoch [6598/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [6599/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [6599/10000], Validation Loss: 0.99262109, Validation Accuracy: 0.5588\n",
      "Epoch [6600/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6600/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6601/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6601/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6602/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6602/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6603/10000], Training Loss: 0.61293909, Training Accuracy: 0.9370\n",
      "Epoch [6603/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6604/10000], Training Loss: 0.59371144, Training Accuracy: 0.9580\n",
      "Epoch [6604/10000], Validation Loss: 0.96321103, Validation Accuracy: 0.5882\n",
      "Epoch [6605/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6605/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6606/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6606/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6607/10000], Training Loss: 0.60606530, Training Accuracy: 0.9454\n",
      "Epoch [6607/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6608/10000], Training Loss: 0.61093781, Training Accuracy: 0.9412\n",
      "Epoch [6608/10000], Validation Loss: 0.99258542, Validation Accuracy: 0.5588\n",
      "Epoch [6609/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [6609/10000], Validation Loss: 0.97801825, Validation Accuracy: 0.5735\n",
      "Epoch [6610/10000], Training Loss: 0.60127122, Training Accuracy: 0.9496\n",
      "Epoch [6610/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6611/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6611/10000], Validation Loss: 0.97792315, Validation Accuracy: 0.5735\n",
      "Epoch [6612/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [6612/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6613/10000], Training Loss: 0.61867189, Training Accuracy: 0.9328\n",
      "Epoch [6613/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6614/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6614/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6615/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6615/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6616/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6616/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6617/10000], Training Loss: 0.59766140, Training Accuracy: 0.9538\n",
      "Epoch [6617/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6618/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6618/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6619/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6619/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6620/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6620/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6621/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6621/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6622/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6622/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6623/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [6623/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6624/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6624/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6625/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6625/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6626/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6626/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6627/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6627/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6628/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6628/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6629/10000], Training Loss: 0.61447059, Training Accuracy: 0.9370\n",
      "Epoch [6629/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6630/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6630/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6631/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6631/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6632/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6632/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6633/10000], Training Loss: 0.60595631, Training Accuracy: 0.9454\n",
      "Epoch [6633/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6634/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6634/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6635/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6635/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6636/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6636/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6637/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6637/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6638/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6638/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6639/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [6639/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6640/10000], Training Loss: 0.60179334, Training Accuracy: 0.9496\n",
      "Epoch [6640/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6641/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6641/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6642/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [6642/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6643/10000], Training Loss: 0.61004545, Training Accuracy: 0.9412\n",
      "Epoch [6643/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6644/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6644/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6645/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6645/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6646/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6646/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6647/10000], Training Loss: 0.61956973, Training Accuracy: 0.9328\n",
      "Epoch [6647/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6648/10000], Training Loss: 0.61446960, Training Accuracy: 0.9370\n",
      "Epoch [6648/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [6649/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6649/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6650/10000], Training Loss: 0.62287198, Training Accuracy: 0.9286\n",
      "Epoch [6650/10000], Validation Loss: 0.97791564, Validation Accuracy: 0.5735\n",
      "Epoch [6651/10000], Training Loss: 0.63127691, Training Accuracy: 0.9202\n",
      "Epoch [6651/10000], Validation Loss: 0.99262175, Validation Accuracy: 0.5588\n",
      "Epoch [6652/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6652/10000], Validation Loss: 0.99262190, Validation Accuracy: 0.5588\n",
      "Epoch [6653/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6653/10000], Validation Loss: 0.99262208, Validation Accuracy: 0.5588\n",
      "Epoch [6654/10000], Training Loss: 0.63125319, Training Accuracy: 0.9202\n",
      "Epoch [6654/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6655/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6655/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6656/10000], Training Loss: 0.62824890, Training Accuracy: 0.9244\n",
      "Epoch [6656/10000], Validation Loss: 1.01783460, Validation Accuracy: 0.5294\n",
      "Epoch [6657/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6657/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [6658/10000], Training Loss: 0.61879920, Training Accuracy: 0.9328\n",
      "Epoch [6658/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [6659/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6659/10000], Validation Loss: 1.05017155, Validation Accuracy: 0.5000\n",
      "Epoch [6660/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6660/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6661/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6661/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6662/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6662/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6663/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [6663/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6664/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6664/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6665/10000], Training Loss: 0.62287377, Training Accuracy: 0.9286\n",
      "Epoch [6665/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6666/10000], Training Loss: 0.61915990, Training Accuracy: 0.9328\n",
      "Epoch [6666/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6667/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6667/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6668/10000], Training Loss: 0.61897774, Training Accuracy: 0.9328\n",
      "Epoch [6668/10000], Validation Loss: 1.06613851, Validation Accuracy: 0.4853\n",
      "Epoch [6669/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6669/10000], Validation Loss: 1.06584203, Validation Accuracy: 0.4853\n",
      "Epoch [6670/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6670/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6671/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [6671/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6672/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6672/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6673/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6673/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6674/10000], Training Loss: 0.61026808, Training Accuracy: 0.9412\n",
      "Epoch [6674/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6675/10000], Training Loss: 0.61867276, Training Accuracy: 0.9328\n",
      "Epoch [6675/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6676/10000], Training Loss: 0.63132421, Training Accuracy: 0.9202\n",
      "Epoch [6676/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6677/10000], Training Loss: 0.61447012, Training Accuracy: 0.9370\n",
      "Epoch [6677/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6678/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [6678/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6679/10000], Training Loss: 0.63545305, Training Accuracy: 0.9160\n",
      "Epoch [6679/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6680/10000], Training Loss: 0.61447871, Training Accuracy: 0.9370\n",
      "Epoch [6680/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6681/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6681/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6682/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6682/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6683/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6683/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6684/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6684/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6685/10000], Training Loss: 0.63609442, Training Accuracy: 0.9160\n",
      "Epoch [6685/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6686/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [6686/10000], Validation Loss: 1.03670302, Validation Accuracy: 0.5147\n",
      "Epoch [6687/10000], Training Loss: 0.61447012, Training Accuracy: 0.9370\n",
      "Epoch [6687/10000], Validation Loss: 1.02258268, Validation Accuracy: 0.5294\n",
      "Epoch [6688/10000], Training Loss: 0.61867187, Training Accuracy: 0.9328\n",
      "Epoch [6688/10000], Validation Loss: 1.02203962, Validation Accuracy: 0.5294\n",
      "Epoch [6689/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6689/10000], Validation Loss: 1.02203810, Validation Accuracy: 0.5294\n",
      "Epoch [6690/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6690/10000], Validation Loss: 1.02489853, Validation Accuracy: 0.5294\n",
      "Epoch [6691/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6691/10000], Validation Loss: 1.03461295, Validation Accuracy: 0.5147\n",
      "Epoch [6692/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6692/10000], Validation Loss: 1.03618348, Validation Accuracy: 0.5147\n",
      "Epoch [6693/10000], Training Loss: 0.61099328, Training Accuracy: 0.9412\n",
      "Epoch [6693/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6694/10000], Training Loss: 0.62700902, Training Accuracy: 0.9244\n",
      "Epoch [6694/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6695/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6695/10000], Validation Loss: 1.03692168, Validation Accuracy: 0.5147\n",
      "Epoch [6696/10000], Training Loss: 0.64129857, Training Accuracy: 0.9118\n",
      "Epoch [6696/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6697/10000], Training Loss: 0.62289511, Training Accuracy: 0.9286\n",
      "Epoch [6697/10000], Validation Loss: 1.02027053, Validation Accuracy: 0.5294\n",
      "Epoch [6698/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6698/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6699/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6699/10000], Validation Loss: 1.02206489, Validation Accuracy: 0.5294\n",
      "Epoch [6700/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6700/10000], Validation Loss: 1.03342888, Validation Accuracy: 0.5147\n",
      "Epoch [6701/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [6701/10000], Validation Loss: 1.02179870, Validation Accuracy: 0.5294\n",
      "Epoch [6702/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6702/10000], Validation Loss: 1.02202266, Validation Accuracy: 0.5294\n",
      "Epoch [6703/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6703/10000], Validation Loss: 1.02202934, Validation Accuracy: 0.5294\n",
      "Epoch [6704/10000], Training Loss: 0.62707525, Training Accuracy: 0.9244\n",
      "Epoch [6704/10000], Validation Loss: 1.02203065, Validation Accuracy: 0.5294\n",
      "Epoch [6705/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6705/10000], Validation Loss: 1.02203119, Validation Accuracy: 0.5294\n",
      "Epoch [6706/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6706/10000], Validation Loss: 1.02203137, Validation Accuracy: 0.5294\n",
      "Epoch [6707/10000], Training Loss: 0.60606685, Training Accuracy: 0.9454\n",
      "Epoch [6707/10000], Validation Loss: 1.02203149, Validation Accuracy: 0.5294\n",
      "Epoch [6708/10000], Training Loss: 0.63547060, Training Accuracy: 0.9160\n",
      "Epoch [6708/10000], Validation Loss: 1.02203268, Validation Accuracy: 0.5294\n",
      "Epoch [6709/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [6709/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6710/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6710/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6711/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [6711/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6712/10000], Training Loss: 0.60606685, Training Accuracy: 0.9454\n",
      "Epoch [6712/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6713/10000], Training Loss: 0.61959944, Training Accuracy: 0.9328\n",
      "Epoch [6713/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [6714/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6714/10000], Validation Loss: 1.03668720, Validation Accuracy: 0.5147\n",
      "Epoch [6715/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6715/10000], Validation Loss: 1.03032333, Validation Accuracy: 0.5147\n",
      "Epoch [6716/10000], Training Loss: 0.61845522, Training Accuracy: 0.9328\n",
      "Epoch [6716/10000], Validation Loss: 1.00732717, Validation Accuracy: 0.5441\n",
      "Epoch [6717/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6717/10000], Validation Loss: 1.00732687, Validation Accuracy: 0.5441\n",
      "Epoch [6718/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6718/10000], Validation Loss: 1.00730595, Validation Accuracy: 0.5441\n",
      "Epoch [6719/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6719/10000], Validation Loss: 1.00637314, Validation Accuracy: 0.5441\n",
      "Epoch [6720/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6720/10000], Validation Loss: 1.00281057, Validation Accuracy: 0.5441\n",
      "Epoch [6721/10000], Training Loss: 0.61858800, Training Accuracy: 0.9328\n",
      "Epoch [6721/10000], Validation Loss: 0.99660999, Validation Accuracy: 0.5588\n",
      "Epoch [6722/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6722/10000], Validation Loss: 1.00683787, Validation Accuracy: 0.5441\n",
      "Epoch [6723/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6723/10000], Validation Loss: 1.00726023, Validation Accuracy: 0.5441\n",
      "Epoch [6724/10000], Training Loss: 0.62707546, Training Accuracy: 0.9244\n",
      "Epoch [6724/10000], Validation Loss: 1.00730094, Validation Accuracy: 0.5441\n",
      "Epoch [6725/10000], Training Loss: 0.61866730, Training Accuracy: 0.9328\n",
      "Epoch [6725/10000], Validation Loss: 1.02203280, Validation Accuracy: 0.5294\n",
      "Epoch [6726/10000], Training Loss: 0.63543438, Training Accuracy: 0.9160\n",
      "Epoch [6726/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [6727/10000], Training Loss: 0.64382330, Training Accuracy: 0.9076\n",
      "Epoch [6727/10000], Validation Loss: 1.01843628, Validation Accuracy: 0.5294\n",
      "Epoch [6728/10000], Training Loss: 0.63856685, Training Accuracy: 0.9118\n",
      "Epoch [6728/10000], Validation Loss: 1.03565130, Validation Accuracy: 0.5147\n",
      "Epoch [6729/10000], Training Loss: 0.65648482, Training Accuracy: 0.8950\n",
      "Epoch [6729/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6730/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6730/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [6731/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6731/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6732/10000], Training Loss: 0.64387952, Training Accuracy: 0.9076\n",
      "Epoch [6732/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6733/10000], Training Loss: 0.65494633, Training Accuracy: 0.8950\n",
      "Epoch [6733/10000], Validation Loss: 1.01760209, Validation Accuracy: 0.5294\n",
      "Epoch [6734/10000], Training Loss: 0.64388147, Training Accuracy: 0.9076\n",
      "Epoch [6734/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6735/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6735/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [6736/10000], Training Loss: 0.63549833, Training Accuracy: 0.9160\n",
      "Epoch [6736/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [6737/10000], Training Loss: 0.61025265, Training Accuracy: 0.9412\n",
      "Epoch [6737/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [6738/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [6738/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [6739/10000], Training Loss: 0.63097861, Training Accuracy: 0.9202\n",
      "Epoch [6739/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [6740/10000], Training Loss: 0.63104893, Training Accuracy: 0.9202\n",
      "Epoch [6740/10000], Validation Loss: 1.02202049, Validation Accuracy: 0.5294\n",
      "Epoch [6741/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6741/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6742/10000], Training Loss: 0.61449410, Training Accuracy: 0.9370\n",
      "Epoch [6742/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6743/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6743/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [6744/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6744/10000], Validation Loss: 1.00812584, Validation Accuracy: 0.5441\n",
      "Epoch [6745/10000], Training Loss: 0.61026854, Training Accuracy: 0.9412\n",
      "Epoch [6745/10000], Validation Loss: 1.02056482, Validation Accuracy: 0.5294\n",
      "Epoch [6746/10000], Training Loss: 0.61026834, Training Accuracy: 0.9412\n",
      "Epoch [6746/10000], Validation Loss: 1.02187517, Validation Accuracy: 0.5294\n",
      "Epoch [6747/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6747/10000], Validation Loss: 1.02197862, Validation Accuracy: 0.5294\n",
      "Epoch [6748/10000], Training Loss: 0.62251353, Training Accuracy: 0.9286\n",
      "Epoch [6748/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6749/10000], Training Loss: 0.63127667, Training Accuracy: 0.9202\n",
      "Epoch [6749/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6750/10000], Training Loss: 0.62287600, Training Accuracy: 0.9286\n",
      "Epoch [6750/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6751/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [6751/10000], Validation Loss: 1.02203235, Validation Accuracy: 0.5294\n",
      "Epoch [6752/10000], Training Loss: 0.63967138, Training Accuracy: 0.9118\n",
      "Epoch [6752/10000], Validation Loss: 1.02201411, Validation Accuracy: 0.5294\n",
      "Epoch [6753/10000], Training Loss: 0.62697238, Training Accuracy: 0.9244\n",
      "Epoch [6753/10000], Validation Loss: 1.00726005, Validation Accuracy: 0.5441\n",
      "Epoch [6754/10000], Training Loss: 0.63127582, Training Accuracy: 0.9202\n",
      "Epoch [6754/10000], Validation Loss: 1.00631568, Validation Accuracy: 0.5441\n",
      "Epoch [6755/10000], Training Loss: 0.61062518, Training Accuracy: 0.9412\n",
      "Epoch [6755/10000], Validation Loss: 1.00732639, Validation Accuracy: 0.5441\n",
      "Epoch [6756/10000], Training Loss: 0.61026525, Training Accuracy: 0.9412\n",
      "Epoch [6756/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6757/10000], Training Loss: 0.61446768, Training Accuracy: 0.9370\n",
      "Epoch [6757/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6758/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6758/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6759/10000], Training Loss: 0.62051325, Training Accuracy: 0.9286\n",
      "Epoch [6759/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [6760/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6760/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6761/10000], Training Loss: 0.64447735, Training Accuracy: 0.9076\n",
      "Epoch [6761/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6762/10000], Training Loss: 0.65229225, Training Accuracy: 0.8992\n",
      "Epoch [6762/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6763/10000], Training Loss: 0.66485425, Training Accuracy: 0.8866\n",
      "Epoch [6763/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6764/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [6764/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6765/10000], Training Loss: 0.68589881, Training Accuracy: 0.8655\n",
      "Epoch [6765/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6766/10000], Training Loss: 0.65668976, Training Accuracy: 0.8950\n",
      "Epoch [6766/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6767/10000], Training Loss: 0.64436860, Training Accuracy: 0.9076\n",
      "Epoch [6767/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6768/10000], Training Loss: 0.63547800, Training Accuracy: 0.9160\n",
      "Epoch [6768/10000], Validation Loss: 0.99300951, Validation Accuracy: 0.5588\n",
      "Epoch [6769/10000], Training Loss: 0.63127673, Training Accuracy: 0.9202\n",
      "Epoch [6769/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6770/10000], Training Loss: 0.63101793, Training Accuracy: 0.9202\n",
      "Epoch [6770/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6771/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6771/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6772/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6772/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6773/10000], Training Loss: 0.61448090, Training Accuracy: 0.9370\n",
      "Epoch [6773/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6774/10000], Training Loss: 0.64147588, Training Accuracy: 0.9076\n",
      "Epoch [6774/10000], Validation Loss: 0.99262226, Validation Accuracy: 0.5588\n",
      "Epoch [6775/10000], Training Loss: 0.62707376, Training Accuracy: 0.9244\n",
      "Epoch [6775/10000], Validation Loss: 1.00705403, Validation Accuracy: 0.5441\n",
      "Epoch [6776/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6776/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6777/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [6777/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [6778/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6778/10000], Validation Loss: 1.00719541, Validation Accuracy: 0.5441\n",
      "Epoch [6779/10000], Training Loss: 0.63127994, Training Accuracy: 0.9202\n",
      "Epoch [6779/10000], Validation Loss: 1.00732714, Validation Accuracy: 0.5441\n",
      "Epoch [6780/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6780/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6781/10000], Training Loss: 0.61026927, Training Accuracy: 0.9412\n",
      "Epoch [6781/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6782/10000], Training Loss: 0.62707923, Training Accuracy: 0.9244\n",
      "Epoch [6782/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6783/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6783/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6784/10000], Training Loss: 0.61867238, Training Accuracy: 0.9328\n",
      "Epoch [6784/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6785/10000], Training Loss: 0.63967569, Training Accuracy: 0.9118\n",
      "Epoch [6785/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [6786/10000], Training Loss: 0.62714867, Training Accuracy: 0.9244\n",
      "Epoch [6786/10000], Validation Loss: 0.99262226, Validation Accuracy: 0.5588\n",
      "Epoch [6787/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6787/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6788/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6788/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6789/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [6789/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6790/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6790/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6791/10000], Training Loss: 0.61473007, Training Accuracy: 0.9370\n",
      "Epoch [6791/10000], Validation Loss: 0.99262291, Validation Accuracy: 0.5588\n",
      "Epoch [6792/10000], Training Loss: 0.63082323, Training Accuracy: 0.9202\n",
      "Epoch [6792/10000], Validation Loss: 0.99248049, Validation Accuracy: 0.5588\n",
      "Epoch [6793/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6793/10000], Validation Loss: 0.99262086, Validation Accuracy: 0.5588\n",
      "Epoch [6794/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6794/10000], Validation Loss: 0.99261731, Validation Accuracy: 0.5588\n",
      "Epoch [6795/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [6795/10000], Validation Loss: 1.00731620, Validation Accuracy: 0.5441\n",
      "Epoch [6796/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6796/10000], Validation Loss: 1.00730929, Validation Accuracy: 0.5441\n",
      "Epoch [6797/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6797/10000], Validation Loss: 1.00730458, Validation Accuracy: 0.5441\n",
      "Epoch [6798/10000], Training Loss: 0.62705817, Training Accuracy: 0.9244\n",
      "Epoch [6798/10000], Validation Loss: 1.00732589, Validation Accuracy: 0.5441\n",
      "Epoch [6799/10000], Training Loss: 0.61448160, Training Accuracy: 0.9370\n",
      "Epoch [6799/10000], Validation Loss: 1.00732410, Validation Accuracy: 0.5441\n",
      "Epoch [6800/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6800/10000], Validation Loss: 1.00732258, Validation Accuracy: 0.5441\n",
      "Epoch [6801/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6801/10000], Validation Loss: 1.00732163, Validation Accuracy: 0.5441\n",
      "Epoch [6802/10000], Training Loss: 0.63547346, Training Accuracy: 0.9160\n",
      "Epoch [6802/10000], Validation Loss: 1.00731519, Validation Accuracy: 0.5441\n",
      "Epoch [6803/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6803/10000], Validation Loss: 1.00730246, Validation Accuracy: 0.5441\n",
      "Epoch [6804/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6804/10000], Validation Loss: 1.00729224, Validation Accuracy: 0.5441\n",
      "Epoch [6805/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6805/10000], Validation Loss: 1.00728589, Validation Accuracy: 0.5441\n",
      "Epoch [6806/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [6806/10000], Validation Loss: 1.00728247, Validation Accuracy: 0.5441\n",
      "Epoch [6807/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6807/10000], Validation Loss: 1.00728068, Validation Accuracy: 0.5441\n",
      "Epoch [6808/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6808/10000], Validation Loss: 1.00727984, Validation Accuracy: 0.5441\n",
      "Epoch [6809/10000], Training Loss: 0.61217148, Training Accuracy: 0.9370\n",
      "Epoch [6809/10000], Validation Loss: 1.00615311, Validation Accuracy: 0.5441\n",
      "Epoch [6810/10000], Training Loss: 0.61447258, Training Accuracy: 0.9370\n",
      "Epoch [6810/10000], Validation Loss: 0.99312469, Validation Accuracy: 0.5588\n",
      "Epoch [6811/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6811/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6812/10000], Training Loss: 0.62312846, Training Accuracy: 0.9286\n",
      "Epoch [6812/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6813/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6813/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6814/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6814/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6815/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6815/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6816/10000], Training Loss: 0.61868534, Training Accuracy: 0.9328\n",
      "Epoch [6816/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6817/10000], Training Loss: 0.61447019, Training Accuracy: 0.9370\n",
      "Epoch [6817/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6818/10000], Training Loss: 0.61026790, Training Accuracy: 0.9412\n",
      "Epoch [6818/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6819/10000], Training Loss: 0.61297160, Training Accuracy: 0.9370\n",
      "Epoch [6819/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6820/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6820/10000], Validation Loss: 1.00736576, Validation Accuracy: 0.5441\n",
      "Epoch [6821/10000], Training Loss: 0.60185616, Training Accuracy: 0.9496\n",
      "Epoch [6821/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6822/10000], Training Loss: 0.62797523, Training Accuracy: 0.9244\n",
      "Epoch [6822/10000], Validation Loss: 1.00178009, Validation Accuracy: 0.5441\n",
      "Epoch [6823/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [6823/10000], Validation Loss: 1.02203059, Validation Accuracy: 0.5294\n",
      "Epoch [6824/10000], Training Loss: 0.60183706, Training Accuracy: 0.9496\n",
      "Epoch [6824/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6825/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6825/10000], Validation Loss: 0.98794413, Validation Accuracy: 0.5588\n",
      "Epoch [6826/10000], Training Loss: 0.62705906, Training Accuracy: 0.9244\n",
      "Epoch [6826/10000], Validation Loss: 0.99262303, Validation Accuracy: 0.5588\n",
      "Epoch [6827/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6827/10000], Validation Loss: 1.01010135, Validation Accuracy: 0.5441\n",
      "Epoch [6828/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6828/10000], Validation Loss: 1.02194414, Validation Accuracy: 0.5294\n",
      "Epoch [6829/10000], Training Loss: 0.63968022, Training Accuracy: 0.9118\n",
      "Epoch [6829/10000], Validation Loss: 1.02202925, Validation Accuracy: 0.5294\n",
      "Epoch [6830/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6830/10000], Validation Loss: 1.02203229, Validation Accuracy: 0.5294\n",
      "Epoch [6831/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6831/10000], Validation Loss: 1.02203271, Validation Accuracy: 0.5294\n",
      "Epoch [6832/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6832/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [6833/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [6833/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [6834/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6834/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [6835/10000], Training Loss: 0.62707319, Training Accuracy: 0.9244\n",
      "Epoch [6835/10000], Validation Loss: 1.02203289, Validation Accuracy: 0.5294\n",
      "Epoch [6836/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6836/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [6837/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6837/10000], Validation Loss: 1.02203283, Validation Accuracy: 0.5294\n",
      "Epoch [6838/10000], Training Loss: 0.63127584, Training Accuracy: 0.9202\n",
      "Epoch [6838/10000], Validation Loss: 1.02203259, Validation Accuracy: 0.5294\n",
      "Epoch [6839/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6839/10000], Validation Loss: 1.02203211, Validation Accuracy: 0.5294\n",
      "Epoch [6840/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6840/10000], Validation Loss: 1.02203175, Validation Accuracy: 0.5294\n",
      "Epoch [6841/10000], Training Loss: 0.61201713, Training Accuracy: 0.9370\n",
      "Epoch [6841/10000], Validation Loss: 0.99261406, Validation Accuracy: 0.5588\n",
      "Epoch [6842/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6842/10000], Validation Loss: 0.99286342, Validation Accuracy: 0.5588\n",
      "Epoch [6843/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6843/10000], Validation Loss: 0.99262258, Validation Accuracy: 0.5588\n",
      "Epoch [6844/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6844/10000], Validation Loss: 0.99262145, Validation Accuracy: 0.5588\n",
      "Epoch [6845/10000], Training Loss: 0.60186432, Training Accuracy: 0.9496\n",
      "Epoch [6845/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6846/10000], Training Loss: 0.62287299, Training Accuracy: 0.9286\n",
      "Epoch [6846/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6847/10000], Training Loss: 0.61867025, Training Accuracy: 0.9328\n",
      "Epoch [6847/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6848/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6848/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6849/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6849/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6850/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6850/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6851/10000], Training Loss: 0.60606629, Training Accuracy: 0.9454\n",
      "Epoch [6851/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6852/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6852/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6853/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6853/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6854/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6854/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6855/10000], Training Loss: 0.61026556, Training Accuracy: 0.9412\n",
      "Epoch [6855/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [6856/10000], Training Loss: 0.62912845, Training Accuracy: 0.9202\n",
      "Epoch [6856/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6857/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6857/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6858/10000], Training Loss: 0.61351085, Training Accuracy: 0.9370\n",
      "Epoch [6858/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6859/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6859/10000], Validation Loss: 1.05759174, Validation Accuracy: 0.4853\n",
      "Epoch [6860/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6860/10000], Validation Loss: 1.03547570, Validation Accuracy: 0.5147\n",
      "Epoch [6861/10000], Training Loss: 0.61332548, Training Accuracy: 0.9370\n",
      "Epoch [6861/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6862/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6862/10000], Validation Loss: 1.03673881, Validation Accuracy: 0.5147\n",
      "Epoch [6863/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6863/10000], Validation Loss: 1.03692922, Validation Accuracy: 0.5147\n",
      "Epoch [6864/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6864/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [6865/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6865/10000], Validation Loss: 1.02203393, Validation Accuracy: 0.5294\n",
      "Epoch [6866/10000], Training Loss: 0.62591663, Training Accuracy: 0.9244\n",
      "Epoch [6866/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [6867/10000], Training Loss: 0.62290481, Training Accuracy: 0.9286\n",
      "Epoch [6867/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [6868/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6868/10000], Validation Loss: 1.00732666, Validation Accuracy: 0.5441\n",
      "Epoch [6869/10000], Training Loss: 0.61091023, Training Accuracy: 0.9412\n",
      "Epoch [6869/10000], Validation Loss: 0.99252012, Validation Accuracy: 0.5588\n",
      "Epoch [6870/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6870/10000], Validation Loss: 1.00682852, Validation Accuracy: 0.5441\n",
      "Epoch [6871/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [6871/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6872/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6872/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6873/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6873/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6874/10000], Training Loss: 0.63128046, Training Accuracy: 0.9202\n",
      "Epoch [6874/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6875/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6875/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6876/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6876/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6877/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6877/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6878/10000], Training Loss: 0.61447009, Training Accuracy: 0.9370\n",
      "Epoch [6878/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6879/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6879/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6880/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [6880/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6881/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6881/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6882/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6882/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6883/10000], Training Loss: 0.62287339, Training Accuracy: 0.9286\n",
      "Epoch [6883/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6884/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6884/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6885/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [6885/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6886/10000], Training Loss: 0.62286913, Training Accuracy: 0.9286\n",
      "Epoch [6886/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6887/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6887/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [6888/10000], Training Loss: 0.60502121, Training Accuracy: 0.9454\n",
      "Epoch [6888/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [6889/10000], Training Loss: 0.63306348, Training Accuracy: 0.9160\n",
      "Epoch [6889/10000], Validation Loss: 1.03674972, Validation Accuracy: 0.5147\n",
      "Epoch [6890/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [6890/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [6891/10000], Training Loss: 0.68169705, Training Accuracy: 0.8697\n",
      "Epoch [6891/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [6892/10000], Training Loss: 0.69201496, Training Accuracy: 0.8571\n",
      "Epoch [6892/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [6893/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [6893/10000], Validation Loss: 1.08013272, Validation Accuracy: 0.4706\n",
      "Epoch [6894/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [6894/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6895/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [6895/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6896/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [6896/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6897/10000], Training Loss: 0.62707502, Training Accuracy: 0.9244\n",
      "Epoch [6897/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6898/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6898/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6899/10000], Training Loss: 0.63548047, Training Accuracy: 0.9160\n",
      "Epoch [6899/10000], Validation Loss: 1.06615096, Validation Accuracy: 0.4853\n",
      "Epoch [6900/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6900/10000], Validation Loss: 1.06615299, Validation Accuracy: 0.4853\n",
      "Epoch [6901/10000], Training Loss: 0.64387852, Training Accuracy: 0.9076\n",
      "Epoch [6901/10000], Validation Loss: 1.06616759, Validation Accuracy: 0.4853\n",
      "Epoch [6902/10000], Training Loss: 0.62293348, Training Accuracy: 0.9286\n",
      "Epoch [6902/10000], Validation Loss: 1.06624895, Validation Accuracy: 0.4853\n",
      "Epoch [6903/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6903/10000], Validation Loss: 1.06681460, Validation Accuracy: 0.4853\n",
      "Epoch [6904/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [6904/10000], Validation Loss: 1.06720644, Validation Accuracy: 0.4853\n",
      "Epoch [6905/10000], Training Loss: 0.63972386, Training Accuracy: 0.9118\n",
      "Epoch [6905/10000], Validation Loss: 1.07692784, Validation Accuracy: 0.4706\n",
      "Epoch [6906/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [6906/10000], Validation Loss: 1.07986158, Validation Accuracy: 0.4706\n",
      "Epoch [6907/10000], Training Loss: 0.64324149, Training Accuracy: 0.9076\n",
      "Epoch [6907/10000], Validation Loss: 1.06534743, Validation Accuracy: 0.4853\n",
      "Epoch [6908/10000], Training Loss: 0.63127785, Training Accuracy: 0.9202\n",
      "Epoch [6908/10000], Validation Loss: 1.05820912, Validation Accuracy: 0.4853\n",
      "Epoch [6909/10000], Training Loss: 0.62707935, Training Accuracy: 0.9244\n",
      "Epoch [6909/10000], Validation Loss: 1.06617624, Validation Accuracy: 0.4853\n",
      "Epoch [6910/10000], Training Loss: 0.66068968, Training Accuracy: 0.8908\n",
      "Epoch [6910/10000], Validation Loss: 1.06613702, Validation Accuracy: 0.4853\n",
      "Epoch [6911/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6911/10000], Validation Loss: 1.08083379, Validation Accuracy: 0.4706\n",
      "Epoch [6912/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [6912/10000], Validation Loss: 1.08082795, Validation Accuracy: 0.4706\n",
      "Epoch [6913/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [6913/10000], Validation Loss: 1.08082467, Validation Accuracy: 0.4706\n",
      "Epoch [6914/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [6914/10000], Validation Loss: 1.08082283, Validation Accuracy: 0.4706\n",
      "Epoch [6915/10000], Training Loss: 0.65648694, Training Accuracy: 0.8950\n",
      "Epoch [6915/10000], Validation Loss: 1.08082211, Validation Accuracy: 0.4706\n",
      "Epoch [6916/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6916/10000], Validation Loss: 1.08082181, Validation Accuracy: 0.4706\n",
      "Epoch [6917/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [6917/10000], Validation Loss: 1.08082169, Validation Accuracy: 0.4706\n",
      "Epoch [6918/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [6918/10000], Validation Loss: 1.08082163, Validation Accuracy: 0.4706\n",
      "Epoch [6919/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [6919/10000], Validation Loss: 1.08082163, Validation Accuracy: 0.4706\n",
      "Epoch [6920/10000], Training Loss: 0.62273215, Training Accuracy: 0.9286\n",
      "Epoch [6920/10000], Validation Loss: 1.08081824, Validation Accuracy: 0.4706\n",
      "Epoch [6921/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [6921/10000], Validation Loss: 1.07878393, Validation Accuracy: 0.4706\n",
      "Epoch [6922/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [6922/10000], Validation Loss: 1.05803245, Validation Accuracy: 0.4853\n",
      "Epoch [6923/10000], Training Loss: 0.65323153, Training Accuracy: 0.8992\n",
      "Epoch [6923/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6924/10000], Training Loss: 0.61817420, Training Accuracy: 0.9328\n",
      "Epoch [6924/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [6925/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6925/10000], Validation Loss: 0.99262753, Validation Accuracy: 0.5588\n",
      "Epoch [6926/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6926/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6927/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [6927/10000], Validation Loss: 0.96324334, Validation Accuracy: 0.5882\n",
      "Epoch [6928/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [6928/10000], Validation Loss: 0.96339041, Validation Accuracy: 0.5882\n",
      "Epoch [6929/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [6929/10000], Validation Loss: 0.96579617, Validation Accuracy: 0.5882\n",
      "Epoch [6930/10000], Training Loss: 0.61446978, Training Accuracy: 0.9370\n",
      "Epoch [6930/10000], Validation Loss: 0.96878713, Validation Accuracy: 0.5735\n",
      "Epoch [6931/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [6931/10000], Validation Loss: 0.96963501, Validation Accuracy: 0.5735\n",
      "Epoch [6932/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6932/10000], Validation Loss: 0.96971935, Validation Accuracy: 0.5735\n",
      "Epoch [6933/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [6933/10000], Validation Loss: 0.96967572, Validation Accuracy: 0.5735\n",
      "Epoch [6934/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6934/10000], Validation Loss: 0.96963513, Validation Accuracy: 0.5735\n",
      "Epoch [6935/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6935/10000], Validation Loss: 0.96961004, Validation Accuracy: 0.5735\n",
      "Epoch [6936/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [6936/10000], Validation Loss: 0.96959662, Validation Accuracy: 0.5735\n",
      "Epoch [6937/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [6937/10000], Validation Loss: 0.96959007, Validation Accuracy: 0.5735\n",
      "Epoch [6938/10000], Training Loss: 0.61125255, Training Accuracy: 0.9412\n",
      "Epoch [6938/10000], Validation Loss: 0.96642619, Validation Accuracy: 0.5882\n",
      "Epoch [6939/10000], Training Loss: 0.63119775, Training Accuracy: 0.9202\n",
      "Epoch [6939/10000], Validation Loss: 0.96343809, Validation Accuracy: 0.5882\n",
      "Epoch [6940/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6940/10000], Validation Loss: 0.96320969, Validation Accuracy: 0.5882\n",
      "Epoch [6941/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6941/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6942/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6942/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6943/10000], Training Loss: 0.60606692, Training Accuracy: 0.9454\n",
      "Epoch [6943/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [6944/10000], Training Loss: 0.61085365, Training Accuracy: 0.9412\n",
      "Epoch [6944/10000], Validation Loss: 0.93402013, Validation Accuracy: 0.6176\n",
      "Epoch [6945/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6945/10000], Validation Loss: 0.91909295, Validation Accuracy: 0.6324\n",
      "Epoch [6946/10000], Training Loss: 0.62707518, Training Accuracy: 0.9244\n",
      "Epoch [6946/10000], Validation Loss: 0.91909203, Validation Accuracy: 0.6324\n",
      "Epoch [6947/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [6947/10000], Validation Loss: 0.91909236, Validation Accuracy: 0.6324\n",
      "Epoch [6948/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [6948/10000], Validation Loss: 0.91910312, Validation Accuracy: 0.6324\n",
      "Epoch [6949/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6949/10000], Validation Loss: 0.91915178, Validation Accuracy: 0.6324\n",
      "Epoch [6950/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [6950/10000], Validation Loss: 0.91922614, Validation Accuracy: 0.6324\n",
      "Epoch [6951/10000], Training Loss: 0.61406465, Training Accuracy: 0.9370\n",
      "Epoch [6951/10000], Validation Loss: 0.92931974, Validation Accuracy: 0.6176\n",
      "Epoch [6952/10000], Training Loss: 0.62703271, Training Accuracy: 0.9244\n",
      "Epoch [6952/10000], Validation Loss: 0.93379831, Validation Accuracy: 0.6176\n",
      "Epoch [6953/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [6953/10000], Validation Loss: 0.93379864, Validation Accuracy: 0.6176\n",
      "Epoch [6954/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6954/10000], Validation Loss: 0.93379891, Validation Accuracy: 0.6176\n",
      "Epoch [6955/10000], Training Loss: 0.61867159, Training Accuracy: 0.9328\n",
      "Epoch [6955/10000], Validation Loss: 0.93379903, Validation Accuracy: 0.6176\n",
      "Epoch [6956/10000], Training Loss: 0.63127529, Training Accuracy: 0.9202\n",
      "Epoch [6956/10000], Validation Loss: 0.93379903, Validation Accuracy: 0.6176\n",
      "Epoch [6957/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6957/10000], Validation Loss: 0.93379903, Validation Accuracy: 0.6176\n",
      "Epoch [6958/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [6958/10000], Validation Loss: 0.93379897, Validation Accuracy: 0.6176\n",
      "Epoch [6959/10000], Training Loss: 0.63127691, Training Accuracy: 0.9202\n",
      "Epoch [6959/10000], Validation Loss: 0.93379897, Validation Accuracy: 0.6176\n",
      "Epoch [6960/10000], Training Loss: 0.62706941, Training Accuracy: 0.9244\n",
      "Epoch [6960/10000], Validation Loss: 0.93379876, Validation Accuracy: 0.6176\n",
      "Epoch [6961/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [6961/10000], Validation Loss: 0.93379864, Validation Accuracy: 0.6176\n",
      "Epoch [6962/10000], Training Loss: 0.61033400, Training Accuracy: 0.9412\n",
      "Epoch [6962/10000], Validation Loss: 0.93439507, Validation Accuracy: 0.6176\n",
      "Epoch [6963/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [6963/10000], Validation Loss: 0.93379340, Validation Accuracy: 0.6176\n",
      "Epoch [6964/10000], Training Loss: 0.60186516, Training Accuracy: 0.9496\n",
      "Epoch [6964/10000], Validation Loss: 0.93379715, Validation Accuracy: 0.6176\n",
      "Epoch [6965/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6965/10000], Validation Loss: 0.93379757, Validation Accuracy: 0.6176\n",
      "Epoch [6966/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [6966/10000], Validation Loss: 0.93379769, Validation Accuracy: 0.6176\n",
      "Epoch [6967/10000], Training Loss: 0.63111815, Training Accuracy: 0.9202\n",
      "Epoch [6967/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6968/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [6968/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6969/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6969/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6970/10000], Training Loss: 0.62326890, Training Accuracy: 0.9286\n",
      "Epoch [6970/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [6971/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [6971/10000], Validation Loss: 0.93378338, Validation Accuracy: 0.6176\n",
      "Epoch [6972/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [6972/10000], Validation Loss: 0.93338400, Validation Accuracy: 0.6176\n",
      "Epoch [6973/10000], Training Loss: 0.63364168, Training Accuracy: 0.9160\n",
      "Epoch [6973/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [6974/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6974/10000], Validation Loss: 1.03673822, Validation Accuracy: 0.5147\n",
      "Epoch [6975/10000], Training Loss: 0.63127691, Training Accuracy: 0.9202\n",
      "Epoch [6975/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [6976/10000], Training Loss: 0.62685720, Training Accuracy: 0.9202\n",
      "Epoch [6976/10000], Validation Loss: 1.03673893, Validation Accuracy: 0.5147\n",
      "Epoch [6977/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [6977/10000], Validation Loss: 1.06614536, Validation Accuracy: 0.4853\n",
      "Epoch [6978/10000], Training Loss: 0.71530206, Training Accuracy: 0.8361\n",
      "Epoch [6978/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [6979/10000], Training Loss: 0.73211707, Training Accuracy: 0.8193\n",
      "Epoch [6979/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [6980/10000], Training Loss: 0.72300637, Training Accuracy: 0.8277\n",
      "Epoch [6980/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [6981/10000], Training Loss: 0.72371386, Training Accuracy: 0.8277\n",
      "Epoch [6981/10000], Validation Loss: 1.11024135, Validation Accuracy: 0.4412\n",
      "Epoch [6982/10000], Training Loss: 0.74578587, Training Accuracy: 0.8067\n",
      "Epoch [6982/10000], Validation Loss: 1.11026841, Validation Accuracy: 0.4412\n",
      "Epoch [6983/10000], Training Loss: 0.71951088, Training Accuracy: 0.8319\n",
      "Epoch [6983/10000], Validation Loss: 1.09556246, Validation Accuracy: 0.4559\n",
      "Epoch [6984/10000], Training Loss: 0.71463304, Training Accuracy: 0.8361\n",
      "Epoch [6984/10000], Validation Loss: 1.08085030, Validation Accuracy: 0.4706\n",
      "Epoch [6985/10000], Training Loss: 0.70272385, Training Accuracy: 0.8487\n",
      "Epoch [6985/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [6986/10000], Training Loss: 0.69051890, Training Accuracy: 0.8613\n",
      "Epoch [6986/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6987/10000], Training Loss: 0.70270547, Training Accuracy: 0.8487\n",
      "Epoch [6987/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6988/10000], Training Loss: 0.70682487, Training Accuracy: 0.8445\n",
      "Epoch [6988/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6989/10000], Training Loss: 0.69445320, Training Accuracy: 0.8571\n",
      "Epoch [6989/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6990/10000], Training Loss: 0.69430200, Training Accuracy: 0.8571\n",
      "Epoch [6990/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6991/10000], Training Loss: 0.68169725, Training Accuracy: 0.8697\n",
      "Epoch [6991/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6992/10000], Training Loss: 0.66631411, Training Accuracy: 0.8866\n",
      "Epoch [6992/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [6993/10000], Training Loss: 0.66782081, Training Accuracy: 0.8824\n",
      "Epoch [6993/10000], Validation Loss: 1.09506834, Validation Accuracy: 0.4559\n",
      "Epoch [6994/10000], Training Loss: 0.63590438, Training Accuracy: 0.9160\n",
      "Epoch [6994/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [6995/10000], Training Loss: 0.65648679, Training Accuracy: 0.8950\n",
      "Epoch [6995/10000], Validation Loss: 1.05144495, Validation Accuracy: 0.5000\n",
      "Epoch [6996/10000], Training Loss: 0.63685950, Training Accuracy: 0.9160\n",
      "Epoch [6996/10000], Validation Loss: 1.05144498, Validation Accuracy: 0.5000\n",
      "Epoch [6997/10000], Training Loss: 0.63159152, Training Accuracy: 0.9202\n",
      "Epoch [6997/10000], Validation Loss: 0.96325010, Validation Accuracy: 0.5882\n",
      "Epoch [6998/10000], Training Loss: 0.62287356, Training Accuracy: 0.9286\n",
      "Epoch [6998/10000], Validation Loss: 0.94850361, Validation Accuracy: 0.6029\n",
      "Epoch [6999/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [6999/10000], Validation Loss: 0.94881549, Validation Accuracy: 0.6029\n",
      "Epoch [7000/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7000/10000], Validation Loss: 0.96310034, Validation Accuracy: 0.5882\n",
      "Epoch [7001/10000], Training Loss: 0.62667161, Training Accuracy: 0.9244\n",
      "Epoch [7001/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7002/10000], Training Loss: 0.61451382, Training Accuracy: 0.9370\n",
      "Epoch [7002/10000], Validation Loss: 0.97878203, Validation Accuracy: 0.5735\n",
      "Epoch [7003/10000], Training Loss: 0.64388025, Training Accuracy: 0.9076\n",
      "Epoch [7003/10000], Validation Loss: 0.99256414, Validation Accuracy: 0.5588\n",
      "Epoch [7004/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7004/10000], Validation Loss: 0.97791418, Validation Accuracy: 0.5735\n",
      "Epoch [7005/10000], Training Loss: 0.61762062, Training Accuracy: 0.9328\n",
      "Epoch [7005/10000], Validation Loss: 0.96000403, Validation Accuracy: 0.5882\n",
      "Epoch [7006/10000], Training Loss: 0.60643173, Training Accuracy: 0.9454\n",
      "Epoch [7006/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7007/10000], Training Loss: 0.61850144, Training Accuracy: 0.9328\n",
      "Epoch [7007/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7008/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7008/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [7009/10000], Training Loss: 0.61867195, Training Accuracy: 0.9328\n",
      "Epoch [7009/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [7010/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7010/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7011/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7011/10000], Validation Loss: 1.00732747, Validation Accuracy: 0.5441\n",
      "Epoch [7012/10000], Training Loss: 0.63128172, Training Accuracy: 0.9202\n",
      "Epoch [7012/10000], Validation Loss: 1.00732777, Validation Accuracy: 0.5441\n",
      "Epoch [7013/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7013/10000], Validation Loss: 1.00732818, Validation Accuracy: 0.5441\n",
      "Epoch [7014/10000], Training Loss: 0.63522020, Training Accuracy: 0.9160\n",
      "Epoch [7014/10000], Validation Loss: 1.00732818, Validation Accuracy: 0.5441\n",
      "Epoch [7015/10000], Training Loss: 0.63745689, Training Accuracy: 0.9118\n",
      "Epoch [7015/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7016/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7016/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7017/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7017/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7018/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7018/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7019/10000], Training Loss: 0.61766751, Training Accuracy: 0.9328\n",
      "Epoch [7019/10000], Validation Loss: 0.93378788, Validation Accuracy: 0.6176\n",
      "Epoch [7020/10000], Training Loss: 0.62255275, Training Accuracy: 0.9286\n",
      "Epoch [7020/10000], Validation Loss: 0.96321139, Validation Accuracy: 0.5882\n",
      "Epoch [7021/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7021/10000], Validation Loss: 0.97808436, Validation Accuracy: 0.5735\n",
      "Epoch [7022/10000], Training Loss: 0.61446213, Training Accuracy: 0.9370\n",
      "Epoch [7022/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7023/10000], Training Loss: 0.63548055, Training Accuracy: 0.9160\n",
      "Epoch [7023/10000], Validation Loss: 0.93381715, Validation Accuracy: 0.6176\n",
      "Epoch [7024/10000], Training Loss: 0.62739463, Training Accuracy: 0.9244\n",
      "Epoch [7024/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7025/10000], Training Loss: 0.61459453, Training Accuracy: 0.9370\n",
      "Epoch [7025/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7026/10000], Training Loss: 0.61867163, Training Accuracy: 0.9328\n",
      "Epoch [7026/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7027/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7027/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7028/10000], Training Loss: 0.61435711, Training Accuracy: 0.9370\n",
      "Epoch [7028/10000], Validation Loss: 0.99267069, Validation Accuracy: 0.5588\n",
      "Epoch [7029/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7029/10000], Validation Loss: 1.02163848, Validation Accuracy: 0.5294\n",
      "Epoch [7030/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7030/10000], Validation Loss: 1.02202898, Validation Accuracy: 0.5294\n",
      "Epoch [7031/10000], Training Loss: 0.60565099, Training Accuracy: 0.9454\n",
      "Epoch [7031/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [7032/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7032/10000], Validation Loss: 1.00799200, Validation Accuracy: 0.5441\n",
      "Epoch [7033/10000], Training Loss: 0.62440234, Training Accuracy: 0.9286\n",
      "Epoch [7033/10000], Validation Loss: 1.00732008, Validation Accuracy: 0.5441\n",
      "Epoch [7034/10000], Training Loss: 0.61838466, Training Accuracy: 0.9328\n",
      "Epoch [7034/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7035/10000], Training Loss: 0.63765510, Training Accuracy: 0.9118\n",
      "Epoch [7035/10000], Validation Loss: 0.96183670, Validation Accuracy: 0.5882\n",
      "Epoch [7036/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7036/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7037/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7037/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7038/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [7038/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7039/10000], Training Loss: 0.61867295, Training Accuracy: 0.9328\n",
      "Epoch [7039/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7040/10000], Training Loss: 0.62616127, Training Accuracy: 0.9244\n",
      "Epoch [7040/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7041/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7041/10000], Validation Loss: 0.94837782, Validation Accuracy: 0.6029\n",
      "Epoch [7042/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7042/10000], Validation Loss: 0.96320811, Validation Accuracy: 0.5882\n",
      "Epoch [7043/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [7043/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7044/10000], Training Loss: 0.62230575, Training Accuracy: 0.9286\n",
      "Epoch [7044/10000], Validation Loss: 0.96320078, Validation Accuracy: 0.5882\n",
      "Epoch [7045/10000], Training Loss: 0.61026833, Training Accuracy: 0.9412\n",
      "Epoch [7045/10000], Validation Loss: 0.96314794, Validation Accuracy: 0.5882\n",
      "Epoch [7046/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7046/10000], Validation Loss: 0.97686398, Validation Accuracy: 0.5735\n",
      "Epoch [7047/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7047/10000], Validation Loss: 0.98455355, Validation Accuracy: 0.5588\n",
      "Epoch [7048/10000], Training Loss: 0.64373228, Training Accuracy: 0.9076\n",
      "Epoch [7048/10000], Validation Loss: 0.99208459, Validation Accuracy: 0.5588\n",
      "Epoch [7049/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7049/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [7050/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7050/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7051/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7051/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7052/10000], Training Loss: 0.61447022, Training Accuracy: 0.9370\n",
      "Epoch [7052/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7053/10000], Training Loss: 0.62287375, Training Accuracy: 0.9286\n",
      "Epoch [7053/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7054/10000], Training Loss: 0.61874002, Training Accuracy: 0.9328\n",
      "Epoch [7054/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7055/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7055/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7056/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7056/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7057/10000], Training Loss: 0.62702849, Training Accuracy: 0.9244\n",
      "Epoch [7057/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7058/10000], Training Loss: 0.63127683, Training Accuracy: 0.9202\n",
      "Epoch [7058/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7059/10000], Training Loss: 0.61867213, Training Accuracy: 0.9328\n",
      "Epoch [7059/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [7060/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [7060/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [7061/10000], Training Loss: 0.59766395, Training Accuracy: 0.9538\n",
      "Epoch [7061/10000], Validation Loss: 0.99262130, Validation Accuracy: 0.5588\n",
      "Epoch [7062/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7062/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7063/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7063/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7064/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [7064/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7065/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7065/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7066/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [7066/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7067/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7067/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7068/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7068/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7069/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7069/10000], Validation Loss: 0.99262124, Validation Accuracy: 0.5588\n",
      "Epoch [7070/10000], Training Loss: 0.61212627, Training Accuracy: 0.9370\n",
      "Epoch [7070/10000], Validation Loss: 0.99714258, Validation Accuracy: 0.5588\n",
      "Epoch [7071/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [7071/10000], Validation Loss: 1.00731787, Validation Accuracy: 0.5441\n",
      "Epoch [7072/10000], Training Loss: 0.61808533, Training Accuracy: 0.9328\n",
      "Epoch [7072/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7073/10000], Training Loss: 0.61867146, Training Accuracy: 0.9328\n",
      "Epoch [7073/10000], Validation Loss: 0.97781193, Validation Accuracy: 0.5735\n",
      "Epoch [7074/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7074/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7075/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [7075/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7076/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7076/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7077/10000], Training Loss: 0.60396081, Training Accuracy: 0.9454\n",
      "Epoch [7077/10000], Validation Loss: 0.96321917, Validation Accuracy: 0.5882\n",
      "Epoch [7078/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7078/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7079/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7079/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7080/10000], Training Loss: 0.61357977, Training Accuracy: 0.9370\n",
      "Epoch [7080/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7081/10000], Training Loss: 0.61447754, Training Accuracy: 0.9370\n",
      "Epoch [7081/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7082/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7082/10000], Validation Loss: 0.97770709, Validation Accuracy: 0.5735\n",
      "Epoch [7083/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [7083/10000], Validation Loss: 0.96321791, Validation Accuracy: 0.5882\n",
      "Epoch [7084/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7084/10000], Validation Loss: 0.96320966, Validation Accuracy: 0.5882\n",
      "Epoch [7085/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7085/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7086/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7086/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7087/10000], Training Loss: 0.61447000, Training Accuracy: 0.9370\n",
      "Epoch [7087/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7088/10000], Training Loss: 0.62707519, Training Accuracy: 0.9244\n",
      "Epoch [7088/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7089/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7089/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7090/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7090/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7091/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7091/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7092/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7092/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7093/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7093/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7094/10000], Training Loss: 0.61866478, Training Accuracy: 0.9328\n",
      "Epoch [7094/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7095/10000], Training Loss: 0.60628608, Training Accuracy: 0.9454\n",
      "Epoch [7095/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7096/10000], Training Loss: 0.61447046, Training Accuracy: 0.9370\n",
      "Epoch [7096/10000], Validation Loss: 0.96321326, Validation Accuracy: 0.5882\n",
      "Epoch [7097/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7097/10000], Validation Loss: 0.96335828, Validation Accuracy: 0.5882\n",
      "Epoch [7098/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7098/10000], Validation Loss: 0.96404970, Validation Accuracy: 0.5882\n",
      "Epoch [7099/10000], Training Loss: 0.61310157, Training Accuracy: 0.9370\n",
      "Epoch [7099/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7100/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7100/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7101/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [7101/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7102/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7102/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7103/10000], Training Loss: 0.61867115, Training Accuracy: 0.9328\n",
      "Epoch [7103/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7104/10000], Training Loss: 0.61045968, Training Accuracy: 0.9412\n",
      "Epoch [7104/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7105/10000], Training Loss: 0.61026826, Training Accuracy: 0.9412\n",
      "Epoch [7105/10000], Validation Loss: 0.94850394, Validation Accuracy: 0.6029\n",
      "Epoch [7106/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [7106/10000], Validation Loss: 0.96201235, Validation Accuracy: 0.5882\n",
      "Epoch [7107/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [7107/10000], Validation Loss: 0.97727513, Validation Accuracy: 0.5735\n",
      "Epoch [7108/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7108/10000], Validation Loss: 0.97790951, Validation Accuracy: 0.5735\n",
      "Epoch [7109/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7109/10000], Validation Loss: 0.97791487, Validation Accuracy: 0.5735\n",
      "Epoch [7110/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7110/10000], Validation Loss: 0.97791529, Validation Accuracy: 0.5735\n",
      "Epoch [7111/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7111/10000], Validation Loss: 0.97791538, Validation Accuracy: 0.5735\n",
      "Epoch [7112/10000], Training Loss: 0.60818667, Training Accuracy: 0.9412\n",
      "Epoch [7112/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7113/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7113/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7114/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [7114/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7115/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7115/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7116/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7116/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7117/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7117/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7118/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7118/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7119/10000], Training Loss: 0.62651355, Training Accuracy: 0.9244\n",
      "Epoch [7119/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7120/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7120/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7121/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7121/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7122/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7122/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7123/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7123/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7124/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7124/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7125/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7125/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7126/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7126/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7127/10000], Training Loss: 0.62214062, Training Accuracy: 0.9286\n",
      "Epoch [7127/10000], Validation Loss: 0.94471341, Validation Accuracy: 0.6029\n",
      "Epoch [7128/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7128/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7129/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7129/10000], Validation Loss: 0.94634140, Validation Accuracy: 0.6029\n",
      "Epoch [7130/10000], Training Loss: 0.61447019, Training Accuracy: 0.9370\n",
      "Epoch [7130/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7131/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7131/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7132/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7132/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7133/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7133/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7134/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7134/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7135/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7135/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7136/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7136/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7137/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7137/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7138/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7138/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7139/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7139/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7140/10000], Training Loss: 0.61025182, Training Accuracy: 0.9412\n",
      "Epoch [7140/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7141/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7141/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7142/10000], Training Loss: 0.60605690, Training Accuracy: 0.9454\n",
      "Epoch [7142/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7143/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [7143/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7144/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7144/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7145/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7145/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7146/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7146/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7147/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7147/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7148/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7148/10000], Validation Loss: 0.96320969, Validation Accuracy: 0.5882\n",
      "Epoch [7149/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7149/10000], Validation Loss: 0.96320981, Validation Accuracy: 0.5882\n",
      "Epoch [7150/10000], Training Loss: 0.59349251, Training Accuracy: 0.9580\n",
      "Epoch [7150/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7151/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7151/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7152/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7152/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7153/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [7153/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7154/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7154/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7155/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7155/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7156/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7156/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7157/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [7157/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7158/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7158/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7159/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7159/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7160/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7160/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7161/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7161/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7162/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7162/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7163/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7163/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7164/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7164/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7165/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7165/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7166/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7166/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7167/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7167/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7168/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7168/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7169/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [7169/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7170/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7170/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7171/10000], Training Loss: 0.61523832, Training Accuracy: 0.9370\n",
      "Epoch [7171/10000], Validation Loss: 0.94857055, Validation Accuracy: 0.6029\n",
      "Epoch [7172/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [7172/10000], Validation Loss: 0.94929695, Validation Accuracy: 0.6029\n",
      "Epoch [7173/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7173/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7174/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7174/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7175/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7175/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7176/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7176/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7177/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7177/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7178/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7178/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7179/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7179/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7180/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7180/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7181/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7181/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7182/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7182/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7183/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7183/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7184/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7184/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7185/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7185/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7186/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7186/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7187/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [7187/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7188/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7188/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7189/10000], Training Loss: 0.61026841, Training Accuracy: 0.9412\n",
      "Epoch [7189/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7190/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7190/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7191/10000], Training Loss: 0.60911973, Training Accuracy: 0.9412\n",
      "Epoch [7191/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7192/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7192/10000], Validation Loss: 0.94850332, Validation Accuracy: 0.6029\n",
      "Epoch [7193/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7193/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7194/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7194/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7195/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7195/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7196/10000], Training Loss: 0.60603470, Training Accuracy: 0.9454\n",
      "Epoch [7196/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7197/10000], Training Loss: 0.60174223, Training Accuracy: 0.9496\n",
      "Epoch [7197/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7198/10000], Training Loss: 0.61398818, Training Accuracy: 0.9370\n",
      "Epoch [7198/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7199/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7199/10000], Validation Loss: 0.97790769, Validation Accuracy: 0.5735\n",
      "Epoch [7200/10000], Training Loss: 0.60186481, Training Accuracy: 0.9496\n",
      "Epoch [7200/10000], Validation Loss: 1.00191721, Validation Accuracy: 0.5441\n",
      "Epoch [7201/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7201/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7202/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7202/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7203/10000], Training Loss: 0.60187015, Training Accuracy: 0.9496\n",
      "Epoch [7203/10000], Validation Loss: 1.00734276, Validation Accuracy: 0.5441\n",
      "Epoch [7204/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7204/10000], Validation Loss: 1.00765339, Validation Accuracy: 0.5441\n",
      "Epoch [7205/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7205/10000], Validation Loss: 1.00864267, Validation Accuracy: 0.5441\n",
      "Epoch [7206/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7206/10000], Validation Loss: 1.00976747, Validation Accuracy: 0.5441\n",
      "Epoch [7207/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7207/10000], Validation Loss: 1.01053488, Validation Accuracy: 0.5441\n",
      "Epoch [7208/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7208/10000], Validation Loss: 1.01095933, Validation Accuracy: 0.5441\n",
      "Epoch [7209/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7209/10000], Validation Loss: 1.01117504, Validation Accuracy: 0.5441\n",
      "Epoch [7210/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [7210/10000], Validation Loss: 1.01128197, Validation Accuracy: 0.5441\n",
      "Epoch [7211/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7211/10000], Validation Loss: 1.01133370, Validation Accuracy: 0.5441\n",
      "Epoch [7212/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [7212/10000], Validation Loss: 1.01135910, Validation Accuracy: 0.5441\n",
      "Epoch [7213/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7213/10000], Validation Loss: 1.01136976, Validation Accuracy: 0.5441\n",
      "Epoch [7214/10000], Training Loss: 0.59267842, Training Accuracy: 0.9580\n",
      "Epoch [7214/10000], Validation Loss: 1.00665057, Validation Accuracy: 0.5441\n",
      "Epoch [7215/10000], Training Loss: 0.61866459, Training Accuracy: 0.9328\n",
      "Epoch [7215/10000], Validation Loss: 0.99933550, Validation Accuracy: 0.5441\n",
      "Epoch [7216/10000], Training Loss: 0.60186510, Training Accuracy: 0.9496\n",
      "Epoch [7216/10000], Validation Loss: 0.99323535, Validation Accuracy: 0.5588\n",
      "Epoch [7217/10000], Training Loss: 0.60611985, Training Accuracy: 0.9454\n",
      "Epoch [7217/10000], Validation Loss: 0.99265015, Validation Accuracy: 0.5588\n",
      "Epoch [7218/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [7218/10000], Validation Loss: 0.99962640, Validation Accuracy: 0.5441\n",
      "Epoch [7219/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7219/10000], Validation Loss: 1.00647381, Validation Accuracy: 0.5441\n",
      "Epoch [7220/10000], Training Loss: 0.63968017, Training Accuracy: 0.9118\n",
      "Epoch [7220/10000], Validation Loss: 1.00710139, Validation Accuracy: 0.5441\n",
      "Epoch [7221/10000], Training Loss: 0.63127683, Training Accuracy: 0.9202\n",
      "Epoch [7221/10000], Validation Loss: 1.00722122, Validation Accuracy: 0.5441\n",
      "Epoch [7222/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7222/10000], Validation Loss: 1.00726226, Validation Accuracy: 0.5441\n",
      "Epoch [7223/10000], Training Loss: 0.63916682, Training Accuracy: 0.9118\n",
      "Epoch [7223/10000], Validation Loss: 1.01035348, Validation Accuracy: 0.5441\n",
      "Epoch [7224/10000], Training Loss: 0.61020350, Training Accuracy: 0.9412\n",
      "Epoch [7224/10000], Validation Loss: 0.99476656, Validation Accuracy: 0.5588\n",
      "Epoch [7225/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7225/10000], Validation Loss: 1.00718054, Validation Accuracy: 0.5441\n",
      "Epoch [7226/10000], Training Loss: 0.60186509, Training Accuracy: 0.9496\n",
      "Epoch [7226/10000], Validation Loss: 0.99261430, Validation Accuracy: 0.5588\n",
      "Epoch [7227/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7227/10000], Validation Loss: 0.97791389, Validation Accuracy: 0.5735\n",
      "Epoch [7228/10000], Training Loss: 0.60640576, Training Accuracy: 0.9454\n",
      "Epoch [7228/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7229/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7229/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7230/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7230/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7231/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7231/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7232/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [7232/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7233/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7233/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7234/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7234/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7235/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7235/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7236/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7236/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7237/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7237/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7238/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7238/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7239/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [7239/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7240/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7240/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7241/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7241/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7242/10000], Training Loss: 0.61027236, Training Accuracy: 0.9412\n",
      "Epoch [7242/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7243/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7243/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7244/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7244/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7245/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7245/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7246/10000], Training Loss: 0.59770330, Training Accuracy: 0.9538\n",
      "Epoch [7246/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7247/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7247/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7248/10000], Training Loss: 0.62287350, Training Accuracy: 0.9286\n",
      "Epoch [7248/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7249/10000], Training Loss: 0.61444302, Training Accuracy: 0.9370\n",
      "Epoch [7249/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7250/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7250/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7251/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7251/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7252/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7252/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7253/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7253/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7254/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7254/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7255/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7255/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [7256/10000], Training Loss: 0.63538477, Training Accuracy: 0.9160\n",
      "Epoch [7256/10000], Validation Loss: 0.99260870, Validation Accuracy: 0.5588\n",
      "Epoch [7257/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7257/10000], Validation Loss: 0.97791567, Validation Accuracy: 0.5735\n",
      "Epoch [7258/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7258/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7259/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7259/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7260/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [7260/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7261/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7261/10000], Validation Loss: 0.97791553, Validation Accuracy: 0.5735\n",
      "Epoch [7262/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7262/10000], Validation Loss: 0.97791556, Validation Accuracy: 0.5735\n",
      "Epoch [7263/10000], Training Loss: 0.58926014, Training Accuracy: 0.9622\n",
      "Epoch [7263/10000], Validation Loss: 0.97791559, Validation Accuracy: 0.5735\n",
      "Epoch [7264/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7264/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7265/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7265/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7266/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7266/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7267/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7267/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7268/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7268/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7269/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7269/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7270/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7270/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7271/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7271/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7272/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [7272/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7273/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7273/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7274/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7274/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7275/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7275/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7276/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7276/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7277/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [7277/10000], Validation Loss: 0.97791561, Validation Accuracy: 0.5735\n",
      "Epoch [7278/10000], Training Loss: 0.59346409, Training Accuracy: 0.9580\n",
      "Epoch [7278/10000], Validation Loss: 0.97791553, Validation Accuracy: 0.5735\n",
      "Epoch [7279/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7279/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7280/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7280/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7281/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7281/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7282/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7282/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7283/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7283/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7284/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7284/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7285/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7285/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7286/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7286/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7287/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7287/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7288/10000], Training Loss: 0.61447013, Training Accuracy: 0.9370\n",
      "Epoch [7288/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7289/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7289/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7290/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7290/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7291/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7291/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7292/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [7292/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7293/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7293/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7294/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7294/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7295/10000], Training Loss: 0.60438932, Training Accuracy: 0.9454\n",
      "Epoch [7295/10000], Validation Loss: 0.97744799, Validation Accuracy: 0.5735\n",
      "Epoch [7296/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7296/10000], Validation Loss: 1.03673619, Validation Accuracy: 0.5147\n",
      "Epoch [7297/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7297/10000], Validation Loss: 1.08084396, Validation Accuracy: 0.4706\n",
      "Epoch [7298/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7298/10000], Validation Loss: 1.08085665, Validation Accuracy: 0.4706\n",
      "Epoch [7299/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [7299/10000], Validation Loss: 1.08085728, Validation Accuracy: 0.4706\n",
      "Epoch [7300/10000], Training Loss: 0.63984003, Training Accuracy: 0.9118\n",
      "Epoch [7300/10000], Validation Loss: 1.06584701, Validation Accuracy: 0.4853\n",
      "Epoch [7301/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7301/10000], Validation Loss: 1.05065328, Validation Accuracy: 0.5000\n",
      "Epoch [7302/10000], Training Loss: 0.62680396, Training Accuracy: 0.9244\n",
      "Epoch [7302/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [7303/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7303/10000], Validation Loss: 1.02203789, Validation Accuracy: 0.5294\n",
      "Epoch [7304/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7304/10000], Validation Loss: 1.00741243, Validation Accuracy: 0.5441\n",
      "Epoch [7305/10000], Training Loss: 0.62701531, Training Accuracy: 0.9244\n",
      "Epoch [7305/10000], Validation Loss: 1.00738278, Validation Accuracy: 0.5441\n",
      "Epoch [7306/10000], Training Loss: 0.61453835, Training Accuracy: 0.9370\n",
      "Epoch [7306/10000], Validation Loss: 1.00710630, Validation Accuracy: 0.5441\n",
      "Epoch [7307/10000], Training Loss: 0.61867179, Training Accuracy: 0.9328\n",
      "Epoch [7307/10000], Validation Loss: 1.00297129, Validation Accuracy: 0.5441\n",
      "Epoch [7308/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7308/10000], Validation Loss: 0.99726778, Validation Accuracy: 0.5588\n",
      "Epoch [7309/10000], Training Loss: 0.62305696, Training Accuracy: 0.9286\n",
      "Epoch [7309/10000], Validation Loss: 0.99264282, Validation Accuracy: 0.5588\n",
      "Epoch [7310/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7310/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [7311/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7311/10000], Validation Loss: 0.99262151, Validation Accuracy: 0.5588\n",
      "Epoch [7312/10000], Training Loss: 0.61447012, Training Accuracy: 0.9370\n",
      "Epoch [7312/10000], Validation Loss: 0.99262208, Validation Accuracy: 0.5588\n",
      "Epoch [7313/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7313/10000], Validation Loss: 0.99262285, Validation Accuracy: 0.5588\n",
      "Epoch [7314/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7314/10000], Validation Loss: 0.99262348, Validation Accuracy: 0.5588\n",
      "Epoch [7315/10000], Training Loss: 0.62260390, Training Accuracy: 0.9286\n",
      "Epoch [7315/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7316/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7316/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7317/10000], Training Loss: 0.61866914, Training Accuracy: 0.9328\n",
      "Epoch [7317/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [7318/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7318/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [7319/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7319/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [7320/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7320/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [7321/10000], Training Loss: 0.61027391, Training Accuracy: 0.9412\n",
      "Epoch [7321/10000], Validation Loss: 1.00541121, Validation Accuracy: 0.5441\n",
      "Epoch [7322/10000], Training Loss: 0.62707518, Training Accuracy: 0.9244\n",
      "Epoch [7322/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7323/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7323/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7324/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7324/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7325/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7325/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7326/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7326/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7327/10000], Training Loss: 0.63127585, Training Accuracy: 0.9202\n",
      "Epoch [7327/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7328/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7328/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7329/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7329/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7330/10000], Training Loss: 0.61446356, Training Accuracy: 0.9370\n",
      "Epoch [7330/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7331/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7331/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7332/10000], Training Loss: 0.61867132, Training Accuracy: 0.9328\n",
      "Epoch [7332/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7333/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7333/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7334/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7334/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7335/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7335/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7336/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7336/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7337/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7337/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7338/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7338/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7339/10000], Training Loss: 0.62705484, Training Accuracy: 0.9244\n",
      "Epoch [7339/10000], Validation Loss: 1.00732738, Validation Accuracy: 0.5441\n",
      "Epoch [7340/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7340/10000], Validation Loss: 1.00732744, Validation Accuracy: 0.5441\n",
      "Epoch [7341/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7341/10000], Validation Loss: 1.00732750, Validation Accuracy: 0.5441\n",
      "Epoch [7342/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7342/10000], Validation Loss: 1.00732756, Validation Accuracy: 0.5441\n",
      "Epoch [7343/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7343/10000], Validation Loss: 1.00732756, Validation Accuracy: 0.5441\n",
      "Epoch [7344/10000], Training Loss: 0.61026882, Training Accuracy: 0.9412\n",
      "Epoch [7344/10000], Validation Loss: 1.00732756, Validation Accuracy: 0.5441\n",
      "Epoch [7345/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7345/10000], Validation Loss: 1.00732756, Validation Accuracy: 0.5441\n",
      "Epoch [7346/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [7346/10000], Validation Loss: 1.00732756, Validation Accuracy: 0.5441\n",
      "Epoch [7347/10000], Training Loss: 0.62279832, Training Accuracy: 0.9286\n",
      "Epoch [7347/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [7348/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7348/10000], Validation Loss: 0.98421150, Validation Accuracy: 0.5588\n",
      "Epoch [7349/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7349/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7350/10000], Training Loss: 0.60180115, Training Accuracy: 0.9496\n",
      "Epoch [7350/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7351/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7351/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7352/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7352/10000], Validation Loss: 0.96320987, Validation Accuracy: 0.5882\n",
      "Epoch [7353/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7353/10000], Validation Loss: 0.96322981, Validation Accuracy: 0.5882\n",
      "Epoch [7354/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7354/10000], Validation Loss: 0.94865677, Validation Accuracy: 0.6029\n",
      "Epoch [7355/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7355/10000], Validation Loss: 0.94890267, Validation Accuracy: 0.6029\n",
      "Epoch [7356/10000], Training Loss: 0.60632495, Training Accuracy: 0.9454\n",
      "Epoch [7356/10000], Validation Loss: 0.94221959, Validation Accuracy: 0.6029\n",
      "Epoch [7357/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7357/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7358/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7358/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7359/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7359/10000], Validation Loss: 0.93389910, Validation Accuracy: 0.6176\n",
      "Epoch [7360/10000], Training Loss: 0.61866879, Training Accuracy: 0.9328\n",
      "Epoch [7360/10000], Validation Loss: 0.94091362, Validation Accuracy: 0.6029\n",
      "Epoch [7361/10000], Training Loss: 0.61026868, Training Accuracy: 0.9412\n",
      "Epoch [7361/10000], Validation Loss: 0.93431309, Validation Accuracy: 0.6176\n",
      "Epoch [7362/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7362/10000], Validation Loss: 0.93391865, Validation Accuracy: 0.6176\n",
      "Epoch [7363/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7363/10000], Validation Loss: 0.93385792, Validation Accuracy: 0.6176\n",
      "Epoch [7364/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7364/10000], Validation Loss: 0.93384081, Validation Accuracy: 0.6176\n",
      "Epoch [7365/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7365/10000], Validation Loss: 0.93383443, Validation Accuracy: 0.6176\n",
      "Epoch [7366/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7366/10000], Validation Loss: 0.93383172, Validation Accuracy: 0.6176\n",
      "Epoch [7367/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7367/10000], Validation Loss: 0.93383050, Validation Accuracy: 0.6176\n",
      "Epoch [7368/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7368/10000], Validation Loss: 0.93382993, Validation Accuracy: 0.6176\n",
      "Epoch [7369/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7369/10000], Validation Loss: 0.93382967, Validation Accuracy: 0.6176\n",
      "Epoch [7370/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7370/10000], Validation Loss: 0.93382952, Validation Accuracy: 0.6176\n",
      "Epoch [7371/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7371/10000], Validation Loss: 0.93382949, Validation Accuracy: 0.6176\n",
      "Epoch [7372/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7372/10000], Validation Loss: 0.93382946, Validation Accuracy: 0.6176\n",
      "Epoch [7373/10000], Training Loss: 0.60184751, Training Accuracy: 0.9496\n",
      "Epoch [7373/10000], Validation Loss: 0.93379802, Validation Accuracy: 0.6176\n",
      "Epoch [7374/10000], Training Loss: 0.60721119, Training Accuracy: 0.9454\n",
      "Epoch [7374/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7375/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [7375/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7376/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7376/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7377/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7377/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7378/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7378/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7379/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7379/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7380/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7380/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7381/10000], Training Loss: 0.61026843, Training Accuracy: 0.9412\n",
      "Epoch [7381/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7382/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7382/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7383/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7383/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7384/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7384/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7385/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7385/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7386/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7386/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7387/10000], Training Loss: 0.60186569, Training Accuracy: 0.9496\n",
      "Epoch [7387/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7388/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7388/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7389/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7389/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7390/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7390/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7391/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7391/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7392/10000], Training Loss: 0.60606673, Training Accuracy: 0.9454\n",
      "Epoch [7392/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7393/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7393/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7394/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7394/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7395/10000], Training Loss: 0.61444922, Training Accuracy: 0.9370\n",
      "Epoch [7395/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7396/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [7396/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7397/10000], Training Loss: 0.60606000, Training Accuracy: 0.9454\n",
      "Epoch [7397/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7398/10000], Training Loss: 0.60606690, Training Accuracy: 0.9454\n",
      "Epoch [7398/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7399/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7399/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7400/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7400/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7401/10000], Training Loss: 0.60186515, Training Accuracy: 0.9496\n",
      "Epoch [7401/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7402/10000], Training Loss: 0.63968022, Training Accuracy: 0.9118\n",
      "Epoch [7402/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7403/10000], Training Loss: 0.61447041, Training Accuracy: 0.9370\n",
      "Epoch [7403/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7404/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [7404/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7405/10000], Training Loss: 0.61447012, Training Accuracy: 0.9370\n",
      "Epoch [7405/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7406/10000], Training Loss: 0.61032747, Training Accuracy: 0.9412\n",
      "Epoch [7406/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [7407/10000], Training Loss: 0.60606393, Training Accuracy: 0.9454\n",
      "Epoch [7407/10000], Validation Loss: 0.96363878, Validation Accuracy: 0.5882\n",
      "Epoch [7408/10000], Training Loss: 0.60676712, Training Accuracy: 0.9454\n",
      "Epoch [7408/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7409/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [7409/10000], Validation Loss: 0.96318725, Validation Accuracy: 0.5882\n",
      "Epoch [7410/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7410/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7411/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7411/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7412/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [7412/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7413/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7413/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7414/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7414/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7415/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7415/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7416/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7416/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7417/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7417/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7418/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7418/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7419/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7419/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7420/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7420/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7421/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7421/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7422/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7422/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7423/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7423/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7424/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7424/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7425/10000], Training Loss: 0.59766320, Training Accuracy: 0.9538\n",
      "Epoch [7425/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7426/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7426/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7427/10000], Training Loss: 0.59346185, Training Accuracy: 0.9580\n",
      "Epoch [7427/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7428/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7428/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7429/10000], Training Loss: 0.61026613, Training Accuracy: 0.9412\n",
      "Epoch [7429/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7430/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [7430/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7431/10000], Training Loss: 0.60186500, Training Accuracy: 0.9496\n",
      "Epoch [7431/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7432/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7432/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7433/10000], Training Loss: 0.61026318, Training Accuracy: 0.9412\n",
      "Epoch [7433/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7434/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7434/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7435/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7435/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7436/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7436/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7437/10000], Training Loss: 0.60598688, Training Accuracy: 0.9454\n",
      "Epoch [7437/10000], Validation Loss: 0.94846955, Validation Accuracy: 0.6029\n",
      "Epoch [7438/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7438/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7439/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7439/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7440/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7440/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7441/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7441/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7442/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7442/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7443/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7443/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7444/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7444/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7445/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7445/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7446/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7446/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7447/10000], Training Loss: 0.59346074, Training Accuracy: 0.9580\n",
      "Epoch [7447/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7448/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7448/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7449/10000], Training Loss: 0.61026781, Training Accuracy: 0.9412\n",
      "Epoch [7449/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7450/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7450/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7451/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7451/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7452/10000], Training Loss: 0.60992822, Training Accuracy: 0.9412\n",
      "Epoch [7452/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7453/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7453/10000], Validation Loss: 0.96352401, Validation Accuracy: 0.5882\n",
      "Epoch [7454/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7454/10000], Validation Loss: 0.96320957, Validation Accuracy: 0.5882\n",
      "Epoch [7455/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [7455/10000], Validation Loss: 0.94850382, Validation Accuracy: 0.6029\n",
      "Epoch [7456/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7456/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7457/10000], Training Loss: 0.61447015, Training Accuracy: 0.9370\n",
      "Epoch [7457/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7458/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7458/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7459/10000], Training Loss: 0.61120889, Training Accuracy: 0.9412\n",
      "Epoch [7459/10000], Validation Loss: 0.94202819, Validation Accuracy: 0.6029\n",
      "Epoch [7460/10000], Training Loss: 0.59723647, Training Accuracy: 0.9538\n",
      "Epoch [7460/10000], Validation Loss: 0.93422922, Validation Accuracy: 0.6176\n",
      "Epoch [7461/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7461/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7462/10000], Training Loss: 0.60959087, Training Accuracy: 0.9412\n",
      "Epoch [7462/10000], Validation Loss: 0.97795987, Validation Accuracy: 0.5735\n",
      "Epoch [7463/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7463/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7464/10000], Training Loss: 0.62271592, Training Accuracy: 0.9286\n",
      "Epoch [7464/10000], Validation Loss: 1.04019272, Validation Accuracy: 0.5147\n",
      "Epoch [7465/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [7465/10000], Validation Loss: 1.05148858, Validation Accuracy: 0.5000\n",
      "Epoch [7466/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7466/10000], Validation Loss: 1.05144966, Validation Accuracy: 0.5000\n",
      "Epoch [7467/10000], Training Loss: 0.61447027, Training Accuracy: 0.9370\n",
      "Epoch [7467/10000], Validation Loss: 1.05144662, Validation Accuracy: 0.5000\n",
      "Epoch [7468/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7468/10000], Validation Loss: 1.05144590, Validation Accuracy: 0.5000\n",
      "Epoch [7469/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7469/10000], Validation Loss: 1.05144572, Validation Accuracy: 0.5000\n",
      "Epoch [7470/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7470/10000], Validation Loss: 1.05144566, Validation Accuracy: 0.5000\n",
      "Epoch [7471/10000], Training Loss: 0.60282057, Training Accuracy: 0.9496\n",
      "Epoch [7471/10000], Validation Loss: 1.02178934, Validation Accuracy: 0.5294\n",
      "Epoch [7472/10000], Training Loss: 0.61447977, Training Accuracy: 0.9370\n",
      "Epoch [7472/10000], Validation Loss: 0.94814488, Validation Accuracy: 0.6029\n",
      "Epoch [7473/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [7473/10000], Validation Loss: 0.91913375, Validation Accuracy: 0.6324\n",
      "Epoch [7474/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7474/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7475/10000], Training Loss: 0.59346198, Training Accuracy: 0.9580\n",
      "Epoch [7475/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7476/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7476/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7477/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7477/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7478/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7478/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7479/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7479/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7480/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7480/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7481/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7481/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7482/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7482/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7483/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7483/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7484/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7484/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7485/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [7485/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7486/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7486/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7487/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7487/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7488/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7488/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7489/10000], Training Loss: 0.61443577, Training Accuracy: 0.9370\n",
      "Epoch [7489/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7490/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7490/10000], Validation Loss: 0.93379897, Validation Accuracy: 0.6176\n",
      "Epoch [7491/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7491/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7492/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7492/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7493/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7493/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7494/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7494/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7495/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7495/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7496/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7496/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7497/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7497/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7498/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7498/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7499/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7499/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7500/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7500/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7501/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7501/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7502/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7502/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7503/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7503/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7504/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [7504/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7505/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [7505/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [7506/10000], Training Loss: 0.62199002, Training Accuracy: 0.9286\n",
      "Epoch [7506/10000], Validation Loss: 0.97791538, Validation Accuracy: 0.5735\n",
      "Epoch [7507/10000], Training Loss: 0.61018990, Training Accuracy: 0.9412\n",
      "Epoch [7507/10000], Validation Loss: 1.08080775, Validation Accuracy: 0.4706\n",
      "Epoch [7508/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7508/10000], Validation Loss: 1.05145174, Validation Accuracy: 0.5000\n",
      "Epoch [7509/10000], Training Loss: 0.61867156, Training Accuracy: 0.9328\n",
      "Epoch [7509/10000], Validation Loss: 1.05144376, Validation Accuracy: 0.5000\n",
      "Epoch [7510/10000], Training Loss: 0.61811776, Training Accuracy: 0.9328\n",
      "Epoch [7510/10000], Validation Loss: 0.99262211, Validation Accuracy: 0.5588\n",
      "Epoch [7511/10000], Training Loss: 0.61874177, Training Accuracy: 0.9328\n",
      "Epoch [7511/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7512/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7512/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7513/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [7513/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7514/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7514/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7515/10000], Training Loss: 0.62707480, Training Accuracy: 0.9244\n",
      "Epoch [7515/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7516/10000], Training Loss: 0.61446978, Training Accuracy: 0.9370\n",
      "Epoch [7516/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7517/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7517/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7518/10000], Training Loss: 0.61448124, Training Accuracy: 0.9370\n",
      "Epoch [7518/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7519/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7519/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7520/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7520/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7521/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7521/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7522/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7522/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7523/10000], Training Loss: 0.61867177, Training Accuracy: 0.9328\n",
      "Epoch [7523/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7524/10000], Training Loss: 0.64388313, Training Accuracy: 0.9076\n",
      "Epoch [7524/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7525/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7525/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7526/10000], Training Loss: 0.63968201, Training Accuracy: 0.9118\n",
      "Epoch [7526/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7527/10000], Training Loss: 0.62422130, Training Accuracy: 0.9286\n",
      "Epoch [7527/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7528/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7528/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7529/10000], Training Loss: 0.61866188, Training Accuracy: 0.9328\n",
      "Epoch [7529/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [7530/10000], Training Loss: 0.62302807, Training Accuracy: 0.9286\n",
      "Epoch [7530/10000], Validation Loss: 1.01553717, Validation Accuracy: 0.5294\n",
      "Epoch [7531/10000], Training Loss: 0.63965576, Training Accuracy: 0.9118\n",
      "Epoch [7531/10000], Validation Loss: 1.05144492, Validation Accuracy: 0.5000\n",
      "Epoch [7532/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7532/10000], Validation Loss: 1.05144474, Validation Accuracy: 0.5000\n",
      "Epoch [7533/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7533/10000], Validation Loss: 1.02210417, Validation Accuracy: 0.5294\n",
      "Epoch [7534/10000], Training Loss: 0.62707514, Training Accuracy: 0.9244\n",
      "Epoch [7534/10000], Validation Loss: 1.02199563, Validation Accuracy: 0.5294\n",
      "Epoch [7535/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7535/10000], Validation Loss: 1.02194872, Validation Accuracy: 0.5294\n",
      "Epoch [7536/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7536/10000], Validation Loss: 1.02190939, Validation Accuracy: 0.5294\n",
      "Epoch [7537/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7537/10000], Validation Loss: 1.02188483, Validation Accuracy: 0.5294\n",
      "Epoch [7538/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [7538/10000], Validation Loss: 1.02187154, Validation Accuracy: 0.5294\n",
      "Epoch [7539/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7539/10000], Validation Loss: 1.02186468, Validation Accuracy: 0.5294\n",
      "Epoch [7540/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7540/10000], Validation Loss: 1.02186134, Validation Accuracy: 0.5294\n",
      "Epoch [7541/10000], Training Loss: 0.63127652, Training Accuracy: 0.9202\n",
      "Epoch [7541/10000], Validation Loss: 1.02187154, Validation Accuracy: 0.5294\n",
      "Epoch [7542/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7542/10000], Validation Loss: 1.02189466, Validation Accuracy: 0.5294\n",
      "Epoch [7543/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7543/10000], Validation Loss: 1.02190468, Validation Accuracy: 0.5294\n",
      "Epoch [7544/10000], Training Loss: 0.61982077, Training Accuracy: 0.9328\n",
      "Epoch [7544/10000], Validation Loss: 1.08084375, Validation Accuracy: 0.4706\n",
      "Epoch [7545/10000], Training Loss: 0.64808359, Training Accuracy: 0.9034\n",
      "Epoch [7545/10000], Validation Loss: 1.06615144, Validation Accuracy: 0.4853\n",
      "Epoch [7546/10000], Training Loss: 0.63547838, Training Accuracy: 0.9160\n",
      "Epoch [7546/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [7547/10000], Training Loss: 0.63547878, Training Accuracy: 0.9160\n",
      "Epoch [7547/10000], Validation Loss: 1.08045006, Validation Accuracy: 0.4706\n",
      "Epoch [7548/10000], Training Loss: 0.63960637, Training Accuracy: 0.9118\n",
      "Epoch [7548/10000], Validation Loss: 1.08085656, Validation Accuracy: 0.4706\n",
      "Epoch [7549/10000], Training Loss: 0.63971806, Training Accuracy: 0.9118\n",
      "Epoch [7549/10000], Validation Loss: 1.08080143, Validation Accuracy: 0.4706\n",
      "Epoch [7550/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [7550/10000], Validation Loss: 1.08085656, Validation Accuracy: 0.4706\n",
      "Epoch [7551/10000], Training Loss: 0.65648696, Training Accuracy: 0.8950\n",
      "Epoch [7551/10000], Validation Loss: 1.08077675, Validation Accuracy: 0.4706\n",
      "Epoch [7552/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [7552/10000], Validation Loss: 1.07902002, Validation Accuracy: 0.4706\n",
      "Epoch [7553/10000], Training Loss: 0.65647273, Training Accuracy: 0.8950\n",
      "Epoch [7553/10000], Validation Loss: 1.07115495, Validation Accuracy: 0.4853\n",
      "Epoch [7554/10000], Training Loss: 0.65648678, Training Accuracy: 0.8950\n",
      "Epoch [7554/10000], Validation Loss: 1.06771612, Validation Accuracy: 0.4853\n",
      "Epoch [7555/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [7555/10000], Validation Loss: 1.06696266, Validation Accuracy: 0.4853\n",
      "Epoch [7556/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7556/10000], Validation Loss: 1.06673712, Validation Accuracy: 0.4853\n",
      "Epoch [7557/10000], Training Loss: 0.64389366, Training Accuracy: 0.9076\n",
      "Epoch [7557/10000], Validation Loss: 1.06856155, Validation Accuracy: 0.4853\n",
      "Epoch [7558/10000], Training Loss: 0.65508919, Training Accuracy: 0.8950\n",
      "Epoch [7558/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [7559/10000], Training Loss: 0.63586456, Training Accuracy: 0.9160\n",
      "Epoch [7559/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [7560/10000], Training Loss: 0.66068849, Training Accuracy: 0.8908\n",
      "Epoch [7560/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [7561/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [7561/10000], Validation Loss: 1.11008310, Validation Accuracy: 0.4412\n",
      "Epoch [7562/10000], Training Loss: 0.68858211, Training Accuracy: 0.8613\n",
      "Epoch [7562/10000], Validation Loss: 1.09556252, Validation Accuracy: 0.4559\n",
      "Epoch [7563/10000], Training Loss: 0.66909200, Training Accuracy: 0.8824\n",
      "Epoch [7563/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [7564/10000], Training Loss: 0.66909201, Training Accuracy: 0.8824\n",
      "Epoch [7564/10000], Validation Loss: 1.08076137, Validation Accuracy: 0.4706\n",
      "Epoch [7565/10000], Training Loss: 0.65226731, Training Accuracy: 0.8992\n",
      "Epoch [7565/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [7566/10000], Training Loss: 0.66068886, Training Accuracy: 0.8908\n",
      "Epoch [7566/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [7567/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [7567/10000], Validation Loss: 1.06614941, Validation Accuracy: 0.4853\n",
      "Epoch [7568/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [7568/10000], Validation Loss: 1.06613564, Validation Accuracy: 0.4853\n",
      "Epoch [7569/10000], Training Loss: 0.64808653, Training Accuracy: 0.9034\n",
      "Epoch [7569/10000], Validation Loss: 1.06600225, Validation Accuracy: 0.4853\n",
      "Epoch [7570/10000], Training Loss: 0.62773227, Training Accuracy: 0.9244\n",
      "Epoch [7570/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [7571/10000], Training Loss: 0.65649981, Training Accuracy: 0.8950\n",
      "Epoch [7571/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [7572/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [7572/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7573/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [7573/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7574/10000], Training Loss: 0.65222907, Training Accuracy: 0.8992\n",
      "Epoch [7574/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [7575/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7575/10000], Validation Loss: 1.05144423, Validation Accuracy: 0.5000\n",
      "Epoch [7576/10000], Training Loss: 0.64809194, Training Accuracy: 0.9034\n",
      "Epoch [7576/10000], Validation Loss: 1.05144227, Validation Accuracy: 0.5000\n",
      "Epoch [7577/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [7577/10000], Validation Loss: 1.06614572, Validation Accuracy: 0.4853\n",
      "Epoch [7578/10000], Training Loss: 0.62707517, Training Accuracy: 0.9244\n",
      "Epoch [7578/10000], Validation Loss: 1.06614381, Validation Accuracy: 0.4853\n",
      "Epoch [7579/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7579/10000], Validation Loss: 1.06614268, Validation Accuracy: 0.4853\n",
      "Epoch [7580/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7580/10000], Validation Loss: 1.06614202, Validation Accuracy: 0.4853\n",
      "Epoch [7581/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [7581/10000], Validation Loss: 1.06614178, Validation Accuracy: 0.4853\n",
      "Epoch [7582/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [7582/10000], Validation Loss: 1.06614161, Validation Accuracy: 0.4853\n",
      "Epoch [7583/10000], Training Loss: 0.62707485, Training Accuracy: 0.9244\n",
      "Epoch [7583/10000], Validation Loss: 1.06614131, Validation Accuracy: 0.4853\n",
      "Epoch [7584/10000], Training Loss: 0.62290259, Training Accuracy: 0.9286\n",
      "Epoch [7584/10000], Validation Loss: 1.06612939, Validation Accuracy: 0.4853\n",
      "Epoch [7585/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7585/10000], Validation Loss: 1.06610346, Validation Accuracy: 0.4853\n",
      "Epoch [7586/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [7586/10000], Validation Loss: 1.06608117, Validation Accuracy: 0.4853\n",
      "Epoch [7587/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7587/10000], Validation Loss: 1.06606698, Validation Accuracy: 0.4853\n",
      "Epoch [7588/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7588/10000], Validation Loss: 1.06605911, Validation Accuracy: 0.4853\n",
      "Epoch [7589/10000], Training Loss: 0.61828625, Training Accuracy: 0.9328\n",
      "Epoch [7589/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [7590/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7590/10000], Validation Loss: 1.05144489, Validation Accuracy: 0.5000\n",
      "Epoch [7591/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7591/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [7592/10000], Training Loss: 0.64368572, Training Accuracy: 0.9076\n",
      "Epoch [7592/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [7593/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7593/10000], Validation Loss: 1.06663007, Validation Accuracy: 0.4853\n",
      "Epoch [7594/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [7594/10000], Validation Loss: 1.08085656, Validation Accuracy: 0.4706\n",
      "Epoch [7595/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [7595/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [7596/10000], Training Loss: 0.65989706, Training Accuracy: 0.8908\n",
      "Epoch [7596/10000], Validation Loss: 1.08085668, Validation Accuracy: 0.4706\n",
      "Epoch [7597/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7597/10000], Validation Loss: 1.12940788, Validation Accuracy: 0.4265\n",
      "Epoch [7598/10000], Training Loss: 0.65341895, Training Accuracy: 0.8992\n",
      "Epoch [7598/10000], Validation Loss: 1.06615072, Validation Accuracy: 0.4853\n",
      "Epoch [7599/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7599/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [7600/10000], Training Loss: 0.63549277, Training Accuracy: 0.9160\n",
      "Epoch [7600/10000], Validation Loss: 1.00915211, Validation Accuracy: 0.5441\n",
      "Epoch [7601/10000], Training Loss: 0.61865026, Training Accuracy: 0.9328\n",
      "Epoch [7601/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7602/10000], Training Loss: 0.65648647, Training Accuracy: 0.8950\n",
      "Epoch [7602/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7603/10000], Training Loss: 0.63127694, Training Accuracy: 0.9202\n",
      "Epoch [7603/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7604/10000], Training Loss: 0.62287336, Training Accuracy: 0.9286\n",
      "Epoch [7604/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [7605/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7605/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [7606/10000], Training Loss: 0.63092562, Training Accuracy: 0.9202\n",
      "Epoch [7606/10000], Validation Loss: 1.02203339, Validation Accuracy: 0.5294\n",
      "Epoch [7607/10000], Training Loss: 0.63547764, Training Accuracy: 0.9160\n",
      "Epoch [7607/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7608/10000], Training Loss: 0.63096095, Training Accuracy: 0.9202\n",
      "Epoch [7608/10000], Validation Loss: 1.00639015, Validation Accuracy: 0.5441\n",
      "Epoch [7609/10000], Training Loss: 0.64388215, Training Accuracy: 0.9076\n",
      "Epoch [7609/10000], Validation Loss: 0.99425560, Validation Accuracy: 0.5588\n",
      "Epoch [7610/10000], Training Loss: 0.66062531, Training Accuracy: 0.8908\n",
      "Epoch [7610/10000], Validation Loss: 0.99263722, Validation Accuracy: 0.5588\n",
      "Epoch [7611/10000], Training Loss: 0.63967394, Training Accuracy: 0.9118\n",
      "Epoch [7611/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7612/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [7612/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7613/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7613/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7614/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7614/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7615/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [7615/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7616/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [7616/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7617/10000], Training Loss: 0.63968028, Training Accuracy: 0.9118\n",
      "Epoch [7617/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7618/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7618/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7619/10000], Training Loss: 0.64388257, Training Accuracy: 0.9076\n",
      "Epoch [7619/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7620/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7620/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7621/10000], Training Loss: 0.62707511, Training Accuracy: 0.9244\n",
      "Epoch [7621/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7622/10000], Training Loss: 0.65228558, Training Accuracy: 0.8992\n",
      "Epoch [7622/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7623/10000], Training Loss: 0.66068870, Training Accuracy: 0.8908\n",
      "Epoch [7623/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7624/10000], Training Loss: 0.64808370, Training Accuracy: 0.9034\n",
      "Epoch [7624/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7625/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [7625/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7626/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7626/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7627/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7627/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [7628/10000], Training Loss: 0.64337197, Training Accuracy: 0.9076\n",
      "Epoch [7628/10000], Validation Loss: 0.99262157, Validation Accuracy: 0.5588\n",
      "Epoch [7629/10000], Training Loss: 0.62747279, Training Accuracy: 0.9244\n",
      "Epoch [7629/10000], Validation Loss: 0.96317172, Validation Accuracy: 0.5882\n",
      "Epoch [7630/10000], Training Loss: 0.62287163, Training Accuracy: 0.9286\n",
      "Epoch [7630/10000], Validation Loss: 0.96307841, Validation Accuracy: 0.5882\n",
      "Epoch [7631/10000], Training Loss: 0.61901536, Training Accuracy: 0.9328\n",
      "Epoch [7631/10000], Validation Loss: 0.96590030, Validation Accuracy: 0.5882\n",
      "Epoch [7632/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7632/10000], Validation Loss: 0.97647357, Validation Accuracy: 0.5735\n",
      "Epoch [7633/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7633/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7634/10000], Training Loss: 0.61092749, Training Accuracy: 0.9412\n",
      "Epoch [7634/10000], Validation Loss: 0.96294212, Validation Accuracy: 0.5882\n",
      "Epoch [7635/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7635/10000], Validation Loss: 0.93379843, Validation Accuracy: 0.6176\n",
      "Epoch [7636/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7636/10000], Validation Loss: 0.90439293, Validation Accuracy: 0.6471\n",
      "Epoch [7637/10000], Training Loss: 0.62707228, Training Accuracy: 0.9244\n",
      "Epoch [7637/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7638/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7638/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7639/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7639/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7640/10000], Training Loss: 0.61031644, Training Accuracy: 0.9412\n",
      "Epoch [7640/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7641/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7641/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7642/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7642/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7643/10000], Training Loss: 0.62215852, Training Accuracy: 0.9286\n",
      "Epoch [7643/10000], Validation Loss: 0.96251944, Validation Accuracy: 0.5882\n",
      "Epoch [7644/10000], Training Loss: 0.61859562, Training Accuracy: 0.9328\n",
      "Epoch [7644/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7645/10000], Training Loss: 0.61811572, Training Accuracy: 0.9328\n",
      "Epoch [7645/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [7646/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7646/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7647/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [7647/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7648/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7648/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7649/10000], Training Loss: 0.63070604, Training Accuracy: 0.9202\n",
      "Epoch [7649/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7650/10000], Training Loss: 0.62698619, Training Accuracy: 0.9244\n",
      "Epoch [7650/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7651/10000], Training Loss: 0.61026714, Training Accuracy: 0.9412\n",
      "Epoch [7651/10000], Validation Loss: 0.93047446, Validation Accuracy: 0.6176\n",
      "Epoch [7652/10000], Training Loss: 0.63967964, Training Accuracy: 0.9118\n",
      "Epoch [7652/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7653/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [7653/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7654/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7654/10000], Validation Loss: 0.93379900, Validation Accuracy: 0.6176\n",
      "Epoch [7655/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7655/10000], Validation Loss: 0.93387204, Validation Accuracy: 0.6176\n",
      "Epoch [7656/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7656/10000], Validation Loss: 0.93437093, Validation Accuracy: 0.6176\n",
      "Epoch [7657/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7657/10000], Validation Loss: 0.93528324, Validation Accuracy: 0.6176\n",
      "Epoch [7658/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [7658/10000], Validation Loss: 0.93608829, Validation Accuracy: 0.6176\n",
      "Epoch [7659/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7659/10000], Validation Loss: 0.93659142, Validation Accuracy: 0.6176\n",
      "Epoch [7660/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7660/10000], Validation Loss: 0.93686223, Validation Accuracy: 0.6176\n",
      "Epoch [7661/10000], Training Loss: 0.62194611, Training Accuracy: 0.9286\n",
      "Epoch [7661/10000], Validation Loss: 0.91912559, Validation Accuracy: 0.6324\n",
      "Epoch [7662/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [7662/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7663/10000], Training Loss: 0.61023482, Training Accuracy: 0.9412\n",
      "Epoch [7663/10000], Validation Loss: 0.93379825, Validation Accuracy: 0.6176\n",
      "Epoch [7664/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7664/10000], Validation Loss: 0.94850358, Validation Accuracy: 0.6029\n",
      "Epoch [7665/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7665/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7666/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7666/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7667/10000], Training Loss: 0.61447010, Training Accuracy: 0.9370\n",
      "Epoch [7667/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7668/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7668/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7669/10000], Training Loss: 0.62287351, Training Accuracy: 0.9286\n",
      "Epoch [7669/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7670/10000], Training Loss: 0.62648503, Training Accuracy: 0.9244\n",
      "Epoch [7670/10000], Validation Loss: 0.93379965, Validation Accuracy: 0.6176\n",
      "Epoch [7671/10000], Training Loss: 0.62287346, Training Accuracy: 0.9286\n",
      "Epoch [7671/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7672/10000], Training Loss: 0.60606658, Training Accuracy: 0.9454\n",
      "Epoch [7672/10000], Validation Loss: 0.90438923, Validation Accuracy: 0.6471\n",
      "Epoch [7673/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7673/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7674/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [7674/10000], Validation Loss: 0.92299917, Validation Accuracy: 0.6324\n",
      "Epoch [7675/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7675/10000], Validation Loss: 0.93378967, Validation Accuracy: 0.6176\n",
      "Epoch [7676/10000], Training Loss: 0.62221272, Training Accuracy: 0.9286\n",
      "Epoch [7676/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7677/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7677/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7678/10000], Training Loss: 0.63546582, Training Accuracy: 0.9160\n",
      "Epoch [7678/10000], Validation Loss: 0.94847286, Validation Accuracy: 0.6029\n",
      "Epoch [7679/10000], Training Loss: 0.62681426, Training Accuracy: 0.9244\n",
      "Epoch [7679/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7680/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7680/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7681/10000], Training Loss: 0.63547639, Training Accuracy: 0.9160\n",
      "Epoch [7681/10000], Validation Loss: 0.91909203, Validation Accuracy: 0.6324\n",
      "Epoch [7682/10000], Training Loss: 0.61028045, Training Accuracy: 0.9412\n",
      "Epoch [7682/10000], Validation Loss: 0.92407712, Validation Accuracy: 0.6324\n",
      "Epoch [7683/10000], Training Loss: 0.61988695, Training Accuracy: 0.9286\n",
      "Epoch [7683/10000], Validation Loss: 0.91909391, Validation Accuracy: 0.6324\n",
      "Epoch [7684/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [7684/10000], Validation Loss: 0.96320933, Validation Accuracy: 0.5882\n",
      "Epoch [7685/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7685/10000], Validation Loss: 0.94881690, Validation Accuracy: 0.6029\n",
      "Epoch [7686/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7686/10000], Validation Loss: 0.95995733, Validation Accuracy: 0.5882\n",
      "Epoch [7687/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7687/10000], Validation Loss: 0.96304056, Validation Accuracy: 0.5882\n",
      "Epoch [7688/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7688/10000], Validation Loss: 0.94850245, Validation Accuracy: 0.6029\n",
      "Epoch [7689/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7689/10000], Validation Loss: 0.94850057, Validation Accuracy: 0.6029\n",
      "Epoch [7690/10000], Training Loss: 0.61444475, Training Accuracy: 0.9370\n",
      "Epoch [7690/10000], Validation Loss: 0.94815317, Validation Accuracy: 0.6029\n",
      "Epoch [7691/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7691/10000], Validation Loss: 0.94139919, Validation Accuracy: 0.6029\n",
      "Epoch [7692/10000], Training Loss: 0.59766537, Training Accuracy: 0.9538\n",
      "Epoch [7692/10000], Validation Loss: 0.93564960, Validation Accuracy: 0.6176\n",
      "Epoch [7693/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7693/10000], Validation Loss: 0.93452194, Validation Accuracy: 0.6176\n",
      "Epoch [7694/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7694/10000], Validation Loss: 0.93425262, Validation Accuracy: 0.6176\n",
      "Epoch [7695/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7695/10000], Validation Loss: 0.93416131, Validation Accuracy: 0.6176\n",
      "Epoch [7696/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7696/10000], Validation Loss: 0.93412429, Validation Accuracy: 0.6176\n",
      "Epoch [7697/10000], Training Loss: 0.62376824, Training Accuracy: 0.9286\n",
      "Epoch [7697/10000], Validation Loss: 0.94849101, Validation Accuracy: 0.6029\n",
      "Epoch [7698/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7698/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7699/10000], Training Loss: 0.59961748, Training Accuracy: 0.9496\n",
      "Epoch [7699/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7700/10000], Training Loss: 0.59346216, Training Accuracy: 0.9580\n",
      "Epoch [7700/10000], Validation Loss: 0.93374965, Validation Accuracy: 0.6176\n",
      "Epoch [7701/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7701/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7702/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7702/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7703/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7703/10000], Validation Loss: 0.90438658, Validation Accuracy: 0.6471\n",
      "Epoch [7704/10000], Training Loss: 0.60186726, Training Accuracy: 0.9496\n",
      "Epoch [7704/10000], Validation Loss: 0.90441191, Validation Accuracy: 0.6471\n",
      "Epoch [7705/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7705/10000], Validation Loss: 0.90457520, Validation Accuracy: 0.6471\n",
      "Epoch [7706/10000], Training Loss: 0.61174339, Training Accuracy: 0.9412\n",
      "Epoch [7706/10000], Validation Loss: 0.93379560, Validation Accuracy: 0.6176\n",
      "Epoch [7707/10000], Training Loss: 0.61636982, Training Accuracy: 0.9328\n",
      "Epoch [7707/10000], Validation Loss: 0.91945198, Validation Accuracy: 0.6324\n",
      "Epoch [7708/10000], Training Loss: 0.61880707, Training Accuracy: 0.9328\n",
      "Epoch [7708/10000], Validation Loss: 0.91916469, Validation Accuracy: 0.6324\n",
      "Epoch [7709/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [7709/10000], Validation Loss: 0.93379763, Validation Accuracy: 0.6176\n",
      "Epoch [7710/10000], Training Loss: 0.62372149, Training Accuracy: 0.9286\n",
      "Epoch [7710/10000], Validation Loss: 0.92327878, Validation Accuracy: 0.6324\n",
      "Epoch [7711/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7711/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7712/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7712/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7713/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7713/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7714/10000], Training Loss: 0.59736770, Training Accuracy: 0.9538\n",
      "Epoch [7714/10000], Validation Loss: 0.90438628, Validation Accuracy: 0.6471\n",
      "Epoch [7715/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7715/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7716/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7716/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7717/10000], Training Loss: 0.59346174, Training Accuracy: 0.9580\n",
      "Epoch [7717/10000], Validation Loss: 0.90438607, Validation Accuracy: 0.6471\n",
      "Epoch [7718/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7718/10000], Validation Loss: 0.90438324, Validation Accuracy: 0.6471\n",
      "Epoch [7719/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [7719/10000], Validation Loss: 0.90436345, Validation Accuracy: 0.6471\n",
      "Epoch [7720/10000], Training Loss: 0.58084408, Training Accuracy: 0.9706\n",
      "Epoch [7720/10000], Validation Loss: 0.90426302, Validation Accuracy: 0.6471\n",
      "Epoch [7721/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7721/10000], Validation Loss: 0.89960933, Validation Accuracy: 0.6471\n",
      "Epoch [7722/10000], Training Loss: 0.57665506, Training Accuracy: 0.9748\n",
      "Epoch [7722/10000], Validation Loss: 0.89306670, Validation Accuracy: 0.6618\n",
      "Epoch [7723/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [7723/10000], Validation Loss: 0.89125857, Validation Accuracy: 0.6618\n",
      "Epoch [7724/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [7724/10000], Validation Loss: 0.89074603, Validation Accuracy: 0.6618\n",
      "Epoch [7725/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7725/10000], Validation Loss: 0.89056054, Validation Accuracy: 0.6618\n",
      "Epoch [7726/10000], Training Loss: 0.58369124, Training Accuracy: 0.9664\n",
      "Epoch [7726/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7727/10000], Training Loss: 0.60599311, Training Accuracy: 0.9454\n",
      "Epoch [7727/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7728/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7728/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7729/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7729/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7730/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7730/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7731/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7731/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7732/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7732/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7733/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7733/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7734/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7734/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7735/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7735/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7736/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7736/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7737/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7737/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7738/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7738/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7739/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7739/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7740/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7740/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7741/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7741/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7742/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7742/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7743/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7743/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7744/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7744/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7745/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7745/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7746/10000], Training Loss: 0.59342119, Training Accuracy: 0.9580\n",
      "Epoch [7746/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7747/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7747/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7748/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7748/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7749/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [7749/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7750/10000], Training Loss: 0.59346161, Training Accuracy: 0.9580\n",
      "Epoch [7750/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7751/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7751/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7752/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7752/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7753/10000], Training Loss: 0.59346185, Training Accuracy: 0.9580\n",
      "Epoch [7753/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7754/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7754/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7755/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7755/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7756/10000], Training Loss: 0.61026857, Training Accuracy: 0.9412\n",
      "Epoch [7756/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7757/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7757/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7758/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7758/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7759/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7759/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7760/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7760/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7761/10000], Training Loss: 0.61026706, Training Accuracy: 0.9412\n",
      "Epoch [7761/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7762/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7762/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7763/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7763/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7764/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7764/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7765/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7765/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7766/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7766/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7767/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7767/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7768/10000], Training Loss: 0.62287240, Training Accuracy: 0.9286\n",
      "Epoch [7768/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7769/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7769/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7770/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7770/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7771/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7771/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7772/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7772/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7773/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7773/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7774/10000], Training Loss: 0.58921352, Training Accuracy: 0.9622\n",
      "Epoch [7774/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7775/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7775/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7776/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7776/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7777/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7777/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7778/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7778/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7779/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7779/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7780/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7780/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7781/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [7781/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7782/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7782/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7783/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7783/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7784/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7784/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7785/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7785/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7786/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7786/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7787/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7787/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7788/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [7788/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7789/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7789/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7790/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7790/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7791/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7791/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7792/10000], Training Loss: 0.61447041, Training Accuracy: 0.9370\n",
      "Epoch [7792/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7793/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7793/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7794/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7794/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7795/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7795/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7796/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7796/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7797/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7797/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7798/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7798/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7799/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7799/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7800/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7800/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7801/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7801/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7802/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7802/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7803/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7803/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7804/10000], Training Loss: 0.61342887, Training Accuracy: 0.9370\n",
      "Epoch [7804/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [7805/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7805/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7806/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7806/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7807/10000], Training Loss: 0.60754200, Training Accuracy: 0.9454\n",
      "Epoch [7807/10000], Validation Loss: 0.91565013, Validation Accuracy: 0.6324\n",
      "Epoch [7808/10000], Training Loss: 0.59346181, Training Accuracy: 0.9580\n",
      "Epoch [7808/10000], Validation Loss: 0.91909230, Validation Accuracy: 0.6324\n",
      "Epoch [7809/10000], Training Loss: 0.59895664, Training Accuracy: 0.9538\n",
      "Epoch [7809/10000], Validation Loss: 0.88968864, Validation Accuracy: 0.6618\n",
      "Epoch [7810/10000], Training Loss: 0.59346348, Training Accuracy: 0.9580\n",
      "Epoch [7810/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7811/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7811/10000], Validation Loss: 0.89509809, Validation Accuracy: 0.6618\n",
      "Epoch [7812/10000], Training Loss: 0.60180986, Training Accuracy: 0.9496\n",
      "Epoch [7812/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7813/10000], Training Loss: 0.58505763, Training Accuracy: 0.9664\n",
      "Epoch [7813/10000], Validation Loss: 0.91908202, Validation Accuracy: 0.6324\n",
      "Epoch [7814/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7814/10000], Validation Loss: 0.91597947, Validation Accuracy: 0.6324\n",
      "Epoch [7815/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7815/10000], Validation Loss: 0.90702763, Validation Accuracy: 0.6471\n",
      "Epoch [7816/10000], Training Loss: 0.62302613, Training Accuracy: 0.9286\n",
      "Epoch [7816/10000], Validation Loss: 0.90516287, Validation Accuracy: 0.6471\n",
      "Epoch [7817/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7817/10000], Validation Loss: 0.89003390, Validation Accuracy: 0.6618\n",
      "Epoch [7818/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7818/10000], Validation Loss: 0.88992128, Validation Accuracy: 0.6618\n",
      "Epoch [7819/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7819/10000], Validation Loss: 0.88988063, Validation Accuracy: 0.6618\n",
      "Epoch [7820/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7820/10000], Validation Loss: 0.88986358, Validation Accuracy: 0.6618\n",
      "Epoch [7821/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7821/10000], Validation Loss: 0.88985592, Validation Accuracy: 0.6618\n",
      "Epoch [7822/10000], Training Loss: 0.60606654, Training Accuracy: 0.9454\n",
      "Epoch [7822/10000], Validation Loss: 0.88984039, Validation Accuracy: 0.6618\n",
      "Epoch [7823/10000], Training Loss: 0.60470212, Training Accuracy: 0.9454\n",
      "Epoch [7823/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7824/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7824/10000], Validation Loss: 0.94696873, Validation Accuracy: 0.6029\n",
      "Epoch [7825/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7825/10000], Validation Loss: 0.93379802, Validation Accuracy: 0.6176\n",
      "Epoch [7826/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7826/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7827/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7827/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7828/10000], Training Loss: 0.61460322, Training Accuracy: 0.9370\n",
      "Epoch [7828/10000], Validation Loss: 0.93380037, Validation Accuracy: 0.6176\n",
      "Epoch [7829/10000], Training Loss: 0.60187317, Training Accuracy: 0.9496\n",
      "Epoch [7829/10000], Validation Loss: 0.96305117, Validation Accuracy: 0.5882\n",
      "Epoch [7830/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7830/10000], Validation Loss: 0.96320948, Validation Accuracy: 0.5882\n",
      "Epoch [7831/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7831/10000], Validation Loss: 0.96316200, Validation Accuracy: 0.5882\n",
      "Epoch [7832/10000], Training Loss: 0.58506427, Training Accuracy: 0.9664\n",
      "Epoch [7832/10000], Validation Loss: 0.96272010, Validation Accuracy: 0.5882\n",
      "Epoch [7833/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7833/10000], Validation Loss: 0.96293673, Validation Accuracy: 0.5882\n",
      "Epoch [7834/10000], Training Loss: 0.62706022, Training Accuracy: 0.9244\n",
      "Epoch [7834/10000], Validation Loss: 0.96169072, Validation Accuracy: 0.5882\n",
      "Epoch [7835/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [7835/10000], Validation Loss: 0.94851503, Validation Accuracy: 0.6029\n",
      "Epoch [7836/10000], Training Loss: 0.60606847, Training Accuracy: 0.9454\n",
      "Epoch [7836/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [7837/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7837/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7838/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [7838/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7839/10000], Training Loss: 0.60186994, Training Accuracy: 0.9496\n",
      "Epoch [7839/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7840/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [7840/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7841/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [7841/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7842/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [7842/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7843/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7843/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7844/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7844/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7845/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [7845/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7846/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7846/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [7847/10000], Training Loss: 0.60705433, Training Accuracy: 0.9454\n",
      "Epoch [7847/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7848/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7848/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7849/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [7849/10000], Validation Loss: 0.97791627, Validation Accuracy: 0.5735\n",
      "Epoch [7850/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [7850/10000], Validation Loss: 1.00760618, Validation Accuracy: 0.5441\n",
      "Epoch [7851/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [7851/10000], Validation Loss: 0.99647999, Validation Accuracy: 0.5588\n",
      "Epoch [7852/10000], Training Loss: 0.63127565, Training Accuracy: 0.9202\n",
      "Epoch [7852/10000], Validation Loss: 1.00097448, Validation Accuracy: 0.5441\n",
      "Epoch [7853/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7853/10000], Validation Loss: 1.00244758, Validation Accuracy: 0.5441\n",
      "Epoch [7854/10000], Training Loss: 0.63105871, Training Accuracy: 0.9202\n",
      "Epoch [7854/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [7855/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7855/10000], Validation Loss: 0.99267495, Validation Accuracy: 0.5588\n",
      "Epoch [7856/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [7856/10000], Validation Loss: 0.99215478, Validation Accuracy: 0.5588\n",
      "Epoch [7857/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [7857/10000], Validation Loss: 0.99239534, Validation Accuracy: 0.5588\n",
      "Epoch [7858/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7858/10000], Validation Loss: 0.99259818, Validation Accuracy: 0.5588\n",
      "Epoch [7859/10000], Training Loss: 0.63523599, Training Accuracy: 0.9160\n",
      "Epoch [7859/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7860/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7860/10000], Validation Loss: 0.96320924, Validation Accuracy: 0.5882\n",
      "Epoch [7861/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7861/10000], Validation Loss: 0.93385407, Validation Accuracy: 0.6176\n",
      "Epoch [7862/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [7862/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7863/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7863/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7864/10000], Training Loss: 0.61952503, Training Accuracy: 0.9328\n",
      "Epoch [7864/10000], Validation Loss: 0.93178514, Validation Accuracy: 0.6176\n",
      "Epoch [7865/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7865/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7866/10000], Training Loss: 0.61787774, Training Accuracy: 0.9328\n",
      "Epoch [7866/10000], Validation Loss: 0.93409672, Validation Accuracy: 0.6176\n",
      "Epoch [7867/10000], Training Loss: 0.60606667, Training Accuracy: 0.9454\n",
      "Epoch [7867/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7868/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7868/10000], Validation Loss: 0.90438619, Validation Accuracy: 0.6471\n",
      "Epoch [7869/10000], Training Loss: 0.59348703, Training Accuracy: 0.9580\n",
      "Epoch [7869/10000], Validation Loss: 0.92363241, Validation Accuracy: 0.6324\n",
      "Epoch [7870/10000], Training Loss: 0.60377935, Training Accuracy: 0.9454\n",
      "Epoch [7870/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7871/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7871/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [7872/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7872/10000], Validation Loss: 0.91863635, Validation Accuracy: 0.6324\n",
      "Epoch [7873/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7873/10000], Validation Loss: 0.90445384, Validation Accuracy: 0.6471\n",
      "Epoch [7874/10000], Training Loss: 0.61447040, Training Accuracy: 0.9370\n",
      "Epoch [7874/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7875/10000], Training Loss: 0.59345293, Training Accuracy: 0.9580\n",
      "Epoch [7875/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7876/10000], Training Loss: 0.61874387, Training Accuracy: 0.9328\n",
      "Epoch [7876/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7877/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7877/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7878/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7878/10000], Validation Loss: 0.90438601, Validation Accuracy: 0.6471\n",
      "Epoch [7879/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7879/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7880/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7880/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7881/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7881/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7882/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7882/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7883/10000], Training Loss: 0.61867169, Training Accuracy: 0.9328\n",
      "Epoch [7883/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7884/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7884/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7885/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7885/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7886/10000], Training Loss: 0.60606912, Training Accuracy: 0.9454\n",
      "Epoch [7886/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7887/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [7887/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7888/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7888/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7889/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [7889/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7890/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7890/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7891/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7891/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7892/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7892/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7893/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7893/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7894/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7894/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7895/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7895/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7896/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7896/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7897/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7897/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7898/10000], Training Loss: 0.58913432, Training Accuracy: 0.9622\n",
      "Epoch [7898/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7899/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7899/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7900/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7900/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7901/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7901/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7902/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7902/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7903/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7903/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7904/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7904/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7905/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7905/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7906/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7906/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7907/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7907/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7908/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7908/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7909/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7909/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7910/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7910/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7911/10000], Training Loss: 0.60164475, Training Accuracy: 0.9496\n",
      "Epoch [7911/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7912/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [7912/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7913/10000], Training Loss: 0.59319205, Training Accuracy: 0.9580\n",
      "Epoch [7913/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7914/10000], Training Loss: 0.60187848, Training Accuracy: 0.9496\n",
      "Epoch [7914/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7915/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [7915/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7916/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7916/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7917/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7917/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7918/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [7918/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7919/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7919/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7920/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7920/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7921/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [7921/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7922/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7922/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7923/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [7923/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7924/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7924/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7925/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7925/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7926/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7926/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7927/10000], Training Loss: 0.59782606, Training Accuracy: 0.9538\n",
      "Epoch [7927/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [7928/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7928/10000], Validation Loss: 0.91909102, Validation Accuracy: 0.6324\n",
      "Epoch [7929/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7929/10000], Validation Loss: 0.91908857, Validation Accuracy: 0.6324\n",
      "Epoch [7930/10000], Training Loss: 0.59346202, Training Accuracy: 0.9580\n",
      "Epoch [7930/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [7931/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7931/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7932/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7932/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7933/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7933/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7934/10000], Training Loss: 0.59766343, Training Accuracy: 0.9538\n",
      "Epoch [7934/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7935/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7935/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7936/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7936/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7937/10000], Training Loss: 0.58510432, Training Accuracy: 0.9664\n",
      "Epoch [7937/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [7938/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7938/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7939/10000], Training Loss: 0.61867772, Training Accuracy: 0.9328\n",
      "Epoch [7939/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7940/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [7940/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7941/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7941/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7942/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7942/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7943/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7943/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7944/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7944/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7945/10000], Training Loss: 0.60021148, Training Accuracy: 0.9496\n",
      "Epoch [7945/10000], Validation Loss: 0.90432456, Validation Accuracy: 0.6471\n",
      "Epoch [7946/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7946/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [7947/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7947/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [7948/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [7948/10000], Validation Loss: 0.87497136, Validation Accuracy: 0.6765\n",
      "Epoch [7949/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [7949/10000], Validation Loss: 0.87469703, Validation Accuracy: 0.6765\n",
      "Epoch [7950/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7950/10000], Validation Loss: 0.88845420, Validation Accuracy: 0.6618\n",
      "Epoch [7951/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7951/10000], Validation Loss: 0.88835174, Validation Accuracy: 0.6618\n",
      "Epoch [7952/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [7952/10000], Validation Loss: 0.88853577, Validation Accuracy: 0.6618\n",
      "Epoch [7953/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [7953/10000], Validation Loss: 0.88865429, Validation Accuracy: 0.6618\n",
      "Epoch [7954/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [7954/10000], Validation Loss: 0.88871408, Validation Accuracy: 0.6618\n",
      "Epoch [7955/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [7955/10000], Validation Loss: 0.88874304, Validation Accuracy: 0.6618\n",
      "Epoch [7956/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7956/10000], Validation Loss: 0.88875702, Validation Accuracy: 0.6618\n",
      "Epoch [7957/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7957/10000], Validation Loss: 0.88876367, Validation Accuracy: 0.6618\n",
      "Epoch [7958/10000], Training Loss: 0.61025159, Training Accuracy: 0.9412\n",
      "Epoch [7958/10000], Validation Loss: 0.88955599, Validation Accuracy: 0.6618\n",
      "Epoch [7959/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7959/10000], Validation Loss: 0.88967758, Validation Accuracy: 0.6618\n",
      "Epoch [7960/10000], Training Loss: 0.58808364, Training Accuracy: 0.9622\n",
      "Epoch [7960/10000], Validation Loss: 0.88967714, Validation Accuracy: 0.6618\n",
      "Epoch [7961/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7961/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7962/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [7962/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7963/10000], Training Loss: 0.59346172, Training Accuracy: 0.9580\n",
      "Epoch [7963/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7964/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [7964/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7965/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [7965/10000], Validation Loss: 0.88968018, Validation Accuracy: 0.6618\n",
      "Epoch [7966/10000], Training Loss: 0.61079714, Training Accuracy: 0.9412\n",
      "Epoch [7966/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7967/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [7967/10000], Validation Loss: 0.87499627, Validation Accuracy: 0.6765\n",
      "Epoch [7968/10000], Training Loss: 0.61447011, Training Accuracy: 0.9370\n",
      "Epoch [7968/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7969/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [7969/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7970/10000], Training Loss: 0.61856421, Training Accuracy: 0.9328\n",
      "Epoch [7970/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [7971/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7971/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [7972/10000], Training Loss: 0.60186524, Training Accuracy: 0.9496\n",
      "Epoch [7972/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7973/10000], Training Loss: 0.61026827, Training Accuracy: 0.9412\n",
      "Epoch [7973/10000], Validation Loss: 0.91909194, Validation Accuracy: 0.6324\n",
      "Epoch [7974/10000], Training Loss: 0.60152868, Training Accuracy: 0.9496\n",
      "Epoch [7974/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7975/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7975/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [7976/10000], Training Loss: 0.61026857, Training Accuracy: 0.9412\n",
      "Epoch [7976/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [7977/10000], Training Loss: 0.61114577, Training Accuracy: 0.9412\n",
      "Epoch [7977/10000], Validation Loss: 0.97791252, Validation Accuracy: 0.5735\n",
      "Epoch [7978/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [7978/10000], Validation Loss: 0.99259484, Validation Accuracy: 0.5588\n",
      "Epoch [7979/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7979/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [7980/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [7980/10000], Validation Loss: 1.00732836, Validation Accuracy: 0.5441\n",
      "Epoch [7981/10000], Training Loss: 0.63547863, Training Accuracy: 0.9160\n",
      "Epoch [7981/10000], Validation Loss: 1.01720235, Validation Accuracy: 0.5294\n",
      "Epoch [7982/10000], Training Loss: 0.63971554, Training Accuracy: 0.9118\n",
      "Epoch [7982/10000], Validation Loss: 1.02134183, Validation Accuracy: 0.5294\n",
      "Epoch [7983/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7983/10000], Validation Loss: 1.02179524, Validation Accuracy: 0.5294\n",
      "Epoch [7984/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [7984/10000], Validation Loss: 1.02189192, Validation Accuracy: 0.5294\n",
      "Epoch [7985/10000], Training Loss: 0.62287351, Training Accuracy: 0.9286\n",
      "Epoch [7985/10000], Validation Loss: 1.02192256, Validation Accuracy: 0.5294\n",
      "Epoch [7986/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [7986/10000], Validation Loss: 1.02193478, Validation Accuracy: 0.5294\n",
      "Epoch [7987/10000], Training Loss: 0.62742327, Training Accuracy: 0.9244\n",
      "Epoch [7987/10000], Validation Loss: 0.97983074, Validation Accuracy: 0.5735\n",
      "Epoch [7988/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [7988/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [7989/10000], Training Loss: 0.62287421, Training Accuracy: 0.9286\n",
      "Epoch [7989/10000], Validation Loss: 0.97783306, Validation Accuracy: 0.5735\n",
      "Epoch [7990/10000], Training Loss: 0.61867169, Training Accuracy: 0.9328\n",
      "Epoch [7990/10000], Validation Loss: 0.96481663, Validation Accuracy: 0.5882\n",
      "Epoch [7991/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [7991/10000], Validation Loss: 0.96326953, Validation Accuracy: 0.5882\n",
      "Epoch [7992/10000], Training Loss: 0.62707567, Training Accuracy: 0.9244\n",
      "Epoch [7992/10000], Validation Loss: 0.96322030, Validation Accuracy: 0.5882\n",
      "Epoch [7993/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [7993/10000], Validation Loss: 0.96321422, Validation Accuracy: 0.5882\n",
      "Epoch [7994/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [7994/10000], Validation Loss: 0.96321270, Validation Accuracy: 0.5882\n",
      "Epoch [7995/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [7995/10000], Validation Loss: 0.96321219, Validation Accuracy: 0.5882\n",
      "Epoch [7996/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [7996/10000], Validation Loss: 0.96321195, Validation Accuracy: 0.5882\n",
      "Epoch [7997/10000], Training Loss: 0.61453261, Training Accuracy: 0.9370\n",
      "Epoch [7997/10000], Validation Loss: 0.96321228, Validation Accuracy: 0.5882\n",
      "Epoch [7998/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [7998/10000], Validation Loss: 0.96321565, Validation Accuracy: 0.5882\n",
      "Epoch [7999/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [7999/10000], Validation Loss: 0.96321857, Validation Accuracy: 0.5882\n",
      "Epoch [8000/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8000/10000], Validation Loss: 0.96322045, Validation Accuracy: 0.5882\n",
      "Epoch [8001/10000], Training Loss: 0.59766435, Training Accuracy: 0.9538\n",
      "Epoch [8001/10000], Validation Loss: 0.96322116, Validation Accuracy: 0.5882\n",
      "Epoch [8002/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8002/10000], Validation Loss: 0.96322146, Validation Accuracy: 0.5882\n",
      "Epoch [8003/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8003/10000], Validation Loss: 0.96322161, Validation Accuracy: 0.5882\n",
      "Epoch [8004/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8004/10000], Validation Loss: 0.96322170, Validation Accuracy: 0.5882\n",
      "Epoch [8005/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [8005/10000], Validation Loss: 0.96322173, Validation Accuracy: 0.5882\n",
      "Epoch [8006/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8006/10000], Validation Loss: 0.96322173, Validation Accuracy: 0.5882\n",
      "Epoch [8007/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8007/10000], Validation Loss: 0.96322173, Validation Accuracy: 0.5882\n",
      "Epoch [8008/10000], Training Loss: 0.61446272, Training Accuracy: 0.9370\n",
      "Epoch [8008/10000], Validation Loss: 0.96321249, Validation Accuracy: 0.5882\n",
      "Epoch [8009/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8009/10000], Validation Loss: 0.96321109, Validation Accuracy: 0.5882\n",
      "Epoch [8010/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8010/10000], Validation Loss: 0.96321070, Validation Accuracy: 0.5882\n",
      "Epoch [8011/10000], Training Loss: 0.59766316, Training Accuracy: 0.9538\n",
      "Epoch [8011/10000], Validation Loss: 0.96321052, Validation Accuracy: 0.5882\n",
      "Epoch [8012/10000], Training Loss: 0.60186550, Training Accuracy: 0.9496\n",
      "Epoch [8012/10000], Validation Loss: 0.99262145, Validation Accuracy: 0.5588\n",
      "Epoch [8013/10000], Training Loss: 0.59346126, Training Accuracy: 0.9580\n",
      "Epoch [8013/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [8014/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8014/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8015/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8015/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8016/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [8016/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8017/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8017/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8018/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8018/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8019/10000], Training Loss: 0.59766259, Training Accuracy: 0.9538\n",
      "Epoch [8019/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8020/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8020/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8021/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8021/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [8022/10000], Training Loss: 0.62315561, Training Accuracy: 0.9286\n",
      "Epoch [8022/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [8023/10000], Training Loss: 0.62287419, Training Accuracy: 0.9286\n",
      "Epoch [8023/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [8024/10000], Training Loss: 0.62707518, Training Accuracy: 0.9244\n",
      "Epoch [8024/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [8025/10000], Training Loss: 0.61885443, Training Accuracy: 0.9328\n",
      "Epoch [8025/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [8026/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [8026/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [8027/10000], Training Loss: 0.61867203, Training Accuracy: 0.9328\n",
      "Epoch [8027/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [8028/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8028/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8029/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8029/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8030/10000], Training Loss: 0.62287323, Training Accuracy: 0.9286\n",
      "Epoch [8030/10000], Validation Loss: 0.99254271, Validation Accuracy: 0.5588\n",
      "Epoch [8031/10000], Training Loss: 0.61871605, Training Accuracy: 0.9328\n",
      "Epoch [8031/10000], Validation Loss: 0.99261031, Validation Accuracy: 0.5588\n",
      "Epoch [8032/10000], Training Loss: 0.63114162, Training Accuracy: 0.9202\n",
      "Epoch [8032/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8033/10000], Training Loss: 0.62745780, Training Accuracy: 0.9244\n",
      "Epoch [8033/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8034/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [8034/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8035/10000], Training Loss: 0.60746229, Training Accuracy: 0.9454\n",
      "Epoch [8035/10000], Validation Loss: 0.86220008, Validation Accuracy: 0.6912\n",
      "Epoch [8036/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8036/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8037/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8037/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8038/10000], Training Loss: 0.61029723, Training Accuracy: 0.9412\n",
      "Epoch [8038/10000], Validation Loss: 0.91909203, Validation Accuracy: 0.6324\n",
      "Epoch [8039/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8039/10000], Validation Loss: 0.91924089, Validation Accuracy: 0.6324\n",
      "Epoch [8040/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8040/10000], Validation Loss: 0.92512774, Validation Accuracy: 0.6176\n",
      "Epoch [8041/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8041/10000], Validation Loss: 0.93149516, Validation Accuracy: 0.6176\n",
      "Epoch [8042/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8042/10000], Validation Loss: 0.93282750, Validation Accuracy: 0.6176\n",
      "Epoch [8043/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8043/10000], Validation Loss: 0.93317121, Validation Accuracy: 0.6176\n",
      "Epoch [8044/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [8044/10000], Validation Loss: 0.93329141, Validation Accuracy: 0.6176\n",
      "Epoch [8045/10000], Training Loss: 0.61027057, Training Accuracy: 0.9412\n",
      "Epoch [8045/10000], Validation Loss: 0.93306443, Validation Accuracy: 0.6176\n",
      "Epoch [8046/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8046/10000], Validation Loss: 0.93288669, Validation Accuracy: 0.6176\n",
      "Epoch [8047/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8047/10000], Validation Loss: 0.93278781, Validation Accuracy: 0.6176\n",
      "Epoch [8048/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8048/10000], Validation Loss: 0.93273684, Validation Accuracy: 0.6176\n",
      "Epoch [8049/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8049/10000], Validation Loss: 0.93271154, Validation Accuracy: 0.6176\n",
      "Epoch [8050/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8050/10000], Validation Loss: 0.93269920, Validation Accuracy: 0.6176\n",
      "Epoch [8051/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8051/10000], Validation Loss: 0.93269312, Validation Accuracy: 0.6176\n",
      "Epoch [8052/10000], Training Loss: 0.61867044, Training Accuracy: 0.9328\n",
      "Epoch [8052/10000], Validation Loss: 0.93111584, Validation Accuracy: 0.6176\n",
      "Epoch [8053/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8053/10000], Validation Loss: 0.92953473, Validation Accuracy: 0.6176\n",
      "Epoch [8054/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8054/10000], Validation Loss: 0.92855519, Validation Accuracy: 0.6176\n",
      "Epoch [8055/10000], Training Loss: 0.61026875, Training Accuracy: 0.9412\n",
      "Epoch [8055/10000], Validation Loss: 0.92794958, Validation Accuracy: 0.6176\n",
      "Epoch [8056/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8056/10000], Validation Loss: 0.92732206, Validation Accuracy: 0.6176\n",
      "Epoch [8057/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8057/10000], Validation Loss: 0.92701548, Validation Accuracy: 0.6176\n",
      "Epoch [8058/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8058/10000], Validation Loss: 0.92686719, Validation Accuracy: 0.6176\n",
      "Epoch [8059/10000], Training Loss: 0.62275058, Training Accuracy: 0.9286\n",
      "Epoch [8059/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8060/10000], Training Loss: 0.60606534, Training Accuracy: 0.9454\n",
      "Epoch [8060/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8061/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8061/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8062/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8062/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8063/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8063/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8064/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8064/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8065/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8065/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8066/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8066/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8067/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8067/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8068/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [8068/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8069/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8069/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8070/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8070/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8071/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8071/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8072/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [8072/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8073/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8073/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8074/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8074/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8075/10000], Training Loss: 0.61444831, Training Accuracy: 0.9370\n",
      "Epoch [8075/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8076/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [8076/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8077/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8077/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8078/10000], Training Loss: 0.61027112, Training Accuracy: 0.9412\n",
      "Epoch [8078/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8079/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8079/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8080/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8080/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8081/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8081/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8082/10000], Training Loss: 0.61501991, Training Accuracy: 0.9370\n",
      "Epoch [8082/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8083/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8083/10000], Validation Loss: 0.91906643, Validation Accuracy: 0.6324\n",
      "Epoch [8084/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [8084/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8085/10000], Training Loss: 0.61026950, Training Accuracy: 0.9412\n",
      "Epoch [8085/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8086/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8086/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8087/10000], Training Loss: 0.61449386, Training Accuracy: 0.9370\n",
      "Epoch [8087/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8088/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8088/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8089/10000], Training Loss: 0.61026843, Training Accuracy: 0.9412\n",
      "Epoch [8089/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8090/10000], Training Loss: 0.60218687, Training Accuracy: 0.9496\n",
      "Epoch [8090/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8091/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8091/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8092/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8092/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8093/10000], Training Loss: 0.59908995, Training Accuracy: 0.9538\n",
      "Epoch [8093/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8094/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8094/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8095/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8095/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8096/10000], Training Loss: 0.59743391, Training Accuracy: 0.9538\n",
      "Epoch [8096/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8097/10000], Training Loss: 0.60606719, Training Accuracy: 0.9454\n",
      "Epoch [8097/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8098/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8098/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8099/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8099/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8100/10000], Training Loss: 0.61049261, Training Accuracy: 0.9412\n",
      "Epoch [8100/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8101/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8101/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8102/10000], Training Loss: 0.62707497, Training Accuracy: 0.9244\n",
      "Epoch [8102/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8103/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8103/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8104/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [8104/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8105/10000], Training Loss: 0.61827976, Training Accuracy: 0.9328\n",
      "Epoch [8105/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8106/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8106/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8107/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8107/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8108/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8108/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8109/10000], Training Loss: 0.60606738, Training Accuracy: 0.9454\n",
      "Epoch [8109/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8110/10000], Training Loss: 0.61446994, Training Accuracy: 0.9370\n",
      "Epoch [8110/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8111/10000], Training Loss: 0.61866128, Training Accuracy: 0.9328\n",
      "Epoch [8111/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8112/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8112/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8113/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8113/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8114/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8114/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8115/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8115/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8116/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8116/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8117/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8117/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8118/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8118/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8119/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8119/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8120/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8120/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8121/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8121/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8122/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8122/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8123/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8123/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8124/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [8124/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8125/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8125/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8126/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8126/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8127/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8127/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8128/10000], Training Loss: 0.60185134, Training Accuracy: 0.9496\n",
      "Epoch [8128/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8129/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8129/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8130/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8130/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8131/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8131/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8132/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8132/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8133/10000], Training Loss: 0.59765890, Training Accuracy: 0.9538\n",
      "Epoch [8133/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8134/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8134/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8135/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8135/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8136/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8136/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8137/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8137/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8138/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8138/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8139/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [8139/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8140/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8140/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8141/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8141/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8142/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [8142/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8143/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8143/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8144/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8144/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8145/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8145/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8146/10000], Training Loss: 0.59766298, Training Accuracy: 0.9538\n",
      "Epoch [8146/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8147/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8147/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8148/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8148/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8149/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8149/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8150/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [8150/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8151/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8151/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8152/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8152/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8153/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [8153/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8154/10000], Training Loss: 0.61447014, Training Accuracy: 0.9370\n",
      "Epoch [8154/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8155/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8155/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8156/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8156/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8157/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8157/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8158/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8158/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8159/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8159/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8160/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8160/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8161/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8161/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8162/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8162/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8163/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8163/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8164/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8164/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8165/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8165/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8166/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8166/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8167/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8167/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8168/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8168/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8169/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8169/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8170/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8170/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8171/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8171/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8172/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8172/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8173/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8173/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8174/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8174/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8175/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8175/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8176/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8176/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8177/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8177/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8178/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8178/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8179/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8179/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8180/10000], Training Loss: 0.60186589, Training Accuracy: 0.9496\n",
      "Epoch [8180/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8181/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [8181/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8182/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8182/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8183/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8183/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8184/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8184/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8185/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8185/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8186/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8186/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8187/10000], Training Loss: 0.60208241, Training Accuracy: 0.9496\n",
      "Epoch [8187/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8188/10000], Training Loss: 0.61026474, Training Accuracy: 0.9412\n",
      "Epoch [8188/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8189/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [8189/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8190/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8190/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8191/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8191/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8192/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8192/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8193/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8193/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8194/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [8194/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8195/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8195/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8196/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8196/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8197/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8197/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8198/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8198/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8199/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8199/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8200/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [8200/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8201/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8201/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8202/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8202/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8203/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8203/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8204/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8204/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8205/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8205/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8206/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8206/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8207/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8207/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8208/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8208/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8209/10000], Training Loss: 0.61026817, Training Accuracy: 0.9412\n",
      "Epoch [8209/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8210/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8210/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8211/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8211/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8212/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8212/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8213/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8213/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8214/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8214/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8215/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8215/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8216/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8216/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8217/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8217/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8218/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8218/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8219/10000], Training Loss: 0.60778808, Training Accuracy: 0.9412\n",
      "Epoch [8219/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8220/10000], Training Loss: 0.61026828, Training Accuracy: 0.9412\n",
      "Epoch [8220/10000], Validation Loss: 0.91126588, Validation Accuracy: 0.6324\n",
      "Epoch [8221/10000], Training Loss: 0.61026898, Training Accuracy: 0.9412\n",
      "Epoch [8221/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8222/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8222/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8223/10000], Training Loss: 0.62292303, Training Accuracy: 0.9286\n",
      "Epoch [8223/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8224/10000], Training Loss: 0.61862760, Training Accuracy: 0.9328\n",
      "Epoch [8224/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8225/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8225/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8226/10000], Training Loss: 0.61102648, Training Accuracy: 0.9412\n",
      "Epoch [8226/10000], Validation Loss: 0.94082639, Validation Accuracy: 0.6029\n",
      "Epoch [8227/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8227/10000], Validation Loss: 0.91909328, Validation Accuracy: 0.6324\n",
      "Epoch [8228/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8228/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8229/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8229/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8230/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8230/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8231/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8231/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8232/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8232/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8233/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8233/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8234/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8234/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8235/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8235/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8236/10000], Training Loss: 0.60606679, Training Accuracy: 0.9454\n",
      "Epoch [8236/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8237/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8237/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8238/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8238/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8239/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8239/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8240/10000], Training Loss: 0.60613979, Training Accuracy: 0.9454\n",
      "Epoch [8240/10000], Validation Loss: 0.91909218, Validation Accuracy: 0.6324\n",
      "Epoch [8241/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8241/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8242/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8242/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8243/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8243/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8244/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8244/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8245/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [8245/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8246/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8246/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8247/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8247/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8248/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8248/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8249/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8249/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8250/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8250/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8251/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8251/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8252/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8252/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8253/10000], Training Loss: 0.61447020, Training Accuracy: 0.9370\n",
      "Epoch [8253/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8254/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8254/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8255/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8255/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8256/10000], Training Loss: 0.61867191, Training Accuracy: 0.9328\n",
      "Epoch [8256/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8257/10000], Training Loss: 0.60493316, Training Accuracy: 0.9454\n",
      "Epoch [8257/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8258/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8258/10000], Validation Loss: 0.94836101, Validation Accuracy: 0.6029\n",
      "Epoch [8259/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8259/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8260/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8260/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8261/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8261/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8262/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8262/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8263/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8263/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8264/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8264/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8265/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8265/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8266/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8266/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8267/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8267/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8268/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8268/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8269/10000], Training Loss: 0.61408104, Training Accuracy: 0.9370\n",
      "Epoch [8269/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8270/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8270/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8271/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8271/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8272/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8272/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8273/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8273/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8274/10000], Training Loss: 0.60568120, Training Accuracy: 0.9454\n",
      "Epoch [8274/10000], Validation Loss: 0.93378887, Validation Accuracy: 0.6176\n",
      "Epoch [8275/10000], Training Loss: 0.60606675, Training Accuracy: 0.9454\n",
      "Epoch [8275/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8276/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8276/10000], Validation Loss: 0.90439260, Validation Accuracy: 0.6471\n",
      "Epoch [8277/10000], Training Loss: 0.61860824, Training Accuracy: 0.9328\n",
      "Epoch [8277/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8278/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8278/10000], Validation Loss: 0.88976941, Validation Accuracy: 0.6618\n",
      "Epoch [8279/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8279/10000], Validation Loss: 0.88605541, Validation Accuracy: 0.6618\n",
      "Epoch [8280/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8280/10000], Validation Loss: 0.88944799, Validation Accuracy: 0.6618\n",
      "Epoch [8281/10000], Training Loss: 0.63968023, Training Accuracy: 0.9118\n",
      "Epoch [8281/10000], Validation Loss: 0.87491924, Validation Accuracy: 0.6765\n",
      "Epoch [8282/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8282/10000], Validation Loss: 0.87494701, Validation Accuracy: 0.6765\n",
      "Epoch [8283/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [8283/10000], Validation Loss: 0.87495509, Validation Accuracy: 0.6765\n",
      "Epoch [8284/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8284/10000], Validation Loss: 0.87495825, Validation Accuracy: 0.6765\n",
      "Epoch [8285/10000], Training Loss: 0.61447007, Training Accuracy: 0.9370\n",
      "Epoch [8285/10000], Validation Loss: 0.87495971, Validation Accuracy: 0.6765\n",
      "Epoch [8286/10000], Training Loss: 0.61867126, Training Accuracy: 0.9328\n",
      "Epoch [8286/10000], Validation Loss: 0.87496358, Validation Accuracy: 0.6765\n",
      "Epoch [8287/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8287/10000], Validation Loss: 0.87497094, Validation Accuracy: 0.6765\n",
      "Epoch [8288/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8288/10000], Validation Loss: 0.87497801, Validation Accuracy: 0.6765\n",
      "Epoch [8289/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8289/10000], Validation Loss: 0.87498286, Validation Accuracy: 0.6765\n",
      "Epoch [8290/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [8290/10000], Validation Loss: 0.87498561, Validation Accuracy: 0.6765\n",
      "Epoch [8291/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8291/10000], Validation Loss: 0.87498707, Validation Accuracy: 0.6765\n",
      "Epoch [8292/10000], Training Loss: 0.62058360, Training Accuracy: 0.9286\n",
      "Epoch [8292/10000], Validation Loss: 0.94831252, Validation Accuracy: 0.6029\n",
      "Epoch [8293/10000], Training Loss: 0.60179538, Training Accuracy: 0.9496\n",
      "Epoch [8293/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8294/10000], Training Loss: 0.62358010, Training Accuracy: 0.9286\n",
      "Epoch [8294/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8295/10000], Training Loss: 0.60186449, Training Accuracy: 0.9496\n",
      "Epoch [8295/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8296/10000], Training Loss: 0.58929546, Training Accuracy: 0.9622\n",
      "Epoch [8296/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8297/10000], Training Loss: 0.60591249, Training Accuracy: 0.9454\n",
      "Epoch [8297/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8298/10000], Training Loss: 0.59358619, Training Accuracy: 0.9580\n",
      "Epoch [8298/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8299/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8299/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8300/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8300/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8301/10000], Training Loss: 0.59346328, Training Accuracy: 0.9580\n",
      "Epoch [8301/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8302/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8302/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8303/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [8303/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8304/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8304/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8305/10000], Training Loss: 0.59766373, Training Accuracy: 0.9538\n",
      "Epoch [8305/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8306/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8306/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8307/10000], Training Loss: 0.61026016, Training Accuracy: 0.9412\n",
      "Epoch [8307/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8308/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8308/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8309/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8309/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8310/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8310/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8311/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8311/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8312/10000], Training Loss: 0.59345802, Training Accuracy: 0.9580\n",
      "Epoch [8312/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8313/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8313/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8314/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8314/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8315/10000], Training Loss: 0.60606678, Training Accuracy: 0.9454\n",
      "Epoch [8315/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8316/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8316/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8317/10000], Training Loss: 0.59346318, Training Accuracy: 0.9580\n",
      "Epoch [8317/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8318/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8318/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8319/10000], Training Loss: 0.61857121, Training Accuracy: 0.9328\n",
      "Epoch [8319/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8320/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8320/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8321/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8321/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8322/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8322/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8323/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8323/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8324/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8324/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8325/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8325/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8326/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8326/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8327/10000], Training Loss: 0.60606634, Training Accuracy: 0.9454\n",
      "Epoch [8327/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8328/10000], Training Loss: 0.58505175, Training Accuracy: 0.9664\n",
      "Epoch [8328/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8329/10000], Training Loss: 0.59766370, Training Accuracy: 0.9538\n",
      "Epoch [8329/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8330/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8330/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8331/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8331/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8332/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8332/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8333/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8333/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8334/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [8334/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8335/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [8335/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8336/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8336/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8337/10000], Training Loss: 0.60186355, Training Accuracy: 0.9496\n",
      "Epoch [8337/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8338/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8338/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8339/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8339/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8340/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [8340/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8341/10000], Training Loss: 0.60186568, Training Accuracy: 0.9496\n",
      "Epoch [8341/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8342/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8342/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8343/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8343/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8344/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [8344/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8345/10000], Training Loss: 0.60186533, Training Accuracy: 0.9496\n",
      "Epoch [8345/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8346/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8346/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8347/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8347/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8348/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8348/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8349/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8349/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8350/10000], Training Loss: 0.60392133, Training Accuracy: 0.9454\n",
      "Epoch [8350/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8351/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [8351/10000], Validation Loss: 0.91888046, Validation Accuracy: 0.6324\n",
      "Epoch [8352/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [8352/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8353/10000], Training Loss: 0.59753389, Training Accuracy: 0.9538\n",
      "Epoch [8353/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8354/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8354/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8355/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8355/10000], Validation Loss: 0.90438607, Validation Accuracy: 0.6471\n",
      "Epoch [8356/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8356/10000], Validation Loss: 0.90438563, Validation Accuracy: 0.6471\n",
      "Epoch [8357/10000], Training Loss: 0.62287244, Training Accuracy: 0.9286\n",
      "Epoch [8357/10000], Validation Loss: 0.90438455, Validation Accuracy: 0.6471\n",
      "Epoch [8358/10000], Training Loss: 0.62286365, Training Accuracy: 0.9286\n",
      "Epoch [8358/10000], Validation Loss: 0.90438315, Validation Accuracy: 0.6471\n",
      "Epoch [8359/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [8359/10000], Validation Loss: 0.90438196, Validation Accuracy: 0.6471\n",
      "Epoch [8360/10000], Training Loss: 0.60082896, Training Accuracy: 0.9496\n",
      "Epoch [8360/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8361/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8361/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8362/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8362/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8363/10000], Training Loss: 0.61447924, Training Accuracy: 0.9370\n",
      "Epoch [8363/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8364/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8364/10000], Validation Loss: 0.87496379, Validation Accuracy: 0.6765\n",
      "Epoch [8365/10000], Training Loss: 0.61449981, Training Accuracy: 0.9370\n",
      "Epoch [8365/10000], Validation Loss: 0.87454110, Validation Accuracy: 0.6765\n",
      "Epoch [8366/10000], Training Loss: 0.62707227, Training Accuracy: 0.9244\n",
      "Epoch [8366/10000], Validation Loss: 0.87497410, Validation Accuracy: 0.6765\n",
      "Epoch [8367/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8367/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8368/10000], Training Loss: 0.62707456, Training Accuracy: 0.9244\n",
      "Epoch [8368/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8369/10000], Training Loss: 0.61043864, Training Accuracy: 0.9412\n",
      "Epoch [8369/10000], Validation Loss: 0.87401810, Validation Accuracy: 0.6765\n",
      "Epoch [8370/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8370/10000], Validation Loss: 0.86026713, Validation Accuracy: 0.6912\n",
      "Epoch [8371/10000], Training Loss: 0.61026810, Training Accuracy: 0.9412\n",
      "Epoch [8371/10000], Validation Loss: 0.86026844, Validation Accuracy: 0.6912\n",
      "Epoch [8372/10000], Training Loss: 0.62706753, Training Accuracy: 0.9244\n",
      "Epoch [8372/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8373/10000], Training Loss: 0.61446993, Training Accuracy: 0.9370\n",
      "Epoch [8373/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8374/10000], Training Loss: 0.61444916, Training Accuracy: 0.9370\n",
      "Epoch [8374/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8375/10000], Training Loss: 0.63547832, Training Accuracy: 0.9160\n",
      "Epoch [8375/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8376/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8376/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8377/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [8377/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8378/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [8378/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8379/10000], Training Loss: 0.61867177, Training Accuracy: 0.9328\n",
      "Epoch [8379/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8380/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8380/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8381/10000], Training Loss: 0.61026852, Training Accuracy: 0.9412\n",
      "Epoch [8381/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8382/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8382/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8383/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8383/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8384/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8384/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8385/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8385/10000], Validation Loss: 0.84556258, Validation Accuracy: 0.7059\n",
      "Epoch [8386/10000], Training Loss: 0.62222777, Training Accuracy: 0.9286\n",
      "Epoch [8386/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8387/10000], Training Loss: 0.62707699, Training Accuracy: 0.9244\n",
      "Epoch [8387/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8388/10000], Training Loss: 0.61845085, Training Accuracy: 0.9328\n",
      "Epoch [8388/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8389/10000], Training Loss: 0.63371341, Training Accuracy: 0.9160\n",
      "Epoch [8389/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8390/10000], Training Loss: 0.63547868, Training Accuracy: 0.9160\n",
      "Epoch [8390/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8391/10000], Training Loss: 0.61447013, Training Accuracy: 0.9370\n",
      "Epoch [8391/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8392/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8392/10000], Validation Loss: 0.88967946, Validation Accuracy: 0.6618\n",
      "Epoch [8393/10000], Training Loss: 0.61867343, Training Accuracy: 0.9328\n",
      "Epoch [8393/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8394/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8394/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8395/10000], Training Loss: 0.62416628, Training Accuracy: 0.9286\n",
      "Epoch [8395/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [8396/10000], Training Loss: 0.62692986, Training Accuracy: 0.9244\n",
      "Epoch [8396/10000], Validation Loss: 0.91909194, Validation Accuracy: 0.6324\n",
      "Epoch [8397/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8397/10000], Validation Loss: 0.93379778, Validation Accuracy: 0.6176\n",
      "Epoch [8398/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8398/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [8399/10000], Training Loss: 0.63127553, Training Accuracy: 0.9202\n",
      "Epoch [8399/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [8400/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8400/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [8401/10000], Training Loss: 0.62317240, Training Accuracy: 0.9286\n",
      "Epoch [8401/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8402/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8402/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8403/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8403/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8404/10000], Training Loss: 0.60186481, Training Accuracy: 0.9496\n",
      "Epoch [8404/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8405/10000], Training Loss: 0.60823022, Training Accuracy: 0.9412\n",
      "Epoch [8405/10000], Validation Loss: 0.93379807, Validation Accuracy: 0.6176\n",
      "Epoch [8406/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [8406/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8407/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8407/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8408/10000], Training Loss: 0.58539225, Training Accuracy: 0.9664\n",
      "Epoch [8408/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8409/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8409/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8410/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8410/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8411/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [8411/10000], Validation Loss: 0.87495819, Validation Accuracy: 0.6765\n",
      "Epoch [8412/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8412/10000], Validation Loss: 0.86963493, Validation Accuracy: 0.6765\n",
      "Epoch [8413/10000], Training Loss: 0.61026825, Training Accuracy: 0.9412\n",
      "Epoch [8413/10000], Validation Loss: 0.86135656, Validation Accuracy: 0.6912\n",
      "Epoch [8414/10000], Training Loss: 0.60924601, Training Accuracy: 0.9412\n",
      "Epoch [8414/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8415/10000], Training Loss: 0.61867116, Training Accuracy: 0.9328\n",
      "Epoch [8415/10000], Validation Loss: 0.86069489, Validation Accuracy: 0.6912\n",
      "Epoch [8416/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8416/10000], Validation Loss: 0.87532592, Validation Accuracy: 0.6765\n",
      "Epoch [8417/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8417/10000], Validation Loss: 0.87478679, Validation Accuracy: 0.6765\n",
      "Epoch [8418/10000], Training Loss: 0.63548004, Training Accuracy: 0.9160\n",
      "Epoch [8418/10000], Validation Loss: 0.87496662, Validation Accuracy: 0.6765\n",
      "Epoch [8419/10000], Training Loss: 0.63547838, Training Accuracy: 0.9160\n",
      "Epoch [8419/10000], Validation Loss: 0.87201399, Validation Accuracy: 0.6765\n",
      "Epoch [8420/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8420/10000], Validation Loss: 0.87765589, Validation Accuracy: 0.6765\n",
      "Epoch [8421/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8421/10000], Validation Loss: 0.87688312, Validation Accuracy: 0.6765\n",
      "Epoch [8422/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8422/10000], Validation Loss: 0.87837386, Validation Accuracy: 0.6765\n",
      "Epoch [8423/10000], Training Loss: 0.62707511, Training Accuracy: 0.9244\n",
      "Epoch [8423/10000], Validation Loss: 0.87966874, Validation Accuracy: 0.6765\n",
      "Epoch [8424/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8424/10000], Validation Loss: 0.88036963, Validation Accuracy: 0.6765\n",
      "Epoch [8425/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8425/10000], Validation Loss: 0.88072905, Validation Accuracy: 0.6765\n",
      "Epoch [8426/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8426/10000], Validation Loss: 0.88090324, Validation Accuracy: 0.6765\n",
      "Epoch [8427/10000], Training Loss: 0.63085734, Training Accuracy: 0.9202\n",
      "Epoch [8427/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8428/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [8428/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8429/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [8429/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8430/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [8430/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8431/10000], Training Loss: 0.63422065, Training Accuracy: 0.9160\n",
      "Epoch [8431/10000], Validation Loss: 0.90840280, Validation Accuracy: 0.6324\n",
      "Epoch [8432/10000], Training Loss: 0.61867190, Training Accuracy: 0.9328\n",
      "Epoch [8432/10000], Validation Loss: 0.88647658, Validation Accuracy: 0.6618\n",
      "Epoch [8433/10000], Training Loss: 0.61444982, Training Accuracy: 0.9370\n",
      "Epoch [8433/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8434/10000], Training Loss: 0.61447027, Training Accuracy: 0.9370\n",
      "Epoch [8434/10000], Validation Loss: 0.90390265, Validation Accuracy: 0.6471\n",
      "Epoch [8435/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8435/10000], Validation Loss: 0.90438655, Validation Accuracy: 0.6471\n",
      "Epoch [8436/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8436/10000], Validation Loss: 0.90452662, Validation Accuracy: 0.6471\n",
      "Epoch [8437/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8437/10000], Validation Loss: 0.90644830, Validation Accuracy: 0.6471\n",
      "Epoch [8438/10000], Training Loss: 0.61263902, Training Accuracy: 0.9370\n",
      "Epoch [8438/10000], Validation Loss: 0.90439287, Validation Accuracy: 0.6471\n",
      "Epoch [8439/10000], Training Loss: 0.60186475, Training Accuracy: 0.9496\n",
      "Epoch [8439/10000], Validation Loss: 0.93377778, Validation Accuracy: 0.6176\n",
      "Epoch [8440/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8440/10000], Validation Loss: 0.91909182, Validation Accuracy: 0.6324\n",
      "Epoch [8441/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8441/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8442/10000], Training Loss: 0.62287350, Training Accuracy: 0.9286\n",
      "Epoch [8442/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8443/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8443/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8444/10000], Training Loss: 0.60606297, Training Accuracy: 0.9454\n",
      "Epoch [8444/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8445/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [8445/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8446/10000], Training Loss: 0.61028853, Training Accuracy: 0.9412\n",
      "Epoch [8446/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8447/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8447/10000], Validation Loss: 0.88974655, Validation Accuracy: 0.6618\n",
      "Epoch [8448/10000], Training Loss: 0.62707524, Training Accuracy: 0.9244\n",
      "Epoch [8448/10000], Validation Loss: 0.87431714, Validation Accuracy: 0.6765\n",
      "Epoch [8449/10000], Training Loss: 0.64808146, Training Accuracy: 0.9034\n",
      "Epoch [8449/10000], Validation Loss: 0.87496442, Validation Accuracy: 0.6765\n",
      "Epoch [8450/10000], Training Loss: 0.64640148, Training Accuracy: 0.9034\n",
      "Epoch [8450/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8451/10000], Training Loss: 0.66487627, Training Accuracy: 0.8866\n",
      "Epoch [8451/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8452/10000], Training Loss: 0.68589874, Training Accuracy: 0.8655\n",
      "Epoch [8452/10000], Validation Loss: 0.87497672, Validation Accuracy: 0.6765\n",
      "Epoch [8453/10000], Training Loss: 0.70690711, Training Accuracy: 0.8445\n",
      "Epoch [8453/10000], Validation Loss: 0.88961381, Validation Accuracy: 0.6618\n",
      "Epoch [8454/10000], Training Loss: 0.71548314, Training Accuracy: 0.8361\n",
      "Epoch [8454/10000], Validation Loss: 0.88283634, Validation Accuracy: 0.6618\n",
      "Epoch [8455/10000], Training Loss: 0.71108907, Training Accuracy: 0.8403\n",
      "Epoch [8455/10000], Validation Loss: 0.87500098, Validation Accuracy: 0.6765\n",
      "Epoch [8456/10000], Training Loss: 0.69432176, Training Accuracy: 0.8571\n",
      "Epoch [8456/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8457/10000], Training Loss: 0.71111116, Training Accuracy: 0.8403\n",
      "Epoch [8457/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8458/10000], Training Loss: 0.69850376, Training Accuracy: 0.8529\n",
      "Epoch [8458/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8459/10000], Training Loss: 0.68641732, Training Accuracy: 0.8655\n",
      "Epoch [8459/10000], Validation Loss: 0.87521493, Validation Accuracy: 0.6765\n",
      "Epoch [8460/10000], Training Loss: 0.67749531, Training Accuracy: 0.8739\n",
      "Epoch [8460/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8461/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [8461/10000], Validation Loss: 0.88788658, Validation Accuracy: 0.6618\n",
      "Epoch [8462/10000], Training Loss: 0.66909602, Training Accuracy: 0.8824\n",
      "Epoch [8462/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8463/10000], Training Loss: 0.63584283, Training Accuracy: 0.9160\n",
      "Epoch [8463/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8464/10000], Training Loss: 0.66429332, Training Accuracy: 0.8866\n",
      "Epoch [8464/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8465/10000], Training Loss: 0.67749536, Training Accuracy: 0.8739\n",
      "Epoch [8465/10000], Validation Loss: 0.90438581, Validation Accuracy: 0.6471\n",
      "Epoch [8466/10000], Training Loss: 0.64836050, Training Accuracy: 0.9034\n",
      "Epoch [8466/10000], Validation Loss: 0.90168020, Validation Accuracy: 0.6471\n",
      "Epoch [8467/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8467/10000], Validation Loss: 0.90438527, Validation Accuracy: 0.6471\n",
      "Epoch [8468/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [8468/10000], Validation Loss: 0.90438607, Validation Accuracy: 0.6471\n",
      "Epoch [8469/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [8469/10000], Validation Loss: 0.90438607, Validation Accuracy: 0.6471\n",
      "Epoch [8470/10000], Training Loss: 0.63968045, Training Accuracy: 0.9118\n",
      "Epoch [8470/10000], Validation Loss: 0.90438637, Validation Accuracy: 0.6471\n",
      "Epoch [8471/10000], Training Loss: 0.64823530, Training Accuracy: 0.9034\n",
      "Epoch [8471/10000], Validation Loss: 0.91909182, Validation Accuracy: 0.6324\n",
      "Epoch [8472/10000], Training Loss: 0.64334454, Training Accuracy: 0.9076\n",
      "Epoch [8472/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8473/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [8473/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8474/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [8474/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8475/10000], Training Loss: 0.65645533, Training Accuracy: 0.8950\n",
      "Epoch [8475/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8476/10000], Training Loss: 0.63968394, Training Accuracy: 0.9118\n",
      "Epoch [8476/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8477/10000], Training Loss: 0.65654976, Training Accuracy: 0.8950\n",
      "Epoch [8477/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8478/10000], Training Loss: 0.66450369, Training Accuracy: 0.8866\n",
      "Epoch [8478/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8479/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [8479/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8480/10000], Training Loss: 0.69849038, Training Accuracy: 0.8529\n",
      "Epoch [8480/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8481/10000], Training Loss: 0.68164422, Training Accuracy: 0.8697\n",
      "Epoch [8481/10000], Validation Loss: 0.90438625, Validation Accuracy: 0.6471\n",
      "Epoch [8482/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [8482/10000], Validation Loss: 0.90438616, Validation Accuracy: 0.6471\n",
      "Epoch [8483/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [8483/10000], Validation Loss: 0.90438634, Validation Accuracy: 0.6471\n",
      "Epoch [8484/10000], Training Loss: 0.65614539, Training Accuracy: 0.8950\n",
      "Epoch [8484/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8485/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [8485/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8486/10000], Training Loss: 0.65648698, Training Accuracy: 0.8950\n",
      "Epoch [8486/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8487/10000], Training Loss: 0.66489033, Training Accuracy: 0.8866\n",
      "Epoch [8487/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8488/10000], Training Loss: 0.64409735, Training Accuracy: 0.9076\n",
      "Epoch [8488/10000], Validation Loss: 0.90438876, Validation Accuracy: 0.6471\n",
      "Epoch [8489/10000], Training Loss: 0.63970588, Training Accuracy: 0.9118\n",
      "Epoch [8489/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8490/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8490/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8491/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [8491/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8492/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [8492/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8493/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [8493/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8494/10000], Training Loss: 0.64809346, Training Accuracy: 0.9034\n",
      "Epoch [8494/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8495/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8495/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8496/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8496/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8497/10000], Training Loss: 0.64388194, Training Accuracy: 0.9076\n",
      "Epoch [8497/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8498/10000], Training Loss: 0.64388215, Training Accuracy: 0.9076\n",
      "Epoch [8498/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8499/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [8499/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8500/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8500/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8501/10000], Training Loss: 0.63547859, Training Accuracy: 0.9160\n",
      "Epoch [8501/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8502/10000], Training Loss: 0.62707471, Training Accuracy: 0.9244\n",
      "Epoch [8502/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8503/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8503/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8504/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [8504/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8505/10000], Training Loss: 0.64078052, Training Accuracy: 0.9076\n",
      "Epoch [8505/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8506/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8506/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8507/10000], Training Loss: 0.63548393, Training Accuracy: 0.9160\n",
      "Epoch [8507/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8508/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8508/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8509/10000], Training Loss: 0.64808363, Training Accuracy: 0.9034\n",
      "Epoch [8509/10000], Validation Loss: 0.91908982, Validation Accuracy: 0.6324\n",
      "Epoch [8510/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8510/10000], Validation Loss: 0.91905019, Validation Accuracy: 0.6324\n",
      "Epoch [8511/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [8511/10000], Validation Loss: 0.91892225, Validation Accuracy: 0.6324\n",
      "Epoch [8512/10000], Training Loss: 0.65831250, Training Accuracy: 0.8908\n",
      "Epoch [8512/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8513/10000], Training Loss: 0.64808360, Training Accuracy: 0.9034\n",
      "Epoch [8513/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8514/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [8514/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8515/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8515/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8516/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [8516/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8517/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8517/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8518/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [8518/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8519/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8519/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8520/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [8520/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8521/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [8521/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8522/10000], Training Loss: 0.62707549, Training Accuracy: 0.9244\n",
      "Epoch [8522/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8523/10000], Training Loss: 0.63547732, Training Accuracy: 0.9160\n",
      "Epoch [8523/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8524/10000], Training Loss: 0.63547849, Training Accuracy: 0.9160\n",
      "Epoch [8524/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8525/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [8525/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8526/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8526/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8527/10000], Training Loss: 0.62304046, Training Accuracy: 0.9286\n",
      "Epoch [8527/10000], Validation Loss: 0.90438616, Validation Accuracy: 0.6471\n",
      "Epoch [8528/10000], Training Loss: 0.63238270, Training Accuracy: 0.9202\n",
      "Epoch [8528/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8529/10000], Training Loss: 0.61460297, Training Accuracy: 0.9370\n",
      "Epoch [8529/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8530/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8530/10000], Validation Loss: 0.87497410, Validation Accuracy: 0.6765\n",
      "Epoch [8531/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8531/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8532/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8532/10000], Validation Loss: 0.87497386, Validation Accuracy: 0.6765\n",
      "Epoch [8533/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8533/10000], Validation Loss: 0.87498903, Validation Accuracy: 0.6765\n",
      "Epoch [8534/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8534/10000], Validation Loss: 0.88861039, Validation Accuracy: 0.6618\n",
      "Epoch [8535/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8535/10000], Validation Loss: 0.88935760, Validation Accuracy: 0.6618\n",
      "Epoch [8536/10000], Training Loss: 0.63290449, Training Accuracy: 0.9202\n",
      "Epoch [8536/10000], Validation Loss: 0.88128024, Validation Accuracy: 0.6618\n",
      "Epoch [8537/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8537/10000], Validation Loss: 0.88959387, Validation Accuracy: 0.6618\n",
      "Epoch [8538/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8538/10000], Validation Loss: 0.88848096, Validation Accuracy: 0.6618\n",
      "Epoch [8539/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8539/10000], Validation Loss: 0.88967991, Validation Accuracy: 0.6618\n",
      "Epoch [8540/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8540/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8541/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8541/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8542/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8542/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8543/10000], Training Loss: 0.61447182, Training Accuracy: 0.9370\n",
      "Epoch [8543/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8544/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8544/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8545/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8545/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8546/10000], Training Loss: 0.59766729, Training Accuracy: 0.9538\n",
      "Epoch [8546/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8547/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8547/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8548/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [8548/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8549/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8549/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8550/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8550/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8551/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8551/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8552/10000], Training Loss: 0.61294358, Training Accuracy: 0.9370\n",
      "Epoch [8552/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8553/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8553/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8554/10000], Training Loss: 0.60961073, Training Accuracy: 0.9412\n",
      "Epoch [8554/10000], Validation Loss: 0.88966689, Validation Accuracy: 0.6618\n",
      "Epoch [8555/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [8555/10000], Validation Loss: 0.89413559, Validation Accuracy: 0.6618\n",
      "Epoch [8556/10000], Training Loss: 0.61446977, Training Accuracy: 0.9370\n",
      "Epoch [8556/10000], Validation Loss: 0.91900894, Validation Accuracy: 0.6324\n",
      "Epoch [8557/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8557/10000], Validation Loss: 0.91908783, Validation Accuracy: 0.6324\n",
      "Epoch [8558/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8558/10000], Validation Loss: 0.91909102, Validation Accuracy: 0.6324\n",
      "Epoch [8559/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8559/10000], Validation Loss: 0.91909149, Validation Accuracy: 0.6324\n",
      "Epoch [8560/10000], Training Loss: 0.61450799, Training Accuracy: 0.9370\n",
      "Epoch [8560/10000], Validation Loss: 0.91909054, Validation Accuracy: 0.6324\n",
      "Epoch [8561/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8561/10000], Validation Loss: 0.91840431, Validation Accuracy: 0.6324\n",
      "Epoch [8562/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8562/10000], Validation Loss: 0.91181490, Validation Accuracy: 0.6324\n",
      "Epoch [8563/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8563/10000], Validation Loss: 0.90722340, Validation Accuracy: 0.6471\n",
      "Epoch [8564/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8564/10000], Validation Loss: 0.90596399, Validation Accuracy: 0.6471\n",
      "Epoch [8565/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8565/10000], Validation Loss: 0.90555865, Validation Accuracy: 0.6471\n",
      "Epoch [8566/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8566/10000], Validation Loss: 0.90540051, Validation Accuracy: 0.6471\n",
      "Epoch [8567/10000], Training Loss: 0.60186919, Training Accuracy: 0.9496\n",
      "Epoch [8567/10000], Validation Loss: 0.90528435, Validation Accuracy: 0.6471\n",
      "Epoch [8568/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8568/10000], Validation Loss: 0.90521076, Validation Accuracy: 0.6471\n",
      "Epoch [8569/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8569/10000], Validation Loss: 0.90517756, Validation Accuracy: 0.6471\n",
      "Epoch [8570/10000], Training Loss: 0.61026880, Training Accuracy: 0.9412\n",
      "Epoch [8570/10000], Validation Loss: 0.90515971, Validation Accuracy: 0.6471\n",
      "Epoch [8571/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8571/10000], Validation Loss: 0.90514907, Validation Accuracy: 0.6471\n",
      "Epoch [8572/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8572/10000], Validation Loss: 0.90514413, Validation Accuracy: 0.6471\n",
      "Epoch [8573/10000], Training Loss: 0.61026910, Training Accuracy: 0.9412\n",
      "Epoch [8573/10000], Validation Loss: 0.90513021, Validation Accuracy: 0.6471\n",
      "Epoch [8574/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8574/10000], Validation Loss: 0.90512371, Validation Accuracy: 0.6471\n",
      "Epoch [8575/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8575/10000], Validation Loss: 0.90512061, Validation Accuracy: 0.6471\n",
      "Epoch [8576/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8576/10000], Validation Loss: 0.90511912, Validation Accuracy: 0.6471\n",
      "Epoch [8577/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8577/10000], Validation Loss: 0.90511829, Validation Accuracy: 0.6471\n",
      "Epoch [8578/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8578/10000], Validation Loss: 0.90511796, Validation Accuracy: 0.6471\n",
      "Epoch [8579/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8579/10000], Validation Loss: 0.90511790, Validation Accuracy: 0.6471\n",
      "Epoch [8580/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8580/10000], Validation Loss: 0.90511787, Validation Accuracy: 0.6471\n",
      "Epoch [8581/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8581/10000], Validation Loss: 0.90511787, Validation Accuracy: 0.6471\n",
      "Epoch [8582/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8582/10000], Validation Loss: 0.90511787, Validation Accuracy: 0.6471\n",
      "Epoch [8583/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8583/10000], Validation Loss: 0.90511787, Validation Accuracy: 0.6471\n",
      "Epoch [8584/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8584/10000], Validation Loss: 0.90511787, Validation Accuracy: 0.6471\n",
      "Epoch [8585/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8585/10000], Validation Loss: 0.90511787, Validation Accuracy: 0.6471\n",
      "Epoch [8586/10000], Training Loss: 0.61446932, Training Accuracy: 0.9370\n",
      "Epoch [8586/10000], Validation Loss: 0.90533048, Validation Accuracy: 0.6471\n",
      "Epoch [8587/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8587/10000], Validation Loss: 0.90552849, Validation Accuracy: 0.6471\n",
      "Epoch [8588/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8588/10000], Validation Loss: 0.90563676, Validation Accuracy: 0.6471\n",
      "Epoch [8589/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8589/10000], Validation Loss: 0.90569201, Validation Accuracy: 0.6471\n",
      "Epoch [8590/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8590/10000], Validation Loss: 0.90571910, Validation Accuracy: 0.6471\n",
      "Epoch [8591/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8591/10000], Validation Loss: 0.90573224, Validation Accuracy: 0.6471\n",
      "Epoch [8592/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8592/10000], Validation Loss: 0.90573815, Validation Accuracy: 0.6471\n",
      "Epoch [8593/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8593/10000], Validation Loss: 0.90574065, Validation Accuracy: 0.6471\n",
      "Epoch [8594/10000], Training Loss: 0.60186563, Training Accuracy: 0.9496\n",
      "Epoch [8594/10000], Validation Loss: 0.90602902, Validation Accuracy: 0.6471\n",
      "Epoch [8595/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8595/10000], Validation Loss: 0.90636986, Validation Accuracy: 0.6471\n",
      "Epoch [8596/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8596/10000], Validation Loss: 0.90655422, Validation Accuracy: 0.6471\n",
      "Epoch [8597/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8597/10000], Validation Loss: 0.90664765, Validation Accuracy: 0.6471\n",
      "Epoch [8598/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8598/10000], Validation Loss: 0.90669379, Validation Accuracy: 0.6471\n",
      "Epoch [8599/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8599/10000], Validation Loss: 0.90671620, Validation Accuracy: 0.6471\n",
      "Epoch [8600/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8600/10000], Validation Loss: 0.90672675, Validation Accuracy: 0.6471\n",
      "Epoch [8601/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8601/10000], Validation Loss: 0.90673077, Validation Accuracy: 0.6471\n",
      "Epoch [8602/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8602/10000], Validation Loss: 0.90673241, Validation Accuracy: 0.6471\n",
      "Epoch [8603/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8603/10000], Validation Loss: 0.90673313, Validation Accuracy: 0.6471\n",
      "Epoch [8604/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [8604/10000], Validation Loss: 0.90673327, Validation Accuracy: 0.6471\n",
      "Epoch [8605/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8605/10000], Validation Loss: 0.90673280, Validation Accuracy: 0.6471\n",
      "Epoch [8606/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8606/10000], Validation Loss: 0.90673235, Validation Accuracy: 0.6471\n",
      "Epoch [8607/10000], Training Loss: 0.60188501, Training Accuracy: 0.9496\n",
      "Epoch [8607/10000], Validation Loss: 0.91113016, Validation Accuracy: 0.6324\n",
      "Epoch [8608/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8608/10000], Validation Loss: 0.91907531, Validation Accuracy: 0.6324\n",
      "Epoch [8609/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8609/10000], Validation Loss: 0.91909143, Validation Accuracy: 0.6324\n",
      "Epoch [8610/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8610/10000], Validation Loss: 0.91909191, Validation Accuracy: 0.6324\n",
      "Epoch [8611/10000], Training Loss: 0.60606682, Training Accuracy: 0.9454\n",
      "Epoch [8611/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8612/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8612/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8613/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8613/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8614/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8614/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8615/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8615/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8616/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8616/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8617/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8617/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8618/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [8618/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8619/10000], Training Loss: 0.61867426, Training Accuracy: 0.9328\n",
      "Epoch [8619/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8620/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8620/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8621/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8621/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8622/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8622/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8623/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8623/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8624/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8624/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8625/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8625/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8626/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8626/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8627/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8627/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8628/10000], Training Loss: 0.60610725, Training Accuracy: 0.9454\n",
      "Epoch [8628/10000], Validation Loss: 0.91880170, Validation Accuracy: 0.6324\n",
      "Epoch [8629/10000], Training Loss: 0.61491781, Training Accuracy: 0.9370\n",
      "Epoch [8629/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8630/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8630/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8631/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8631/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8632/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8632/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8633/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8633/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8634/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8634/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8635/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [8635/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8636/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8636/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8637/10000], Training Loss: 0.62284609, Training Accuracy: 0.9286\n",
      "Epoch [8637/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8638/10000], Training Loss: 0.62707498, Training Accuracy: 0.9244\n",
      "Epoch [8638/10000], Validation Loss: 0.93379864, Validation Accuracy: 0.6176\n",
      "Epoch [8639/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8639/10000], Validation Loss: 0.93381733, Validation Accuracy: 0.6176\n",
      "Epoch [8640/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8640/10000], Validation Loss: 0.93389621, Validation Accuracy: 0.6176\n",
      "Epoch [8641/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [8641/10000], Validation Loss: 0.93401283, Validation Accuracy: 0.6176\n",
      "Epoch [8642/10000], Training Loss: 0.62287033, Training Accuracy: 0.9286\n",
      "Epoch [8642/10000], Validation Loss: 0.93403843, Validation Accuracy: 0.6176\n",
      "Epoch [8643/10000], Training Loss: 0.61865700, Training Accuracy: 0.9328\n",
      "Epoch [8643/10000], Validation Loss: 0.93379799, Validation Accuracy: 0.6176\n",
      "Epoch [8644/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [8644/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8645/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [8645/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8646/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8646/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8647/10000], Training Loss: 0.61867109, Training Accuracy: 0.9328\n",
      "Epoch [8647/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8648/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8648/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8649/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8649/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8650/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8650/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8651/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8651/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8652/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8652/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8653/10000], Training Loss: 0.62713367, Training Accuracy: 0.9244\n",
      "Epoch [8653/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8654/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8654/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8655/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8655/10000], Validation Loss: 0.94845074, Validation Accuracy: 0.6029\n",
      "Epoch [8656/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8656/10000], Validation Loss: 0.94406372, Validation Accuracy: 0.6029\n",
      "Epoch [8657/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8657/10000], Validation Loss: 0.93666232, Validation Accuracy: 0.6176\n",
      "Epoch [8658/10000], Training Loss: 0.64388176, Training Accuracy: 0.9076\n",
      "Epoch [8658/10000], Validation Loss: 0.93486795, Validation Accuracy: 0.6176\n",
      "Epoch [8659/10000], Training Loss: 0.62243433, Training Accuracy: 0.9286\n",
      "Epoch [8659/10000], Validation Loss: 0.93379563, Validation Accuracy: 0.6176\n",
      "Epoch [8660/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8660/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8661/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8661/10000], Validation Loss: 0.91872671, Validation Accuracy: 0.6324\n",
      "Epoch [8662/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8662/10000], Validation Loss: 0.90438616, Validation Accuracy: 0.6471\n",
      "Epoch [8663/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8663/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8664/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8664/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8665/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8665/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8666/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8666/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8667/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8667/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8668/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8668/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8669/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8669/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8670/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8670/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8671/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8671/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8672/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8672/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8673/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [8673/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8674/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [8674/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8675/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8675/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8676/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8676/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8677/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [8677/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8678/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8678/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8679/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8679/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8680/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8680/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8681/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8681/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8682/10000], Training Loss: 0.61446624, Training Accuracy: 0.9370\n",
      "Epoch [8682/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8683/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8683/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8684/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8684/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8685/10000], Training Loss: 0.61866833, Training Accuracy: 0.9328\n",
      "Epoch [8685/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8686/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8686/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8687/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8687/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8688/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8688/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8689/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8689/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8690/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8690/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8691/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8691/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8692/10000], Training Loss: 0.61026841, Training Accuracy: 0.9412\n",
      "Epoch [8692/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8693/10000], Training Loss: 0.61865348, Training Accuracy: 0.9328\n",
      "Epoch [8693/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8694/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8694/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8695/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8695/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8696/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8696/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8697/10000], Training Loss: 0.60635260, Training Accuracy: 0.9454\n",
      "Epoch [8697/10000], Validation Loss: 0.90440828, Validation Accuracy: 0.6471\n",
      "Epoch [8698/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8698/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8699/10000], Training Loss: 0.61867181, Training Accuracy: 0.9328\n",
      "Epoch [8699/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8700/10000], Training Loss: 0.61896414, Training Accuracy: 0.9328\n",
      "Epoch [8700/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8701/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8701/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8702/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8702/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8703/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8703/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8704/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [8704/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8705/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8705/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8706/10000], Training Loss: 0.61867166, Training Accuracy: 0.9328\n",
      "Epoch [8706/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8707/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8707/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8708/10000], Training Loss: 0.62260987, Training Accuracy: 0.9286\n",
      "Epoch [8708/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8709/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8709/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8710/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8710/10000], Validation Loss: 0.86026856, Validation Accuracy: 0.6912\n",
      "Epoch [8711/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8711/10000], Validation Loss: 0.87496674, Validation Accuracy: 0.6765\n",
      "Epoch [8712/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8712/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8713/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8713/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8714/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8714/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8715/10000], Training Loss: 0.63279291, Training Accuracy: 0.9202\n",
      "Epoch [8715/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8716/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8716/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8717/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8717/10000], Validation Loss: 0.88967744, Validation Accuracy: 0.6618\n",
      "Epoch [8718/10000], Training Loss: 0.61026846, Training Accuracy: 0.9412\n",
      "Epoch [8718/10000], Validation Loss: 0.90310881, Validation Accuracy: 0.6471\n",
      "Epoch [8719/10000], Training Loss: 0.62709730, Training Accuracy: 0.9244\n",
      "Epoch [8719/10000], Validation Loss: 0.93043196, Validation Accuracy: 0.6176\n",
      "Epoch [8720/10000], Training Loss: 0.61866856, Training Accuracy: 0.9328\n",
      "Epoch [8720/10000], Validation Loss: 0.93012175, Validation Accuracy: 0.6176\n",
      "Epoch [8721/10000], Training Loss: 0.61447255, Training Accuracy: 0.9370\n",
      "Epoch [8721/10000], Validation Loss: 0.92818871, Validation Accuracy: 0.6176\n",
      "Epoch [8722/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8722/10000], Validation Loss: 0.92971188, Validation Accuracy: 0.6176\n",
      "Epoch [8723/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8723/10000], Validation Loss: 0.93034074, Validation Accuracy: 0.6176\n",
      "Epoch [8724/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8724/10000], Validation Loss: 0.93061674, Validation Accuracy: 0.6176\n",
      "Epoch [8725/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8725/10000], Validation Loss: 0.93074352, Validation Accuracy: 0.6176\n",
      "Epoch [8726/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8726/10000], Validation Loss: 0.93080255, Validation Accuracy: 0.6176\n",
      "Epoch [8727/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8727/10000], Validation Loss: 0.93083078, Validation Accuracy: 0.6176\n",
      "Epoch [8728/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8728/10000], Validation Loss: 0.93084434, Validation Accuracy: 0.6176\n",
      "Epoch [8729/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8729/10000], Validation Loss: 0.93085089, Validation Accuracy: 0.6176\n",
      "Epoch [8730/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8730/10000], Validation Loss: 0.93085352, Validation Accuracy: 0.6176\n",
      "Epoch [8731/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8731/10000], Validation Loss: 0.93085399, Validation Accuracy: 0.6176\n",
      "Epoch [8732/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8732/10000], Validation Loss: 0.93085426, Validation Accuracy: 0.6176\n",
      "Epoch [8733/10000], Training Loss: 0.63547686, Training Accuracy: 0.9160\n",
      "Epoch [8733/10000], Validation Loss: 0.92979437, Validation Accuracy: 0.6176\n",
      "Epoch [8734/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8734/10000], Validation Loss: 0.92920464, Validation Accuracy: 0.6176\n",
      "Epoch [8735/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8735/10000], Validation Loss: 0.92890450, Validation Accuracy: 0.6176\n",
      "Epoch [8736/10000], Training Loss: 0.61867302, Training Accuracy: 0.9328\n",
      "Epoch [8736/10000], Validation Loss: 0.92848593, Validation Accuracy: 0.6176\n",
      "Epoch [8737/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8737/10000], Validation Loss: 0.92706418, Validation Accuracy: 0.6176\n",
      "Epoch [8738/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8738/10000], Validation Loss: 0.92635420, Validation Accuracy: 0.6176\n",
      "Epoch [8739/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8739/10000], Validation Loss: 0.92601278, Validation Accuracy: 0.6176\n",
      "Epoch [8740/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8740/10000], Validation Loss: 0.92584980, Validation Accuracy: 0.6176\n",
      "Epoch [8741/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8741/10000], Validation Loss: 0.92577222, Validation Accuracy: 0.6176\n",
      "Epoch [8742/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8742/10000], Validation Loss: 0.92573577, Validation Accuracy: 0.6176\n",
      "Epoch [8743/10000], Training Loss: 0.62287390, Training Accuracy: 0.9286\n",
      "Epoch [8743/10000], Validation Loss: 0.92574236, Validation Accuracy: 0.6176\n",
      "Epoch [8744/10000], Training Loss: 0.61056191, Training Accuracy: 0.9412\n",
      "Epoch [8744/10000], Validation Loss: 0.91894770, Validation Accuracy: 0.6324\n",
      "Epoch [8745/10000], Training Loss: 0.62287343, Training Accuracy: 0.9286\n",
      "Epoch [8745/10000], Validation Loss: 0.91927040, Validation Accuracy: 0.6324\n",
      "Epoch [8746/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8746/10000], Validation Loss: 0.91909117, Validation Accuracy: 0.6324\n",
      "Epoch [8747/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8747/10000], Validation Loss: 0.91909161, Validation Accuracy: 0.6324\n",
      "Epoch [8748/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8748/10000], Validation Loss: 0.91909176, Validation Accuracy: 0.6324\n",
      "Epoch [8749/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8749/10000], Validation Loss: 0.91909179, Validation Accuracy: 0.6324\n",
      "Epoch [8750/10000], Training Loss: 0.62291267, Training Accuracy: 0.9286\n",
      "Epoch [8750/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8751/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8751/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8752/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8752/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8753/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8753/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8754/10000], Training Loss: 0.61446015, Training Accuracy: 0.9370\n",
      "Epoch [8754/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8755/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [8755/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8756/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [8756/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8757/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8757/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8758/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8758/10000], Validation Loss: 0.90443674, Validation Accuracy: 0.6471\n",
      "Epoch [8759/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8759/10000], Validation Loss: 0.91909173, Validation Accuracy: 0.6324\n",
      "Epoch [8760/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8760/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8761/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8761/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8762/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8762/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8763/10000], Training Loss: 0.61859946, Training Accuracy: 0.9328\n",
      "Epoch [8763/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8764/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8764/10000], Validation Loss: 0.92955035, Validation Accuracy: 0.6176\n",
      "Epoch [8765/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [8765/10000], Validation Loss: 0.93379402, Validation Accuracy: 0.6176\n",
      "Epoch [8766/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8766/10000], Validation Loss: 0.93377066, Validation Accuracy: 0.6176\n",
      "Epoch [8767/10000], Training Loss: 0.62245630, Training Accuracy: 0.9286\n",
      "Epoch [8767/10000], Validation Loss: 0.93374032, Validation Accuracy: 0.6176\n",
      "Epoch [8768/10000], Training Loss: 0.61446981, Training Accuracy: 0.9370\n",
      "Epoch [8768/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8769/10000], Training Loss: 0.61867191, Training Accuracy: 0.9328\n",
      "Epoch [8769/10000], Validation Loss: 0.88985193, Validation Accuracy: 0.6618\n",
      "Epoch [8770/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8770/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8771/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [8771/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8772/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8772/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8773/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8773/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8774/10000], Training Loss: 0.61452954, Training Accuracy: 0.9370\n",
      "Epoch [8774/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8775/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8775/10000], Validation Loss: 0.87500858, Validation Accuracy: 0.6765\n",
      "Epoch [8776/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8776/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8777/10000], Training Loss: 0.61867171, Training Accuracy: 0.9328\n",
      "Epoch [8777/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8778/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8778/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8779/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8779/10000], Validation Loss: 0.86026847, Validation Accuracy: 0.6912\n",
      "Epoch [8780/10000], Training Loss: 0.60205177, Training Accuracy: 0.9496\n",
      "Epoch [8780/10000], Validation Loss: 0.88968042, Validation Accuracy: 0.6618\n",
      "Epoch [8781/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8781/10000], Validation Loss: 0.90817419, Validation Accuracy: 0.6471\n",
      "Epoch [8782/10000], Training Loss: 0.60187023, Training Accuracy: 0.9496\n",
      "Epoch [8782/10000], Validation Loss: 0.91909191, Validation Accuracy: 0.6324\n",
      "Epoch [8783/10000], Training Loss: 0.62622809, Training Accuracy: 0.9244\n",
      "Epoch [8783/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8784/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8784/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8785/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8785/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8786/10000], Training Loss: 0.61867189, Training Accuracy: 0.9328\n",
      "Epoch [8786/10000], Validation Loss: 0.90438533, Validation Accuracy: 0.6471\n",
      "Epoch [8787/10000], Training Loss: 0.61866838, Training Accuracy: 0.9328\n",
      "Epoch [8787/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8788/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8788/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8789/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8789/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8790/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [8790/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8791/10000], Training Loss: 0.60611249, Training Accuracy: 0.9454\n",
      "Epoch [8791/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8792/10000], Training Loss: 0.60606667, Training Accuracy: 0.9454\n",
      "Epoch [8792/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8793/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8793/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8794/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8794/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8795/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8795/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8796/10000], Training Loss: 0.62707508, Training Accuracy: 0.9244\n",
      "Epoch [8796/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8797/10000], Training Loss: 0.61446972, Training Accuracy: 0.9370\n",
      "Epoch [8797/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8798/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8798/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8799/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8799/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8800/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8800/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8801/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8801/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8802/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8802/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8803/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8803/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8804/10000], Training Loss: 0.60606617, Training Accuracy: 0.9454\n",
      "Epoch [8804/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8805/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8805/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8806/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8806/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8807/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8807/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8808/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8808/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8809/10000], Training Loss: 0.61439019, Training Accuracy: 0.9370\n",
      "Epoch [8809/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8810/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8810/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8811/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8811/10000], Validation Loss: 0.91953012, Validation Accuracy: 0.6324\n",
      "Epoch [8812/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8812/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8813/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8813/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8814/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8814/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8815/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8815/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8816/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8816/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8817/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [8817/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8818/10000], Training Loss: 0.61028821, Training Accuracy: 0.9412\n",
      "Epoch [8818/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8819/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8819/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8820/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8820/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8821/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8821/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8822/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8822/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8823/10000], Training Loss: 0.60606654, Training Accuracy: 0.9454\n",
      "Epoch [8823/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8824/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8824/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8825/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8825/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8826/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8826/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8827/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8827/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8828/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8828/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8829/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8829/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8830/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8830/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8831/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8831/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8832/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8832/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8833/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [8833/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8834/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8834/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8835/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8835/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8836/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [8836/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8837/10000], Training Loss: 0.62178258, Training Accuracy: 0.9286\n",
      "Epoch [8837/10000], Validation Loss: 0.93370557, Validation Accuracy: 0.6176\n",
      "Epoch [8838/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8838/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8839/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8839/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8840/10000], Training Loss: 0.60390524, Training Accuracy: 0.9454\n",
      "Epoch [8840/10000], Validation Loss: 0.90430054, Validation Accuracy: 0.6471\n",
      "Epoch [8841/10000], Training Loss: 0.63155691, Training Accuracy: 0.9202\n",
      "Epoch [8841/10000], Validation Loss: 0.94850361, Validation Accuracy: 0.6029\n",
      "Epoch [8842/10000], Training Loss: 0.63547855, Training Accuracy: 0.9160\n",
      "Epoch [8842/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8843/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8843/10000], Validation Loss: 0.95387316, Validation Accuracy: 0.6029\n",
      "Epoch [8844/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8844/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8845/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8845/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8846/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8846/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8847/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8847/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8848/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8848/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8849/10000], Training Loss: 0.61027362, Training Accuracy: 0.9412\n",
      "Epoch [8849/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8850/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [8850/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8851/10000], Training Loss: 0.61431017, Training Accuracy: 0.9370\n",
      "Epoch [8851/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8852/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8852/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8853/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8853/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8854/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8854/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8855/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8855/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8856/10000], Training Loss: 0.62178809, Training Accuracy: 0.9286\n",
      "Epoch [8856/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8857/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8857/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8858/10000], Training Loss: 0.60606694, Training Accuracy: 0.9454\n",
      "Epoch [8858/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8859/10000], Training Loss: 0.62986307, Training Accuracy: 0.9202\n",
      "Epoch [8859/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8860/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [8860/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8861/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8861/10000], Validation Loss: 0.94850618, Validation Accuracy: 0.6029\n",
      "Epoch [8862/10000], Training Loss: 0.61871724, Training Accuracy: 0.9328\n",
      "Epoch [8862/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8863/10000], Training Loss: 0.62707531, Training Accuracy: 0.9244\n",
      "Epoch [8863/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8864/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8864/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8865/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8865/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8866/10000], Training Loss: 0.61867121, Training Accuracy: 0.9328\n",
      "Epoch [8866/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8867/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8867/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8868/10000], Training Loss: 0.62701243, Training Accuracy: 0.9244\n",
      "Epoch [8868/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8869/10000], Training Loss: 0.61442619, Training Accuracy: 0.9370\n",
      "Epoch [8869/10000], Validation Loss: 0.94850099, Validation Accuracy: 0.6029\n",
      "Epoch [8870/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8870/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8871/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8871/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8872/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8872/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8873/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8873/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8874/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8874/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8875/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [8875/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8876/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8876/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8877/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8877/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8878/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [8878/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8879/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8879/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8880/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8880/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8881/10000], Training Loss: 0.62707595, Training Accuracy: 0.9244\n",
      "Epoch [8881/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8882/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [8882/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8883/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8883/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8884/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8884/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8885/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8885/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8886/10000], Training Loss: 0.62301588, Training Accuracy: 0.9286\n",
      "Epoch [8886/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8887/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [8887/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8888/10000], Training Loss: 0.62287320, Training Accuracy: 0.9286\n",
      "Epoch [8888/10000], Validation Loss: 0.93379858, Validation Accuracy: 0.6176\n",
      "Epoch [8889/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8889/10000], Validation Loss: 0.93379846, Validation Accuracy: 0.6176\n",
      "Epoch [8890/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8890/10000], Validation Loss: 0.94850177, Validation Accuracy: 0.6029\n",
      "Epoch [8891/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [8891/10000], Validation Loss: 0.94850340, Validation Accuracy: 0.6029\n",
      "Epoch [8892/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8892/10000], Validation Loss: 0.94850329, Validation Accuracy: 0.6029\n",
      "Epoch [8893/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [8893/10000], Validation Loss: 0.94850326, Validation Accuracy: 0.6029\n",
      "Epoch [8894/10000], Training Loss: 0.61026854, Training Accuracy: 0.9412\n",
      "Epoch [8894/10000], Validation Loss: 0.94850326, Validation Accuracy: 0.6029\n",
      "Epoch [8895/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [8895/10000], Validation Loss: 0.94850320, Validation Accuracy: 0.6029\n",
      "Epoch [8896/10000], Training Loss: 0.61891557, Training Accuracy: 0.9328\n",
      "Epoch [8896/10000], Validation Loss: 0.94850388, Validation Accuracy: 0.6029\n",
      "Epoch [8897/10000], Training Loss: 0.61026691, Training Accuracy: 0.9412\n",
      "Epoch [8897/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8898/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [8898/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8899/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [8899/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8900/10000], Training Loss: 0.65228461, Training Accuracy: 0.8992\n",
      "Epoch [8900/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8901/10000], Training Loss: 0.62287300, Training Accuracy: 0.9286\n",
      "Epoch [8901/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8902/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8902/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8903/10000], Training Loss: 0.62712398, Training Accuracy: 0.9244\n",
      "Epoch [8903/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8904/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [8904/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8905/10000], Training Loss: 0.63547850, Training Accuracy: 0.9160\n",
      "Epoch [8905/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8906/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [8906/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8907/10000], Training Loss: 0.64809216, Training Accuracy: 0.9034\n",
      "Epoch [8907/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8908/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8908/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8909/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [8909/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8910/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [8910/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8911/10000], Training Loss: 0.61730224, Training Accuracy: 0.9328\n",
      "Epoch [8911/10000], Validation Loss: 0.94851080, Validation Accuracy: 0.6029\n",
      "Epoch [8912/10000], Training Loss: 0.64137551, Training Accuracy: 0.9118\n",
      "Epoch [8912/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [8913/10000], Training Loss: 0.68589875, Training Accuracy: 0.8655\n",
      "Epoch [8913/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8914/10000], Training Loss: 0.74888234, Training Accuracy: 0.8025\n",
      "Epoch [8914/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8915/10000], Training Loss: 0.75742720, Training Accuracy: 0.7941\n",
      "Epoch [8915/10000], Validation Loss: 0.97300586, Validation Accuracy: 0.5735\n",
      "Epoch [8916/10000], Training Loss: 0.76573055, Training Accuracy: 0.7857\n",
      "Epoch [8916/10000], Validation Loss: 0.94915113, Validation Accuracy: 0.6029\n",
      "Epoch [8917/10000], Training Loss: 0.76993385, Training Accuracy: 0.7815\n",
      "Epoch [8917/10000], Validation Loss: 0.94835609, Validation Accuracy: 0.6029\n",
      "Epoch [8918/10000], Training Loss: 0.76086763, Training Accuracy: 0.7899\n",
      "Epoch [8918/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8919/10000], Training Loss: 0.74472237, Training Accuracy: 0.8067\n",
      "Epoch [8919/10000], Validation Loss: 0.97787473, Validation Accuracy: 0.5735\n",
      "Epoch [8920/10000], Training Loss: 0.72371391, Training Accuracy: 0.8277\n",
      "Epoch [8920/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8921/10000], Training Loss: 0.71951218, Training Accuracy: 0.8319\n",
      "Epoch [8921/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8922/10000], Training Loss: 0.73631890, Training Accuracy: 0.8151\n",
      "Epoch [8922/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8923/10000], Training Loss: 0.74052057, Training Accuracy: 0.8109\n",
      "Epoch [8923/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8924/10000], Training Loss: 0.72602728, Training Accuracy: 0.8235\n",
      "Epoch [8924/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [8925/10000], Training Loss: 0.73663915, Training Accuracy: 0.8151\n",
      "Epoch [8925/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [8926/10000], Training Loss: 0.75312533, Training Accuracy: 0.7983\n",
      "Epoch [8926/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8927/10000], Training Loss: 0.76993033, Training Accuracy: 0.7815\n",
      "Epoch [8927/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8928/10000], Training Loss: 0.79094074, Training Accuracy: 0.7605\n",
      "Epoch [8928/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8929/10000], Training Loss: 0.76152902, Training Accuracy: 0.7899\n",
      "Epoch [8929/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8930/10000], Training Loss: 0.76992232, Training Accuracy: 0.7815\n",
      "Epoch [8930/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8931/10000], Training Loss: 0.76993207, Training Accuracy: 0.7815\n",
      "Epoch [8931/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8932/10000], Training Loss: 0.76010099, Training Accuracy: 0.7899\n",
      "Epoch [8932/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8933/10000], Training Loss: 0.77413470, Training Accuracy: 0.7773\n",
      "Epoch [8933/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8934/10000], Training Loss: 0.73349449, Training Accuracy: 0.8193\n",
      "Epoch [8934/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8935/10000], Training Loss: 0.70270731, Training Accuracy: 0.8487\n",
      "Epoch [8935/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8936/10000], Training Loss: 0.70690714, Training Accuracy: 0.8445\n",
      "Epoch [8936/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8937/10000], Training Loss: 0.69010041, Training Accuracy: 0.8613\n",
      "Epoch [8937/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8938/10000], Training Loss: 0.72370875, Training Accuracy: 0.8277\n",
      "Epoch [8938/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8939/10000], Training Loss: 0.70690714, Training Accuracy: 0.8445\n",
      "Epoch [8939/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8940/10000], Training Loss: 0.70270547, Training Accuracy: 0.8487\n",
      "Epoch [8940/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8941/10000], Training Loss: 0.70769876, Training Accuracy: 0.8445\n",
      "Epoch [8941/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8942/10000], Training Loss: 0.70690715, Training Accuracy: 0.8445\n",
      "Epoch [8942/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8943/10000], Training Loss: 0.68589851, Training Accuracy: 0.8655\n",
      "Epoch [8943/10000], Validation Loss: 0.99262059, Validation Accuracy: 0.5588\n",
      "Epoch [8944/10000], Training Loss: 0.69850410, Training Accuracy: 0.8529\n",
      "Epoch [8944/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8945/10000], Training Loss: 0.68589775, Training Accuracy: 0.8655\n",
      "Epoch [8945/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8946/10000], Training Loss: 0.66909540, Training Accuracy: 0.8824\n",
      "Epoch [8946/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8947/10000], Training Loss: 0.65647880, Training Accuracy: 0.8950\n",
      "Epoch [8947/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8948/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [8948/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [8949/10000], Training Loss: 0.66909073, Training Accuracy: 0.8824\n",
      "Epoch [8949/10000], Validation Loss: 0.96320957, Validation Accuracy: 0.5882\n",
      "Epoch [8950/10000], Training Loss: 0.65228520, Training Accuracy: 0.8992\n",
      "Epoch [8950/10000], Validation Loss: 0.96320951, Validation Accuracy: 0.5882\n",
      "Epoch [8951/10000], Training Loss: 0.67329369, Training Accuracy: 0.8782\n",
      "Epoch [8951/10000], Validation Loss: 0.96320945, Validation Accuracy: 0.5882\n",
      "Epoch [8952/10000], Training Loss: 0.66070545, Training Accuracy: 0.8908\n",
      "Epoch [8952/10000], Validation Loss: 0.94902420, Validation Accuracy: 0.6029\n",
      "Epoch [8953/10000], Training Loss: 0.65648683, Training Accuracy: 0.8950\n",
      "Epoch [8953/10000], Validation Loss: 0.94850385, Validation Accuracy: 0.6029\n",
      "Epoch [8954/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [8954/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8955/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [8955/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8956/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [8956/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8957/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [8957/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8958/10000], Training Loss: 0.66909180, Training Accuracy: 0.8824\n",
      "Epoch [8958/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8959/10000], Training Loss: 0.65229768, Training Accuracy: 0.8992\n",
      "Epoch [8959/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8960/10000], Training Loss: 0.66068866, Training Accuracy: 0.8908\n",
      "Epoch [8960/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [8961/10000], Training Loss: 0.63968024, Training Accuracy: 0.9118\n",
      "Epoch [8961/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8962/10000], Training Loss: 0.66068865, Training Accuracy: 0.8908\n",
      "Epoch [8962/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8963/10000], Training Loss: 0.65833386, Training Accuracy: 0.8908\n",
      "Epoch [8963/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [8964/10000], Training Loss: 0.64814390, Training Accuracy: 0.9034\n",
      "Epoch [8964/10000], Validation Loss: 0.91909155, Validation Accuracy: 0.6324\n",
      "Epoch [8965/10000], Training Loss: 0.66909202, Training Accuracy: 0.8824\n",
      "Epoch [8965/10000], Validation Loss: 0.90487927, Validation Accuracy: 0.6471\n",
      "Epoch [8966/10000], Training Loss: 0.66909203, Training Accuracy: 0.8824\n",
      "Epoch [8966/10000], Validation Loss: 0.88968080, Validation Accuracy: 0.6618\n",
      "Epoch [8967/10000], Training Loss: 0.67328996, Training Accuracy: 0.8782\n",
      "Epoch [8967/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8968/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [8968/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8969/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [8969/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8970/10000], Training Loss: 0.65228530, Training Accuracy: 0.8992\n",
      "Epoch [8970/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8971/10000], Training Loss: 0.66789496, Training Accuracy: 0.8824\n",
      "Epoch [8971/10000], Validation Loss: 0.88959220, Validation Accuracy: 0.6618\n",
      "Epoch [8972/10000], Training Loss: 0.64200334, Training Accuracy: 0.9076\n",
      "Epoch [8972/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8973/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [8973/10000], Validation Loss: 0.87497437, Validation Accuracy: 0.6765\n",
      "Epoch [8974/10000], Training Loss: 0.65649586, Training Accuracy: 0.8950\n",
      "Epoch [8974/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8975/10000], Training Loss: 0.63965127, Training Accuracy: 0.9118\n",
      "Epoch [8975/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8976/10000], Training Loss: 0.63970143, Training Accuracy: 0.9118\n",
      "Epoch [8976/10000], Validation Loss: 0.87497434, Validation Accuracy: 0.6765\n",
      "Epoch [8977/10000], Training Loss: 0.64993699, Training Accuracy: 0.8992\n",
      "Epoch [8977/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [8978/10000], Training Loss: 0.63968936, Training Accuracy: 0.9118\n",
      "Epoch [8978/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8979/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [8979/10000], Validation Loss: 0.91909248, Validation Accuracy: 0.6324\n",
      "Epoch [8980/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [8980/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [8981/10000], Training Loss: 0.61145783, Training Accuracy: 0.9412\n",
      "Epoch [8981/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8982/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [8982/10000], Validation Loss: 0.88968024, Validation Accuracy: 0.6618\n",
      "Epoch [8983/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [8983/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [8984/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8984/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8985/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8985/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8986/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8986/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8987/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [8987/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [8988/10000], Training Loss: 0.59689500, Training Accuracy: 0.9538\n",
      "Epoch [8988/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [8989/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [8989/10000], Validation Loss: 0.93051481, Validation Accuracy: 0.6176\n",
      "Epoch [8990/10000], Training Loss: 0.60186384, Training Accuracy: 0.9496\n",
      "Epoch [8990/10000], Validation Loss: 0.94850343, Validation Accuracy: 0.6029\n",
      "Epoch [8991/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [8991/10000], Validation Loss: 0.93389827, Validation Accuracy: 0.6176\n",
      "Epoch [8992/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [8992/10000], Validation Loss: 0.94850391, Validation Accuracy: 0.6029\n",
      "Epoch [8993/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [8993/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8994/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [8994/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8995/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [8995/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8996/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8996/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8997/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [8997/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8998/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [8998/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [8999/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [8999/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9000/10000], Training Loss: 0.60611011, Training Accuracy: 0.9454\n",
      "Epoch [9000/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9001/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9001/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9002/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9002/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9003/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9003/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9004/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9004/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9005/10000], Training Loss: 0.60606405, Training Accuracy: 0.9454\n",
      "Epoch [9005/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9006/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9006/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9007/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9007/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9008/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9008/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9009/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9009/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9010/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9010/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9011/10000], Training Loss: 0.59832516, Training Accuracy: 0.9538\n",
      "Epoch [9011/10000], Validation Loss: 0.94983485, Validation Accuracy: 0.6029\n",
      "Epoch [9012/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [9012/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9013/10000], Training Loss: 0.60186730, Training Accuracy: 0.9496\n",
      "Epoch [9013/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9014/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9014/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9015/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9015/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9016/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9016/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9017/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9017/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9018/10000], Training Loss: 0.59777782, Training Accuracy: 0.9538\n",
      "Epoch [9018/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9019/10000], Training Loss: 0.61029997, Training Accuracy: 0.9412\n",
      "Epoch [9019/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9020/10000], Training Loss: 0.60579438, Training Accuracy: 0.9454\n",
      "Epoch [9020/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9021/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9021/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9022/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9022/10000], Validation Loss: 0.95377314, Validation Accuracy: 0.6029\n",
      "Epoch [9023/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9023/10000], Validation Loss: 0.96320954, Validation Accuracy: 0.5882\n",
      "Epoch [9024/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9024/10000], Validation Loss: 0.96321198, Validation Accuracy: 0.5882\n",
      "Epoch [9025/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9025/10000], Validation Loss: 0.96321750, Validation Accuracy: 0.5882\n",
      "Epoch [9026/10000], Training Loss: 0.60606679, Training Accuracy: 0.9454\n",
      "Epoch [9026/10000], Validation Loss: 0.96322331, Validation Accuracy: 0.5882\n",
      "Epoch [9027/10000], Training Loss: 0.61445892, Training Accuracy: 0.9370\n",
      "Epoch [9027/10000], Validation Loss: 0.96341202, Validation Accuracy: 0.5882\n",
      "Epoch [9028/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9028/10000], Validation Loss: 0.96391991, Validation Accuracy: 0.5882\n",
      "Epoch [9029/10000], Training Loss: 0.60641142, Training Accuracy: 0.9454\n",
      "Epoch [9029/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9030/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9030/10000], Validation Loss: 0.99113441, Validation Accuracy: 0.5588\n",
      "Epoch [9031/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9031/10000], Validation Loss: 0.96340963, Validation Accuracy: 0.5882\n",
      "Epoch [9032/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9032/10000], Validation Loss: 0.96321735, Validation Accuracy: 0.5882\n",
      "Epoch [9033/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [9033/10000], Validation Loss: 0.96321115, Validation Accuracy: 0.5882\n",
      "Epoch [9034/10000], Training Loss: 0.57666463, Training Accuracy: 0.9748\n",
      "Epoch [9034/10000], Validation Loss: 0.96320978, Validation Accuracy: 0.5882\n",
      "Epoch [9035/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9035/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9036/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9036/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9037/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9037/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9038/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9038/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9039/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9039/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9040/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9040/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9041/10000], Training Loss: 0.61026842, Training Accuracy: 0.9412\n",
      "Epoch [9041/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9042/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9042/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9043/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9043/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9044/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9044/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9045/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9045/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9046/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9046/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9047/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9047/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9048/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9048/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9049/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9049/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9050/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9050/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9051/10000], Training Loss: 0.58856128, Training Accuracy: 0.9622\n",
      "Epoch [9051/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9052/10000], Training Loss: 0.60146120, Training Accuracy: 0.9496\n",
      "Epoch [9052/10000], Validation Loss: 0.97790709, Validation Accuracy: 0.5735\n",
      "Epoch [9053/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9053/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9054/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9054/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9055/10000], Training Loss: 0.59763807, Training Accuracy: 0.9538\n",
      "Epoch [9055/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9056/10000], Training Loss: 0.60606580, Training Accuracy: 0.9454\n",
      "Epoch [9056/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9057/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9057/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9058/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9058/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9059/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9059/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9060/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9060/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9061/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9061/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9062/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9062/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9063/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9063/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9064/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9064/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9065/10000], Training Loss: 0.60186543, Training Accuracy: 0.9496\n",
      "Epoch [9065/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9066/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9066/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9067/10000], Training Loss: 0.61021024, Training Accuracy: 0.9412\n",
      "Epoch [9067/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9068/10000], Training Loss: 0.61447138, Training Accuracy: 0.9370\n",
      "Epoch [9068/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9069/10000], Training Loss: 0.61867099, Training Accuracy: 0.9328\n",
      "Epoch [9069/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9070/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9070/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9071/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9071/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9072/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9072/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9073/10000], Training Loss: 0.59766155, Training Accuracy: 0.9538\n",
      "Epoch [9073/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9074/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9074/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9075/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9075/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9076/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9076/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9077/10000], Training Loss: 0.60186503, Training Accuracy: 0.9496\n",
      "Epoch [9077/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9078/10000], Training Loss: 0.61026868, Training Accuracy: 0.9412\n",
      "Epoch [9078/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9079/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9079/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9080/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9080/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9081/10000], Training Loss: 0.60600644, Training Accuracy: 0.9454\n",
      "Epoch [9081/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9082/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9082/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9083/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9083/10000], Validation Loss: 0.95931599, Validation Accuracy: 0.5882\n",
      "Epoch [9084/10000], Training Loss: 0.63126252, Training Accuracy: 0.9202\n",
      "Epoch [9084/10000], Validation Loss: 0.94850996, Validation Accuracy: 0.6029\n",
      "Epoch [9085/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9085/10000], Validation Loss: 0.94850397, Validation Accuracy: 0.6029\n",
      "Epoch [9086/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9086/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [9087/10000], Training Loss: 0.60604973, Training Accuracy: 0.9454\n",
      "Epoch [9087/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [9088/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9088/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [9089/10000], Training Loss: 0.59862235, Training Accuracy: 0.9538\n",
      "Epoch [9089/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9090/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9090/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [9091/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9091/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9092/10000], Training Loss: 0.60606394, Training Accuracy: 0.9454\n",
      "Epoch [9092/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9093/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9093/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9094/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9094/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9095/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9095/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9096/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9096/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9097/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9097/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9098/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9098/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9099/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9099/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9100/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9100/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9101/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9101/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9102/10000], Training Loss: 0.60190560, Training Accuracy: 0.9496\n",
      "Epoch [9102/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9103/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9103/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9104/10000], Training Loss: 0.60186520, Training Accuracy: 0.9496\n",
      "Epoch [9104/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9105/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9105/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9106/10000], Training Loss: 0.60188300, Training Accuracy: 0.9496\n",
      "Epoch [9106/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9107/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9107/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9108/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [9108/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9109/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9109/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9110/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9110/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9111/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9111/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9112/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9112/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9113/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9113/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9114/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9114/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9115/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9115/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9116/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9116/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9117/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9117/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9118/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9118/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9119/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9119/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9120/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9120/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9121/10000], Training Loss: 0.60605712, Training Accuracy: 0.9454\n",
      "Epoch [9121/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9122/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9122/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9123/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9123/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9124/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9124/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9125/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9125/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9126/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9126/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9127/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9127/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9128/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9128/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9129/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9129/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9130/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9130/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9131/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9131/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9132/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9132/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9133/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9133/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9134/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9134/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9135/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9135/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9136/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9136/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9137/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9137/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9138/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9138/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9139/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9139/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9140/10000], Training Loss: 0.60605947, Training Accuracy: 0.9454\n",
      "Epoch [9140/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9141/10000], Training Loss: 0.59767660, Training Accuracy: 0.9538\n",
      "Epoch [9141/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9142/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9142/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9143/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9143/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9144/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9144/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9145/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9145/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9146/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9146/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9147/10000], Training Loss: 0.61447049, Training Accuracy: 0.9370\n",
      "Epoch [9147/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9148/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9148/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9149/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9149/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9150/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9150/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9151/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9151/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9152/10000], Training Loss: 0.59346202, Training Accuracy: 0.9580\n",
      "Epoch [9152/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9153/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9153/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9154/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9154/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9155/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9155/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9156/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9156/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9157/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9157/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9158/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9158/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9159/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9159/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9160/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9160/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9161/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9161/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9162/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9162/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9163/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9163/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9164/10000], Training Loss: 0.59766341, Training Accuracy: 0.9538\n",
      "Epoch [9164/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9165/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9165/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9166/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9166/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9167/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9167/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9168/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9168/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9169/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9169/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9170/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9170/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9171/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9171/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9172/10000], Training Loss: 0.59343009, Training Accuracy: 0.9580\n",
      "Epoch [9172/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9173/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9173/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9174/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9174/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9175/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9175/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9176/10000], Training Loss: 0.60186355, Training Accuracy: 0.9496\n",
      "Epoch [9176/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9177/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9177/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9178/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9178/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9179/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9179/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9180/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9180/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9181/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9181/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9182/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9182/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9183/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9183/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9184/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9184/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9185/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9185/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9186/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9186/10000], Validation Loss: 0.93379790, Validation Accuracy: 0.6176\n",
      "Epoch [9187/10000], Training Loss: 0.60067084, Training Accuracy: 0.9496\n",
      "Epoch [9187/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [9188/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9188/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9189/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9189/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9190/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9190/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9191/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9191/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9192/10000], Training Loss: 0.61424984, Training Accuracy: 0.9370\n",
      "Epoch [9192/10000], Validation Loss: 0.94850889, Validation Accuracy: 0.6029\n",
      "Epoch [9193/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9193/10000], Validation Loss: 0.96320915, Validation Accuracy: 0.5882\n",
      "Epoch [9194/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9194/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9195/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9195/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9196/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9196/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9197/10000], Training Loss: 0.59345744, Training Accuracy: 0.9580\n",
      "Epoch [9197/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9198/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9198/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9199/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [9199/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9200/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9200/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9201/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [9201/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9202/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9202/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9203/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9203/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9204/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9204/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9205/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9205/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9206/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9206/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9207/10000], Training Loss: 0.59346428, Training Accuracy: 0.9580\n",
      "Epoch [9207/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9208/10000], Training Loss: 0.60272379, Training Accuracy: 0.9496\n",
      "Epoch [9208/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9209/10000], Training Loss: 0.59316601, Training Accuracy: 0.9580\n",
      "Epoch [9209/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9210/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9210/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9211/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9211/10000], Validation Loss: 0.96320945, Validation Accuracy: 0.5882\n",
      "Epoch [9212/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9212/10000], Validation Loss: 0.96320251, Validation Accuracy: 0.5882\n",
      "Epoch [9213/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9213/10000], Validation Loss: 0.96316734, Validation Accuracy: 0.5882\n",
      "Epoch [9214/10000], Training Loss: 0.58926011, Training Accuracy: 0.9622\n",
      "Epoch [9214/10000], Validation Loss: 0.96311134, Validation Accuracy: 0.5882\n",
      "Epoch [9215/10000], Training Loss: 0.59345817, Training Accuracy: 0.9580\n",
      "Epoch [9215/10000], Validation Loss: 0.96310809, Validation Accuracy: 0.5882\n",
      "Epoch [9216/10000], Training Loss: 0.59347735, Training Accuracy: 0.9580\n",
      "Epoch [9216/10000], Validation Loss: 0.96317637, Validation Accuracy: 0.5882\n",
      "Epoch [9217/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9217/10000], Validation Loss: 0.96319410, Validation Accuracy: 0.5882\n",
      "Epoch [9218/10000], Training Loss: 0.58926017, Training Accuracy: 0.9622\n",
      "Epoch [9218/10000], Validation Loss: 0.96319881, Validation Accuracy: 0.5882\n",
      "Epoch [9219/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [9219/10000], Validation Loss: 0.96320036, Validation Accuracy: 0.5882\n",
      "Epoch [9220/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9220/10000], Validation Loss: 0.96320105, Validation Accuracy: 0.5882\n",
      "Epoch [9221/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9221/10000], Validation Loss: 0.96320131, Validation Accuracy: 0.5882\n",
      "Epoch [9222/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9222/10000], Validation Loss: 0.96320143, Validation Accuracy: 0.5882\n",
      "Epoch [9223/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9223/10000], Validation Loss: 0.96320155, Validation Accuracy: 0.5882\n",
      "Epoch [9224/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9224/10000], Validation Loss: 0.96320167, Validation Accuracy: 0.5882\n",
      "Epoch [9225/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9225/10000], Validation Loss: 0.96320173, Validation Accuracy: 0.5882\n",
      "Epoch [9226/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9226/10000], Validation Loss: 0.96320173, Validation Accuracy: 0.5882\n",
      "Epoch [9227/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9227/10000], Validation Loss: 0.96320173, Validation Accuracy: 0.5882\n",
      "Epoch [9228/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9228/10000], Validation Loss: 0.96320173, Validation Accuracy: 0.5882\n",
      "Epoch [9229/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9229/10000], Validation Loss: 0.96320179, Validation Accuracy: 0.5882\n",
      "Epoch [9230/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9230/10000], Validation Loss: 0.96320179, Validation Accuracy: 0.5882\n",
      "Epoch [9231/10000], Training Loss: 0.58919048, Training Accuracy: 0.9622\n",
      "Epoch [9231/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9232/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9232/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9233/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9233/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9234/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9234/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9235/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9235/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9236/10000], Training Loss: 0.58916256, Training Accuracy: 0.9622\n",
      "Epoch [9236/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9237/10000], Training Loss: 0.58927379, Training Accuracy: 0.9622\n",
      "Epoch [9237/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9238/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9238/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9239/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9239/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9240/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9240/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9241/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9241/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9242/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9242/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9243/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9243/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9244/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9244/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [9245/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9245/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [9246/10000], Training Loss: 0.60177748, Training Accuracy: 0.9496\n",
      "Epoch [9246/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9247/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9247/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9248/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9248/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9249/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9249/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9250/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9250/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9251/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9251/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9252/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9252/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9253/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9253/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9254/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9254/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9255/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9255/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9256/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9256/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9257/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9257/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9258/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9258/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9259/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9259/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9260/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9260/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9261/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9261/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9262/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9262/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9263/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9263/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9264/10000], Training Loss: 0.58925673, Training Accuracy: 0.9622\n",
      "Epoch [9264/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9265/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9265/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9266/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9266/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9267/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9267/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9268/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9268/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9269/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [9269/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9270/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9270/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9271/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9271/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9272/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9272/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9273/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9273/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9274/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9274/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9275/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9275/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9276/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9276/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9277/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9277/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9278/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9278/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9279/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9279/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9280/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9280/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9281/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9281/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9282/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9282/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9283/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9283/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9284/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9284/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9285/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9285/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9286/10000], Training Loss: 0.59346154, Training Accuracy: 0.9580\n",
      "Epoch [9286/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9287/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [9287/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9288/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9288/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9289/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [9289/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9290/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9290/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9291/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9291/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9292/10000], Training Loss: 0.57665505, Training Accuracy: 0.9748\n",
      "Epoch [9292/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9293/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9293/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9294/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9294/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9295/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9295/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9296/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9296/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9297/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [9297/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9298/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9298/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9299/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9299/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9300/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9300/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9301/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9301/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9302/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9302/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9303/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [9303/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9304/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9304/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9305/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9305/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9306/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9306/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9307/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9307/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9308/10000], Training Loss: 0.58919705, Training Accuracy: 0.9622\n",
      "Epoch [9308/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9309/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9309/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9310/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9310/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9311/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9311/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9312/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9312/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9313/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9313/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9314/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9314/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9315/10000], Training Loss: 0.60606704, Training Accuracy: 0.9454\n",
      "Epoch [9315/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9316/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9316/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9317/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9317/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9318/10000], Training Loss: 0.57665504, Training Accuracy: 0.9748\n",
      "Epoch [9318/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9319/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9319/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9320/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [9320/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9321/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9321/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9322/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9322/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9323/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9323/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9324/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9324/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9325/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9325/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9326/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9326/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9327/10000], Training Loss: 0.58926025, Training Accuracy: 0.9622\n",
      "Epoch [9327/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9328/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9328/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9329/10000], Training Loss: 0.59346119, Training Accuracy: 0.9580\n",
      "Epoch [9329/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9330/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9330/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9331/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9331/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9332/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9332/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9333/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9333/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9334/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9334/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9335/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9335/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9336/10000], Training Loss: 0.59346175, Training Accuracy: 0.9580\n",
      "Epoch [9336/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9337/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9337/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9338/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9338/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9339/10000], Training Loss: 0.59766342, Training Accuracy: 0.9538\n",
      "Epoch [9339/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9340/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9340/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9341/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [9341/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9342/10000], Training Loss: 0.58926138, Training Accuracy: 0.9622\n",
      "Epoch [9342/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9343/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9343/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9344/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9344/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9345/10000], Training Loss: 0.58505868, Training Accuracy: 0.9664\n",
      "Epoch [9345/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9346/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9346/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9347/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9347/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9348/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9348/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9349/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9349/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9350/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9350/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9351/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9351/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9352/10000], Training Loss: 0.58926080, Training Accuracy: 0.9622\n",
      "Epoch [9352/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9353/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9353/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9354/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9354/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9355/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9355/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9356/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9356/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9357/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9357/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9358/10000], Training Loss: 0.59346178, Training Accuracy: 0.9580\n",
      "Epoch [9358/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9359/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9359/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9360/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9360/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9361/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9361/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9362/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9362/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9363/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9363/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9364/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9364/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9365/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9365/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9366/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9366/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9367/10000], Training Loss: 0.59766431, Training Accuracy: 0.9538\n",
      "Epoch [9367/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9368/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [9368/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9369/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9369/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9370/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9370/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9371/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9371/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9372/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9372/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9373/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9373/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9374/10000], Training Loss: 0.62282859, Training Accuracy: 0.9286\n",
      "Epoch [9374/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9375/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9375/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9376/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9376/10000], Validation Loss: 0.97782883, Validation Accuracy: 0.5735\n",
      "Epoch [9377/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9377/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9378/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9378/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9379/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9379/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9380/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9380/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9381/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9381/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9382/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9382/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9383/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9383/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9384/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9384/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9385/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9385/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9386/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9386/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9387/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9387/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9388/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9388/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9389/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9389/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9390/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9390/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9391/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9391/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9392/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9392/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9393/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9393/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9394/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9394/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9395/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9395/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9396/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9396/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9397/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9397/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9398/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9398/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9399/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9399/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9400/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9400/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9401/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9401/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9402/10000], Training Loss: 0.58505831, Training Accuracy: 0.9664\n",
      "Epoch [9402/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9403/10000], Training Loss: 0.58506417, Training Accuracy: 0.9664\n",
      "Epoch [9403/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9404/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9404/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9405/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9405/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9406/10000], Training Loss: 0.58505842, Training Accuracy: 0.9664\n",
      "Epoch [9406/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9407/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9407/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9408/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9408/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9409/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9409/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9410/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9410/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9411/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9411/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9412/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9412/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9413/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9413/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9414/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9414/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9415/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9415/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9416/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9416/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9417/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9417/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9418/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9418/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9419/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9419/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9420/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9420/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9421/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [9421/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9422/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9422/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9423/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9423/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9424/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9424/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9425/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9425/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9426/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9426/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9427/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9427/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9428/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9428/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9429/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9429/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9430/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9430/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9431/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9431/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9432/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9432/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9433/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9433/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9434/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9434/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9435/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9435/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9436/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9436/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9437/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9437/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9438/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9438/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9439/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9439/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9440/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9440/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9441/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9441/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9442/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9442/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9443/10000], Training Loss: 0.60187063, Training Accuracy: 0.9496\n",
      "Epoch [9443/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9444/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9444/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9445/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9445/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9446/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9446/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9447/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9447/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9448/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9448/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9449/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9449/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9450/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9450/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9451/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9451/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9452/10000], Training Loss: 0.61447009, Training Accuracy: 0.9370\n",
      "Epoch [9452/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9453/10000], Training Loss: 0.59766346, Training Accuracy: 0.9538\n",
      "Epoch [9453/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9454/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9454/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9455/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9455/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9456/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9456/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9457/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9457/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9458/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9458/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9459/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9459/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9460/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9460/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9461/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9461/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9462/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9462/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9463/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9463/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9464/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9464/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9465/10000], Training Loss: 0.59765381, Training Accuracy: 0.9538\n",
      "Epoch [9465/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9466/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9466/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9467/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9467/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9468/10000], Training Loss: 0.58505839, Training Accuracy: 0.9664\n",
      "Epoch [9468/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9469/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9469/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9470/10000], Training Loss: 0.58085673, Training Accuracy: 0.9706\n",
      "Epoch [9470/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9471/10000], Training Loss: 0.58926043, Training Accuracy: 0.9622\n",
      "Epoch [9471/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9472/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9472/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9473/10000], Training Loss: 0.58085672, Training Accuracy: 0.9706\n",
      "Epoch [9473/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9474/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9474/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9475/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9475/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9476/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9476/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9477/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9477/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9478/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9478/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9479/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9479/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9480/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9480/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9481/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9481/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9482/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9482/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9483/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9483/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9484/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9484/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9485/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9485/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9486/10000], Training Loss: 0.57245335, Training Accuracy: 0.9790\n",
      "Epoch [9486/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9487/10000], Training Loss: 0.58505840, Training Accuracy: 0.9664\n",
      "Epoch [9487/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9488/10000], Training Loss: 0.58085671, Training Accuracy: 0.9706\n",
      "Epoch [9488/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9489/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9489/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9490/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9490/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9491/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9491/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9492/10000], Training Loss: 0.58926008, Training Accuracy: 0.9622\n",
      "Epoch [9492/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9493/10000], Training Loss: 0.59346176, Training Accuracy: 0.9580\n",
      "Epoch [9493/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9494/10000], Training Loss: 0.59230228, Training Accuracy: 0.9580\n",
      "Epoch [9494/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9495/10000], Training Loss: 0.57656036, Training Accuracy: 0.9748\n",
      "Epoch [9495/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9496/10000], Training Loss: 0.60186252, Training Accuracy: 0.9496\n",
      "Epoch [9496/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [9497/10000], Training Loss: 0.61867182, Training Accuracy: 0.9328\n",
      "Epoch [9497/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9498/10000], Training Loss: 0.62707461, Training Accuracy: 0.9244\n",
      "Epoch [9498/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9499/10000], Training Loss: 0.61867831, Training Accuracy: 0.9328\n",
      "Epoch [9499/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [9500/10000], Training Loss: 0.61423295, Training Accuracy: 0.9370\n",
      "Epoch [9500/10000], Validation Loss: 1.02206916, Validation Accuracy: 0.5294\n",
      "Epoch [9501/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9501/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9502/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9502/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9503/10000], Training Loss: 0.59334809, Training Accuracy: 0.9580\n",
      "Epoch [9503/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9504/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9504/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [9505/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9505/10000], Validation Loss: 1.00743848, Validation Accuracy: 0.5441\n",
      "Epoch [9506/10000], Training Loss: 0.60608516, Training Accuracy: 0.9454\n",
      "Epoch [9506/10000], Validation Loss: 1.02201223, Validation Accuracy: 0.5294\n",
      "Epoch [9507/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9507/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [9508/10000], Training Loss: 0.58455224, Training Accuracy: 0.9664\n",
      "Epoch [9508/10000], Validation Loss: 1.02256244, Validation Accuracy: 0.5294\n",
      "Epoch [9509/10000], Training Loss: 0.61446961, Training Accuracy: 0.9370\n",
      "Epoch [9509/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9510/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9510/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9511/10000], Training Loss: 0.62719648, Training Accuracy: 0.9244\n",
      "Epoch [9511/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9512/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9512/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9513/10000], Training Loss: 0.63126880, Training Accuracy: 0.9202\n",
      "Epoch [9513/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9514/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [9514/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9515/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9515/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9516/10000], Training Loss: 0.62817003, Training Accuracy: 0.9244\n",
      "Epoch [9516/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9517/10000], Training Loss: 0.60606701, Training Accuracy: 0.9454\n",
      "Epoch [9517/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9518/10000], Training Loss: 0.62706575, Training Accuracy: 0.9244\n",
      "Epoch [9518/10000], Validation Loss: 1.03572881, Validation Accuracy: 0.5147\n",
      "Epoch [9519/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [9519/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [9520/10000], Training Loss: 0.64351050, Training Accuracy: 0.9076\n",
      "Epoch [9520/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9521/10000], Training Loss: 0.63127694, Training Accuracy: 0.9202\n",
      "Epoch [9521/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9522/10000], Training Loss: 0.63133249, Training Accuracy: 0.9202\n",
      "Epoch [9522/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9523/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9523/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9524/10000], Training Loss: 0.64002283, Training Accuracy: 0.9118\n",
      "Epoch [9524/10000], Validation Loss: 1.05046886, Validation Accuracy: 0.5000\n",
      "Epoch [9525/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9525/10000], Validation Loss: 1.05144483, Validation Accuracy: 0.5000\n",
      "Epoch [9526/10000], Training Loss: 0.62707508, Training Accuracy: 0.9244\n",
      "Epoch [9526/10000], Validation Loss: 1.03673738, Validation Accuracy: 0.5147\n",
      "Epoch [9527/10000], Training Loss: 0.61884836, Training Accuracy: 0.9328\n",
      "Epoch [9527/10000], Validation Loss: 1.04760379, Validation Accuracy: 0.5000\n",
      "Epoch [9528/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9528/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [9529/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9529/10000], Validation Loss: 1.02195311, Validation Accuracy: 0.5294\n",
      "Epoch [9530/10000], Training Loss: 0.61448109, Training Accuracy: 0.9370\n",
      "Epoch [9530/10000], Validation Loss: 1.00825727, Validation Accuracy: 0.5441\n",
      "Epoch [9531/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9531/10000], Validation Loss: 1.02054021, Validation Accuracy: 0.5294\n",
      "Epoch [9532/10000], Training Loss: 0.60607048, Training Accuracy: 0.9454\n",
      "Epoch [9532/10000], Validation Loss: 1.02114689, Validation Accuracy: 0.5294\n",
      "Epoch [9533/10000], Training Loss: 0.60607023, Training Accuracy: 0.9454\n",
      "Epoch [9533/10000], Validation Loss: 1.02126348, Validation Accuracy: 0.5294\n",
      "Epoch [9534/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9534/10000], Validation Loss: 1.03577551, Validation Accuracy: 0.5147\n",
      "Epoch [9535/10000], Training Loss: 0.59766356, Training Accuracy: 0.9538\n",
      "Epoch [9535/10000], Validation Loss: 1.03549260, Validation Accuracy: 0.5147\n",
      "Epoch [9536/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9536/10000], Validation Loss: 1.03527761, Validation Accuracy: 0.5147\n",
      "Epoch [9537/10000], Training Loss: 0.59766950, Training Accuracy: 0.9538\n",
      "Epoch [9537/10000], Validation Loss: 1.03290886, Validation Accuracy: 0.5147\n",
      "Epoch [9538/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9538/10000], Validation Loss: 1.03082597, Validation Accuracy: 0.5147\n",
      "Epoch [9539/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9539/10000], Validation Loss: 1.02964583, Validation Accuracy: 0.5147\n",
      "Epoch [9540/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9540/10000], Validation Loss: 1.02905837, Validation Accuracy: 0.5147\n",
      "Epoch [9541/10000], Training Loss: 0.60606691, Training Accuracy: 0.9454\n",
      "Epoch [9541/10000], Validation Loss: 1.02867550, Validation Accuracy: 0.5147\n",
      "Epoch [9542/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9542/10000], Validation Loss: 1.02849236, Validation Accuracy: 0.5147\n",
      "Epoch [9543/10000], Training Loss: 0.60389225, Training Accuracy: 0.9454\n",
      "Epoch [9543/10000], Validation Loss: 1.03673899, Validation Accuracy: 0.5147\n",
      "Epoch [9544/10000], Training Loss: 0.62300711, Training Accuracy: 0.9286\n",
      "Epoch [9544/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9545/10000], Training Loss: 0.64388201, Training Accuracy: 0.9076\n",
      "Epoch [9545/10000], Validation Loss: 1.06637889, Validation Accuracy: 0.4853\n",
      "Epoch [9546/10000], Training Loss: 0.64899129, Training Accuracy: 0.8992\n",
      "Epoch [9546/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [9547/10000], Training Loss: 0.65229080, Training Accuracy: 0.8992\n",
      "Epoch [9547/10000], Validation Loss: 1.09556258, Validation Accuracy: 0.4559\n",
      "Epoch [9548/10000], Training Loss: 0.63969040, Training Accuracy: 0.9118\n",
      "Epoch [9548/10000], Validation Loss: 1.09556282, Validation Accuracy: 0.4559\n",
      "Epoch [9549/10000], Training Loss: 0.65011939, Training Accuracy: 0.8992\n",
      "Epoch [9549/10000], Validation Loss: 1.08105081, Validation Accuracy: 0.4706\n",
      "Epoch [9550/10000], Training Loss: 0.62706098, Training Accuracy: 0.9244\n",
      "Epoch [9550/10000], Validation Loss: 1.00712749, Validation Accuracy: 0.5441\n",
      "Epoch [9551/10000], Training Loss: 0.62707522, Training Accuracy: 0.9244\n",
      "Epoch [9551/10000], Validation Loss: 0.97791392, Validation Accuracy: 0.5735\n",
      "Epoch [9552/10000], Training Loss: 0.63127687, Training Accuracy: 0.9202\n",
      "Epoch [9552/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9553/10000], Training Loss: 0.60606692, Training Accuracy: 0.9454\n",
      "Epoch [9553/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9554/10000], Training Loss: 0.62721765, Training Accuracy: 0.9244\n",
      "Epoch [9554/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [9555/10000], Training Loss: 0.60044073, Training Accuracy: 0.9496\n",
      "Epoch [9555/10000], Validation Loss: 0.93403772, Validation Accuracy: 0.6176\n",
      "Epoch [9556/10000], Training Loss: 0.60185538, Training Accuracy: 0.9496\n",
      "Epoch [9556/10000], Validation Loss: 0.98363647, Validation Accuracy: 0.5588\n",
      "Epoch [9557/10000], Training Loss: 0.65649291, Training Accuracy: 0.8950\n",
      "Epoch [9557/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [9558/10000], Training Loss: 0.68999371, Training Accuracy: 0.8613\n",
      "Epoch [9558/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [9559/10000], Training Loss: 0.67296277, Training Accuracy: 0.8782\n",
      "Epoch [9559/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9560/10000], Training Loss: 0.66489032, Training Accuracy: 0.8866\n",
      "Epoch [9560/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9561/10000], Training Loss: 0.66918577, Training Accuracy: 0.8824\n",
      "Epoch [9561/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9562/10000], Training Loss: 0.65648469, Training Accuracy: 0.8950\n",
      "Epoch [9562/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9563/10000], Training Loss: 0.65648686, Training Accuracy: 0.8950\n",
      "Epoch [9563/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9564/10000], Training Loss: 0.66506150, Training Accuracy: 0.8866\n",
      "Epoch [9564/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9565/10000], Training Loss: 0.66473738, Training Accuracy: 0.8866\n",
      "Epoch [9565/10000], Validation Loss: 1.01336619, Validation Accuracy: 0.5441\n",
      "Epoch [9566/10000], Training Loss: 0.65228529, Training Accuracy: 0.8992\n",
      "Epoch [9566/10000], Validation Loss: 0.97261700, Validation Accuracy: 0.5882\n",
      "Epoch [9567/10000], Training Loss: 0.63974065, Training Accuracy: 0.9118\n",
      "Epoch [9567/10000], Validation Loss: 0.97791100, Validation Accuracy: 0.5735\n",
      "Epoch [9568/10000], Training Loss: 0.63970432, Training Accuracy: 0.9118\n",
      "Epoch [9568/10000], Validation Loss: 0.97791147, Validation Accuracy: 0.5735\n",
      "Epoch [9569/10000], Training Loss: 0.64341755, Training Accuracy: 0.9076\n",
      "Epoch [9569/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9570/10000], Training Loss: 0.65648697, Training Accuracy: 0.8950\n",
      "Epoch [9570/10000], Validation Loss: 0.96294490, Validation Accuracy: 0.5882\n",
      "Epoch [9571/10000], Training Loss: 0.64387304, Training Accuracy: 0.9076\n",
      "Epoch [9571/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9572/10000], Training Loss: 0.65228484, Training Accuracy: 0.8992\n",
      "Epoch [9572/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9573/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9573/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9574/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [9574/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9575/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [9575/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9576/10000], Training Loss: 0.63127467, Training Accuracy: 0.9202\n",
      "Epoch [9576/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9577/10000], Training Loss: 0.61854554, Training Accuracy: 0.9328\n",
      "Epoch [9577/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9578/10000], Training Loss: 0.60606106, Training Accuracy: 0.9454\n",
      "Epoch [9578/10000], Validation Loss: 0.96320978, Validation Accuracy: 0.5882\n",
      "Epoch [9579/10000], Training Loss: 0.61447328, Training Accuracy: 0.9370\n",
      "Epoch [9579/10000], Validation Loss: 0.96328822, Validation Accuracy: 0.5882\n",
      "Epoch [9580/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9580/10000], Validation Loss: 0.96529889, Validation Accuracy: 0.5882\n",
      "Epoch [9581/10000], Training Loss: 0.62707523, Training Accuracy: 0.9244\n",
      "Epoch [9581/10000], Validation Loss: 0.98476499, Validation Accuracy: 0.5588\n",
      "Epoch [9582/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9582/10000], Validation Loss: 0.98759347, Validation Accuracy: 0.5588\n",
      "Epoch [9583/10000], Training Loss: 0.61026855, Training Accuracy: 0.9412\n",
      "Epoch [9583/10000], Validation Loss: 0.98876876, Validation Accuracy: 0.5588\n",
      "Epoch [9584/10000], Training Loss: 0.61388189, Training Accuracy: 0.9370\n",
      "Epoch [9584/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [9585/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [9585/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [9586/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9586/10000], Validation Loss: 1.03336427, Validation Accuracy: 0.5147\n",
      "Epoch [9587/10000], Training Loss: 0.60186521, Training Accuracy: 0.9496\n",
      "Epoch [9587/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [9588/10000], Training Loss: 0.60186453, Training Accuracy: 0.9496\n",
      "Epoch [9588/10000], Validation Loss: 1.03674093, Validation Accuracy: 0.5147\n",
      "Epoch [9589/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9589/10000], Validation Loss: 1.03675726, Validation Accuracy: 0.5147\n",
      "Epoch [9590/10000], Training Loss: 0.61233879, Training Accuracy: 0.9370\n",
      "Epoch [9590/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9591/10000], Training Loss: 0.62098239, Training Accuracy: 0.9286\n",
      "Epoch [9591/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [9592/10000], Training Loss: 0.62023315, Training Accuracy: 0.9328\n",
      "Epoch [9592/10000], Validation Loss: 1.00200620, Validation Accuracy: 0.5441\n",
      "Epoch [9593/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9593/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [9594/10000], Training Loss: 0.63598184, Training Accuracy: 0.9160\n",
      "Epoch [9594/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [9595/10000], Training Loss: 0.63550582, Training Accuracy: 0.9160\n",
      "Epoch [9595/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9596/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [9596/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9597/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9597/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9598/10000], Training Loss: 0.64388193, Training Accuracy: 0.9076\n",
      "Epoch [9598/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9599/10000], Training Loss: 0.63961173, Training Accuracy: 0.9118\n",
      "Epoch [9599/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9600/10000], Training Loss: 0.62363736, Training Accuracy: 0.9286\n",
      "Epoch [9600/10000], Validation Loss: 0.97791538, Validation Accuracy: 0.5735\n",
      "Epoch [9601/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9601/10000], Validation Loss: 0.97760722, Validation Accuracy: 0.5735\n",
      "Epoch [9602/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9602/10000], Validation Loss: 0.95649806, Validation Accuracy: 0.5882\n",
      "Epoch [9603/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [9603/10000], Validation Loss: 0.93626243, Validation Accuracy: 0.6176\n",
      "Epoch [9604/10000], Training Loss: 0.62714394, Training Accuracy: 0.9244\n",
      "Epoch [9604/10000], Validation Loss: 0.93379813, Validation Accuracy: 0.6176\n",
      "Epoch [9605/10000], Training Loss: 0.64379277, Training Accuracy: 0.9076\n",
      "Epoch [9605/10000], Validation Loss: 0.95059335, Validation Accuracy: 0.6029\n",
      "Epoch [9606/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [9606/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9607/10000], Training Loss: 0.61447113, Training Accuracy: 0.9370\n",
      "Epoch [9607/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9608/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9608/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9609/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9609/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9610/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9610/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9611/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9611/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9612/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9612/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9613/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9613/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9614/10000], Training Loss: 0.61026810, Training Accuracy: 0.9412\n",
      "Epoch [9614/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9615/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9615/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9616/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9616/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9617/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9617/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9618/10000], Training Loss: 0.62288006, Training Accuracy: 0.9286\n",
      "Epoch [9618/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9619/10000], Training Loss: 0.60186515, Training Accuracy: 0.9496\n",
      "Epoch [9619/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9620/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9620/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9621/10000], Training Loss: 0.61447020, Training Accuracy: 0.9370\n",
      "Epoch [9621/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9622/10000], Training Loss: 0.62701489, Training Accuracy: 0.9244\n",
      "Epoch [9622/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9623/10000], Training Loss: 0.61026337, Training Accuracy: 0.9412\n",
      "Epoch [9623/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9624/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9624/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9625/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9625/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9626/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9626/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9627/10000], Training Loss: 0.61897051, Training Accuracy: 0.9328\n",
      "Epoch [9627/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9628/10000], Training Loss: 0.62707508, Training Accuracy: 0.9244\n",
      "Epoch [9628/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9629/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9629/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9630/10000], Training Loss: 0.61025439, Training Accuracy: 0.9412\n",
      "Epoch [9630/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9631/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9631/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9632/10000], Training Loss: 0.61026843, Training Accuracy: 0.9412\n",
      "Epoch [9632/10000], Validation Loss: 0.96320924, Validation Accuracy: 0.5882\n",
      "Epoch [9633/10000], Training Loss: 0.60606671, Training Accuracy: 0.9454\n",
      "Epoch [9633/10000], Validation Loss: 0.96320829, Validation Accuracy: 0.5882\n",
      "Epoch [9634/10000], Training Loss: 0.61026854, Training Accuracy: 0.9412\n",
      "Epoch [9634/10000], Validation Loss: 0.96320722, Validation Accuracy: 0.5882\n",
      "Epoch [9635/10000], Training Loss: 0.60606626, Training Accuracy: 0.9454\n",
      "Epoch [9635/10000], Validation Loss: 0.96320638, Validation Accuracy: 0.5882\n",
      "Epoch [9636/10000], Training Loss: 0.60186517, Training Accuracy: 0.9496\n",
      "Epoch [9636/10000], Validation Loss: 0.96320564, Validation Accuracy: 0.5882\n",
      "Epoch [9637/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9637/10000], Validation Loss: 0.96320525, Validation Accuracy: 0.5882\n",
      "Epoch [9638/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9638/10000], Validation Loss: 0.96320504, Validation Accuracy: 0.5882\n",
      "Epoch [9639/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9639/10000], Validation Loss: 0.96320492, Validation Accuracy: 0.5882\n",
      "Epoch [9640/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9640/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9641/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9641/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9642/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9642/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9643/10000], Training Loss: 0.61447022, Training Accuracy: 0.9370\n",
      "Epoch [9643/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9644/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [9644/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9645/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9645/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9646/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9646/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9647/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9647/10000], Validation Loss: 0.96320486, Validation Accuracy: 0.5882\n",
      "Epoch [9648/10000], Training Loss: 0.62707540, Training Accuracy: 0.9244\n",
      "Epoch [9648/10000], Validation Loss: 0.96320468, Validation Accuracy: 0.5882\n",
      "Epoch [9649/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9649/10000], Validation Loss: 0.96320465, Validation Accuracy: 0.5882\n",
      "Epoch [9650/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9650/10000], Validation Loss: 0.96320459, Validation Accuracy: 0.5882\n",
      "Epoch [9651/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9651/10000], Validation Loss: 0.96320459, Validation Accuracy: 0.5882\n",
      "Epoch [9652/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9652/10000], Validation Loss: 0.96320459, Validation Accuracy: 0.5882\n",
      "Epoch [9653/10000], Training Loss: 0.59345816, Training Accuracy: 0.9580\n",
      "Epoch [9653/10000], Validation Loss: 0.96320689, Validation Accuracy: 0.5882\n",
      "Epoch [9654/10000], Training Loss: 0.59766369, Training Accuracy: 0.9538\n",
      "Epoch [9654/10000], Validation Loss: 0.96320790, Validation Accuracy: 0.5882\n",
      "Epoch [9655/10000], Training Loss: 0.59766345, Training Accuracy: 0.9538\n",
      "Epoch [9655/10000], Validation Loss: 0.96320817, Validation Accuracy: 0.5882\n",
      "Epoch [9656/10000], Training Loss: 0.61366870, Training Accuracy: 0.9370\n",
      "Epoch [9656/10000], Validation Loss: 0.94919270, Validation Accuracy: 0.6029\n",
      "Epoch [9657/10000], Training Loss: 0.61447005, Training Accuracy: 0.9370\n",
      "Epoch [9657/10000], Validation Loss: 0.94851390, Validation Accuracy: 0.6029\n",
      "Epoch [9658/10000], Training Loss: 0.62116706, Training Accuracy: 0.9286\n",
      "Epoch [9658/10000], Validation Loss: 0.97782132, Validation Accuracy: 0.5735\n",
      "Epoch [9659/10000], Training Loss: 0.61037200, Training Accuracy: 0.9412\n",
      "Epoch [9659/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9660/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9660/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9661/10000], Training Loss: 0.60614742, Training Accuracy: 0.9454\n",
      "Epoch [9661/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9662/10000], Training Loss: 0.61525364, Training Accuracy: 0.9370\n",
      "Epoch [9662/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9663/10000], Training Loss: 0.61867613, Training Accuracy: 0.9328\n",
      "Epoch [9663/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9664/10000], Training Loss: 0.61863180, Training Accuracy: 0.9328\n",
      "Epoch [9664/10000], Validation Loss: 0.97775605, Validation Accuracy: 0.5735\n",
      "Epoch [9665/10000], Training Loss: 0.61446100, Training Accuracy: 0.9370\n",
      "Epoch [9665/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9666/10000], Training Loss: 0.61026296, Training Accuracy: 0.9412\n",
      "Epoch [9666/10000], Validation Loss: 0.97791266, Validation Accuracy: 0.5735\n",
      "Epoch [9667/10000], Training Loss: 0.61026847, Training Accuracy: 0.9412\n",
      "Epoch [9667/10000], Validation Loss: 0.97744903, Validation Accuracy: 0.5735\n",
      "Epoch [9668/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9668/10000], Validation Loss: 0.97353083, Validation Accuracy: 0.5735\n",
      "Epoch [9669/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9669/10000], Validation Loss: 0.99847388, Validation Accuracy: 0.5588\n",
      "Epoch [9670/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9670/10000], Validation Loss: 0.99649298, Validation Accuracy: 0.5588\n",
      "Epoch [9671/10000], Training Loss: 0.62580369, Training Accuracy: 0.9244\n",
      "Epoch [9671/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9672/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [9672/10000], Validation Loss: 0.99259719, Validation Accuracy: 0.5588\n",
      "Epoch [9673/10000], Training Loss: 0.64808442, Training Accuracy: 0.9034\n",
      "Epoch [9673/10000], Validation Loss: 0.99256164, Validation Accuracy: 0.5588\n",
      "Epoch [9674/10000], Training Loss: 0.66031104, Training Accuracy: 0.8908\n",
      "Epoch [9674/10000], Validation Loss: 0.97824857, Validation Accuracy: 0.5735\n",
      "Epoch [9675/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9675/10000], Validation Loss: 0.99793693, Validation Accuracy: 0.5588\n",
      "Epoch [9676/10000], Training Loss: 0.64807639, Training Accuracy: 0.9034\n",
      "Epoch [9676/10000], Validation Loss: 1.00947493, Validation Accuracy: 0.5441\n",
      "Epoch [9677/10000], Training Loss: 0.61853437, Training Accuracy: 0.9328\n",
      "Epoch [9677/10000], Validation Loss: 1.05301648, Validation Accuracy: 0.5000\n",
      "Epoch [9678/10000], Training Loss: 0.62240197, Training Accuracy: 0.9286\n",
      "Epoch [9678/10000], Validation Loss: 1.03670979, Validation Accuracy: 0.5147\n",
      "Epoch [9679/10000], Training Loss: 0.64441920, Training Accuracy: 0.9076\n",
      "Epoch [9679/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [9680/10000], Training Loss: 0.62296693, Training Accuracy: 0.9286\n",
      "Epoch [9680/10000], Validation Loss: 1.03673902, Validation Accuracy: 0.5147\n",
      "Epoch [9681/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9681/10000], Validation Loss: 1.02203315, Validation Accuracy: 0.5294\n",
      "Epoch [9682/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [9682/10000], Validation Loss: 1.02203262, Validation Accuracy: 0.5294\n",
      "Epoch [9683/10000], Training Loss: 0.64199973, Training Accuracy: 0.9076\n",
      "Epoch [9683/10000], Validation Loss: 1.02219620, Validation Accuracy: 0.5294\n",
      "Epoch [9684/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9684/10000], Validation Loss: 1.03677455, Validation Accuracy: 0.5147\n",
      "Epoch [9685/10000], Training Loss: 0.62633980, Training Accuracy: 0.9244\n",
      "Epoch [9685/10000], Validation Loss: 1.00732782, Validation Accuracy: 0.5441\n",
      "Epoch [9686/10000], Training Loss: 0.63508679, Training Accuracy: 0.9160\n",
      "Epoch [9686/10000], Validation Loss: 1.02203196, Validation Accuracy: 0.5294\n",
      "Epoch [9687/10000], Training Loss: 0.63961102, Training Accuracy: 0.9118\n",
      "Epoch [9687/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9688/10000], Training Loss: 0.63548449, Training Accuracy: 0.9160\n",
      "Epoch [9688/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9689/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9689/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9690/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9690/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9691/10000], Training Loss: 0.63869003, Training Accuracy: 0.9118\n",
      "Epoch [9691/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9692/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9692/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9693/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9693/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9694/10000], Training Loss: 0.62717936, Training Accuracy: 0.9244\n",
      "Epoch [9694/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9695/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9695/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9696/10000], Training Loss: 0.60606752, Training Accuracy: 0.9454\n",
      "Epoch [9696/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9697/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9697/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9698/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9698/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9699/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9699/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9700/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9700/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9701/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9701/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9702/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9702/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9703/10000], Training Loss: 0.60606673, Training Accuracy: 0.9454\n",
      "Epoch [9703/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9704/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9704/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9705/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9705/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9706/10000], Training Loss: 0.63968298, Training Accuracy: 0.9118\n",
      "Epoch [9706/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9707/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9707/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9708/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9708/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9709/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9709/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9710/10000], Training Loss: 0.62707229, Training Accuracy: 0.9244\n",
      "Epoch [9710/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9711/10000], Training Loss: 0.61026858, Training Accuracy: 0.9412\n",
      "Epoch [9711/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9712/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9712/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9713/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9713/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9714/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9714/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9715/10000], Training Loss: 0.61864769, Training Accuracy: 0.9328\n",
      "Epoch [9715/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9716/10000], Training Loss: 0.61446937, Training Accuracy: 0.9370\n",
      "Epoch [9716/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9717/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9717/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9718/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [9718/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9719/10000], Training Loss: 0.61026504, Training Accuracy: 0.9412\n",
      "Epoch [9719/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9720/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9720/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9721/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9721/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9722/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9722/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9723/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9723/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9724/10000], Training Loss: 0.62291986, Training Accuracy: 0.9286\n",
      "Epoch [9724/10000], Validation Loss: 0.99262142, Validation Accuracy: 0.5588\n",
      "Epoch [9725/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9725/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9726/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9726/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9727/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9727/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9728/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9728/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9729/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9729/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9730/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9730/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9731/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9731/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9732/10000], Training Loss: 0.58926009, Training Accuracy: 0.9622\n",
      "Epoch [9732/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9733/10000], Training Loss: 0.61447387, Training Accuracy: 0.9370\n",
      "Epoch [9733/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9734/10000], Training Loss: 0.60991425, Training Accuracy: 0.9412\n",
      "Epoch [9734/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9735/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [9735/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9736/10000], Training Loss: 0.60186511, Training Accuracy: 0.9496\n",
      "Epoch [9736/10000], Validation Loss: 0.99246392, Validation Accuracy: 0.5588\n",
      "Epoch [9737/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9737/10000], Validation Loss: 0.97906521, Validation Accuracy: 0.5735\n",
      "Epoch [9738/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9738/10000], Validation Loss: 0.97796616, Validation Accuracy: 0.5735\n",
      "Epoch [9739/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9739/10000], Validation Loss: 0.97792685, Validation Accuracy: 0.5735\n",
      "Epoch [9740/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [9740/10000], Validation Loss: 0.97792110, Validation Accuracy: 0.5735\n",
      "Epoch [9741/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [9741/10000], Validation Loss: 0.97791949, Validation Accuracy: 0.5735\n",
      "Epoch [9742/10000], Training Loss: 0.61409616, Training Accuracy: 0.9370\n",
      "Epoch [9742/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9743/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9743/10000], Validation Loss: 0.97515735, Validation Accuracy: 0.5735\n",
      "Epoch [9744/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9744/10000], Validation Loss: 0.94858688, Validation Accuracy: 0.6029\n",
      "Epoch [9745/10000], Training Loss: 0.62287348, Training Accuracy: 0.9286\n",
      "Epoch [9745/10000], Validation Loss: 0.94850773, Validation Accuracy: 0.6029\n",
      "Epoch [9746/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9746/10000], Validation Loss: 0.94850469, Validation Accuracy: 0.6029\n",
      "Epoch [9747/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9747/10000], Validation Loss: 0.94850421, Validation Accuracy: 0.6029\n",
      "Epoch [9748/10000], Training Loss: 0.61148653, Training Accuracy: 0.9412\n",
      "Epoch [9748/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9749/10000], Training Loss: 0.62707509, Training Accuracy: 0.9244\n",
      "Epoch [9749/10000], Validation Loss: 0.96320605, Validation Accuracy: 0.5882\n",
      "Epoch [9750/10000], Training Loss: 0.64802980, Training Accuracy: 0.9034\n",
      "Epoch [9750/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9751/10000], Training Loss: 0.63114091, Training Accuracy: 0.9202\n",
      "Epoch [9751/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9752/10000], Training Loss: 0.61446959, Training Accuracy: 0.9370\n",
      "Epoch [9752/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9753/10000], Training Loss: 0.61840950, Training Accuracy: 0.9328\n",
      "Epoch [9753/10000], Validation Loss: 0.94999763, Validation Accuracy: 0.6029\n",
      "Epoch [9754/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9754/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9755/10000], Training Loss: 0.61565288, Training Accuracy: 0.9370\n",
      "Epoch [9755/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9756/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9756/10000], Validation Loss: 1.03673905, Validation Accuracy: 0.5147\n",
      "Epoch [9757/10000], Training Loss: 0.66129668, Training Accuracy: 0.8908\n",
      "Epoch [9757/10000], Validation Loss: 1.02203006, Validation Accuracy: 0.5294\n",
      "Epoch [9758/10000], Training Loss: 0.63548086, Training Accuracy: 0.9160\n",
      "Epoch [9758/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9759/10000], Training Loss: 0.66904799, Training Accuracy: 0.8824\n",
      "Epoch [9759/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9760/10000], Training Loss: 0.64387195, Training Accuracy: 0.9076\n",
      "Epoch [9760/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9761/10000], Training Loss: 0.63962941, Training Accuracy: 0.9118\n",
      "Epoch [9761/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9762/10000], Training Loss: 0.64808362, Training Accuracy: 0.9034\n",
      "Epoch [9762/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9763/10000], Training Loss: 0.64207500, Training Accuracy: 0.9076\n",
      "Epoch [9763/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9764/10000], Training Loss: 0.63127713, Training Accuracy: 0.9202\n",
      "Epoch [9764/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9765/10000], Training Loss: 0.62288600, Training Accuracy: 0.9286\n",
      "Epoch [9765/10000], Validation Loss: 1.00732732, Validation Accuracy: 0.5441\n",
      "Epoch [9766/10000], Training Loss: 0.63547856, Training Accuracy: 0.9160\n",
      "Epoch [9766/10000], Validation Loss: 1.02181336, Validation Accuracy: 0.5294\n",
      "Epoch [9767/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [9767/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [9768/10000], Training Loss: 0.63968026, Training Accuracy: 0.9118\n",
      "Epoch [9768/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [9769/10000], Training Loss: 0.65648706, Training Accuracy: 0.8950\n",
      "Epoch [9769/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [9770/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9770/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [9771/10000], Training Loss: 0.63127651, Training Accuracy: 0.9202\n",
      "Epoch [9771/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [9772/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9772/10000], Validation Loss: 1.02203318, Validation Accuracy: 0.5294\n",
      "Epoch [9773/10000], Training Loss: 0.63996377, Training Accuracy: 0.9118\n",
      "Epoch [9773/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9774/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9774/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9775/10000], Training Loss: 0.63547759, Training Accuracy: 0.9160\n",
      "Epoch [9775/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9776/10000], Training Loss: 0.61867406, Training Accuracy: 0.9328\n",
      "Epoch [9776/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9777/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [9777/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9778/10000], Training Loss: 0.61026851, Training Accuracy: 0.9412\n",
      "Epoch [9778/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9779/10000], Training Loss: 0.61863776, Training Accuracy: 0.9328\n",
      "Epoch [9779/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9780/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9780/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9781/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9781/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9782/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9782/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9783/10000], Training Loss: 0.61606281, Training Accuracy: 0.9370\n",
      "Epoch [9783/10000], Validation Loss: 0.94850373, Validation Accuracy: 0.6029\n",
      "Epoch [9784/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9784/10000], Validation Loss: 0.97809121, Validation Accuracy: 0.5735\n",
      "Epoch [9785/10000], Training Loss: 0.62707675, Training Accuracy: 0.9244\n",
      "Epoch [9785/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9786/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9786/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9787/10000], Training Loss: 0.61867126, Training Accuracy: 0.9328\n",
      "Epoch [9787/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9788/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9788/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9789/10000], Training Loss: 0.61443935, Training Accuracy: 0.9370\n",
      "Epoch [9789/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9790/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9790/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9791/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9791/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9792/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9792/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9793/10000], Training Loss: 0.61445544, Training Accuracy: 0.9370\n",
      "Epoch [9793/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9794/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9794/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9795/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [9795/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9796/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9796/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9797/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9797/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9798/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [9798/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9799/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9799/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9800/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [9800/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9801/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9801/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9802/10000], Training Loss: 0.63547858, Training Accuracy: 0.9160\n",
      "Epoch [9802/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9803/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9803/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9804/10000], Training Loss: 0.60186514, Training Accuracy: 0.9496\n",
      "Epoch [9804/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9805/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9805/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9806/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9806/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9807/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9807/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9808/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [9808/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9809/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9809/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9810/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9810/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9811/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9811/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9812/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9812/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9813/10000], Training Loss: 0.61446768, Training Accuracy: 0.9370\n",
      "Epoch [9813/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9814/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9814/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9815/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9815/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9816/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9816/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9817/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9817/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9818/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9818/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9819/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9819/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9820/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9820/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9821/10000], Training Loss: 0.60606660, Training Accuracy: 0.9454\n",
      "Epoch [9821/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9822/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9822/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9823/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9823/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9824/10000], Training Loss: 0.61430677, Training Accuracy: 0.9370\n",
      "Epoch [9824/10000], Validation Loss: 0.99262139, Validation Accuracy: 0.5588\n",
      "Epoch [9825/10000], Training Loss: 0.63127688, Training Accuracy: 0.9202\n",
      "Epoch [9825/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9826/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9826/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9827/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9827/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9828/10000], Training Loss: 0.61146580, Training Accuracy: 0.9412\n",
      "Epoch [9828/10000], Validation Loss: 1.00732729, Validation Accuracy: 0.5441\n",
      "Epoch [9829/10000], Training Loss: 0.61863279, Training Accuracy: 0.9328\n",
      "Epoch [9829/10000], Validation Loss: 1.00732809, Validation Accuracy: 0.5441\n",
      "Epoch [9830/10000], Training Loss: 0.62707524, Training Accuracy: 0.9244\n",
      "Epoch [9830/10000], Validation Loss: 1.02203310, Validation Accuracy: 0.5294\n",
      "Epoch [9831/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9831/10000], Validation Loss: 1.02688253, Validation Accuracy: 0.5294\n",
      "Epoch [9832/10000], Training Loss: 0.62079303, Training Accuracy: 0.9286\n",
      "Epoch [9832/10000], Validation Loss: 1.00732723, Validation Accuracy: 0.5441\n",
      "Epoch [9833/10000], Training Loss: 0.61446748, Training Accuracy: 0.9370\n",
      "Epoch [9833/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9834/10000], Training Loss: 0.63116981, Training Accuracy: 0.9202\n",
      "Epoch [9834/10000], Validation Loss: 1.00713271, Validation Accuracy: 0.5441\n",
      "Epoch [9835/10000], Training Loss: 0.61447016, Training Accuracy: 0.9370\n",
      "Epoch [9835/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9836/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9836/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9837/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [9837/10000], Validation Loss: 0.97790250, Validation Accuracy: 0.5735\n",
      "Epoch [9838/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9838/10000], Validation Loss: 0.97769210, Validation Accuracy: 0.5735\n",
      "Epoch [9839/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9839/10000], Validation Loss: 0.97708610, Validation Accuracy: 0.5735\n",
      "Epoch [9840/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9840/10000], Validation Loss: 0.97640505, Validation Accuracy: 0.5735\n",
      "Epoch [9841/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9841/10000], Validation Loss: 0.97592798, Validation Accuracy: 0.5735\n",
      "Epoch [9842/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [9842/10000], Validation Loss: 0.97565696, Validation Accuracy: 0.5735\n",
      "Epoch [9843/10000], Training Loss: 0.62707337, Training Accuracy: 0.9244\n",
      "Epoch [9843/10000], Validation Loss: 0.97589841, Validation Accuracy: 0.5735\n",
      "Epoch [9844/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9844/10000], Validation Loss: 0.97600660, Validation Accuracy: 0.5735\n",
      "Epoch [9845/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9845/10000], Validation Loss: 0.97605726, Validation Accuracy: 0.5735\n",
      "Epoch [9846/10000], Training Loss: 0.61026841, Training Accuracy: 0.9412\n",
      "Epoch [9846/10000], Validation Loss: 0.97608474, Validation Accuracy: 0.5735\n",
      "Epoch [9847/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9847/10000], Validation Loss: 0.97611108, Validation Accuracy: 0.5735\n",
      "Epoch [9848/10000], Training Loss: 0.62707536, Training Accuracy: 0.9244\n",
      "Epoch [9848/10000], Validation Loss: 0.97623780, Validation Accuracy: 0.5735\n",
      "Epoch [9849/10000], Training Loss: 0.61464670, Training Accuracy: 0.9370\n",
      "Epoch [9849/10000], Validation Loss: 0.97791505, Validation Accuracy: 0.5735\n",
      "Epoch [9850/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9850/10000], Validation Loss: 0.97769231, Validation Accuracy: 0.5735\n",
      "Epoch [9851/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9851/10000], Validation Loss: 0.96340385, Validation Accuracy: 0.5882\n",
      "Epoch [9852/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9852/10000], Validation Loss: 0.96389633, Validation Accuracy: 0.5882\n",
      "Epoch [9853/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [9853/10000], Validation Loss: 0.96450981, Validation Accuracy: 0.5882\n",
      "Epoch [9854/10000], Training Loss: 0.59348011, Training Accuracy: 0.9580\n",
      "Epoch [9854/10000], Validation Loss: 0.96829426, Validation Accuracy: 0.5882\n",
      "Epoch [9855/10000], Training Loss: 0.61026841, Training Accuracy: 0.9412\n",
      "Epoch [9855/10000], Validation Loss: 0.97608960, Validation Accuracy: 0.5735\n",
      "Epoch [9856/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9856/10000], Validation Loss: 0.97758481, Validation Accuracy: 0.5735\n",
      "Epoch [9857/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9857/10000], Validation Loss: 0.97920108, Validation Accuracy: 0.5735\n",
      "Epoch [9858/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9858/10000], Validation Loss: 0.98117402, Validation Accuracy: 0.5735\n",
      "Epoch [9859/10000], Training Loss: 0.59766367, Training Accuracy: 0.9538\n",
      "Epoch [9859/10000], Validation Loss: 0.99134362, Validation Accuracy: 0.5588\n",
      "Epoch [9860/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9860/10000], Validation Loss: 0.99239254, Validation Accuracy: 0.5588\n",
      "Epoch [9861/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9861/10000], Validation Loss: 0.99239486, Validation Accuracy: 0.5588\n",
      "Epoch [9862/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9862/10000], Validation Loss: 0.99239600, Validation Accuracy: 0.5588\n",
      "Epoch [9863/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9863/10000], Validation Loss: 0.99239647, Validation Accuracy: 0.5588\n",
      "Epoch [9864/10000], Training Loss: 0.62287349, Training Accuracy: 0.9286\n",
      "Epoch [9864/10000], Validation Loss: 0.99239421, Validation Accuracy: 0.5588\n",
      "Epoch [9865/10000], Training Loss: 0.61103348, Training Accuracy: 0.9412\n",
      "Epoch [9865/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9866/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9866/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9867/10000], Training Loss: 0.61027300, Training Accuracy: 0.9412\n",
      "Epoch [9867/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9868/10000], Training Loss: 0.62287350, Training Accuracy: 0.9286\n",
      "Epoch [9868/10000], Validation Loss: 0.97789773, Validation Accuracy: 0.5735\n",
      "Epoch [9869/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9869/10000], Validation Loss: 0.96348149, Validation Accuracy: 0.5882\n",
      "Epoch [9870/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9870/10000], Validation Loss: 0.94850546, Validation Accuracy: 0.6029\n",
      "Epoch [9871/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9871/10000], Validation Loss: 0.94850391, Validation Accuracy: 0.6029\n",
      "Epoch [9872/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9872/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [9873/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9873/10000], Validation Loss: 0.94850379, Validation Accuracy: 0.6029\n",
      "Epoch [9874/10000], Training Loss: 0.61643756, Training Accuracy: 0.9328\n",
      "Epoch [9874/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9875/10000], Training Loss: 0.62287342, Training Accuracy: 0.9286\n",
      "Epoch [9875/10000], Validation Loss: 0.96320972, Validation Accuracy: 0.5882\n",
      "Epoch [9876/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [9876/10000], Validation Loss: 1.00655732, Validation Accuracy: 0.5441\n",
      "Epoch [9877/10000], Training Loss: 0.60186734, Training Accuracy: 0.9496\n",
      "Epoch [9877/10000], Validation Loss: 1.00732473, Validation Accuracy: 0.5441\n",
      "Epoch [9878/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9878/10000], Validation Loss: 1.00732708, Validation Accuracy: 0.5441\n",
      "Epoch [9879/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9879/10000], Validation Loss: 1.00732720, Validation Accuracy: 0.5441\n",
      "Epoch [9880/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9880/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9881/10000], Training Loss: 0.59766419, Training Accuracy: 0.9538\n",
      "Epoch [9881/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9882/10000], Training Loss: 0.63127685, Training Accuracy: 0.9202\n",
      "Epoch [9882/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9883/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9883/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9884/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9884/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9885/10000], Training Loss: 0.61512637, Training Accuracy: 0.9370\n",
      "Epoch [9885/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9886/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9886/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9887/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9887/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9888/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9888/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9889/10000], Training Loss: 0.62287354, Training Accuracy: 0.9286\n",
      "Epoch [9889/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9890/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9890/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9891/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9891/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9892/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9892/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9893/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [9893/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9894/10000], Training Loss: 0.60620677, Training Accuracy: 0.9454\n",
      "Epoch [9894/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9895/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9895/10000], Validation Loss: 0.99262244, Validation Accuracy: 0.5588\n",
      "Epoch [9896/10000], Training Loss: 0.60927639, Training Accuracy: 0.9412\n",
      "Epoch [9896/10000], Validation Loss: 0.96320960, Validation Accuracy: 0.5882\n",
      "Epoch [9897/10000], Training Loss: 0.60239416, Training Accuracy: 0.9496\n",
      "Epoch [9897/10000], Validation Loss: 0.97791556, Validation Accuracy: 0.5735\n",
      "Epoch [9898/10000], Training Loss: 0.58505841, Training Accuracy: 0.9664\n",
      "Epoch [9898/10000], Validation Loss: 0.99219680, Validation Accuracy: 0.5588\n",
      "Epoch [9899/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9899/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9900/10000], Training Loss: 0.61867174, Training Accuracy: 0.9328\n",
      "Epoch [9900/10000], Validation Loss: 0.99262106, Validation Accuracy: 0.5588\n",
      "Epoch [9901/10000], Training Loss: 0.61026167, Training Accuracy: 0.9412\n",
      "Epoch [9901/10000], Validation Loss: 0.99261463, Validation Accuracy: 0.5588\n",
      "Epoch [9902/10000], Training Loss: 0.60783511, Training Accuracy: 0.9412\n",
      "Epoch [9902/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9903/10000], Training Loss: 0.59766344, Training Accuracy: 0.9538\n",
      "Epoch [9903/10000], Validation Loss: 1.02203313, Validation Accuracy: 0.5294\n",
      "Epoch [9904/10000], Training Loss: 0.59766343, Training Accuracy: 0.9538\n",
      "Epoch [9904/10000], Validation Loss: 1.00733560, Validation Accuracy: 0.5441\n",
      "Epoch [9905/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9905/10000], Validation Loss: 1.00732726, Validation Accuracy: 0.5441\n",
      "Epoch [9906/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9906/10000], Validation Loss: 1.00732714, Validation Accuracy: 0.5441\n",
      "Epoch [9907/10000], Training Loss: 0.61548391, Training Accuracy: 0.9370\n",
      "Epoch [9907/10000], Validation Loss: 0.99535397, Validation Accuracy: 0.5588\n",
      "Epoch [9908/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9908/10000], Validation Loss: 0.97791544, Validation Accuracy: 0.5735\n",
      "Epoch [9909/10000], Training Loss: 0.61012151, Training Accuracy: 0.9412\n",
      "Epoch [9909/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9910/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9910/10000], Validation Loss: 0.96320990, Validation Accuracy: 0.5882\n",
      "Epoch [9911/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [9911/10000], Validation Loss: 0.96328822, Validation Accuracy: 0.5882\n",
      "Epoch [9912/10000], Training Loss: 0.62287714, Training Accuracy: 0.9286\n",
      "Epoch [9912/10000], Validation Loss: 0.96371809, Validation Accuracy: 0.5882\n",
      "Epoch [9913/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9913/10000], Validation Loss: 0.96399745, Validation Accuracy: 0.5882\n",
      "Epoch [9914/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9914/10000], Validation Loss: 0.96417904, Validation Accuracy: 0.5882\n",
      "Epoch [9915/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9915/10000], Validation Loss: 0.96427935, Validation Accuracy: 0.5882\n",
      "Epoch [9916/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9916/10000], Validation Loss: 0.96433109, Validation Accuracy: 0.5882\n",
      "Epoch [9917/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9917/10000], Validation Loss: 0.96435672, Validation Accuracy: 0.5882\n",
      "Epoch [9918/10000], Training Loss: 0.61026851, Training Accuracy: 0.9412\n",
      "Epoch [9918/10000], Validation Loss: 0.96436194, Validation Accuracy: 0.5882\n",
      "Epoch [9919/10000], Training Loss: 0.62783921, Training Accuracy: 0.9244\n",
      "Epoch [9919/10000], Validation Loss: 0.93379787, Validation Accuracy: 0.6176\n",
      "Epoch [9920/10000], Training Loss: 0.62707521, Training Accuracy: 0.9244\n",
      "Epoch [9920/10000], Validation Loss: 0.93379784, Validation Accuracy: 0.6176\n",
      "Epoch [9921/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9921/10000], Validation Loss: 0.91909200, Validation Accuracy: 0.6324\n",
      "Epoch [9922/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9922/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [9923/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9923/10000], Validation Loss: 0.90672338, Validation Accuracy: 0.6471\n",
      "Epoch [9924/10000], Training Loss: 0.61867183, Training Accuracy: 0.9328\n",
      "Epoch [9924/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9925/10000], Training Loss: 0.59346177, Training Accuracy: 0.9580\n",
      "Epoch [9925/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9926/10000], Training Loss: 0.61447018, Training Accuracy: 0.9370\n",
      "Epoch [9926/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9927/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9927/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9928/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9928/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9929/10000], Training Loss: 0.62714263, Training Accuracy: 0.9244\n",
      "Epoch [9929/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9930/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [9930/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9931/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9931/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9932/10000], Training Loss: 0.60186513, Training Accuracy: 0.9496\n",
      "Epoch [9932/10000], Validation Loss: 0.91909197, Validation Accuracy: 0.6324\n",
      "Epoch [9933/10000], Training Loss: 0.61043070, Training Accuracy: 0.9412\n",
      "Epoch [9933/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [9934/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9934/10000], Validation Loss: 0.90438610, Validation Accuracy: 0.6471\n",
      "Epoch [9935/10000], Training Loss: 0.60606680, Training Accuracy: 0.9454\n",
      "Epoch [9935/10000], Validation Loss: 0.90438613, Validation Accuracy: 0.6471\n",
      "Epoch [9936/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9936/10000], Validation Loss: 0.90438709, Validation Accuracy: 0.6471\n",
      "Epoch [9937/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9937/10000], Validation Loss: 0.88968468, Validation Accuracy: 0.6618\n",
      "Epoch [9938/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9938/10000], Validation Loss: 0.88968945, Validation Accuracy: 0.6618\n",
      "Epoch [9939/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9939/10000], Validation Loss: 0.88969332, Validation Accuracy: 0.6618\n",
      "Epoch [9940/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9940/10000], Validation Loss: 0.88969573, Validation Accuracy: 0.6618\n",
      "Epoch [9941/10000], Training Loss: 0.60606790, Training Accuracy: 0.9454\n",
      "Epoch [9941/10000], Validation Loss: 0.88969877, Validation Accuracy: 0.6618\n",
      "Epoch [9942/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9942/10000], Validation Loss: 0.88970438, Validation Accuracy: 0.6618\n",
      "Epoch [9943/10000], Training Loss: 0.61026850, Training Accuracy: 0.9412\n",
      "Epoch [9943/10000], Validation Loss: 0.88970760, Validation Accuracy: 0.6618\n",
      "Epoch [9944/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9944/10000], Validation Loss: 0.88970929, Validation Accuracy: 0.6618\n",
      "Epoch [9945/10000], Training Loss: 0.60186512, Training Accuracy: 0.9496\n",
      "Epoch [9945/10000], Validation Loss: 0.88971016, Validation Accuracy: 0.6618\n",
      "Epoch [9946/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [9946/10000], Validation Loss: 0.88971058, Validation Accuracy: 0.6618\n",
      "Epoch [9947/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9947/10000], Validation Loss: 0.88971072, Validation Accuracy: 0.6618\n",
      "Epoch [9948/10000], Training Loss: 0.60186515, Training Accuracy: 0.9496\n",
      "Epoch [9948/10000], Validation Loss: 0.88971072, Validation Accuracy: 0.6618\n",
      "Epoch [9949/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9949/10000], Validation Loss: 0.88971072, Validation Accuracy: 0.6618\n",
      "Epoch [9950/10000], Training Loss: 0.63127723, Training Accuracy: 0.9202\n",
      "Epoch [9950/10000], Validation Loss: 0.88971034, Validation Accuracy: 0.6618\n",
      "Epoch [9951/10000], Training Loss: 0.62656015, Training Accuracy: 0.9244\n",
      "Epoch [9951/10000], Validation Loss: 0.94842178, Validation Accuracy: 0.6029\n",
      "Epoch [9952/10000], Training Loss: 0.60606681, Training Accuracy: 0.9454\n",
      "Epoch [9952/10000], Validation Loss: 0.97790444, Validation Accuracy: 0.5735\n",
      "Epoch [9953/10000], Training Loss: 0.63547857, Training Accuracy: 0.9160\n",
      "Epoch [9953/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9954/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [9954/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9955/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9955/10000], Validation Loss: 0.99262446, Validation Accuracy: 0.5588\n",
      "Epoch [9956/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9956/10000], Validation Loss: 1.01766670, Validation Accuracy: 0.5294\n",
      "Epoch [9957/10000], Training Loss: 0.63166440, Training Accuracy: 0.9202\n",
      "Epoch [9957/10000], Validation Loss: 1.01769859, Validation Accuracy: 0.5294\n",
      "Epoch [9958/10000], Training Loss: 0.61026152, Training Accuracy: 0.9412\n",
      "Epoch [9958/10000], Validation Loss: 1.01160908, Validation Accuracy: 0.5441\n",
      "Epoch [9959/10000], Training Loss: 0.62287382, Training Accuracy: 0.9286\n",
      "Epoch [9959/10000], Validation Loss: 1.00909513, Validation Accuracy: 0.5441\n",
      "Epoch [9960/10000], Training Loss: 0.62707520, Training Accuracy: 0.9244\n",
      "Epoch [9960/10000], Validation Loss: 1.00845453, Validation Accuracy: 0.5441\n",
      "Epoch [9961/10000], Training Loss: 0.63127689, Training Accuracy: 0.9202\n",
      "Epoch [9961/10000], Validation Loss: 1.00823054, Validation Accuracy: 0.5441\n",
      "Epoch [9962/10000], Training Loss: 0.62707600, Training Accuracy: 0.9244\n",
      "Epoch [9962/10000], Validation Loss: 1.00818318, Validation Accuracy: 0.5441\n",
      "Epoch [9963/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [9963/10000], Validation Loss: 1.00824225, Validation Accuracy: 0.5441\n",
      "Epoch [9964/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9964/10000], Validation Loss: 1.00827199, Validation Accuracy: 0.5441\n",
      "Epoch [9965/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9965/10000], Validation Loss: 1.00828657, Validation Accuracy: 0.5441\n",
      "Epoch [9966/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9966/10000], Validation Loss: 1.00829494, Validation Accuracy: 0.5441\n",
      "Epoch [9967/10000], Training Loss: 0.63127685, Training Accuracy: 0.9202\n",
      "Epoch [9967/10000], Validation Loss: 1.00830311, Validation Accuracy: 0.5441\n",
      "Epoch [9968/10000], Training Loss: 0.63127393, Training Accuracy: 0.9202\n",
      "Epoch [9968/10000], Validation Loss: 1.00818491, Validation Accuracy: 0.5441\n",
      "Epoch [9969/10000], Training Loss: 0.63547581, Training Accuracy: 0.9160\n",
      "Epoch [9969/10000], Validation Loss: 1.00796646, Validation Accuracy: 0.5441\n",
      "Epoch [9970/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9970/10000], Validation Loss: 1.00790590, Validation Accuracy: 0.5441\n",
      "Epoch [9971/10000], Training Loss: 0.62283193, Training Accuracy: 0.9286\n",
      "Epoch [9971/10000], Validation Loss: 1.00828454, Validation Accuracy: 0.5441\n",
      "Epoch [9972/10000], Training Loss: 0.61026848, Training Accuracy: 0.9412\n",
      "Epoch [9972/10000], Validation Loss: 1.00928921, Validation Accuracy: 0.5441\n",
      "Epoch [9973/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9973/10000], Validation Loss: 1.01003790, Validation Accuracy: 0.5441\n",
      "Epoch [9974/10000], Training Loss: 0.61867386, Training Accuracy: 0.9328\n",
      "Epoch [9974/10000], Validation Loss: 1.01072472, Validation Accuracy: 0.5441\n",
      "Epoch [9975/10000], Training Loss: 0.62287352, Training Accuracy: 0.9286\n",
      "Epoch [9975/10000], Validation Loss: 1.01240176, Validation Accuracy: 0.5441\n",
      "Epoch [9976/10000], Training Loss: 0.63126780, Training Accuracy: 0.9202\n",
      "Epoch [9976/10000], Validation Loss: 1.02173418, Validation Accuracy: 0.5294\n",
      "Epoch [9977/10000], Training Loss: 0.65704250, Training Accuracy: 0.8950\n",
      "Epoch [9977/10000], Validation Loss: 1.06596559, Validation Accuracy: 0.4853\n",
      "Epoch [9978/10000], Training Loss: 0.65075713, Training Accuracy: 0.8992\n",
      "Epoch [9978/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9979/10000], Training Loss: 0.64808370, Training Accuracy: 0.9034\n",
      "Epoch [9979/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9980/10000], Training Loss: 0.64388192, Training Accuracy: 0.9076\n",
      "Epoch [9980/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9981/10000], Training Loss: 0.64808361, Training Accuracy: 0.9034\n",
      "Epoch [9981/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9982/10000], Training Loss: 0.63968033, Training Accuracy: 0.9118\n",
      "Epoch [9982/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9983/10000], Training Loss: 0.66489034, Training Accuracy: 0.8866\n",
      "Epoch [9983/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9984/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [9984/10000], Validation Loss: 1.06615078, Validation Accuracy: 0.4853\n",
      "Epoch [9985/10000], Training Loss: 0.62968431, Training Accuracy: 0.9202\n",
      "Epoch [9985/10000], Validation Loss: 1.02973610, Validation Accuracy: 0.5147\n",
      "Epoch [9986/10000], Training Loss: 0.60607305, Training Accuracy: 0.9454\n",
      "Epoch [9986/10000], Validation Loss: 1.00171956, Validation Accuracy: 0.5441\n",
      "Epoch [9987/10000], Training Loss: 0.61867186, Training Accuracy: 0.9328\n",
      "Epoch [9987/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9988/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9988/10000], Validation Loss: 0.94850376, Validation Accuracy: 0.6029\n",
      "Epoch [9989/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [9989/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9990/10000], Training Loss: 0.63127690, Training Accuracy: 0.9202\n",
      "Epoch [9990/10000], Validation Loss: 0.96320963, Validation Accuracy: 0.5882\n",
      "Epoch [9991/10000], Training Loss: 0.61447017, Training Accuracy: 0.9370\n",
      "Epoch [9991/10000], Validation Loss: 0.96320984, Validation Accuracy: 0.5882\n",
      "Epoch [9992/10000], Training Loss: 0.60545198, Training Accuracy: 0.9454\n",
      "Epoch [9992/10000], Validation Loss: 0.99252173, Validation Accuracy: 0.5588\n",
      "Epoch [9993/10000], Training Loss: 0.61026849, Training Accuracy: 0.9412\n",
      "Epoch [9993/10000], Validation Loss: 0.99262136, Validation Accuracy: 0.5588\n",
      "Epoch [9994/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9994/10000], Validation Loss: 0.98335457, Validation Accuracy: 0.5735\n",
      "Epoch [9995/10000], Training Loss: 0.63127679, Training Accuracy: 0.9202\n",
      "Epoch [9995/10000], Validation Loss: 0.97791553, Validation Accuracy: 0.5735\n",
      "Epoch [9996/10000], Training Loss: 0.63968025, Training Accuracy: 0.9118\n",
      "Epoch [9996/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9997/10000], Training Loss: 0.62287353, Training Accuracy: 0.9286\n",
      "Epoch [9997/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9998/10000], Training Loss: 0.61867184, Training Accuracy: 0.9328\n",
      "Epoch [9998/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [9999/10000], Training Loss: 0.61867185, Training Accuracy: 0.9328\n",
      "Epoch [9999/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n",
      "Epoch [10000/10000], Training Loss: 0.62287065, Training Accuracy: 0.9286\n",
      "Epoch [10000/10000], Validation Loss: 0.97791550, Validation Accuracy: 0.5735\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chatgpt 3.5 generated code\n",
    "# Training loop\n",
    "BERT_total_epochs = number_of_epochs\n",
    "# BERT_total_epochs = BERT_number_of_epochs\n",
    "\n",
    "# Lists to store training/validation losses and training/validation accuracies\n",
    "BERT_train_losses = []  \n",
    "BERT_val_losses = []    \n",
    "BERT_train_accuracies = []  \n",
    "BERT_val_accuracies = []    \n",
    "\n",
    "for epoch in range(BERT_total_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for inputs, one_hot_labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, torch.argmax(one_hot_labels, dim=1))\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the total training loss for this epoch\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == torch.argmax(one_hot_labels, dim=1)).sum().item()\n",
    "        total_train += one_hot_labels.size(0)\n",
    "    \n",
    "    # Calculate average training loss and accuracy for this epoch\n",
    "    average_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    # Store training loss and accuracy values\n",
    "    BERT_train_losses.append(average_train_loss)\n",
    "    BERT_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Print the training loss and accuracy for this epoch\n",
    "    print(f'Epoch [{epoch+1}/{BERT_total_epochs}], Training Loss: {average_train_loss:.8f}, Training Accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, one_hot_labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            one_hot_labels = one_hot_labels.to(device)\n",
    "            \n",
    "            # Forward pass (validation)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.argmax(one_hot_labels, dim=1))\n",
    "            \n",
    "            # Update the total validation loss for this epoch\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Calculate validation accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == torch.argmax(one_hot_labels, dim=1)).sum().item()\n",
    "            total_val += one_hot_labels.size(0)\n",
    "    \n",
    "    # Calculate average validation loss and accuracy for this epoch\n",
    "    average_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    \n",
    "    # Store validation loss and accuracy values\n",
    "    BERT_val_losses.append(average_val_loss)\n",
    "    BERT_val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print the validation loss and accuracy for this epoch\n",
    "    print(f'Epoch [{epoch+1}/{BERT_total_epochs}], Validation Loss: {average_val_loss:.8f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Plot the losses and accuracies at the end of all epochs\n",
    "BERT_x_epochs = list(range(1, BERT_total_epochs + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(BERT_x_epochs, BERT_train_losses, label='BERT Training Loss')\n",
    "plt.plot(BERT_x_epochs, BERT_val_losses, label='BERT Validation Loss')\n",
    "plt.xlabel('BERT Epochs')\n",
    "plt.ylabel('BERT Loss')\n",
    "plt.title('BERT Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(BERT_x_epochs, BERT_train_accuracies, label='BERT Training Accuracy')\n",
    "plt.plot(BERT_x_epochs, BERT_val_accuracies, label='BERT Validation Accuracy')\n",
    "plt.xlabel('BERT Epochs')\n",
    "plt.ylabel('BERT Accuracy')\n",
    "plt.title('BERT Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4118\n"
     ]
    }
   ],
   "source": [
    "# chatgpt 3.5 generated code\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, one_hot_labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, labels = torch.max(one_hot_labels, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis BERT\n",
    "Execution time for 10000 epochs on RTX 3090: 3m 57.4s and test accuracy of 0.4118 at 10000 epochs.\n",
    "\n",
    "Training and validation losses are all over the map, which isn't surprising given the cheap and dirty implementation given to BERT here. The test accuracy of 0.4418 pretty much sums it up. BERT is going to require more research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
